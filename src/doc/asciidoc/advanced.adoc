== Advanced features

=== Template tests

_selenium_jupiter_ takes advantage on the standard feature of JUnit 5 called http://junit.org/junit5/docs/current/user-guide/#writing-tests-test-templates[test templates]. Test templates can be seen as an special kind of parameterized tests, in which the test is executed several times according to the data provided by some extension. In our case, the extension is _selenium_jupiter_ itself, and the test template is configured using a custom file in JSON called *browsers scenario*. 

Let's see some examples. Consider the following test. A couple of things are new in this test. First of all, instead of declaring the method with the usual `@Test` annotation, we are using the JUnit 5's annotation `@TestTemplate`. With this we are saying to JUnit that this method is not a regular test case but a template. Second, the parameter type of the method `templateTest` is `WebDriver`. This is the generic interface of Selenium WebDriver, and the concise type (i.e. `ChromeDriver`, `FirefoxDriver`, `RemoteWebDriver`, etc.) will be determined by _selenium_jupiter_ in runtime.

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/template/TemplateTest.java[tags=snippet-in-doc,indent=0]
----

The last piece we need in this test template is what we call _browser scenario_. As introduced before, this scenario is defined in a JSOn file following a simple notation. 

The path of the JSON browser scenario is established in the configuration key called `sel.jup.browser.template.json.file`. By default, this key has the value `classpath:browsers.json`. This means that the JSON scenario is defined in a file called `browsers.json` located in the classpath (see section link:#configuration[Configuration] for further details about configuration).

NOTE: If the configuration key `sel.jup.browser.template.json.file` do not start with the word `classpath:`, the file will be searched using relative of absolute paths. 

Now imagine that the content of the file `browsers.json` is as follows:

[source,json]
----
include::../../test/resources/browsers.json[indent=0]
----

When we execute the template test, in this case we will have three actual tests: the first using the _latest_ version of Chrome, the second using the previous to stable version of Chrome (`latest-1`), and third using two versions older than the current stable (`latest-2`). For instance, if we run the test in Eclipse, we will get the following output:

[.thumb]
.Example of test template execution (with one parameter) with Eclipse
image::test-template-01.png[scaledwidth=100%]

Generally speaking, a browser within the JSON scenario is defined using two parameters:

- `type`: Type of browsers. The accepted values are:
   * `chrome`: For local Chrome browsers.
   * `firefox`: For local Firefox browsers.
   * `edge`: For local Edge browsers.
   * `opera`: For local Opera browsers.
   * `safari`: For local Safari browsers.
   * `appium`: For local mobile emulated devices.
   * `phantomjs`: For local PhtanomJS headless browsers.
   * `chrome-in-docker`: For Chrome browsers in Docker.
   * `firefox-in-docker`: For Firefox browsers in Docker.
   * `opera-in-docker`: For Opera browsers in Docker.
- `version`: Optional value for the version. Wildcard for latest versions (`latest`, `latest-1`, etc) are accepted. Concrete versions are also valid (e.g. `63.0`, `57.0`, etc., depending of the browser).
 
Finally, more than one parameters can be defined in the test template. For instance, consider the following test in which a couple of `WebDriver` parameters are declared in the test template.

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/template/TemplateTwoBrowsersTest.java[tags=snippet-in-doc,indent=0]
----

The JSON scenario should be defined accordingly. Each browser array in this case (for each test template execution) should declare two browsers. For instance, using the following JSON scenario, the first execution will be based on Chrome in Docker (first parameter) and Firefox in Docker (second parameter); and the second exection will be based on the headless browser PhantomJS (first parameter) and Opera in Docker (second paramter).

[source,json]
----
include::../../test/resources/browsers-two.json[indent=0]
----

If we execute this test using in GUI, the JUnit tab shows two tests executed with the values defined in the JSON scenario.

[.thumb]
.Example of test template execution (with two parameters) with Eclipse
image::test-template-02.png[scaledwidth=100%]


=== Using options

So far, we have discovered how to use different local browsers (Chrome, Firefox, Edge, Opera, Safari, PhamtomJS, HtmlUnit) of Docker browsers (Chrome, Firefox, Opera) with its default options and supposing that the browser to be used is installed on the machine running the test. Nevertheless, if you have used intensively Selenium WebDriver, different questions might come to your mind:

* What if I need to specify options (e.g. `ChromeOptions`, `FirefoxOptions`, etc) to my WebDriver object?
* What if need to specify desired capabilities (e.g. browser type, version, platform)?
* And what about remote browsers (http://www.seleniumhq.org/projects/grid/[Selenium Grid])? How is `RemoteWebDriver` supported by _selenium-jupiter_?

In order to support the advance features of Selenium WebDriver, _selenium-jupiter_ provides several annotations aimed to allow a fine-grained control of the WebDriver object instantiation. These annotations are:

* `Arguments` (_parameter-level_) : Used to add arguments to the options.
* `Preferences` (_parameter-level_) : Used to set preferences to the options.
* `Binary` (_parameter-level_) : Used to set the location of the browser binary.
* `Extensions` (_parameter-level_) : User to add extensions to the browser.
 * `Options` (_field-level_): Annotation to configure _options_ (e.g. `ChromeOptions` for Chrome, `FirefoOptions` for Firefox, `EdgeOptions` for Edge, `OperaOptions` for Opera, and `SafariOptions` for Safari). 
* `DriverCapabilities` (_parameter-level_ or _field-level_): Annotation to configure the desired _capabilities_ (WebDriver's object `DesiredCapabilities`).
* `DriverUrl` (_parameter-level_ or _field-level_): Annotation used to identify the URL value needed to instantiate a `RemoteWebDriver` object.

The annotations marked as _parameter-level_ are applied to a single WebDriver parameter. The annotations marked as _field-level_ are applied globally in a test class. Keep reading to find out several examples about that.

The following https://github.com/bonigarcia/selenium-jupiter/blob/master/src/test/java/io/github/bonigarcia/test/advance/ChromeWithOptionsJupiterTest.java[example] shows how to specify options for Chrome. In the first test (called `headlessTest`), we are setting the argument `--headless`, used in Chrome to work as a headless browser. In the second test (`webrtcTest`), we are using two different arguments: `--use-fake-device-for-media-stream` and `--use-fake-ui-for-media-stream`, used to fake user media (i.e. camera and microphone) in https://webrtc.org/[WebRTC] applications. In the third test (`extensionTest`), we are adding an extension to Chrome using the `@Extensions` annotation. The value of this field is an extension file that will be searched: i) using value as its relative/absolute path; ii) using value as a file name in the project classpath.

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/ChromeWithOptionsJupiterTest.java[tags=snippet-in-doc,indent=0]
----

As introduced before, this annotation `@Options` can be used also at _field-level_, as shown in this other https://github.com/bonigarcia/selenium-jupiter/blob/master/src/test/java/io/github/bonigarcia/test/advance/FirefoxWithGlobalOptionsJupiterTest.java[example]. This test is setting to `true` the Firefox preferences `media.navigator.streams.fake` and `media.navigator.permission.disabled`, used also for WebRTC.

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/FirefoxWithGlobalOptionsJupiterTest.java[tags=snippet-in-doc,indent=0]
----

=== Using capabilities

The annotation `@DriverCapabilities` is used to specify WebDriver capabilities (i.e. type browser, version, platform, etc.). These capabilities are typically used for Selenium Grid tets (i.e. tests using remote browsers). To that aim, an Selenium Hub (also known as _Selenium Server_) should be up an running, and its URL should known. This URL will be specified using the _selenium-jupiter_ annotation `@DriverUrl`. 

The following example provides a complete https://github.com/bonigarcia/selenium-jupiter/blob/master/src/test/java/io/github/bonigarcia/test/advance/RemoteWebDriverJupiterTest.java[example] about this. As you can see, in the test setup (`@BeforeAll`) a Selenium Grid is implemented, first starting a Hub (a.k.a. _Selenium Server_), and then a couple of nodes (Chrome a Firefox) are registered in the Hub. Therefore, remote test using `RemoteWebDriver` can be executed, simply pointing to the Hub (whose URL in this case is `http://localhost:4444/wd/hub` in this example) and selecting the browser to be used using the `Capabilities`.

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/RemoteWebDriverJupiterTest.java[tags=snippet-in-doc,indent=0]
----

The following class contains an example which uses Chrome as browser and capabilities defined using `@DriverCapabilities`. Concretely, this example uses the mobile emulation feature provided out of the box by Chrome (i.e. render the web page using small screen resolutions to emulate smartphones).

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/ChromeWithGlobalCapabilitiesJupiterTest.java[tags=snippet-in-doc,indent=0]
----

=== AppiumDriver

The annotation `@DriverCapabilities` can be also used to specify the desired capabilities to create an instances of AppiumDriver to drive mobile devices (Android or iOS). If not `@DriverUrl` is specified, _selenium-jupiter_ will start automatically an instance of Appium Server (by default in port 4723) in the localhost after each test execution (this server is shutdown before each test). For example:

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/AppiumChromeJupiterTest.java[tags=snippet-in-doc,indent=0]
----

We can also specify a custom Appium Server URL changing the value of `@DriverUrl`, at field-level or parameter-level:

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/AppiumApkJupiterTest.java[tags=snippet-in-doc,indent=0]
----


=== Tuning WebDriverManager

As introduced before, _selenium-jupiter_ internally uses https://github.com/bonigarcia/webdrivermanager[WebDriverManager] to manage the required binary to control localc browsers. This tool can be configured in several ways, for example to force using a given version of the binary (by default it tries to use the latest version), or force to use the cache (instead of connecting to the online repository to download the binary artifact). For further information about this configuration capabilities, please take a look to the https://github.com/bonigarcia/webdrivermanager[WebDriverManager documentation].

In this section we are going to present a couple of simple examples tuning somehow WebDriverManger. The following example shows how to force a version number for a binary, concretely for Edge:

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/EdgeSettingVersionJupiterTest.java[tags=snippet-in-doc,indent=0]
----

This other example shows how to force cache (i.e. binaries previously downloaded by WebDriverManager) to avoid the connection with online repository to check the latest version: 

[source,java]
----
include::../../test/java/io/github/bonigarcia/test/advance/ForceCacheJupiterTest.java[tags=snippet-in-doc,indent=0]
----


=== Screenshots

_selenium-jupiter_ provides several built-in features for making *screenshots* for each of the browser sessions at the end of the test. These screenshots, can be encoded as *Base64* or stored as *PNG* images. The following configuration keys are used to control the way and format in which screenshots are made:

- `sel.jup.screenshot.at.the.end.of.tests`: This key indicates whether or not screenshots will be made at the end of every browser session. The accepted valued for this configuration key are:
   * `true` : Screenshots are always taken at the end of tests.
   * `false` : Screenshots are not taken at the end of tests.
   * `whenfailure` : Screenshots are only taken if the test fails.
- `sel.jup.screenshot.format`: Format for the screenshot. The accepted values for this key are two:
   * `base64` : Base64 screenshots are logged using the *debug* level of (https://www.slf4j.org/)[Simple Logging Facade for Java (SLF4J)]. You can copy&paste the resulting Base 64 string in the URL bar of any browser and watch the screenshot.
   * `png` : Screenshots are stored as PNG images. The output folder for these images is configured using the configuration key `sel.jup.output.folder` (the default value of this property is `.`, i.e. the local folder).
 
Take into account that a big `base64` string will be added to your logs if this option if configured. This feature can be especially useful for build server in the cloud (such as Travis CI), in which we don't have access to the server file system but can track easily the test output log. 

[source]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running io.github.bonigarcia.test.basic.ChromeJupiterTest
...
2017-12-13 02:41:53 [main] DEBUG i.g.bonigarcia.SeleniumExtension - Screenshot (in Base64) at the end of session 5712cce700bb76d8f5f5d65a00e2c7bc (copy&paste this string as URL in browser to watch it)
data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAykAAANaCAIAAAACvpRSAAAgAElEQVR4nOy9e3xV1Zn//1lr384t5+RyCDmBhJBwSRACBAqhXFQsYlGLZeygrWVGbalTtVU72gv9fgfnK3Yq36mdqTqOLTL1R8fyq2Wk3kCGSqEMlxKQiyQICZAAJySHnJyT5Nz2ZX3/ODGEk71DDuSCuN4vXrySnXX2WWfvtc767Od51vMQxhg4HA6Hw+FwOOkTDofTfQkdiH5wOBwOh8PhcEzh2ovD4XA4HA5n8ODai8PhcDgcDmfw4NqLw+FwOBwOZ/Dg2ovD4XA4HA5n8ODai8PhcDgcDmfw4NqLw+FwOBwOp5/5wx/+YPUnrr04HA6Hw+Fw+pOk8LKSX1x7cTgcDofD4fQb3SWXqfzi2o
...
nr2SgWY2TMdyRZMNENknWYTIo75WxuUWNCij9k178gCKO3BHLtkeQjiMYEgXy66/8f5nl+x57/98mYAvFysJUmckrGBLMv/dC0SlJSUjrXpwn3Ba6MgAlILbL+//8/5fAruDfRSl08WQBr2oDm4uNtmZOPKRm7GSgptWXBFJPrAAAAl0lEQVS4/biJEm74sxVmrvz///+U468MXDMRZc7zY5Aj1uDndWEG2gCWk+R5ARMgl5aZrga3N7XBT9vCbxrBWPjx/3/96tsQz8LL4foDPzSVlH4crofHwrFXxyDZx1xHaWN7EjwAiT/f69Gf/8G1O5SUDCBnj2EW8huvfnTLaFNSMsD043+89QUmwCz/yUhp9AFYT/DCDwBA0OZPpbBVqwAAAABJRU5ErkJggg==
Tests run: 2, Failures: 1, Errors: 0, Skipped: 1, Time elapsed: 7.219 sec <<< FAILURE! - in io.github.bonigarcia.test.basic.ChromeJupiterTest
testWithOneChrome(ChromeDriver)  Time elapsed: 6.594 sec  <<< FAILURE!
----


=== Integration with Jenkins

_selenium_jupiter_ provides seamless integration with Jenkins through one of its plugins: the https://wiki.jenkins.io/display/JENKINS/JUnit+Attachments+Plugin[Jenkins attachment plugin]. The idea is to provide the ability to attache output files (typically PNG screenshots and MP4 recordings of Docker browsers), and keep these files attached to the job execution. This is done in _selenium_jupiter_ setting the configuration key `sel.jup.output.folder` to an special value: `surefire-reports`.

When this configuration key is configured with that value, _selenium_jupiter_ will store the generated files in the proper folder, in a way that the Jenkins attachment plugin is able to find those files and export them in the Jenkins GUI. For instance, consider the following https://github.com/bonigarcia/selenium-jupiter/blob/master/src/test/java/io/github/bonigarcia/test/docker/DockerFirefoxWithOptionsJupiterTest.java[test], when is executed in Jenkins (with the attachment plugin) and the following configuration:

[source]
----
mvn clean test -Dtest=DockerFirefoxWithOptionsJupiterTest -Dsel.jup.recording=true -Dsel.jup.output.folder=surefire-reports -Dsel.jup.screenshot.at.the.end.of.tests=true
----

In this case, at the the execution of this test, two recordings in MP4 and two screenshots in PNG will be attached to the job as follows. 

[.thumb]
.Example of test execution through Jenkins with attachements
image::jenkins-attachements-test.png[scaledwidth=100%]

We can watch the recording simply clicking in the attached MP4 files.

[.thumb]
.Example of test execution through Jenkins with attachements
image::jenkins-attachements-test-mp4.png[scaledwidth=100%]

Test template are also compatible with this feature. For instance, the following test
https://github.com/bonigarcia/selenium-jupiter/blob/master/src/test/java/io/github/bonigarcia/test/template/TemplateTest.java[test], when is executed in Jenkins using the the following configuration:

[source]
----
mvn clean test -Dtest=TemplateTest -Dsel.jup.recording=true -Dsel.jup.output.folder=surefire-reports -Dsel.jup.screenshot.at.the.end.of.tests=true
----

... will result in the following attachements:

[.thumb]
.Example of template test execution through Jenkins with attachements
image::jenkins-attachements-template.png[scaledwidth=100%]

... and we can see the recording, for instace:

[.thumb]
.Example of template test execution through Jenkins with attachements
image::jenkins-attachements-template-mp4.png[scaledwidth=100%]
