<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>SemanticSearchServiceHelper.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">semantic-search</a> &gt; <a href="index.source.html" class="el_package">org.molgenis.semanticsearch.service.impl</a> &gt; <span class="el_source">SemanticSearchServiceHelper.java</span></div><h1>SemanticSearchServiceHelper.java</h1><pre class="source lang-java linenums">package org.molgenis.semanticsearch.service.impl;

import com.google.common.collect.Sets;
import org.apache.commons.lang3.StringUtils;
import org.apache.lucene.queryparser.classic.QueryParser;
import org.molgenis.data.DataService;
import org.molgenis.data.Entity;
import org.molgenis.data.MolgenisDataAccessException;
import org.molgenis.data.QueryRule;
import org.molgenis.data.QueryRule.Operator;
import org.molgenis.data.meta.model.AttributeMetadata;
import org.molgenis.data.meta.model.EntityType;
import org.molgenis.data.meta.model.EntityTypeMetadata;
import org.molgenis.data.support.QueryImpl;
import org.molgenis.ontology.core.ic.TermFrequencyService;
import org.molgenis.ontology.core.model.OntologyTerm;
import org.molgenis.ontology.core.service.OntologyService;
import org.molgenis.semanticsearch.string.NGramDistanceAlgorithm;
import org.molgenis.semanticsearch.string.Stemmer;

import java.util.*;
import java.util.stream.Collectors;

import static java.util.Arrays.stream;
import static java.util.Objects.requireNonNull;
import static org.molgenis.data.meta.AttributeType.COMPOUND;
import static org.molgenis.data.meta.model.EntityTypeMetadata.ENTITY_TYPE_META_DATA;

public class SemanticSearchServiceHelper
{
	private final TermFrequencyService termFrequencyService;

	private final DataService dataService;

	private final OntologyService ontologyService;

	public final static int MAX_NUM_TAGS = 3;

	private final static char SPACE_CHAR = ' ';
	private final static String COMMA_CHAR = &quot;,&quot;;
	private final static String CARET_CHARACTER = &quot;^&quot;;
	private final static String ESCAPED_CARET_CHARACTER = &quot;\\^&quot;;
	private final static String ILLEGAL_CHARS_REGEX = &quot;[^\\p{L}'a-zA-Z0-9\\.~]+&quot;;

	public SemanticSearchServiceHelper(DataService dataService, OntologyService ontologyService,
			TermFrequencyService termFrequencyService)
<span class="fc" id="L47">	{</span>
<span class="fc" id="L48">		this.dataService = requireNonNull(dataService);</span>
<span class="fc" id="L49">		this.ontologyService = requireNonNull(ontologyService);</span>
<span class="fc" id="L50">		this.termFrequencyService = requireNonNull(termFrequencyService);</span>
<span class="fc" id="L51">	}</span>

	/**
	 * Create a disMaxJunc query rule based on the given search terms as well as the information from given ontology
	 * terms
	 *
	 * @return disMaxJunc queryRule
	 */
	public QueryRule createDisMaxQueryRuleForAttribute(Set&lt;String&gt; searchTerms, Collection&lt;OntologyTerm&gt; ontologyTerms)
	{
<span class="fc" id="L61">		List&lt;String&gt; queryTerms = new ArrayList&lt;&gt;();</span>

<span class="pc bpc" id="L63" title="1 of 2 branches missed.">		if (searchTerms != null)</span>
		{
<span class="fc" id="L65">			queryTerms.addAll(searchTerms.stream()</span>
<span class="fc" id="L66">										 .filter(StringUtils::isNotBlank)</span>
<span class="fc" id="L67">										 .map(this::processQueryString)</span>
<span class="fc" id="L68">										 .collect(Collectors.toList()));</span>
		}

		// Handle tags with only one ontologyterm
<span class="fc" id="L72">		ontologyTerms.stream()</span>
<span class="pc bpc" id="L73" title="1 of 2 branches missed.">					 .filter(ontologyTerm -&gt; !ontologyTerm.getIRI().contains(COMMA_CHAR))</span>
<span class="fc" id="L74">					 .forEach(ot -&gt; queryTerms.addAll(parseOntologyTermQueries(ot)));</span>

<span class="fc" id="L76">		QueryRule disMaxQueryRule = createDisMaxQueryRuleForTerms(queryTerms);</span>

		// Handle tags with multiple ontologyterms
<span class="fc" id="L79">		ontologyTerms.stream()</span>
<span class="fc" id="L80">					 .filter(ontologyTerm -&gt; ontologyTerm.getIRI().contains(COMMA_CHAR))</span>
<span class="pc" id="L81">					 .forEach(ot -&gt; disMaxQueryRule.getNestedRules().add(createShouldQueryRule(ot.getIRI())));</span>

<span class="fc" id="L83">		return disMaxQueryRule;</span>
	}

	/**
	 * Create disMaxJunc query rule based a list of queryTerm. All queryTerms are lower cased and stop words are removed
	 *
	 * @return disMaxJunc queryRule
	 */
	public QueryRule createDisMaxQueryRuleForTerms(List&lt;String&gt; queryTerms)
	{
<span class="fc" id="L93">		List&lt;QueryRule&gt; rules = new ArrayList&lt;&gt;();</span>
<span class="fc" id="L94">		queryTerms.stream().filter(StringUtils::isNotEmpty).map(this::escapeCharsExcludingCaretChar).forEach(query -&gt;</span>
		{
<span class="fc" id="L96">			rules.add(new QueryRule(AttributeMetadata.LABEL, Operator.FUZZY_MATCH, query));</span>
<span class="fc" id="L97">			rules.add(new QueryRule(AttributeMetadata.DESCRIPTION, Operator.FUZZY_MATCH, query));</span>
<span class="fc" id="L98">		});</span>
<span class="fc" id="L99">		QueryRule finalDisMaxQuery = new QueryRule(rules);</span>
<span class="fc" id="L100">		finalDisMaxQuery.setOperator(Operator.DIS_MAX);</span>
<span class="fc" id="L101">		return finalDisMaxQuery;</span>
	}

	/**
	 * Create a disMaxQueryRule with corresponding boosted value
	 *
	 * @return a disMaxQueryRule with boosted value
	 */
	public QueryRule createBoostedDisMaxQueryRuleForTerms(List&lt;String&gt; queryTerms, Double boostValue)
	{
<span class="fc" id="L111">		QueryRule finalDisMaxQuery = createDisMaxQueryRuleForTerms(queryTerms);</span>
<span class="pc bpc" id="L112" title="2 of 4 branches missed.">		if (boostValue != null &amp;&amp; boostValue.intValue() != 0)</span>
		{
<span class="nc" id="L114">			finalDisMaxQuery.setValue(boostValue);</span>
		}
<span class="fc" id="L116">		return finalDisMaxQuery;</span>
	}

	/**
	 * Create a boolean should query for composite tags containing multiple ontology terms
	 *
	 * @return return a boolean should queryRule
	 */
	public QueryRule createShouldQueryRule(String multiOntologyTermIri)
	{
<span class="fc" id="L126">		QueryRule shouldQueryRule = new QueryRule(new ArrayList&lt;&gt;());</span>
<span class="fc" id="L127">		shouldQueryRule.setOperator(Operator.SHOULD);</span>
<span class="fc bfc" id="L128" title="All 2 branches covered.">		for (String ontologyTermIri : multiOntologyTermIri.split(COMMA_CHAR))</span>
		{
<span class="fc" id="L130">			OntologyTerm ontologyTerm = ontologyService.getOntologyTerm(ontologyTermIri);</span>
<span class="fc" id="L131">			List&lt;String&gt; queryTerms = parseOntologyTermQueries(ontologyTerm);</span>
<span class="fc" id="L132">			Double termFrequency = getBestInverseDocumentFrequency(queryTerms);</span>
<span class="fc" id="L133">			shouldQueryRule.getNestedRules().add(createBoostedDisMaxQueryRuleForTerms(queryTerms, termFrequency));</span>
		}
<span class="fc" id="L135">		return shouldQueryRule;</span>
	}

	/**
	 * Create a list of string queries based on the information collected from current ontologyterm including label,
	 * synonyms and child ontologyterms
	 */
	public List&lt;String&gt; parseOntologyTermQueries(OntologyTerm ontologyTerm)
	{
<span class="fc" id="L144">		List&lt;String&gt; queryTerms = getOtLabelAndSynonyms(ontologyTerm).stream()</span>
<span class="fc" id="L145">																	 .map(this::processQueryString)</span>
<span class="fc" id="L146">																	 .collect(Collectors.toList());</span>

<span class="fc bfc" id="L148" title="All 2 branches covered.">		for (OntologyTerm childOt : ontologyService.getChildren(ontologyTerm))</span>
		{
<span class="fc" id="L150">			double boostedNumber = Math.pow(0.5, ontologyService.getOntologyTermDistance(ontologyTerm, childOt));</span>
<span class="fc" id="L151">			getOtLabelAndSynonyms(childOt).forEach(</span>
<span class="fc" id="L152">					synonym -&gt; queryTerms.add(parseBoostQueryString(synonym, boostedNumber)));</span>
<span class="fc" id="L153">		}</span>
<span class="fc" id="L154">		return queryTerms;</span>
	}

	/**
	 * A helper function to collect synonyms as well as label of ontologyterm
	 *
	 * @return a list of synonyms plus label
	 */
	public Set&lt;String&gt; getOtLabelAndSynonyms(OntologyTerm ontologyTerm)
	{
<span class="fc" id="L164">		Set&lt;String&gt; allTerms = Sets.newLinkedHashSet(ontologyTerm.getSynonyms());</span>
<span class="fc" id="L165">		allTerms.add(ontologyTerm.getLabel());</span>
<span class="fc" id="L166">		return allTerms;</span>
	}

	public Map&lt;String, String&gt; collectExpandedQueryMap(Set&lt;String&gt; queryTerms, Collection&lt;OntologyTerm&gt; ontologyTerms)
	{
<span class="nc" id="L171">		Map&lt;String, String&gt; expandedQueryMap = new LinkedHashMap&lt;&gt;();</span>

<span class="nc" id="L173">		queryTerms.stream()</span>
<span class="nc" id="L174">				  .filter(StringUtils::isNotBlank)</span>
<span class="nc" id="L175">				  .forEach(queryTerm -&gt; expandedQueryMap.put(Stemmer.cleanStemPhrase(queryTerm), queryTerm));</span>

<span class="nc bnc" id="L177" title="All 2 branches missed.">		for (OntologyTerm ontologyTerm : ontologyTerms)</span>
		{
<span class="nc bnc" id="L179" title="All 2 branches missed.">			if (!ontologyTerm.getIRI().contains(COMMA_CHAR))</span>
			{
<span class="nc" id="L181">				collectOntologyTermQueryMap(expandedQueryMap, ontologyTerm);</span>
			}
			else
			{
<span class="nc bnc" id="L185" title="All 2 branches missed.">				for (String ontologyTermIri : ontologyTerm.getIRI().split(COMMA_CHAR))</span>
				{
<span class="nc" id="L187">					collectOntologyTermQueryMap(expandedQueryMap, ontologyService.getOntologyTerm(ontologyTermIri));</span>
				}
			}
<span class="nc" id="L190">		}</span>
<span class="nc" id="L191">		return expandedQueryMap;</span>
	}

	public void collectOntologyTermQueryMap(Map&lt;String, String&gt; expanedQueryMap, OntologyTerm ontologyTerm)
	{
<span class="nc bnc" id="L196" title="All 2 branches missed.">		if (ontologyTerm != null)</span>
		{
<span class="nc" id="L198">			getOtLabelAndSynonyms(ontologyTerm).forEach(</span>
<span class="nc" id="L199">					term -&gt; expanedQueryMap.put(Stemmer.cleanStemPhrase(term), ontologyTerm.getLabel()));</span>

<span class="nc bnc" id="L201" title="All 2 branches missed.">			for (OntologyTerm childOntologyTerm : ontologyService.getChildren(ontologyTerm))</span>
			{
<span class="nc" id="L203">				getOtLabelAndSynonyms(childOntologyTerm).forEach(</span>
<span class="nc" id="L204">						term -&gt; expanedQueryMap.put(Stemmer.cleanStemPhrase(term), ontologyTerm.getLabel()));</span>
<span class="nc" id="L205">			}</span>
		}
<span class="nc" id="L207">	}</span>

	/**
	 * A helper function that gets identifiers of all the attributes from one EntityType
	 */
	public List&lt;String&gt; getAttributeIdentifiers(EntityType sourceEntityType)
	{
<span class="fc" id="L214">		Entity EntityTypeEntity = dataService.findOne(ENTITY_TYPE_META_DATA,</span>
<span class="fc" id="L215">				new QueryImpl&lt;&gt;().eq(EntityTypeMetadata.ID, sourceEntityType.getId()));</span>

<span class="pc bpc" id="L217" title="1 of 2 branches missed.">		if (EntityTypeEntity == null) throw new MolgenisDataAccessException(</span>
<span class="nc" id="L218">				&quot;Could not find EntityTypeEntity by the name of &quot; + sourceEntityType.getId());</span>

<span class="fc" id="L220">		List&lt;String&gt; attributeIdentifiers = new ArrayList&lt;&gt;();</span>

<span class="fc" id="L222">		recursivelyCollectAttributeIdentifiers(EntityTypeEntity.getEntities(EntityTypeMetadata.ATTRIBUTES),</span>
				attributeIdentifiers);

<span class="fc" id="L225">		return attributeIdentifiers;</span>
	}

	private void recursivelyCollectAttributeIdentifiers(Iterable&lt;Entity&gt; attributeEntities,
			List&lt;String&gt; attributeIdentifiers)
	{
<span class="fc bfc" id="L231" title="All 2 branches covered.">		for (Entity attributeEntity : attributeEntities)</span>
		{
<span class="pc bpc" id="L233" title="1 of 2 branches missed.">			if (!attributeEntity.getString(AttributeMetadata.TYPE).equals(COMPOUND.toString()))</span>
			{
<span class="fc" id="L235">				attributeIdentifiers.add(attributeEntity.getString(AttributeMetadata.ID));</span>
			}
<span class="fc" id="L237">			Iterable&lt;Entity&gt; entities = attributeEntity.getEntities(AttributeMetadata.CHILDREN);</span>

<span class="pc bpc" id="L239" title="1 of 2 branches missed.">			if (entities != null)</span>
			{
<span class="fc" id="L241">				recursivelyCollectAttributeIdentifiers(entities, attributeIdentifiers);</span>
			}
<span class="fc" id="L243">		}</span>
<span class="fc" id="L244">	}</span>

	public List&lt;OntologyTerm&gt; findTags(String description, List&lt;String&gt; ontologyIds)
	{
<span class="fc" id="L248">		Set&lt;String&gt; searchTerms = removeStopWords(description);</span>

<span class="fc" id="L250">		List&lt;OntologyTerm&gt; matchingOntologyTerms = ontologyService.findOntologyTerms(ontologyIds, searchTerms,</span>
				MAX_NUM_TAGS);

<span class="fc" id="L253">		return matchingOntologyTerms;</span>
	}

	public String processQueryString(String queryString)
	{
<span class="fc" id="L258">		return StringUtils.join(removeStopWords(queryString), SPACE_CHAR);</span>
	}

	public String parseBoostQueryString(String queryString, double boost)
	{
<span class="fc" id="L263">		return StringUtils.join(removeStopWords(queryString).stream()</span>
<span class="fc" id="L264">															.map(word -&gt; word + CARET_CHARACTER + boost)</span>
<span class="fc" id="L265">															.collect(Collectors.toSet()), SPACE_CHAR);</span>
	}

	public String escapeCharsExcludingCaretChar(String string)
	{
<span class="fc" id="L270">		return QueryParser.escape(string).replace(ESCAPED_CARET_CHARACTER, CARET_CHARACTER);</span>
	}

	public Set&lt;String&gt; removeStopWords(String description)
	{
<span class="fc" id="L275">		Set&lt;String&gt; searchTerms = stream(description.split(ILLEGAL_CHARS_REGEX)).map(String::toLowerCase)</span>
<span class="fc" id="L276">																				.filter(w -&gt;</span>
<span class="fc" id="L277">																						!NGramDistanceAlgorithm.STOPWORDSLIST</span>
<span class="fc bfc" id="L278" title="All 2 branches covered.">																								.contains(w)</span>
<span class="fc bfc" id="L279" title="All 2 branches covered.">																								&amp;&amp; StringUtils.isNotEmpty(</span>
																								w))
<span class="fc" id="L281">																				.collect(Collectors.toSet());</span>
<span class="fc" id="L282">		return searchTerms;</span>
	}

	private Double getBestInverseDocumentFrequency(List&lt;String&gt; terms)
	{
<span class="fc" id="L287">		Optional&lt;String&gt; findFirst = terms.stream().sorted(Comparator.comparingInt(String::length)).findFirst();</span>

<span class="fc" id="L289">		return findFirst.map(termFrequencyService::getTermFrequency).orElse(null);</span>
	}
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.1.201803210924</span></div></body></html>