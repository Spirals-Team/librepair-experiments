[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Apache SAMOA
[INFO] samoa-instances
[INFO] samoa-api
[INFO] samoa-test
[INFO] samoa-local
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Apache SAMOA 0.5.0-incubating-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- license-maven-plugin:1.8:update-file-header (first) @ samoa ---
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-api
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-instances
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-local
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-storm
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-flink
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-apex
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-samza
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-test
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/samoa-threads
[INFO] Will search files to update from root /root/workspace/apache/incubator-samoa/232818360/bin
[INFO] Scan 393 files header done in 1.379s.
[INFO] All files are up-to-date.
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ samoa ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building samoa-instances 0.5.0-incubating-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- license-maven-plugin:1.8:update-file-header (first) @ samoa-instances ---
[WARNING] No file to scan.
[INFO] 
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ samoa-instances ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ samoa-instances ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-instances/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:compile (default-compile) @ samoa-instances ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ samoa-instances ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-instances/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:testCompile (default-testCompile) @ samoa-instances ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ samoa-instances ---
[INFO] Surefire report directory: /root/workspace/apache/incubator-samoa/232818360/samoa-instances/target/surefire-reports
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18.1/surefire-junit4-2.18.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18.1/surefire-junit4-2.18.1.pom (3 KB at 3.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.18.1/surefire-providers-2.18.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.18.1/surefire-providers-2.18.1.pom (3 KB at 57.8 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18.1/surefire-junit4-2.18.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18.1/surefire-junit4-2.18.1.jar (67 KB at 1053.9 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.samoa.instances.ArffLoaderTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 sec - in org.apache.samoa.instances.ArffLoaderTest

Results :

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building samoa-api 0.5.0-incubating-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- license-maven-plugin:1.8:update-file-header (first) @ samoa-api ---
[WARNING] No file to scan.
[INFO] 
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ samoa-api ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ samoa-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:compile (default-compile) @ samoa-api ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ samoa-api ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-api/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:testCompile (default-testCompile) @ samoa-api ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ samoa-api ---
[INFO] Surefire report directory: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.samoa.streams.fs.LocalFileStreamSourceTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.08 sec - in org.apache.samoa.streams.fs.LocalFileStreamSourceTest
Running org.apache.samoa.streams.fs.HDFSFileStreamSourceTest
2017-05-16 17:08:34,241 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(442)) - starting cluster: numNameNodes=1, numDataNodes=1
2017-05-16 17:08:34,750 WARN  [main] util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(62)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2017-05-16 17:08:34,875 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:34,896 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:34,932 INFO  [main] Configuration.deprecation (Configuration.java:warnOnceIfDeprecated(1049)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2017-05-16 17:08:34,932 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:34,932 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:34,934 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:34,936 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:34
2017-05-16 17:08:34,938 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:34,938 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:34,940 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:34,940 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:34,964 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:34,964 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:34,964 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:34,965 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:34,966 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:34,966 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:34,966 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:34,966 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:34,966 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:35,005 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:35,005 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:35,005 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:35,006 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:35,008 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:35,081 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:35,081 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:35,081 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:35,082 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:35,085 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:35,092 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:35,093 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:35,093 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:35,093 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:35,095 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:35,096 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:35,096 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:35,097 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:35,097 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:35,099 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:35,099 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:35,100 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:35,100 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:35,105 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:35,105 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:35,105 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:35,172 INFO  [main] namenode.FSImage (FSImage.java:format(145)) - Allocated new BlockPoolId: BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:35,272 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1 has been successfully formatted.
2017-05-16 17:08:35,356 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2 has been successfully formatted.
2017-05-16 17:08:35,540 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-05-16 17:08:35,564 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1367)) - createNameNode []
2017-05-16 17:08:35,591 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(124)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-05-16 17:08:35,665 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(376)) - Scheduled snapshot period at 10 second(s).
2017-05-16 17:08:35,665 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2017-05-16 17:08:35,667 INFO  [main] namenode.NameNode (NameNode.java:setClientNamenodeAddress(349)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-05-16 17:08:35,702 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1694)) - Starting Web-server for hdfs at: http://localhost:0
2017-05-16 17:08:35,746 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-05-16 17:08:35,750 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-05-16 17:08:35,804 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:35,815 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-05-16 17:08:35,815 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:35,850 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-05-16 17:08:35,852 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:35,890 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 52553
2017-05-16 17:08:35,890 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:35,918 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_52553_hdfs____2joxa8/webapp
2017-05-16 17:08:36,186 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52553
2017-05-16 17:08:36,191 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:36,191 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:36,192 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:36,192 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:36,193 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:36,193 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:36
2017-05-16 17:08:36,193 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:36,193 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:36,194 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:36,194 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:36,201 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:36,202 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:36,202 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:36,202 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:36,202 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:36,202 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:36,203 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:36,203 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:36,203 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:36,203 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:36,203 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:36,203 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:36,204 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:36,204 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:36,204 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:36,205 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:36,205 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:36,205 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:36,209 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:36,209 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:36,209 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:36,210 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:36,210 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:36,211 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:36,211 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:36,211 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:36,212 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:36,212 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:36,212 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:36,212 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:36,212 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:36,213 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:36,214 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:36,214 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:36,215 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:36,268 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:36,302 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:36,304 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current
2017-05-16 17:08:36,304 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current
2017-05-16 17:08:36,305 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(656)) - No edit log streams selected.
2017-05-16 17:08:36,330 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(214)) - Loading 1 INodes.
2017-05-16 17:08:36,339 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(182)) - Loaded FSImage in 0 seconds.
2017-05-16 17:08:36,339 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(937)) - Loaded image for txid 0 from /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/fsimage_0000000000000000000
2017-05-16 17:08:36,349 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1027)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-05-16 17:08:36,353 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1173)) - Starting log segment at 1
2017-05-16 17:08:36,436 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-05-16 17:08:36,437 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(746)) - Finished loading FSImage in 222 msecs
2017-05-16 17:08:36,636 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(329)) - RPC server is binding to localhost:0
2017-05-16 17:08:36,646 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:36,659 INFO  [Socket Reader #1 for port 38528] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 38528
2017-05-16 17:08:36,706 INFO  [main] namenode.NameNode (NameNode.java:initialize(603)) - Clients are to use localhost:38528 to access this namenode/service.
2017-05-16 17:08:36,709 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:registerMBean(6642)) - Registered FSNamesystemState MBean
2017-05-16 17:08:36,859 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:36,860 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:36,860 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1219)) - initializing replication queues
2017-05-16 17:08:36,863 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5737)) - STATE* Leaving safe mode after 0 secs
2017-05-16 17:08:36,863 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5748)) - STATE* Network topology has 0 racks and 0 datanodes
2017-05-16 17:08:36,865 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5751)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2612)) - Total number of blocks            = 0
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2613)) - Number of invalid blocks          = 0
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2614)) - Number of under-replicated blocks = 0
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2615)) - Number of  over-replicated blocks = 0
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2617)) - Number of blocks being written    = 0
2017-05-16 17:08:36,876 INFO  [Replication Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2618)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-05-16 17:08:36,905 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:36,906 INFO  [IPC Server listener on 38528] ipc.Server (Server.java:run(674)) - IPC Server listener on 38528: starting
2017-05-16 17:08:37,092 INFO  [main] namenode.NameNode (NameNode.java:startCommonServices(646)) - NameNode RPC up at: localhost/127.0.0.1:38528
2017-05-16 17:08:37,093 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1140)) - Starting services required for active state
2017-05-16 17:08:37,125 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1407)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1,[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2
2017-05-16 17:08:37,125 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1412)) - Starting DataNode 0 with hostname set to: localhost
2017-05-16 17:08:37,139 INFO  [CacheReplicationMonitor(1416228953)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-05-16 17:08:37,139 INFO  [CacheReplicationMonitor(1416228953)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(178)) - Rescanning after 5382614410 milliseconds
2017-05-16 17:08:37,143 INFO  [CacheReplicationMonitor(1416228953)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(201)) - Scanned 0 directive(s) and 0 block(s) in 4 millisecond(s).
2017-05-16 17:08:37,285 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2017-05-16 17:08:37,288 INFO  [main] datanode.DataNode (DataNode.java:<init>(414)) - Configured hostname is localhost
2017-05-16 17:08:37,295 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1049)) - Starting DataNode with maxLockedMemory = 0
2017-05-16 17:08:37,311 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(848)) - Opened streaming server at /127.0.0.1:53672
2017-05-16 17:08:37,313 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-05-16 17:08:37,314 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-05-16 17:08:37,317 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-05-16 17:08:37,317 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:37,318 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-05-16 17:08:37,318 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:37,321 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:37,321 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 59072
2017-05-16 17:08:37,321 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:37,327 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_59072_datanode____xd03f2/webapp
2017-05-16 17:08:37,437 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:59072
2017-05-16 17:08:37,448 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1066)) - dnUserName = root
2017-05-16 17:08:37,448 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1067)) - supergroup = supergroup
2017-05-16 17:08:37,460 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:37,461 INFO  [Socket Reader #1 for port 39428] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 39428
2017-05-16 17:08:37,472 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(723)) - Opened IPC server at /127.0.0.1:39428
2017-05-16 17:08:37,479 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-05-16 17:08:37,481 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-05-16 17:08:37,531 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:run(821)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38528 starting to offer service
2017-05-16 17:08:37,535 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:37,541 INFO  [IPC Server listener on 39428] ipc.Server (Server.java:run(674)) - IPC Server listener on 39428: starting
2017-05-16 17:08:37,984 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (DataStorage.java:recoverTransitionRead(399)) - DataNode version: -56 and NameNode layout version: -60
2017-05-16 17:08:38,052 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,052 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,154 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,154 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,232 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:38,233 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1 is not formatted for BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:38,233 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:38,256 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,257 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,360 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:38,360 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2 is not formatted for BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:38,360 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:38,363 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,364 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,466 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,468 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,571 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,572 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,611 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(141)) - Analyzing storage directories for bpid BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:38,612 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:38,613 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-1931889257-172.17.0.4-1494947315139 is not formatted.
2017-05-16 17:08:38,613 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:38,613 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-1931889257-172.17.0.4-1494947315139 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-1931889257-172.17.0.4-1494947315139/current
2017-05-16 17:08:38,652 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:38,653 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-1931889257-172.17.0.4-1494947315139 is not formatted.
2017-05-16 17:08:38,653 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:38,653 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-1931889257-172.17.0.4-1494947315139 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-1931889257-172.17.0.4-1494947315139/current
2017-05-16 17:08:38,674 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,675 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,695 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:38,695 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:38,770 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (DataNode.java:initStorage(1314)) - Setting up storage: nsid=1327669282;bpid=BP-1931889257-172.17.0.4-1494947315139;lv=-56;nsInfo=lv=-60;cid=testClusterID;nsid=1327669282;c=0;bpid=BP-1931889257-172.17.0.4-1494947315139;dnuuid=null
2017-05-16 17:08:38,777 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,777 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,830 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (DataNode.java:checkDatanodeUuid(1142)) - Generated and persisted new Datanode UUID 1cb0086a-27e3-48ca-91bf-682dac750170
2017-05-16 17:08:38,862 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current
2017-05-16 17:08:38,863 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current, StorageType: DISK
2017-05-16 17:08:38,864 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current
2017-05-16 17:08:38,864 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current, StorageType: DISK
2017-05-16 17:08:38,869 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(1804)) - Registered FSDatasetState MBean
2017-05-16 17:08:38,873 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DirectoryScanner (DirectoryScanner.java:start(330)) - Periodic Directory Tree Verification scan starting at 1494951887873 with interval 21600000
2017-05-16 17:08:38,875 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2207)) - Adding block pool BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:38,877 INFO  [Thread-69] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:38,880 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:38,881 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,877 INFO  [Thread-68] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:38,929 INFO  [Thread-68] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-1931889257-172.17.0.4-1494947315139 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 46ms
2017-05-16 17:08:38,929 INFO  [Thread-69] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-1931889257-172.17.0.4-1494947315139 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 52ms
2017-05-16 17:08:38,929 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(283)) - Total time to scan all replicas for block pool BP-1931889257-172.17.0.4-1494947315139: 54ms
2017-05-16 17:08:38,934 INFO  [Thread-72] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:38,935 INFO  [Thread-72] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 1ms
2017-05-16 17:08:38,944 INFO  [Thread-73] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:38,944 INFO  [Thread-73] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-1931889257-172.17.0.4-1494947315139 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 0ms
2017-05-16 17:08:38,944 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(162)) - Total time to add all replicas to map: 15ms
2017-05-16 17:08:38,946 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:register(781)) - Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid null) service to localhost/127.0.0.1:38528 beginning handshake with NN
2017-05-16 17:08:38,980 INFO  [IPC Server handler 9 on 38528] hdfs.StateChange (DatanodeManager.java:registerDatanode(903)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=1cb0086a-27e3-48ca-91bf-682dac750170, infoPort=59072, ipcPort=39428, storageInfo=lv=-56;cid=testClusterID;nsid=1327669282;c=0) storage 1cb0086a-27e3-48ca-91bf-682dac750170
2017-05-16 17:08:38,983 INFO  [IPC Server handler 9 on 38528] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:38,984 INFO  [IPC Server handler 9 on 38528] net.NetworkTopology (NetworkTopology.java:add(419)) - Adding a new node: /default-rack/127.0.0.1:53672
2017-05-16 17:08:38,990 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2237)) - !dn.datanode.isDatanodeFullyStarted()
2017-05-16 17:08:38,990 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:38,990 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:register(794)) - Block pool Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid null) service to localhost/127.0.0.1:38528 successfully registered with NN
2017-05-16 17:08:38,992 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:offerService(653)) - For namenode localhost/127.0.0.1:38528 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-05-16 17:08:39,004 INFO  [IPC Server handler 2 on 38528] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:39,004 INFO  [IPC Server handler 2 on 38528] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-b4751d59-1fde-4142-90a6-ed96e2610caf for DN 127.0.0.1:53672
2017-05-16 17:08:39,005 INFO  [IPC Server handler 2 on 38528] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9 for DN 127.0.0.1:53672
2017-05-16 17:08:39,017 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(503)) - Namenode Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid 1cb0086a-27e3-48ca-91bf-682dac750170) service to localhost/127.0.0.1:38528 trying to claim ACTIVE state with txid=1
2017-05-16 17:08:39,018 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(515)) - Acknowledging ACTIVE Namenode Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid 1cb0086a-27e3-48ca-91bf-682dac750170) service to localhost/127.0.0.1:38528
2017-05-16 17:08:39,029 INFO  [IPC Server handler 0 on 38528] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:39,033 INFO  [IPC Server handler 0 on 38528] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9 node DatanodeRegistration(127.0.0.1, datanodeUuid=1cb0086a-27e3-48ca-91bf-682dac750170, infoPort=59072, ipcPort=39428, storageInfo=lv=-56;cid=testClusterID;nsid=1327669282;c=0), blocks: 0, hasStaleStorages: true, processing time: 8 msecs
2017-05-16 17:08:39,033 INFO  [IPC Server handler 0 on 38528] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-b4751d59-1fde-4142-90a6-ed96e2610caf,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:39,033 INFO  [IPC Server handler 0 on 38528] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-b4751d59-1fde-4142-90a6-ed96e2610caf node DatanodeRegistration(127.0.0.1, datanodeUuid=1cb0086a-27e3-48ca-91bf-682dac750170, infoPort=59072, ipcPort=39428, storageInfo=lv=-56;cid=testClusterID;nsid=1327669282;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-05-16 17:08:39,054 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:blockReport(514)) - Sent 1 blockreports 0 blocks total. Took 1 msec to generate and 34 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@5f6e06b8
2017-05-16 17:08:39,054 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPOfferService.java:processCommandFromActive(689)) - Got finalize command for block pool BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:39,060 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlockMap
2017-05-16 17:08:39,060 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:39,062 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.5% max memory 3.5 GB = 17.9 MB
2017-05-16 17:08:39,062 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^21 = 2097152 entries
2017-05-16 17:08:39,066 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.BlockPoolSliceScanner (BlockPoolSliceScanner.java:<init>(190)) - Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:39,077 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataBlockScanner (DataBlockScanner.java:addBlockPool(264)) - Added bpid=BP-1931889257-172.17.0.4-1494947315139 to blockPoolScannerMap, new size=1
2017-05-16 17:08:39,100 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:39,112 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:39,142 INFO  [IPC Server handler 5 on 38528] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:39,158 INFO  [IPC Server handler 6 on 38528] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:39,186 INFO  [IPC Server handler 7 on 38528] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1.txt. BP-1931889257-172.17.0.4-1494947315139 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9:NORMAL:127.0.0.1:53672|RBW]]}
2017-05-16 17:08:39,247 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-1990619097_1 at /127.0.0.1:55474 [Receiving block BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001 src: /127.0.0.1:55474 dest: /127.0.0.1:53672
2017-05-16 17:08:39,333 INFO  [PacketResponder: BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:55474, dest: /127.0.0.1:53672, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1990619097_1, offset: 0, srvID: 1cb0086a-27e3-48ca-91bf-682dac750170, blockid: BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001, duration: 24444904
2017-05-16 17:08:39,342 INFO  [PacketResponder: BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-1931889257-172.17.0.4-1494947315139:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:39,358 INFO  [IPC Server handler 8 on 38528] namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(3691)) - BLOCK* checkFileProgress: blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9:NORMAL:127.0.0.1:53672|RBW]]} has not reached minimal replication 1
2017-05-16 17:08:39,358 INFO  [IPC Server handler 8 on 38528] namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-05-16 17:08:39,359 INFO  [IPC Server handler 8 on 38528] namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-05-16 17:08:39,362 INFO  [IPC Server handler 9 on 38528] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53672 is added to blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-b60d9567-0a4e-42eb-9eb1-26abe29eb4d9:NORMAL:127.0.0.1:53672|RBW]]} size 1
2017-05-16 17:08:39,779 INFO  [IPC Server handler 2 on 38528] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1.txt is closed by DFSClient_NONMAPREDUCE_-1990619097_1
2017-05-16 17:08:39,784 INFO  [IPC Server handler 0 on 38528] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/minidfsTest/1.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:39,785 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1706)) - Shutting down the Mini HDFS Cluster
2017-05-16 17:08:39,785 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1738)) - Shutting down DataNode 0
2017-05-16 17:08:39,786 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60cf80e7] datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-05-16 17:08:39,786 WARN  [main] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(376)) - DirectoryScanner: shutdown has been called
2017-05-16 17:08:39,800 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:39,801 WARN  [989126847@qtp-1004009692-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:59072] http.HttpServer2 (HttpServer2.java:isRunning(460)) - HttpServer Acceptor: isRunning is false. Rechecking.
2017-05-16 17:08:39,803 WARN  [989126847@qtp-1004009692-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:59072] http.HttpServer2 (HttpServer2.java:isRunning(469)) - HttpServer Acceptor: isRunning is false
2017-05-16 17:08:39,803 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 0
2017-05-16 17:08:39,803 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 39428
2017-05-16 17:08:39,809 INFO  [IPC Server listener on 39428] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 39428
2017-05-16 17:08:39,810 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:39,811 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:offerService(738)) - BPOfferService for Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid 1cb0086a-27e3-48ca-91bf-682dac750170) service to localhost/127.0.0.1:38528 interrupted
2017-05-16 17:08:39,811 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BPServiceActor.java:run(861)) - Ending block pool service for: Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid 1cb0086a-27e3-48ca-91bf-682dac750170) service to localhost/127.0.0.1:38528
2017-05-16 17:08:39,812 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1931889257-172.17.0.4-1494947315139 (Datanode Uuid 1cb0086a-27e3-48ca-91bf-682dac750170)
2017-05-16 17:08:39,812 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] datanode.DataBlockScanner (DataBlockScanner.java:removeBlockPool(273)) - Removed bpid=BP-1931889257-172.17.0.4-1494947315139 from blockPoolScannerMap
2017-05-16 17:08:39,812 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:38528] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2217)) - Removing block pool BP-1931889257-172.17.0.4-1494947315139
2017-05-16 17:08:39,814 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(172)) - Shutting down all async disk service threads
2017-05-16 17:08:39,815 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(180)) - All async disk service threads have been shut down
2017-05-16 17:08:39,815 INFO  [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@50a1a8d] impl.FsDatasetImpl (FsDatasetImpl.java:run(2662)) - LazyWriter was interrupted, exiting
2017-05-16 17:08:39,818 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(161)) - Shutting down all async lazy persist service threads
2017-05-16 17:08:39,819 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(168)) - All async lazy persist service threads have been shut down
2017-05-16 17:08:39,819 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1720)) - Shutdown complete.
2017-05-16 17:08:39,819 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:39,821 INFO  [main] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1214)) - Ending log segment 1
2017-05-16 17:08:39,821 INFO  [main] namenode.FSEditLog (FSEditLog.java:printStatistics(691)) - Number of transactions: 8 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 2 2 
2017-05-16 17:08:39,821 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@64bc21ac] namenode.FSNamesystem (FSNamesystem.java:run(5274)) - LazyPersistFileScrubber was interrupted, exiting
2017-05-16 17:08:39,822 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@593e824f] namenode.FSNamesystem (FSNamesystem.java:run(5207)) - NameNodeEditLogRoller was interrupted, exiting
2017-05-16 17:08:39,824 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_0000000000000000001-0000000000000000008
2017-05-16 17:08:39,824 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_0000000000000000001-0000000000000000008
2017-05-16 17:08:39,828 INFO  [CacheReplicationMonitor(1416228953)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-05-16 17:08:39,839 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 38528
2017-05-16 17:08:39,857 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:39,857 INFO  [IPC Server listener on 38528] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 38528
2017-05-16 17:08:39,858 INFO  [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor@3d97a632] blockmanagement.BlockManager (BlockManager.java:run(3533)) - Stopping ReplicationMonitor.
2017-05-16 17:08:39,858 WARN  [org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor@70dd7e15] blockmanagement.DecommissionManager (DecommissionManager.java:run(78)) - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
2017-05-16 17:08:39,891 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:39,891 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1334)) - Stopping services started for standby state
2017-05-16 17:08:39,902 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:39,903 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2017-05-16 17:08:39,904 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2017-05-16 17:08:39,904 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - DataNode metrics system shutdown complete.
2017-05-16 17:08:39,941 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(442)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-05-16 17:08:39,944 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:39,945 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:39,945 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:39,945 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:39,946 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:39,946 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:39
2017-05-16 17:08:39,946 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:39,946 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:39,946 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:39,947 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:39,953 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:39,953 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:39,954 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:39,954 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:39,954 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:39,955 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:39,955 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:39,955 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:39,955 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:39,955 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:39,956 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:39,956 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:39,959 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:39,960 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:39,960 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:39,960 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:39,960 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:39,961 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:39,962 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:39,962 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:39,962 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:39,962 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:39,962 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:39,962 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:39,962 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:39,963 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:39,963 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:39,963 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:39,963 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:39,964 INFO  [main] namenode.FSImage (FSImage.java:format(145)) - Allocated new BlockPoolId: BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:40,049 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1 has been successfully formatted.
2017-05-16 17:08:40,108 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2 has been successfully formatted.
2017-05-16 17:08:40,203 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-05-16 17:08:40,205 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1367)) - createNameNode []
2017-05-16 17:08:40,209 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(124)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-05-16 17:08:40,212 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(376)) - Scheduled snapshot period at 10 second(s).
2017-05-16 17:08:40,212 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2017-05-16 17:08:40,215 INFO  [main] namenode.NameNode (NameNode.java:setClientNamenodeAddress(349)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-05-16 17:08:40,220 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1694)) - Starting Web-server for hdfs at: http://localhost:0
2017-05-16 17:08:40,220 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-05-16 17:08:40,221 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:40,225 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-05-16 17:08:40,225 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:40,226 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-05-16 17:08:40,226 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:40,230 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 45314
2017-05-16 17:08:40,230 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:40,234 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_45314_hdfs____.eokrfl/webapp
2017-05-16 17:08:40,345 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45314
2017-05-16 17:08:40,347 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:40,348 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:40,349 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:40,350 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:40,351 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:40,357 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:40
2017-05-16 17:08:40,358 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:40,359 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:40,361 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:40,362 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:40,383 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:40,384 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:40,384 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:40,385 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:40,385 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:40,386 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:40,386 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:40,387 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:40,387 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:40,388 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:40,388 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:40,389 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:40,391 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:40,391 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:40,392 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:40,392 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:40,393 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:40,393 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:40,487 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:40,488 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:40,488 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:40,488 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:40,488 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:40,501 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:40,502 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:40,502 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:40,504 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:40,504 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:40,505 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:40,505 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:40,506 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:40,506 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:40,507 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:40,508 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:40,508 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:40,552 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:40,586 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:40,592 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current
2017-05-16 17:08:40,592 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current
2017-05-16 17:08:40,593 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(656)) - No edit log streams selected.
2017-05-16 17:08:40,594 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(214)) - Loading 1 INodes.
2017-05-16 17:08:40,594 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(182)) - Loaded FSImage in 0 seconds.
2017-05-16 17:08:40,594 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(937)) - Loaded image for txid 0 from /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/fsimage_0000000000000000000
2017-05-16 17:08:40,595 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1027)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-05-16 17:08:40,595 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1173)) - Starting log segment at 1
2017-05-16 17:08:40,662 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-05-16 17:08:40,663 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(746)) - Finished loading FSImage in 155 msecs
2017-05-16 17:08:40,664 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(329)) - RPC server is binding to localhost:0
2017-05-16 17:08:40,665 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:40,666 INFO  [Socket Reader #1 for port 51467] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 51467
2017-05-16 17:08:40,682 INFO  [main] namenode.NameNode (NameNode.java:initialize(603)) - Clients are to use localhost:51467 to access this namenode/service.
2017-05-16 17:08:40,685 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:registerMBean(6642)) - Registered FSNamesystemState MBean
2017-05-16 17:08:40,716 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:40,716 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:40,716 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1219)) - initializing replication queues
2017-05-16 17:08:40,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5737)) - STATE* Leaving safe mode after 0 secs
2017-05-16 17:08:40,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5748)) - STATE* Network topology has 0 racks and 0 datanodes
2017-05-16 17:08:40,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5751)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-05-16 17:08:40,731 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:40,750 INFO  [IPC Server listener on 51467] ipc.Server (Server.java:run(674)) - IPC Server listener on 51467: starting
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2612)) - Total number of blocks            = 0
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2613)) - Number of invalid blocks          = 0
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2614)) - Number of under-replicated blocks = 0
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2615)) - Number of  over-replicated blocks = 0
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2617)) - Number of blocks being written    = 0
2017-05-16 17:08:40,750 INFO  [Replication Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2618)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2017-05-16 17:08:40,757 INFO  [main] namenode.NameNode (NameNode.java:startCommonServices(646)) - NameNode RPC up at: localhost/127.0.0.1:51467
2017-05-16 17:08:40,757 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1140)) - Starting services required for active state
2017-05-16 17:08:40,768 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1407)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1,[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2
2017-05-16 17:08:40,768 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1412)) - Starting DataNode 0 with hostname set to: localhost
2017-05-16 17:08:40,771 INFO  [CacheReplicationMonitor(1065786871)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-05-16 17:08:40,771 INFO  [CacheReplicationMonitor(1065786871)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(178)) - Rescanning after 5382618042 milliseconds
2017-05-16 17:08:40,772 INFO  [CacheReplicationMonitor(1065786871)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(201)) - Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-05-16 17:08:40,797 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2017-05-16 17:08:40,797 INFO  [main] datanode.DataNode (DataNode.java:<init>(414)) - Configured hostname is localhost
2017-05-16 17:08:40,797 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1049)) - Starting DataNode with maxLockedMemory = 0
2017-05-16 17:08:40,798 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(848)) - Opened streaming server at /127.0.0.1:49763
2017-05-16 17:08:40,798 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-05-16 17:08:40,798 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-05-16 17:08:40,799 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-05-16 17:08:40,799 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:40,800 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-05-16 17:08:40,800 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:40,801 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:40,801 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 32884
2017-05-16 17:08:40,801 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:40,808 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_32884_datanode____g00ov0/webapp
2017-05-16 17:08:40,911 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:32884
2017-05-16 17:08:40,921 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1066)) - dnUserName = root
2017-05-16 17:08:40,922 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1067)) - supergroup = supergroup
2017-05-16 17:08:40,922 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:40,924 INFO  [Socket Reader #1 for port 35408] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 35408
2017-05-16 17:08:40,935 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(723)) - Opened IPC server at /127.0.0.1:35408
2017-05-16 17:08:40,938 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-05-16 17:08:40,939 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-05-16 17:08:40,944 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:run(821)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:51467 starting to offer service
2017-05-16 17:08:40,945 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:40,945 INFO  [IPC Server listener on 35408] ipc.Server (Server.java:run(674)) - IPC Server listener on 35408: starting
2017-05-16 17:08:40,970 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:40,971 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:40,989 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (DataStorage.java:recoverTransitionRead(399)) - DataNode version: -56 and NameNode layout version: -60
2017-05-16 17:08:41,024 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:41,025 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1 is not formatted for BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,025 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:41,072 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:41,073 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:41,099 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:41,099 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2 is not formatted for BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,099 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:41,174 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:41,175 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:41,281 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(141)) - Analyzing storage directories for bpid BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,282 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:41,282 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-324633289-172.17.0.4-1494947319964 is not formatted.
2017-05-16 17:08:41,282 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:41,282 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-324633289-172.17.0.4-1494947319964 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-324633289-172.17.0.4-1494947319964/current
2017-05-16 17:08:41,284 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:41,286 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:41,326 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:41,326 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-324633289-172.17.0.4-1494947319964 is not formatted.
2017-05-16 17:08:41,326 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:41,327 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-324633289-172.17.0.4-1494947319964 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-324633289-172.17.0.4-1494947319964/current
2017-05-16 17:08:41,368 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:41,368 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:41,387 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:41,388 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:41,444 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (DataNode.java:initStorage(1314)) - Setting up storage: nsid=70170024;bpid=BP-324633289-172.17.0.4-1494947319964;lv=-56;nsInfo=lv=-60;cid=testClusterID;nsid=70170024;c=0;bpid=BP-324633289-172.17.0.4-1494947319964;dnuuid=null
2017-05-16 17:08:41,490 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:41,490 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:41,519 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (DataNode.java:checkDatanodeUuid(1142)) - Generated and persisted new Datanode UUID cb0e23d4-723c-4c0b-a8c4-b2ed75476908
2017-05-16 17:08:41,520 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current
2017-05-16 17:08:41,520 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current, StorageType: DISK
2017-05-16 17:08:41,520 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current
2017-05-16 17:08:41,520 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current, StorageType: DISK
2017-05-16 17:08:41,531 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(1804)) - Registered FSDatasetState MBean
2017-05-16 17:08:41,531 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DirectoryScanner (DirectoryScanner.java:start(330)) - Periodic Directory Tree Verification scan starting at 1494951694531 with interval 21600000
2017-05-16 17:08:41,532 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2207)) - Adding block pool BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,532 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:41,533 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:41,561 INFO  [Thread-142] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-324633289-172.17.0.4-1494947319964 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 29ms
2017-05-16 17:08:41,569 INFO  [Thread-143] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-324633289-172.17.0.4-1494947319964 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 35ms
2017-05-16 17:08:41,570 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(283)) - Total time to scan all replicas for block pool BP-324633289-172.17.0.4-1494947319964: 37ms
2017-05-16 17:08:41,571 INFO  [Thread-146] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:41,571 INFO  [Thread-146] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 0ms
2017-05-16 17:08:41,576 INFO  [Thread-147] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:41,577 INFO  [Thread-147] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-324633289-172.17.0.4-1494947319964 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 0ms
2017-05-16 17:08:41,577 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(162)) - Total time to add all replicas to map: 7ms
2017-05-16 17:08:41,578 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:register(781)) - Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid null) service to localhost/127.0.0.1:51467 beginning handshake with NN
2017-05-16 17:08:41,579 INFO  [IPC Server handler 7 on 51467] hdfs.StateChange (DatanodeManager.java:registerDatanode(903)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=cb0e23d4-723c-4c0b-a8c4-b2ed75476908, infoPort=32884, ipcPort=35408, storageInfo=lv=-56;cid=testClusterID;nsid=70170024;c=0) storage cb0e23d4-723c-4c0b-a8c4-b2ed75476908
2017-05-16 17:08:41,580 INFO  [IPC Server handler 7 on 51467] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:41,580 INFO  [IPC Server handler 7 on 51467] net.NetworkTopology (NetworkTopology.java:add(419)) - Adding a new node: /default-rack/127.0.0.1:49763
2017-05-16 17:08:41,581 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:register(794)) - Block pool Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid null) service to localhost/127.0.0.1:51467 successfully registered with NN
2017-05-16 17:08:41,581 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:offerService(653)) - For namenode localhost/127.0.0.1:51467 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-05-16 17:08:41,586 INFO  [IPC Server handler 8 on 51467] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:41,586 INFO  [IPC Server handler 8 on 51467] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-aa24b977-e012-473d-8b26-1aa23260e434 for DN 127.0.0.1:49763
2017-05-16 17:08:41,587 INFO  [IPC Server handler 8 on 51467] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-3b241552-6289-4b3a-9fd1-0c969c553175 for DN 127.0.0.1:49763
2017-05-16 17:08:41,588 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(503)) - Namenode Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid cb0e23d4-723c-4c0b-a8c4-b2ed75476908) service to localhost/127.0.0.1:51467 trying to claim ACTIVE state with txid=1
2017-05-16 17:08:41,588 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(515)) - Acknowledging ACTIVE Namenode Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid cb0e23d4-723c-4c0b-a8c4-b2ed75476908) service to localhost/127.0.0.1:51467
2017-05-16 17:08:41,589 INFO  [IPC Server handler 9 on 51467] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-3b241552-6289-4b3a-9fd1-0c969c553175,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:41,589 INFO  [IPC Server handler 9 on 51467] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-3b241552-6289-4b3a-9fd1-0c969c553175 node DatanodeRegistration(127.0.0.1, datanodeUuid=cb0e23d4-723c-4c0b-a8c4-b2ed75476908, infoPort=32884, ipcPort=35408, storageInfo=lv=-56;cid=testClusterID;nsid=70170024;c=0), blocks: 0, hasStaleStorages: true, processing time: 0 msecs
2017-05-16 17:08:41,590 INFO  [IPC Server handler 9 on 51467] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-aa24b977-e012-473d-8b26-1aa23260e434,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:41,590 INFO  [IPC Server handler 9 on 51467] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-aa24b977-e012-473d-8b26-1aa23260e434 node DatanodeRegistration(127.0.0.1, datanodeUuid=cb0e23d4-723c-4c0b-a8c4-b2ed75476908, infoPort=32884, ipcPort=35408, storageInfo=lv=-56;cid=testClusterID;nsid=70170024;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-05-16 17:08:41,591 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:blockReport(514)) - Sent 1 blockreports 0 blocks total. Took 0 msec to generate and 3 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@16336560
2017-05-16 17:08:41,592 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPOfferService.java:processCommandFromActive(689)) - Got finalize command for block pool BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,592 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:41,596 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:41,593 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlockMap
2017-05-16 17:08:41,597 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:41,597 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.5% max memory 3.5 GB = 17.9 MB
2017-05-16 17:08:41,597 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^21 = 2097152 entries
2017-05-16 17:08:41,599 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.BlockPoolSliceScanner (BlockPoolSliceScanner.java:<init>(190)) - Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:41,602 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataBlockScanner (DataBlockScanner.java:addBlockPool(264)) - Added bpid=BP-324633289-172.17.0.4-1494947319964 to blockPoolScannerMap, new size=1
2017-05-16 17:08:41,605 INFO  [IPC Server handler 2 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:41,616 INFO  [IPC Server handler 3 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:41,630 INFO  [IPC Server handler 4 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1.txt. BP-324633289-172.17.0.4-1494947319964 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-3b241552-6289-4b3a-9fd1-0c969c553175:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:41,639 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50041 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001 src: /127.0.0.1:50041 dest: /127.0.0.1:49763
2017-05-16 17:08:41,649 INFO  [IPC Server handler 6 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|FINALIZED]]} size 0
2017-05-16 17:08:41,646 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50041, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001, duration: 806636
2017-05-16 17:08:41,652 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:41,654 INFO  [IPC Server handler 7 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1.txt is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:41,657 INFO  [IPC Server handler 8 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/2.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:41,663 INFO  [IPC Server handler 9 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/2.txt. BP-324633289-172.17.0.4-1494947319964 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:41,670 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50042 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002 src: /127.0.0.1:50042 dest: /127.0.0.1:49763
2017-05-16 17:08:41,682 INFO  [IPC Server handler 0 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-3b241552-6289-4b3a-9fd1-0c969c553175:NORMAL:127.0.0.1:49763|FINALIZED]]} size 0
2017-05-16 17:08:41,682 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50042, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002, duration: 7723298
2017-05-16 17:08:41,682 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:41,688 INFO  [IPC Server handler 1 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/2.txt is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:41,691 INFO  [IPC Server handler 2 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/3.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:41,701 INFO  [IPC Server handler 3 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/3.txt. BP-324633289-172.17.0.4-1494947319964 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:41,705 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50043 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003 src: /127.0.0.1:50043 dest: /127.0.0.1:49763
2017-05-16 17:08:41,732 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50043, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003, duration: 10430642
2017-05-16 17:08:41,733 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:41,737 INFO  [IPC Server handler 4 on 51467] namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(3691)) - BLOCK* checkFileProgress: blk_1073741827_1003{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]} has not reached minimal replication 1
2017-05-16 17:08:41,741 INFO  [IPC Server handler 5 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741827_1003{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]} size 1
2017-05-16 17:08:42,142 INFO  [IPC Server handler 6 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/3.txt is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:42,145 INFO  [IPC Server handler 7 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/4.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:42,149 INFO  [IPC Server handler 8 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/4.txt. BP-324633289-172.17.0.4-1494947319964 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:42,151 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50044 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004 src: /127.0.0.1:50044 dest: /127.0.0.1:49763
2017-05-16 17:08:42,168 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50044, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004, duration: 6292946
2017-05-16 17:08:42,168 INFO  [IPC Server handler 9 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-3b241552-6289-4b3a-9fd1-0c969c553175:NORMAL:127.0.0.1:49763|FINALIZED]]} size 0
2017-05-16 17:08:42,169 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:42,173 INFO  [IPC Server handler 0 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/4.txt is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:42,177 INFO  [IPC Server handler 1 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:42,179 INFO  [IPC Server handler 2 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:42,185 INFO  [IPC Server handler 3 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1. BP-324633289-172.17.0.4-1494947319964 blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-3b241552-6289-4b3a-9fd1-0c969c553175:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:42,189 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50045 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005 src: /127.0.0.1:50045 dest: /127.0.0.1:49763
2017-05-16 17:08:42,209 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50045, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005, duration: 8034625
2017-05-16 17:08:42,210 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:42,211 INFO  [IPC Server handler 4 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741829_1005{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|FINALIZED]]} size 0
2017-05-16 17:08:42,212 INFO  [IPC Server handler 5 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1 is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:42,214 INFO  [IPC Server handler 6 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:42,217 INFO  [IPC Server handler 7 on 51467] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/2. BP-324633289-172.17.0.4-1494947319964 blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-aa24b977-e012-473d-8b26-1aa23260e434:NORMAL:127.0.0.1:49763|RBW]]}
2017-05-16 17:08:42,225 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_-728712491_1 at /127.0.0.1:50046 [Receiving block BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006 src: /127.0.0.1:50046 dest: /127.0.0.1:49763
2017-05-16 17:08:42,235 INFO  [IPC Server handler 8 on 51467] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:49763 is added to blk_1073741830_1006{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-3b241552-6289-4b3a-9fd1-0c969c553175:NORMAL:127.0.0.1:49763|FINALIZED]]} size 0
2017-05-16 17:08:42,239 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50046, dest: /127.0.0.1:49763, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-728712491_1, offset: 0, srvID: cb0e23d4-723c-4c0b-a8c4-b2ed75476908, blockid: BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006, duration: 7658177
2017-05-16 17:08:42,239 INFO  [PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-324633289-172.17.0.4-1494947319964:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:42,246 INFO  [IPC Server handler 9 on 51467] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/2 is closed by DFSClient_NONMAPREDUCE_-728712491_1
2017-05-16 17:08:42,247 INFO  [IPC Server handler 0 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:42,256 INFO  [IPC Server handler 1 on 51467] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:42,264 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1706)) - Shutting down the Mini HDFS Cluster
2017-05-16 17:08:42,264 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1738)) - Shutting down DataNode 0
2017-05-16 17:08:42,265 WARN  [main] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(376)) - DirectoryScanner: shutdown has been called
2017-05-16 17:08:42,265 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29fc1a2b] datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-05-16 17:08:42,271 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:42,271 WARN  [2141932519@qtp-128077491-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:32884] http.HttpServer2 (HttpServer2.java:isRunning(460)) - HttpServer Acceptor: isRunning is false. Rechecking.
2017-05-16 17:08:42,271 WARN  [2141932519@qtp-128077491-1 - Acceptor0 HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:32884] http.HttpServer2 (HttpServer2.java:isRunning(469)) - HttpServer Acceptor: isRunning is false
2017-05-16 17:08:42,371 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 0
2017-05-16 17:08:42,372 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 35408
2017-05-16 17:08:42,372 INFO  [IPC Server listener on 35408] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 35408
2017-05-16 17:08:42,377 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:42,377 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:offerService(738)) - BPOfferService for Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid cb0e23d4-723c-4c0b-a8c4-b2ed75476908) service to localhost/127.0.0.1:51467 interrupted
2017-05-16 17:08:42,377 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BPServiceActor.java:run(861)) - Ending block pool service for: Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid cb0e23d4-723c-4c0b-a8c4-b2ed75476908) service to localhost/127.0.0.1:51467
2017-05-16 17:08:42,377 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-324633289-172.17.0.4-1494947319964 (Datanode Uuid cb0e23d4-723c-4c0b-a8c4-b2ed75476908)
2017-05-16 17:08:42,377 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] datanode.DataBlockScanner (DataBlockScanner.java:removeBlockPool(273)) - Removed bpid=BP-324633289-172.17.0.4-1494947319964 from blockPoolScannerMap
2017-05-16 17:08:42,377 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51467] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2217)) - Removing block pool BP-324633289-172.17.0.4-1494947319964
2017-05-16 17:08:42,379 INFO  [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@14aea4d6] impl.FsDatasetImpl (FsDatasetImpl.java:run(2662)) - LazyWriter was interrupted, exiting
2017-05-16 17:08:42,379 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(172)) - Shutting down all async disk service threads
2017-05-16 17:08:42,379 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(180)) - All async disk service threads have been shut down
2017-05-16 17:08:42,379 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(161)) - Shutting down all async lazy persist service threads
2017-05-16 17:08:42,380 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(168)) - All async lazy persist service threads have been shut down
2017-05-16 17:08:42,380 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1720)) - Shutdown complete.
2017-05-16 17:08:42,380 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:42,381 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@383790cf] namenode.FSNamesystem (FSNamesystem.java:run(5207)) - NameNodeEditLogRoller was interrupted, exiting
2017-05-16 17:08:42,381 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@74971ed9] namenode.FSNamesystem (FSNamesystem.java:run(5274)) - LazyPersistFileScrubber was interrupted, exiting
2017-05-16 17:08:42,381 INFO  [main] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1214)) - Ending log segment 1
2017-05-16 17:08:42,381 INFO  [main] namenode.FSEditLog (FSEditLog.java:printStatistics(691)) - Number of transactions: 33 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 2 Number of syncs: 22 SyncTimes(ms): 4 0 
2017-05-16 17:08:42,382 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_0000000000000000001-0000000000000000033
2017-05-16 17:08:42,383 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_0000000000000000001-0000000000000000033
2017-05-16 17:08:42,383 INFO  [CacheReplicationMonitor(1065786871)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-05-16 17:08:42,384 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 51467
2017-05-16 17:08:42,386 INFO  [IPC Server listener on 51467] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 51467
2017-05-16 17:08:42,388 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:42,388 INFO  [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor@aa004a0] blockmanagement.BlockManager (BlockManager.java:run(3533)) - Stopping ReplicationMonitor.
2017-05-16 17:08:42,388 WARN  [org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor@1bbae752] blockmanagement.DecommissionManager (DecommissionManager.java:run(78)) - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
2017-05-16 17:08:42,398 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:42,399 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1334)) - Stopping services started for standby state
2017-05-16 17:08:42,428 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:42,529 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2017-05-16 17:08:42,531 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2017-05-16 17:08:42,533 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - DataNode metrics system shutdown complete.
2017-05-16 17:08:42,590 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(442)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-05-16 17:08:42,593 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:42,594 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:42,594 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:42,594 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:42,594 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:42,595 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:42
2017-05-16 17:08:42,595 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:42,595 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:42,595 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:42,595 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:42,602 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:42,602 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:42,603 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:42,603 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:42,603 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:42,603 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:42,604 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:42,604 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:42,604 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:42,604 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:42,605 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:42,605 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:42,608 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:42,609 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:42,609 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:42,609 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:42,609 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:42,610 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:42,610 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:42,610 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:42,611 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:42,611 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:42,611 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:42,611 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:42,611 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:42,611 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:42,612 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:42,612 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:42,612 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:42,613 INFO  [main] namenode.FSImage (FSImage.java:format(145)) - Allocated new BlockPoolId: BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:42,697 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1 has been successfully formatted.
2017-05-16 17:08:42,773 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2 has been successfully formatted.
2017-05-16 17:08:42,895 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-05-16 17:08:42,896 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1367)) - createNameNode []
2017-05-16 17:08:42,896 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(124)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-05-16 17:08:42,897 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(376)) - Scheduled snapshot period at 10 second(s).
2017-05-16 17:08:42,897 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2017-05-16 17:08:42,898 INFO  [main] namenode.NameNode (NameNode.java:setClientNamenodeAddress(349)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-05-16 17:08:42,900 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1694)) - Starting Web-server for hdfs at: http://localhost:0
2017-05-16 17:08:42,900 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-05-16 17:08:42,901 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:42,901 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-05-16 17:08:42,901 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:42,902 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-05-16 17:08:42,902 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:42,903 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 46269
2017-05-16 17:08:42,903 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:42,906 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_46269_hdfs____.6h6zz7/webapp
2017-05-16 17:08:43,012 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:46269
2017-05-16 17:08:43,018 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:43,019 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:43,019 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:43,019 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:43,019 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:43,020 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:43
2017-05-16 17:08:43,020 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:43,020 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:43,021 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:43,021 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:43,029 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:43,030 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:43,031 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:43,031 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:43,035 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:43,035 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:43,035 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:43,035 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:43,036 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:43,036 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:43,036 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:43,045 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:43,046 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:43,046 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:43,046 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:43,046 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:43,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:43,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:43,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:43,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:43,048 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:43,057 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:43,057 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:43,057 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:43,057 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:43,058 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:43,059 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:43,059 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:43,092 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:43,134 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:43,137 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current
2017-05-16 17:08:43,138 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current
2017-05-16 17:08:43,139 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(656)) - No edit log streams selected.
2017-05-16 17:08:43,140 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(214)) - Loading 1 INodes.
2017-05-16 17:08:43,141 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(182)) - Loaded FSImage in 0 seconds.
2017-05-16 17:08:43,141 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(937)) - Loaded image for txid 0 from /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/fsimage_0000000000000000000
2017-05-16 17:08:43,142 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1027)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-05-16 17:08:43,142 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1173)) - Starting log segment at 1
2017-05-16 17:08:43,319 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-05-16 17:08:43,319 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(746)) - Finished loading FSImage in 260 msecs
2017-05-16 17:08:43,320 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(329)) - RPC server is binding to localhost:0
2017-05-16 17:08:43,320 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:43,321 INFO  [Socket Reader #1 for port 47879] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 47879
2017-05-16 17:08:43,325 INFO  [main] namenode.NameNode (NameNode.java:initialize(603)) - Clients are to use localhost:47879 to access this namenode/service.
2017-05-16 17:08:43,329 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:registerMBean(6642)) - Registered FSNamesystemState MBean
2017-05-16 17:08:43,346 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:43,346 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:43,346 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1219)) - initializing replication queues
2017-05-16 17:08:43,346 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5737)) - STATE* Leaving safe mode after 0 secs
2017-05-16 17:08:43,347 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5748)) - STATE* Network topology has 0 racks and 0 datanodes
2017-05-16 17:08:43,347 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5751)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2612)) - Total number of blocks            = 0
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2613)) - Number of invalid blocks          = 0
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2614)) - Number of under-replicated blocks = 0
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2615)) - Number of  over-replicated blocks = 0
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2617)) - Number of blocks being written    = 0
2017-05-16 17:08:43,371 INFO  [Replication Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2618)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2017-05-16 17:08:43,371 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:43,373 INFO  [IPC Server listener on 47879] ipc.Server (Server.java:run(674)) - IPC Server listener on 47879: starting
2017-05-16 17:08:43,390 INFO  [main] namenode.NameNode (NameNode.java:startCommonServices(646)) - NameNode RPC up at: localhost/127.0.0.1:47879
2017-05-16 17:08:43,397 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1140)) - Starting services required for active state
2017-05-16 17:08:43,433 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1407)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1,[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2
2017-05-16 17:08:43,433 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1412)) - Starting DataNode 0 with hostname set to: localhost
2017-05-16 17:08:43,435 INFO  [CacheReplicationMonitor(155027124)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-05-16 17:08:43,435 INFO  [CacheReplicationMonitor(155027124)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(178)) - Rescanning after 5382620706 milliseconds
2017-05-16 17:08:43,436 INFO  [CacheReplicationMonitor(155027124)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(201)) - Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-05-16 17:08:43,468 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2017-05-16 17:08:43,469 INFO  [main] datanode.DataNode (DataNode.java:<init>(414)) - Configured hostname is localhost
2017-05-16 17:08:43,469 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1049)) - Starting DataNode with maxLockedMemory = 0
2017-05-16 17:08:43,470 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(848)) - Opened streaming server at /127.0.0.1:34128
2017-05-16 17:08:43,470 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-05-16 17:08:43,470 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-05-16 17:08:43,471 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-05-16 17:08:43,471 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:43,471 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-05-16 17:08:43,471 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:43,472 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:43,472 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 52003
2017-05-16 17:08:43,472 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:43,476 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_52003_datanode____42s3tp/webapp
2017-05-16 17:08:43,615 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:52003
2017-05-16 17:08:43,617 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1066)) - dnUserName = root
2017-05-16 17:08:43,617 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1067)) - supergroup = supergroup
2017-05-16 17:08:43,618 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:43,631 INFO  [Socket Reader #1 for port 52875] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 52875
2017-05-16 17:08:43,634 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(723)) - Opened IPC server at /127.0.0.1:52875
2017-05-16 17:08:43,636 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-05-16 17:08:43,638 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-05-16 17:08:43,639 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:run(821)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:47879 starting to offer service
2017-05-16 17:08:43,665 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:43,665 INFO  [IPC Server listener on 52875] ipc.Server (Server.java:run(674)) - IPC Server listener on 52875: starting
2017-05-16 17:08:43,692 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (DataStorage.java:recoverTransitionRead(399)) - DataNode version: -56 and NameNode layout version: -60
2017-05-16 17:08:43,694 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:43,694 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:43,737 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:43,738 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1 is not formatted for BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:43,738 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:43,796 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:43,797 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2 is not formatted for BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:43,797 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:43,797 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:43,797 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:43,899 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:43,899 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:43,960 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(141)) - Analyzing storage directories for bpid BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:43,960 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:43,960 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-2109847274-172.17.0.4-1494947322613 is not formatted.
2017-05-16 17:08:43,961 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:43,961 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-2109847274-172.17.0.4-1494947322613 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-2109847274-172.17.0.4-1494947322613/current
2017-05-16 17:08:43,998 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:43,999 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-2109847274-172.17.0.4-1494947322613 is not formatted.
2017-05-16 17:08:43,999 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:43,999 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-2109847274-172.17.0.4-1494947322613 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-2109847274-172.17.0.4-1494947322613/current
2017-05-16 17:08:44,000 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:44,001 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:44,025 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:44,026 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:44,101 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (DataNode.java:initStorage(1314)) - Setting up storage: nsid=1812171141;bpid=BP-2109847274-172.17.0.4-1494947322613;lv=-56;nsInfo=lv=-60;cid=testClusterID;nsid=1812171141;c=0;bpid=BP-2109847274-172.17.0.4-1494947322613;dnuuid=null
2017-05-16 17:08:44,102 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:44,102 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:44,205 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:44,205 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:44,213 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (DataNode.java:checkDatanodeUuid(1142)) - Generated and persisted new Datanode UUID dc25b1f8-7b00-4359-b625-041c597b5d6f
2017-05-16 17:08:44,214 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current
2017-05-16 17:08:44,215 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current, StorageType: DISK
2017-05-16 17:08:44,215 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current
2017-05-16 17:08:44,216 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current, StorageType: DISK
2017-05-16 17:08:44,221 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(1804)) - Registered FSDatasetState MBean
2017-05-16 17:08:44,222 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DirectoryScanner (DirectoryScanner.java:start(330)) - Periodic Directory Tree Verification scan starting at 1494949130222 with interval 21600000
2017-05-16 17:08:44,222 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2207)) - Adding block pool BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:44,222 INFO  [Thread-236] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:44,223 INFO  [Thread-237] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:44,241 INFO  [Thread-237] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-2109847274-172.17.0.4-1494947322613 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 18ms
2017-05-16 17:08:44,251 INFO  [Thread-236] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-2109847274-172.17.0.4-1494947322613 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 29ms
2017-05-16 17:08:44,251 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(283)) - Total time to scan all replicas for block pool BP-2109847274-172.17.0.4-1494947322613: 29ms
2017-05-16 17:08:44,252 INFO  [Thread-241] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:44,252 INFO  [Thread-240] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:44,252 INFO  [Thread-240] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 0ms
2017-05-16 17:08:44,253 INFO  [Thread-241] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-2109847274-172.17.0.4-1494947322613 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 1ms
2017-05-16 17:08:44,253 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(162)) - Total time to add all replicas to map: 2ms
2017-05-16 17:08:44,253 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:register(781)) - Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid null) service to localhost/127.0.0.1:47879 beginning handshake with NN
2017-05-16 17:08:44,254 INFO  [IPC Server handler 7 on 47879] hdfs.StateChange (DatanodeManager.java:registerDatanode(903)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=dc25b1f8-7b00-4359-b625-041c597b5d6f, infoPort=52003, ipcPort=52875, storageInfo=lv=-56;cid=testClusterID;nsid=1812171141;c=0) storage dc25b1f8-7b00-4359-b625-041c597b5d6f
2017-05-16 17:08:44,254 INFO  [IPC Server handler 7 on 47879] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:44,254 INFO  [IPC Server handler 7 on 47879] net.NetworkTopology (NetworkTopology.java:add(419)) - Adding a new node: /default-rack/127.0.0.1:34128
2017-05-16 17:08:44,262 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:register(794)) - Block pool Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid null) service to localhost/127.0.0.1:47879 successfully registered with NN
2017-05-16 17:08:44,263 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:offerService(653)) - For namenode localhost/127.0.0.1:47879 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-05-16 17:08:44,269 INFO  [IPC Server handler 8 on 47879] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:44,269 INFO  [IPC Server handler 8 on 47879] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc for DN 127.0.0.1:34128
2017-05-16 17:08:44,269 INFO  [IPC Server handler 8 on 47879] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-7c330950-5926-43f1-8128-41b19e1963ed for DN 127.0.0.1:34128
2017-05-16 17:08:44,271 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(503)) - Namenode Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid dc25b1f8-7b00-4359-b625-041c597b5d6f) service to localhost/127.0.0.1:47879 trying to claim ACTIVE state with txid=1
2017-05-16 17:08:44,271 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(515)) - Acknowledging ACTIVE Namenode Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid dc25b1f8-7b00-4359-b625-041c597b5d6f) service to localhost/127.0.0.1:47879
2017-05-16 17:08:44,272 INFO  [IPC Server handler 9 on 47879] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:44,273 INFO  [IPC Server handler 9 on 47879] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc node DatanodeRegistration(127.0.0.1, datanodeUuid=dc25b1f8-7b00-4359-b625-041c597b5d6f, infoPort=52003, ipcPort=52875, storageInfo=lv=-56;cid=testClusterID;nsid=1812171141;c=0), blocks: 0, hasStaleStorages: true, processing time: 1 msecs
2017-05-16 17:08:44,273 INFO  [IPC Server handler 9 on 47879] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-7c330950-5926-43f1-8128-41b19e1963ed,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:44,274 INFO  [IPC Server handler 9 on 47879] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-7c330950-5926-43f1-8128-41b19e1963ed node DatanodeRegistration(127.0.0.1, datanodeUuid=dc25b1f8-7b00-4359-b625-041c597b5d6f, infoPort=52003, ipcPort=52875, storageInfo=lv=-56;cid=testClusterID;nsid=1812171141;c=0), blocks: 0, hasStaleStorages: false, processing time: 1 msecs
2017-05-16 17:08:44,274 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:blockReport(514)) - Sent 1 blockreports 0 blocks total. Took 0 msec to generate and 3 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@3393dfb7
2017-05-16 17:08:44,275 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPOfferService.java:processCommandFromActive(689)) - Got finalize command for block pool BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:44,275 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlockMap
2017-05-16 17:08:44,275 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:44,275 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.5% max memory 3.5 GB = 17.9 MB
2017-05-16 17:08:44,275 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^21 = 2097152 entries
2017-05-16 17:08:44,277 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.BlockPoolSliceScanner (BlockPoolSliceScanner.java:<init>(190)) - Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:44,277 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataBlockScanner (DataBlockScanner.java:addBlockPool(264)) - Added bpid=BP-2109847274-172.17.0.4-1494947322613 to blockPoolScannerMap, new size=1
2017-05-16 17:08:44,311 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:44,316 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:44,323 INFO  [IPC Server handler 2 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:44,329 INFO  [IPC Server handler 3 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:44,343 INFO  [IPC Server handler 4 on 47879] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1. BP-2109847274-172.17.0.4-1494947322613 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]}
2017-05-16 17:08:44,351 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_2088534873_1 at /127.0.0.1:50274 [Receiving block BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001 src: /127.0.0.1:50274 dest: /127.0.0.1:34128
2017-05-16 17:08:44,371 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50274, dest: /127.0.0.1:34128, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2088534873_1, offset: 0, srvID: dc25b1f8-7b00-4359-b625-041c597b5d6f, blockid: BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001, duration: 1767459
2017-05-16 17:08:44,372 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:44,377 INFO  [IPC Server handler 6 on 47879] namenode.FSNamesystem (FSNamesystem.java:checkFileProgress(3691)) - BLOCK* checkFileProgress: blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]} has not reached minimal replication 1
2017-05-16 17:08:44,377 INFO  [IPC Server handler 6 on 47879] namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-05-16 17:08:44,377 INFO  [IPC Server handler 6 on 47879] namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-05-16 17:08:44,380 INFO  [IPC Server handler 7 on 47879] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:34128 is added to blk_1073741825_1001{blockUCState=COMMITTED, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]} size 1
2017-05-16 17:08:44,783 INFO  [IPC Server handler 8 on 47879] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1 is closed by DFSClient_NONMAPREDUCE_2088534873_1
2017-05-16 17:08:44,788 INFO  [IPC Server handler 9 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:44,792 INFO  [IPC Server handler 0 on 47879] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/2. BP-2109847274-172.17.0.4-1494947322613 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]}
2017-05-16 17:08:44,796 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_2088534873_1 at /127.0.0.1:50275 [Receiving block BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002 src: /127.0.0.1:50275 dest: /127.0.0.1:34128
2017-05-16 17:08:44,811 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50275, dest: /127.0.0.1:34128, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2088534873_1, offset: 0, srvID: dc25b1f8-7b00-4359-b625-041c597b5d6f, blockid: BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002, duration: 999882
2017-05-16 17:08:44,811 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:44,813 INFO  [IPC Server handler 1 on 47879] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:34128 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7c330950-5926-43f1-8128-41b19e1963ed:NORMAL:127.0.0.1:34128|FINALIZED]]} size 0
2017-05-16 17:08:44,814 INFO  [IPC Server handler 2 on 47879] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/2 is closed by DFSClient_NONMAPREDUCE_2088534873_1
2017-05-16 17:08:44,816 INFO  [IPC Server handler 3 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:44,821 INFO  [IPC Server handler 4 on 47879] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/3. BP-2109847274-172.17.0.4-1494947322613 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]}
2017-05-16 17:08:44,824 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_2088534873_1 at /127.0.0.1:50276 [Receiving block BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003 src: /127.0.0.1:50276 dest: /127.0.0.1:34128
2017-05-16 17:08:44,834 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50276, dest: /127.0.0.1:34128, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2088534873_1, offset: 0, srvID: dc25b1f8-7b00-4359-b625-041c597b5d6f, blockid: BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003, duration: 1421527
2017-05-16 17:08:44,835 INFO  [IPC Server handler 5 on 47879] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:34128 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]} size 0
2017-05-16 17:08:44,836 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:44,839 INFO  [IPC Server handler 6 on 47879] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/3 is closed by DFSClient_NONMAPREDUCE_2088534873_1
2017-05-16 17:08:44,841 INFO  [IPC Server handler 7 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:44,843 INFO  [IPC Server handler 8 on 47879] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/4. BP-2109847274-172.17.0.4-1494947322613 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-41c88f3f-633d-4dab-a7c2-021f1ec73dbc:NORMAL:127.0.0.1:34128|RBW]]}
2017-05-16 17:08:44,846 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_2088534873_1 at /127.0.0.1:50277 [Receiving block BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004 src: /127.0.0.1:50277 dest: /127.0.0.1:34128
2017-05-16 17:08:44,850 INFO  [IPC Server handler 9 on 47879] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:34128 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7c330950-5926-43f1-8128-41b19e1963ed:NORMAL:127.0.0.1:34128|FINALIZED]]} size 0
2017-05-16 17:08:44,851 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:50277, dest: /127.0.0.1:34128, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2088534873_1, offset: 0, srvID: dc25b1f8-7b00-4359-b625-041c597b5d6f, blockid: BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004, duration: 1231672
2017-05-16 17:08:44,851 INFO  [PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-2109847274-172.17.0.4-1494947322613:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:44,854 INFO  [IPC Server handler 0 on 47879] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/4 is closed by DFSClient_NONMAPREDUCE_2088534873_1
2017-05-16 17:08:44,857 INFO  [IPC Server handler 1 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:44,859 INFO  [IPC Server handler 2 on 47879] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:44,862 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1706)) - Shutting down the Mini HDFS Cluster
2017-05-16 17:08:44,862 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1738)) - Shutting down DataNode 0
2017-05-16 17:08:44,862 WARN  [main] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(376)) - DirectoryScanner: shutdown has been called
2017-05-16 17:08:44,862 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5ff60a8c] datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-05-16 17:08:44,886 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:44,987 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 0
2017-05-16 17:08:44,987 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 52875
2017-05-16 17:08:44,988 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:44,988 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:offerService(738)) - BPOfferService for Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid dc25b1f8-7b00-4359-b625-041c597b5d6f) service to localhost/127.0.0.1:47879 interrupted
2017-05-16 17:08:44,988 INFO  [IPC Server listener on 52875] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 52875
2017-05-16 17:08:44,988 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BPServiceActor.java:run(861)) - Ending block pool service for: Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid dc25b1f8-7b00-4359-b625-041c597b5d6f) service to localhost/127.0.0.1:47879
2017-05-16 17:08:44,988 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-2109847274-172.17.0.4-1494947322613 (Datanode Uuid dc25b1f8-7b00-4359-b625-041c597b5d6f)
2017-05-16 17:08:44,989 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] datanode.DataBlockScanner (DataBlockScanner.java:removeBlockPool(273)) - Removed bpid=BP-2109847274-172.17.0.4-1494947322613 from blockPoolScannerMap
2017-05-16 17:08:44,989 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:47879] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2217)) - Removing block pool BP-2109847274-172.17.0.4-1494947322613
2017-05-16 17:08:44,990 INFO  [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@11afe198] impl.FsDatasetImpl (FsDatasetImpl.java:run(2662)) - LazyWriter was interrupted, exiting
2017-05-16 17:08:44,990 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(172)) - Shutting down all async disk service threads
2017-05-16 17:08:44,990 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(180)) - All async disk service threads have been shut down
2017-05-16 17:08:44,990 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(161)) - Shutting down all async lazy persist service threads
2017-05-16 17:08:44,990 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(168)) - All async lazy persist service threads have been shut down
2017-05-16 17:08:44,991 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1720)) - Shutdown complete.
2017-05-16 17:08:44,991 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:44,991 INFO  [main] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1214)) - Ending log segment 1
2017-05-16 17:08:44,991 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@9fec931] namenode.FSNamesystem (FSNamesystem.java:run(5207)) - NameNodeEditLogRoller was interrupted, exiting
2017-05-16 17:08:44,991 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5cbd159f] namenode.FSNamesystem (FSNamesystem.java:run(5274)) - LazyPersistFileScrubber was interrupted, exiting
2017-05-16 17:08:44,991 INFO  [main] namenode.FSEditLog (FSEditLog.java:printStatistics(691)) - Number of transactions: 23 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 17 SyncTimes(ms): 1 1 
2017-05-16 17:08:44,992 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_0000000000000000001-0000000000000000023
2017-05-16 17:08:44,992 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_0000000000000000001-0000000000000000023
2017-05-16 17:08:44,993 INFO  [CacheReplicationMonitor(155027124)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-05-16 17:08:44,993 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 47879
2017-05-16 17:08:44,994 INFO  [IPC Server listener on 47879] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 47879
2017-05-16 17:08:44,994 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:44,994 INFO  [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor@69da0b12] blockmanagement.BlockManager (BlockManager.java:run(3533)) - Stopping ReplicationMonitor.
2017-05-16 17:08:45,001 WARN  [org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor@3f29e26] blockmanagement.DecommissionManager (DecommissionManager.java:run(78)) - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
2017-05-16 17:08:45,013 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:45,013 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1334)) - Stopping services started for standby state
2017-05-16 17:08:45,046 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:45,146 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2017-05-16 17:08:45,147 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2017-05-16 17:08:45,148 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - DataNode metrics system shutdown complete.
2017-05-16 17:08:45,168 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(442)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-05-16 17:08:45,171 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:45,171 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:45,172 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:45,172 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:45,172 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:45,172 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:45
2017-05-16 17:08:45,173 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:45,173 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,173 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:45,173 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:45,179 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:45,179 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:45,179 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:45,179 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:45,180 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:45,180 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:45,180 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:45,180 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:45,180 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:45,180 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:45,180 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:45,180 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:45,181 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:45,181 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:45,181 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:45,181 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,181 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:45,181 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:45,185 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:45,186 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:45,186 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,186 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:45,186 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:45,187 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:45,187 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:45,187 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:45,187 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:45,187 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:45,187 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:45,188 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,189 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:45,189 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:45,189 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:45,189 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:45,189 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:45,190 INFO  [main] namenode.FSImage (FSImage.java:format(145)) - Allocated new BlockPoolId: BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:45,280 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1 has been successfully formatted.
2017-05-16 17:08:45,340 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2 has been successfully formatted.
2017-05-16 17:08:45,417 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-05-16 17:08:45,418 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1367)) - createNameNode []
2017-05-16 17:08:45,419 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(124)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-05-16 17:08:45,421 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(376)) - Scheduled snapshot period at 10 second(s).
2017-05-16 17:08:45,421 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2017-05-16 17:08:45,421 INFO  [main] namenode.NameNode (NameNode.java:setClientNamenodeAddress(349)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-05-16 17:08:45,423 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1694)) - Starting Web-server for hdfs at: http://localhost:0
2017-05-16 17:08:45,424 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-05-16 17:08:45,424 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:45,425 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-05-16 17:08:45,425 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:45,425 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-05-16 17:08:45,425 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:45,426 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 39009
2017-05-16 17:08:45,426 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:45,441 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_39009_hdfs____con9od/webapp
2017-05-16 17:08:45,537 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:39009
2017-05-16 17:08:45,544 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:45,545 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:45,546 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:45,546 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:45,546 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:45,547 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:45
2017-05-16 17:08:45,547 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:45,547 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,547 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:45,547 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:45,553 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:45,554 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:45,555 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:45,555 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:45,555 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:45,555 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:45,555 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:45,555 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:45,555 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,556 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:45,556 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:45,559 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:45,559 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:45,560 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,560 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:45,560 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:45,561 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:45,561 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:45,561 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:45,561 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:45,561 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:45,561 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:45,562 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:45,562 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:45,562 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:45,563 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:45,563 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:45,563 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:45,593 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:45,627 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:45,629 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current
2017-05-16 17:08:45,629 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current
2017-05-16 17:08:45,629 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(656)) - No edit log streams selected.
2017-05-16 17:08:45,630 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(214)) - Loading 1 INodes.
2017-05-16 17:08:45,630 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(182)) - Loaded FSImage in 0 seconds.
2017-05-16 17:08:45,630 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(937)) - Loaded image for txid 0 from /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/fsimage_0000000000000000000
2017-05-16 17:08:45,631 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1027)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-05-16 17:08:45,631 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1173)) - Starting log segment at 1
2017-05-16 17:08:45,703 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-05-16 17:08:45,703 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(746)) - Finished loading FSImage in 140 msecs
2017-05-16 17:08:45,704 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(329)) - RPC server is binding to localhost:0
2017-05-16 17:08:45,704 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:45,706 INFO  [Socket Reader #1 for port 40595] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 40595
2017-05-16 17:08:45,708 INFO  [main] namenode.NameNode (NameNode.java:initialize(603)) - Clients are to use localhost:40595 to access this namenode/service.
2017-05-16 17:08:45,708 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:registerMBean(6642)) - Registered FSNamesystemState MBean
2017-05-16 17:08:45,717 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:45,717 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:45,717 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1219)) - initializing replication queues
2017-05-16 17:08:45,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5737)) - STATE* Leaving safe mode after 0 secs
2017-05-16 17:08:45,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5748)) - STATE* Network topology has 0 racks and 0 datanodes
2017-05-16 17:08:45,718 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5751)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2612)) - Total number of blocks            = 0
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2613)) - Number of invalid blocks          = 0
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2614)) - Number of under-replicated blocks = 0
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2615)) - Number of  over-replicated blocks = 0
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2617)) - Number of blocks being written    = 0
2017-05-16 17:08:45,727 INFO  [Replication Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2618)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-05-16 17:08:45,727 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:45,733 INFO  [IPC Server listener on 40595] ipc.Server (Server.java:run(674)) - IPC Server listener on 40595: starting
2017-05-16 17:08:45,740 INFO  [main] namenode.NameNode (NameNode.java:startCommonServices(646)) - NameNode RPC up at: localhost/127.0.0.1:40595
2017-05-16 17:08:45,740 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1140)) - Starting services required for active state
2017-05-16 17:08:45,745 INFO  [CacheReplicationMonitor(629264552)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-05-16 17:08:45,746 INFO  [CacheReplicationMonitor(629264552)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(178)) - Rescanning after 5382623017 milliseconds
2017-05-16 17:08:45,747 INFO  [CacheReplicationMonitor(629264552)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(201)) - Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-05-16 17:08:45,748 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1407)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1,[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2
2017-05-16 17:08:45,748 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1412)) - Starting DataNode 0 with hostname set to: localhost
2017-05-16 17:08:45,761 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2017-05-16 17:08:45,762 INFO  [main] datanode.DataNode (DataNode.java:<init>(414)) - Configured hostname is localhost
2017-05-16 17:08:45,762 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1049)) - Starting DataNode with maxLockedMemory = 0
2017-05-16 17:08:45,762 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(848)) - Opened streaming server at /127.0.0.1:53218
2017-05-16 17:08:45,762 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-05-16 17:08:45,763 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-05-16 17:08:45,763 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-05-16 17:08:45,764 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:45,764 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-05-16 17:08:45,764 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:45,764 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:45,765 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 43522
2017-05-16 17:08:45,765 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:45,767 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_43522_datanode____f0gmyl/webapp
2017-05-16 17:08:45,857 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43522
2017-05-16 17:08:45,857 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1066)) - dnUserName = root
2017-05-16 17:08:45,858 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1067)) - supergroup = supergroup
2017-05-16 17:08:45,858 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:45,863 INFO  [Socket Reader #1 for port 59507] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 59507
2017-05-16 17:08:45,865 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(723)) - Opened IPC server at /127.0.0.1:59507
2017-05-16 17:08:45,874 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-05-16 17:08:45,874 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-05-16 17:08:45,881 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:run(821)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40595 starting to offer service
2017-05-16 17:08:45,881 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:45,882 INFO  [IPC Server listener on 59507] ipc.Server (Server.java:run(674)) - IPC Server listener on 59507: starting
2017-05-16 17:08:45,918 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:45,918 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:45,932 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (DataStorage.java:recoverTransitionRead(399)) - DataNode version: -56 and NameNode layout version: -60
2017-05-16 17:08:45,972 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:45,973 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1 is not formatted for BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:45,973 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:46,020 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:46,020 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:46,056 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:46,056 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2 is not formatted for BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,056 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:46,122 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:46,123 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:46,186 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(141)) - Analyzing storage directories for bpid BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,186 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:46,186 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-602134415-172.17.0.4-1494947325190 is not formatted.
2017-05-16 17:08:46,186 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:46,186 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-602134415-172.17.0.4-1494947325190 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-602134415-172.17.0.4-1494947325190/current
2017-05-16 17:08:46,224 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:46,224 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:46,239 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:46,239 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-602134415-172.17.0.4-1494947325190 is not formatted.
2017-05-16 17:08:46,239 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:46,239 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-602134415-172.17.0.4-1494947325190 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-602134415-172.17.0.4-1494947325190/current
2017-05-16 17:08:46,276 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:46,276 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:46,325 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:46,326 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:46,362 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (DataNode.java:initStorage(1314)) - Setting up storage: nsid=1936280359;bpid=BP-602134415-172.17.0.4-1494947325190;lv=-56;nsInfo=lv=-60;cid=testClusterID;nsid=1936280359;c=0;bpid=BP-602134415-172.17.0.4-1494947325190;dnuuid=null
2017-05-16 17:08:46,427 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:46,427 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:46,447 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (DataNode.java:checkDatanodeUuid(1142)) - Generated and persisted new Datanode UUID 15347845-321a-4262-8b44-a1ea6586e2e0
2017-05-16 17:08:46,448 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current
2017-05-16 17:08:46,448 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current, StorageType: DISK
2017-05-16 17:08:46,448 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current
2017-05-16 17:08:46,448 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current, StorageType: DISK
2017-05-16 17:08:46,452 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(1804)) - Registered FSDatasetState MBean
2017-05-16 17:08:46,452 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DirectoryScanner (DirectoryScanner.java:start(330)) - Periodic Directory Tree Verification scan starting at 1494953284452 with interval 21600000
2017-05-16 17:08:46,454 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2207)) - Adding block pool BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,454 INFO  [Thread-322] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:46,455 INFO  [Thread-323] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:46,462 INFO  [Thread-322] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-602134415-172.17.0.4-1494947325190 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 8ms
2017-05-16 17:08:46,462 INFO  [Thread-323] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-602134415-172.17.0.4-1494947325190 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 7ms
2017-05-16 17:08:46,463 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(283)) - Total time to scan all replicas for block pool BP-602134415-172.17.0.4-1494947325190: 9ms
2017-05-16 17:08:46,463 INFO  [Thread-326] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:46,463 INFO  [Thread-327] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:46,463 INFO  [Thread-327] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 0ms
2017-05-16 17:08:46,463 INFO  [Thread-326] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-602134415-172.17.0.4-1494947325190 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 0ms
2017-05-16 17:08:46,464 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(162)) - Total time to add all replicas to map: 1ms
2017-05-16 17:08:46,464 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:register(781)) - Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid null) service to localhost/127.0.0.1:40595 beginning handshake with NN
2017-05-16 17:08:46,466 INFO  [IPC Server handler 7 on 40595] hdfs.StateChange (DatanodeManager.java:registerDatanode(903)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=15347845-321a-4262-8b44-a1ea6586e2e0, infoPort=43522, ipcPort=59507, storageInfo=lv=-56;cid=testClusterID;nsid=1936280359;c=0) storage 15347845-321a-4262-8b44-a1ea6586e2e0
2017-05-16 17:08:46,466 INFO  [IPC Server handler 7 on 40595] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:46,466 INFO  [IPC Server handler 7 on 40595] net.NetworkTopology (NetworkTopology.java:add(419)) - Adding a new node: /default-rack/127.0.0.1:53218
2017-05-16 17:08:46,467 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:register(794)) - Block pool Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid null) service to localhost/127.0.0.1:40595 successfully registered with NN
2017-05-16 17:08:46,467 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:offerService(653)) - For namenode localhost/127.0.0.1:40595 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-05-16 17:08:46,469 INFO  [IPC Server handler 9 on 40595] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:46,469 INFO  [IPC Server handler 9 on 40595] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-57bfda57-2be1-4a9c-986b-7062c4774deb for DN 127.0.0.1:53218
2017-05-16 17:08:46,469 INFO  [IPC Server handler 9 on 40595] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e for DN 127.0.0.1:53218
2017-05-16 17:08:46,470 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(503)) - Namenode Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid 15347845-321a-4262-8b44-a1ea6586e2e0) service to localhost/127.0.0.1:40595 trying to claim ACTIVE state with txid=1
2017-05-16 17:08:46,471 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(515)) - Acknowledging ACTIVE Namenode Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid 15347845-321a-4262-8b44-a1ea6586e2e0) service to localhost/127.0.0.1:40595
2017-05-16 17:08:46,472 INFO  [IPC Server handler 8 on 40595] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:46,472 INFO  [IPC Server handler 8 on 40595] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e node DatanodeRegistration(127.0.0.1, datanodeUuid=15347845-321a-4262-8b44-a1ea6586e2e0, infoPort=43522, ipcPort=59507, storageInfo=lv=-56;cid=testClusterID;nsid=1936280359;c=0), blocks: 0, hasStaleStorages: true, processing time: 0 msecs
2017-05-16 17:08:46,472 INFO  [IPC Server handler 8 on 40595] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-57bfda57-2be1-4a9c-986b-7062c4774deb,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:46,472 INFO  [IPC Server handler 8 on 40595] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-57bfda57-2be1-4a9c-986b-7062c4774deb node DatanodeRegistration(127.0.0.1, datanodeUuid=15347845-321a-4262-8b44-a1ea6586e2e0, infoPort=43522, ipcPort=59507, storageInfo=lv=-56;cid=testClusterID;nsid=1936280359;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-05-16 17:08:46,473 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:blockReport(514)) - Sent 1 blockreports 0 blocks total. Took 0 msec to generate and 2 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@1681873f
2017-05-16 17:08:46,473 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPOfferService.java:processCommandFromActive(689)) - Got finalize command for block pool BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,474 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlockMap
2017-05-16 17:08:46,474 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:46,475 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.5% max memory 3.5 GB = 17.9 MB
2017-05-16 17:08:46,475 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^21 = 2097152 entries
2017-05-16 17:08:46,478 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.BlockPoolSliceScanner (BlockPoolSliceScanner.java:<init>(190)) - Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,479 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataBlockScanner (DataBlockScanner.java:addBlockPool(264)) - Added bpid=BP-602134415-172.17.0.4-1494947325190 to blockPoolScannerMap, new size=1
2017-05-16 17:08:46,529 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:46,536 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:46,539 INFO  [IPC Server handler 2 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:46,542 INFO  [IPC Server handler 3 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:46,545 INFO  [IPC Server handler 4 on 40595] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1.txt. BP-602134415-172.17.0.4-1494947325190 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-57bfda57-2be1-4a9c-986b-7062c4774deb:NORMAL:127.0.0.1:53218|RBW]]}
2017-05-16 17:08:46,548 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_922753754_1 at /127.0.0.1:55850 [Receiving block BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001 src: /127.0.0.1:55850 dest: /127.0.0.1:53218
2017-05-16 17:08:46,557 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:55850, dest: /127.0.0.1:53218, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_922753754_1, offset: 0, srvID: 15347845-321a-4262-8b44-a1ea6586e2e0, blockid: BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001, duration: 1203642
2017-05-16 17:08:46,558 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:46,558 INFO  [IPC Server handler 6 on 40595] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53218 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-57bfda57-2be1-4a9c-986b-7062c4774deb:NORMAL:127.0.0.1:53218|RBW]]} size 0
2017-05-16 17:08:46,560 INFO  [IPC Server handler 6 on 40595] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1.txt is closed by DFSClient_NONMAPREDUCE_922753754_1
2017-05-16 17:08:46,562 INFO  [IPC Server handler 9 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/2.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:46,566 INFO  [IPC Server handler 8 on 40595] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/2.txt. BP-602134415-172.17.0.4-1494947325190 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-57bfda57-2be1-4a9c-986b-7062c4774deb:NORMAL:127.0.0.1:53218|RBW]]}
2017-05-16 17:08:46,567 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_922753754_1 at /127.0.0.1:55851 [Receiving block BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002 src: /127.0.0.1:55851 dest: /127.0.0.1:53218
2017-05-16 17:08:46,574 INFO  [IPC Server handler 0 on 40595] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53218 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e:NORMAL:127.0.0.1:53218|FINALIZED]]} size 0
2017-05-16 17:08:46,574 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:55851, dest: /127.0.0.1:53218, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_922753754_1, offset: 0, srvID: 15347845-321a-4262-8b44-a1ea6586e2e0, blockid: BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002, duration: 1958770
2017-05-16 17:08:46,574 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:46,576 INFO  [IPC Server handler 1 on 40595] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/2.txt is closed by DFSClient_NONMAPREDUCE_922753754_1
2017-05-16 17:08:46,581 INFO  [IPC Server handler 2 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/3.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:46,590 INFO  [IPC Server handler 3 on 40595] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/3.txt. BP-602134415-172.17.0.4-1494947325190 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e:NORMAL:127.0.0.1:53218|RBW]]}
2017-05-16 17:08:46,671 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_922753754_1 at /127.0.0.1:55852 [Receiving block BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003 src: /127.0.0.1:55852 dest: /127.0.0.1:53218
2017-05-16 17:08:46,674 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:55852, dest: /127.0.0.1:53218, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_922753754_1, offset: 0, srvID: 15347845-321a-4262-8b44-a1ea6586e2e0, blockid: BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003, duration: 988725
2017-05-16 17:08:46,674 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:46,674 INFO  [IPC Server handler 4 on 40595] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53218 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-57bfda57-2be1-4a9c-986b-7062c4774deb:NORMAL:127.0.0.1:53218|FINALIZED]]} size 0
2017-05-16 17:08:46,676 INFO  [IPC Server handler 5 on 40595] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/3.txt is closed by DFSClient_NONMAPREDUCE_922753754_1
2017-05-16 17:08:46,678 INFO  [IPC Server handler 7 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/4.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:46,680 INFO  [IPC Server handler 6 on 40595] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/4.txt. BP-602134415-172.17.0.4-1494947325190 blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e:NORMAL:127.0.0.1:53218|RBW]]}
2017-05-16 17:08:46,681 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_922753754_1 at /127.0.0.1:55853 [Receiving block BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004 src: /127.0.0.1:55853 dest: /127.0.0.1:53218
2017-05-16 17:08:46,684 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:55853, dest: /127.0.0.1:53218, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_922753754_1, offset: 0, srvID: 15347845-321a-4262-8b44-a1ea6586e2e0, blockid: BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004, duration: 1275755
2017-05-16 17:08:46,684 INFO  [PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-602134415-172.17.0.4-1494947325190:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:46,685 INFO  [IPC Server handler 9 on 40595] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:53218 is added to blk_1073741828_1004{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-9f4ec4e3-a41a-4239-bf6f-a162a212d67e:NORMAL:127.0.0.1:53218|RBW]]} size 0
2017-05-16 17:08:46,691 INFO  [IPC Server handler 8 on 40595] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/4.txt is closed by DFSClient_NONMAPREDUCE_922753754_1
2017-05-16 17:08:46,692 INFO  [IPC Server handler 0 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,693 INFO  [IPC Server handler 1 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/minidfsTest	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,703 INFO  [IPC Server handler 2 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/minidfsTest/1.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,741 INFO  [IPC Server handler 3 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/minidfsTest/2.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,744 INFO  [IPC Server handler 4 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/minidfsTest/3.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,750 INFO  [IPC Server handler 5 on 40595] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/minidfsTest/4.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:46,752 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1706)) - Shutting down the Mini HDFS Cluster
2017-05-16 17:08:46,752 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1738)) - Shutting down DataNode 0
2017-05-16 17:08:46,753 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6ab7ce48] datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-05-16 17:08:46,753 WARN  [main] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(376)) - DirectoryScanner: shutdown has been called
2017-05-16 17:08:46,763 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:46,864 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 1
2017-05-16 17:08:46,866 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 0
2017-05-16 17:08:46,866 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 59507
2017-05-16 17:08:46,867 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:46,867 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:offerService(738)) - BPOfferService for Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid 15347845-321a-4262-8b44-a1ea6586e2e0) service to localhost/127.0.0.1:40595 interrupted
2017-05-16 17:08:46,867 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BPServiceActor.java:run(861)) - Ending block pool service for: Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid 15347845-321a-4262-8b44-a1ea6586e2e0) service to localhost/127.0.0.1:40595
2017-05-16 17:08:46,867 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-602134415-172.17.0.4-1494947325190 (Datanode Uuid 15347845-321a-4262-8b44-a1ea6586e2e0)
2017-05-16 17:08:46,867 INFO  [IPC Server listener on 59507] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 59507
2017-05-16 17:08:46,867 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] datanode.DataBlockScanner (DataBlockScanner.java:removeBlockPool(273)) - Removed bpid=BP-602134415-172.17.0.4-1494947325190 from blockPoolScannerMap
2017-05-16 17:08:46,868 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:40595] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2217)) - Removing block pool BP-602134415-172.17.0.4-1494947325190
2017-05-16 17:08:46,868 INFO  [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@1a53f8a2] impl.FsDatasetImpl (FsDatasetImpl.java:run(2662)) - LazyWriter was interrupted, exiting
2017-05-16 17:08:46,869 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(172)) - Shutting down all async disk service threads
2017-05-16 17:08:46,869 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(180)) - All async disk service threads have been shut down
2017-05-16 17:08:46,869 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(161)) - Shutting down all async lazy persist service threads
2017-05-16 17:08:46,869 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(168)) - All async lazy persist service threads have been shut down
2017-05-16 17:08:46,869 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1720)) - Shutdown complete.
2017-05-16 17:08:46,869 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:46,870 INFO  [main] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1214)) - Ending log segment 1
2017-05-16 17:08:46,870 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6aba5d30] namenode.FSNamesystem (FSNamesystem.java:run(5207)) - NameNodeEditLogRoller was interrupted, exiting
2017-05-16 17:08:46,870 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@61d34b4] namenode.FSNamesystem (FSNamesystem.java:run(5274)) - LazyPersistFileScrubber was interrupted, exiting
2017-05-16 17:08:46,870 INFO  [main] namenode.FSEditLog (FSEditLog.java:printStatistics(691)) - Number of transactions: 23 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 16 SyncTimes(ms): 2 1 
2017-05-16 17:08:46,871 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_0000000000000000001-0000000000000000023
2017-05-16 17:08:46,871 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_0000000000000000001-0000000000000000023
2017-05-16 17:08:46,871 INFO  [CacheReplicationMonitor(629264552)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-05-16 17:08:46,872 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 40595
2017-05-16 17:08:46,872 INFO  [IPC Server listener on 40595] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 40595
2017-05-16 17:08:46,873 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:46,873 INFO  [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor@3fc05ea2] blockmanagement.BlockManager (BlockManager.java:run(3533)) - Stopping ReplicationMonitor.
2017-05-16 17:08:46,873 WARN  [org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor@2009f9b0] blockmanagement.DecommissionManager (DecommissionManager.java:run(78)) - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
2017-05-16 17:08:46,879 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:46,880 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1334)) - Stopping services started for standby state
2017-05-16 17:08:46,882 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:46,983 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2017-05-16 17:08:46,984 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2017-05-16 17:08:46,984 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - DataNode metrics system shutdown complete.
2017-05-16 17:08:47,003 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(442)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-05-16 17:08:47,005 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:47,006 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:47,006 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:47,006 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:47,007 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:47,007 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:47
2017-05-16 17:08:47,007 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:47,007 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,007 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:47,007 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:47,015 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:47,016 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:47,016 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:47,016 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:47,016 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:47,016 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:47,016 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:47,017 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:47,017 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:47,017 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,017 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:47,017 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:47,021 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:47,022 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:47,022 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,022 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:47,022 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:47,023 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:47,023 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:47,024 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:47,024 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:47,024 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:47,024 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:47,024 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,024 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:47,024 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:47,025 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:47,025 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:47,025 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:47,026 INFO  [main] namenode.FSImage (FSImage.java:format(145)) - Allocated new BlockPoolId: BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:47,108 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1 has been successfully formatted.
2017-05-16 17:08:47,184 INFO  [main] common.Storage (NNStorage.java:format(552)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2 has been successfully formatted.
2017-05-16 17:08:47,376 INFO  [main] namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-05-16 17:08:47,377 INFO  [main] namenode.NameNode (NameNode.java:createNameNode(1367)) - createNameNode []
2017-05-16 17:08:47,378 WARN  [main] impl.MetricsConfig (MetricsConfig.java:loadFirst(124)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-05-16 17:08:47,378 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(376)) - Scheduled snapshot period at 10 second(s).
2017-05-16 17:08:47,378 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2017-05-16 17:08:47,379 INFO  [main] namenode.NameNode (NameNode.java:setClientNamenodeAddress(349)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-05-16 17:08:47,381 INFO  [main] hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1694)) - Starting Web-server for hdfs at: http://localhost:0
2017-05-16 17:08:47,381 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-05-16 17:08:47,382 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:47,382 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-05-16 17:08:47,382 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:47,383 INFO  [main] http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-05-16 17:08:47,383 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:47,383 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 54849
2017-05-16 17:08:47,384 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:47,393 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_54849_hdfs____polnc8/webapp
2017-05-16 17:08:47,480 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:54849
2017-05-16 17:08:47,481 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - No KeyProvider found.
2017-05-16 17:08:47,482 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(786)) - fsLock is fair:true
2017-05-16 17:08:47,482 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(232)) - dfs.block.invalidate.limit=1000
2017-05-16 17:08:47,482 INFO  [main] blockmanagement.DatanodeManager (DatanodeManager.java:<init>(238)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-05-16 17:08:47,483 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-05-16 17:08:47,483 INFO  [main] blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 May 16 17:08:47
2017-05-16 17:08:47,483 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-05-16 17:08:47,483 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,483 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.5 GB = 71.4 MB
2017-05-16 17:08:47,484 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(364)) - dfs.block.access.token.enable=false
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(349)) - defaultReplication         = 1
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(350)) - maxReplication             = 512
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(351)) - minReplication             = 1
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(352)) - maxReplicationStreams      = 2
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(353)) - shouldCheckForEnoughRacks  = false
2017-05-16 17:08:47,491 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(354)) - replicationRecheckInterval = 3000
2017-05-16 17:08:47,492 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(355)) - encryptDataTransfer        = false
2017-05-16 17:08:47,492 INFO  [main] blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxNumBlocksToLog          = 1000
2017-05-16 17:08:47,492 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(809)) - fsOwner             = root (auth:SIMPLE)
2017-05-16 17:08:47,492 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(810)) - supergroup          = supergroup
2017-05-16 17:08:47,492 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(811)) - isPermissionEnabled = true
2017-05-16 17:08:47,492 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(822)) - HA Enabled: false
2017-05-16 17:08:47,492 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(859)) - Append Enabled: true
2017-05-16 17:08:47,493 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-05-16 17:08:47,493 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,493 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.5 GB = 35.7 MB
2017-05-16 17:08:47,493 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-05-16 17:08:47,497 INFO  [main] namenode.NameNode (FSDirectory.java:<init>(234)) - Caching file names occuring more than 10 times
2017-05-16 17:08:47,497 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-05-16 17:08:47,497 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,498 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.5 GB = 8.9 MB
2017-05-16 17:08:47,498 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-05-16 17:08:47,499 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5663)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-05-16 17:08:47,499 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5664)) - dfs.namenode.safemode.min.datanodes = 0
2017-05-16 17:08:47,499 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:<init>(5665)) - dfs.namenode.safemode.extension     = 0
2017-05-16 17:08:47,499 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(957)) - Retry cache on namenode is enabled
2017-05-16 17:08:47,499 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initRetryCache(965)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-05-16 17:08:47,499 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-05-16 17:08:47,500 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:47,500 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.5 GB = 1.1 MB
2017-05-16 17:08:47,500 INFO  [main] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-05-16 17:08:47,501 INFO  [main] namenode.NNConf (NNConf.java:<init>(62)) - ACLs enabled? false
2017-05-16 17:08:47,501 INFO  [main] namenode.NNConf (NNConf.java:<init>(66)) - XAttrs enabled? true
2017-05-16 17:08:47,501 INFO  [main] namenode.NNConf (NNConf.java:<init>(74)) - Maximum size of an xattr: 16384
2017-05-16 17:08:47,855 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:47,889 INFO  [main] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:47,891 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current
2017-05-16 17:08:47,891 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current
2017-05-16 17:08:47,891 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(656)) - No edit log streams selected.
2017-05-16 17:08:47,892 INFO  [main] namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(214)) - Loading 1 INodes.
2017-05-16 17:08:47,892 INFO  [main] namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(182)) - Loaded FSImage in 0 seconds.
2017-05-16 17:08:47,892 INFO  [main] namenode.FSImage (FSImage.java:loadFSImage(937)) - Loaded image for txid 0 from /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/fsimage_0000000000000000000
2017-05-16 17:08:47,893 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1027)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-05-16 17:08:47,893 INFO  [main] namenode.FSEditLog (FSEditLog.java:startLogSegment(1173)) - Starting log segment at 1
2017-05-16 17:08:47,957 INFO  [main] namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-05-16 17:08:47,958 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(746)) - Finished loading FSImage in 457 msecs
2017-05-16 17:08:47,958 INFO  [main] namenode.NameNode (NameNodeRpcServer.java:<init>(329)) - RPC server is binding to localhost:0
2017-05-16 17:08:47,958 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:47,961 INFO  [main] namenode.NameNode (NameNode.java:initialize(603)) - Clients are to use localhost:51315 to access this namenode/service.
2017-05-16 17:08:47,962 INFO  [Socket Reader #1 for port 51315] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 51315
2017-05-16 17:08:47,969 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:registerMBean(6642)) - Registered FSNamesystemState MBean
2017-05-16 17:08:47,981 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:47,981 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(6253)) - Number of blocks under construction: 0
2017-05-16 17:08:47,981 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1219)) - initializing replication queues
2017-05-16 17:08:47,981 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5737)) - STATE* Leaving safe mode after 0 secs
2017-05-16 17:08:47,981 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5748)) - STATE* Network topology has 0 racks and 0 datanodes
2017-05-16 17:08:47,982 INFO  [main] hdfs.StateChange (FSNamesystem.java:leave(5751)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-05-16 17:08:47,989 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2612)) - Total number of blocks            = 0
2017-05-16 17:08:47,989 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2613)) - Number of invalid blocks          = 0
2017-05-16 17:08:47,989 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2614)) - Number of under-replicated blocks = 0
2017-05-16 17:08:47,989 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2615)) - Number of  over-replicated blocks = 0
2017-05-16 17:08:47,989 INFO  [Replication Queue Initializer] blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2617)) - Number of blocks being written    = 0
2017-05-16 17:08:47,990 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:47,992 INFO  [Replication Queue Initializer] hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2618)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2017-05-16 17:08:47,992 INFO  [IPC Server listener on 51315] ipc.Server (Server.java:run(674)) - IPC Server listener on 51315: starting
2017-05-16 17:08:47,998 INFO  [main] namenode.NameNode (NameNode.java:startCommonServices(646)) - NameNode RPC up at: localhost/127.0.0.1:51315
2017-05-16 17:08:47,998 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1140)) - Starting services required for active state
2017-05-16 17:08:47,998 INFO  [CacheReplicationMonitor(1217929608)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-05-16 17:08:47,999 INFO  [CacheReplicationMonitor(1217929608)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(178)) - Rescanning after 5382625270 milliseconds
2017-05-16 17:08:48,000 INFO  [CacheReplicationMonitor(1217929608)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(201)) - Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-05-16 17:08:48,003 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1407)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1,[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2
2017-05-16 17:08:48,003 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1412)) - Starting DataNode 0 with hostname set to: localhost
2017-05-16 17:08:48,011 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2017-05-16 17:08:48,011 INFO  [main] datanode.DataNode (DataNode.java:<init>(414)) - Configured hostname is localhost
2017-05-16 17:08:48,011 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1049)) - Starting DataNode with maxLockedMemory = 0
2017-05-16 17:08:48,012 INFO  [main] datanode.DataNode (DataNode.java:initDataXceiver(848)) - Opened streaming server at /127.0.0.1:47126
2017-05-16 17:08:48,012 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-05-16 17:08:48,012 INFO  [main] datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-05-16 17:08:48,012 INFO  [main] http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-05-16 17:08:48,013 INFO  [main] http.HttpServer2 (HttpServer2.java:addGlobalFilter(699)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-05-16 17:08:48,013 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(677)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-05-16 17:08:48,013 INFO  [main] http.HttpServer2 (HttpServer2.java:addFilter(684)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-05-16 17:08:48,014 INFO  [main] http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(603)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-05-16 17:08:48,014 INFO  [main] http.HttpServer2 (HttpServer2.java:openListeners(887)) - Jetty bound to port 45870
2017-05-16 17:08:48,014 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-05-16 17:08:48,017 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Extract jar:file:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_45870_datanode____.u7icdl/webapp
2017-05-16 17:08:48,118 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:45870
2017-05-16 17:08:48,119 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1066)) - dnUserName = root
2017-05-16 17:08:48,119 INFO  [main] datanode.DataNode (DataNode.java:startDataNode(1067)) - supergroup = supergroup
2017-05-16 17:08:48,120 INFO  [main] ipc.CallQueueManager (CallQueueManager.java:<init>(53)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-05-16 17:08:48,127 INFO  [Socket Reader #1 for port 42799] ipc.Server (Server.java:run(605)) - Starting Socket Reader #1 for port 42799
2017-05-16 17:08:48,134 INFO  [main] datanode.DataNode (DataNode.java:initIpcServer(723)) - Opened IPC server at /127.0.0.1:42799
2017-05-16 17:08:48,135 INFO  [main] datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-05-16 17:08:48,136 INFO  [main] datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-05-16 17:08:48,136 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:run(821)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:51315 starting to offer service
2017-05-16 17:08:48,138 INFO  [IPC Server Responder] ipc.Server (Server.java:run(827)) - IPC Server Responder: starting
2017-05-16 17:08:48,138 INFO  [IPC Server listener on 42799] ipc.Server (Server.java:run(674)) - IPC Server listener on 42799: starting
2017-05-16 17:08:48,162 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,162 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,163 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (DataStorage.java:recoverTransitionRead(399)) - DataNode version: -56 and NameNode layout version: -60
2017-05-16 17:08:48,252 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:48,252 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1 is not formatted for BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,252 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:48,264 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,264 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,366 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,366 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,388 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (Storage.java:tryLock(715)) - Lock on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/in_use.lock acquired by nodename 234@repairnator
2017-05-16 17:08:48,389 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (DataStorage.java:addStorageLocations(281)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2 is not formatted for BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,389 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (DataStorage.java:addStorageLocations(283)) - Formatting ...
2017-05-16 17:08:48,469 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,469 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,552 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(141)) - Analyzing storage directories for bpid BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,552 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:48,552 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-920202634-172.17.0.4-1494947327026 is not formatted.
2017-05-16 17:08:48,552 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:48,552 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-920202634-172.17.0.4-1494947327026 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current/BP-920202634-172.17.0.4-1494947327026/current
2017-05-16 17:08:48,571 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,571 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,592 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (Storage.java:lock(675)) - Locking is disabled
2017-05-16 17:08:48,592 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(172)) - Storage directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-920202634-172.17.0.4-1494947327026 is not formatted.
2017-05-16 17:08:48,592 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(173)) - Formatting ...
2017-05-16 17:08:48,593 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:format(225)) - Formatting block pool BP-920202634-172.17.0.4-1494947327026 directory /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current/BP-920202634-172.17.0.4-1494947327026/current
2017-05-16 17:08:48,672 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,672 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,681 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:48,681 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] common.Storage (BlockPoolSliceStorage.java:doTransition(313)) - Restored 0 block files from trash.
2017-05-16 17:08:48,773 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,773 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,794 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (DataNode.java:initStorage(1314)) - Setting up storage: nsid=555450819;bpid=BP-920202634-172.17.0.4-1494947327026;lv=-56;nsInfo=lv=-60;cid=testClusterID;nsid=555450819;c=0;bpid=BP-920202634-172.17.0.4-1494947327026;dnuuid=null
2017-05-16 17:08:48,875 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,875 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,965 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (DataNode.java:checkDatanodeUuid(1142)) - Generated and persisted new Datanode UUID b3d1953c-f34b-4dbf-8548-6569241fdb1b
2017-05-16 17:08:48,965 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current
2017-05-16 17:08:48,965 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current, StorageType: DISK
2017-05-16 17:08:48,965 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsVolumeList.java:addVolume(222)) - Added new volume: /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current
2017-05-16 17:08:48,966 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(317)) - Added volume - /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current, StorageType: DISK
2017-05-16 17:08:48,966 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(1804)) - Registered FSDatasetState MBean
2017-05-16 17:08:48,966 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DirectoryScanner (DirectoryScanner.java:start(330)) - Periodic Directory Tree Verification scan starting at 1494963319966 with interval 21600000
2017-05-16 17:08:48,966 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2207)) - Adding block pool BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,967 INFO  [Thread-410] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:48,967 INFO  [Thread-411] impl.FsDatasetImpl (FsVolumeList.java:run(254)) - Scanning block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:48,971 INFO  [Thread-411] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-920202634-172.17.0.4-1494947327026 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 3ms
2017-05-16 17:08:48,980 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2230)) - dnInfo.length != numDataNodes
2017-05-16 17:08:48,980 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2182)) - Waiting for cluster to become active
2017-05-16 17:08:48,981 INFO  [Thread-410] impl.FsDatasetImpl (FsVolumeList.java:run(259)) - Time taken to scan block pool BP-920202634-172.17.0.4-1494947327026 on /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 14ms
2017-05-16 17:08:48,981 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(283)) - Total time to scan all replicas for block pool BP-920202634-172.17.0.4-1494947327026: 14ms
2017-05-16 17:08:48,982 INFO  [Thread-414] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current...
2017-05-16 17:08:48,982 INFO  [Thread-414] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/current: 0ms
2017-05-16 17:08:48,989 INFO  [Thread-415] impl.FsDatasetImpl (FsVolumeList.java:run(134)) - Adding replicas to map for block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current...
2017-05-16 17:08:48,989 INFO  [Thread-415] impl.FsDatasetImpl (FsVolumeList.java:run(139)) - Time to add replicas to map for block pool BP-920202634-172.17.0.4-1494947327026 on volume /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/current: 0ms
2017-05-16 17:08:48,989 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(162)) - Total time to add all replicas to map: 8ms
2017-05-16 17:08:48,989 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:register(781)) - Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid null) service to localhost/127.0.0.1:51315 beginning handshake with NN
2017-05-16 17:08:48,990 INFO  [IPC Server handler 0 on 51315] hdfs.StateChange (DatanodeManager.java:registerDatanode(903)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, datanodeUuid=b3d1953c-f34b-4dbf-8548-6569241fdb1b, infoPort=45870, ipcPort=42799, storageInfo=lv=-56;cid=testClusterID;nsid=555450819;c=0) storage b3d1953c-f34b-4dbf-8548-6569241fdb1b
2017-05-16 17:08:48,991 INFO  [IPC Server handler 0 on 51315] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:48,991 INFO  [IPC Server handler 0 on 51315] net.NetworkTopology (NetworkTopology.java:add(419)) - Adding a new node: /default-rack/127.0.0.1:47126
2017-05-16 17:08:48,992 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:register(794)) - Block pool Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid null) service to localhost/127.0.0.1:51315 successfully registered with NN
2017-05-16 17:08:48,992 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:offerService(653)) - For namenode localhost/127.0.0.1:51315 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-05-16 17:08:48,993 INFO  [IPC Server handler 1 on 51315] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(388)) - Number of failed storage changes from 0 to 0
2017-05-16 17:08:48,993 INFO  [IPC Server handler 1 on 51315] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-f00f4c0f-e6cb-44b0-b659-1a184f045efd for DN 127.0.0.1:47126
2017-05-16 17:08:48,993 INFO  [IPC Server handler 1 on 51315] blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(743)) - Adding new storage ID DS-46a8f775-2b0f-41f1-b3f6-05c53363cd05 for DN 127.0.0.1:47126
2017-05-16 17:08:48,994 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(503)) - Namenode Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid b3d1953c-f34b-4dbf-8548-6569241fdb1b) service to localhost/127.0.0.1:51315 trying to claim ACTIVE state with txid=1
2017-05-16 17:08:48,994 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(515)) - Acknowledging ACTIVE Namenode Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid b3d1953c-f34b-4dbf-8548-6569241fdb1b) service to localhost/127.0.0.1:51315
2017-05-16 17:08:48,995 INFO  [IPC Server handler 2 on 51315] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-f00f4c0f-e6cb-44b0-b659-1a184f045efd,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:48,995 INFO  [IPC Server handler 2 on 51315] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-f00f4c0f-e6cb-44b0-b659-1a184f045efd node DatanodeRegistration(127.0.0.1, datanodeUuid=b3d1953c-f34b-4dbf-8548-6569241fdb1b, infoPort=45870, ipcPort=42799, storageInfo=lv=-56;cid=testClusterID;nsid=555450819;c=0), blocks: 0, hasStaleStorages: true, processing time: 0 msecs
2017-05-16 17:08:48,995 INFO  [IPC Server handler 2 on 51315] blockmanagement.BlockManager (BlockManager.java:processReport(1815)) - BLOCK* processReport: Received first block report from DatanodeStorage[DS-46a8f775-2b0f-41f1-b3f6-05c53363cd05,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-05-16 17:08:48,995 INFO  [IPC Server handler 2 on 51315] BlockStateChange (BlockManager.java:processReport(1831)) - BLOCK* processReport: from storage DS-46a8f775-2b0f-41f1-b3f6-05c53363cd05 node DatanodeRegistration(127.0.0.1, datanodeUuid=b3d1953c-f34b-4dbf-8548-6569241fdb1b, infoPort=45870, ipcPort=42799, storageInfo=lv=-56;cid=testClusterID;nsid=555450819;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-05-16 17:08:48,996 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:blockReport(514)) - Sent 1 blockreports 0 blocks total. Took 0 msec to generate and 2 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@238f3385
2017-05-16 17:08:48,996 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPOfferService.java:processCommandFromActive(689)) - Got finalize command for block pool BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,997 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlockMap
2017-05-16 17:08:48,997 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-05-16 17:08:48,997 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.5% max memory 3.5 GB = 17.9 MB
2017-05-16 17:08:48,997 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^21 = 2097152 entries
2017-05-16 17:08:48,999 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.BlockPoolSliceScanner (BlockPoolSliceScanner.java:<init>(190)) - Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:48,999 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataBlockScanner (DataBlockScanner.java:addBlockPool(264)) - Added bpid=BP-920202634-172.17.0.4-1494947327026 to blockPoolScannerMap, new size=1
2017-05-16 17:08:49,083 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:49,088 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2213)) - Cluster is active
2017-05-16 17:08:49,091 INFO  [IPC Server handler 5 on 51315] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/minidfsTest	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2017-05-16 17:08:49,094 INFO  [IPC Server handler 6 on 51315] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/minidfsTest/1.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2017-05-16 17:08:49,104 INFO  [IPC Server handler 7 on 51315] hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3660)) - BLOCK* allocateBlock: /minidfsTest/1.txt. BP-920202634-172.17.0.4-1494947327026 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-f00f4c0f-e6cb-44b0-b659-1a184f045efd:NORMAL:127.0.0.1:47126|RBW]]}
2017-05-16 17:08:49,110 INFO  [DataXceiver for client DFSClient_NONMAPREDUCE_974807945_1 at /127.0.0.1:51869 [Receiving block BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001]] datanode.DataNode (DataXceiver.java:writeBlock(593)) - Receiving BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001 src: /127.0.0.1:51869 dest: /127.0.0.1:47126
2017-05-16 17:08:49,115 INFO  [PacketResponder: BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1292)) - src: /127.0.0.1:51869, dest: /127.0.0.1:47126, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_974807945_1, offset: 0, srvID: b3d1953c-f34b-4dbf-8548-6569241fdb1b, blockid: BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001, duration: 503185
2017-05-16 17:08:49,115 INFO  [PacketResponder: BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[]] datanode.DataNode (BlockReceiver.java:run(1273)) - PacketResponder: BP-920202634-172.17.0.4-1494947327026:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-05-16 17:08:49,116 INFO  [IPC Server handler 9 on 51315] BlockStateChange (BlockManager.java:logAddStoredBlock(2473)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:47126 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-f00f4c0f-e6cb-44b0-b659-1a184f045efd:NORMAL:127.0.0.1:47126|RBW]]} size 0
2017-05-16 17:08:49,121 INFO  [IPC Server handler 0 on 51315] hdfs.StateChange (FSNamesystem.java:completeFile(3581)) - DIR* completeFile: /minidfsTest/1.txt is closed by DFSClient_NONMAPREDUCE_974807945_1
2017-05-16 17:08:49,123 INFO  [IPC Server handler 1 on 51315] FSNamesystem.audit (FSNamesystem.java:logAuditMessage(9332)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/minidfsTest/1.txt	dst=null	perm=null	proto=rpc
2017-05-16 17:08:49,124 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1706)) - Shutting down the Mini HDFS Cluster
2017-05-16 17:08:49,124 INFO  [main] hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1738)) - Shutting down DataNode 0
2017-05-16 17:08:49,124 WARN  [main] datanode.DirectoryScanner (DirectoryScanner.java:shutdown(376)) - DirectoryScanner: shutdown has been called
2017-05-16 17:08:49,125 INFO  [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@720bf653] datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-05-16 17:08:49,132 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:49,233 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1655)) - Waiting for threadgroup to exit, active threads is 0
2017-05-16 17:08:49,233 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 42799
2017-05-16 17:08:49,234 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:49,234 INFO  [IPC Server listener on 42799] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 42799
2017-05-16 17:08:49,235 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:offerService(738)) - BPOfferService for Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid b3d1953c-f34b-4dbf-8548-6569241fdb1b) service to localhost/127.0.0.1:51315 interrupted
2017-05-16 17:08:49,235 WARN  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BPServiceActor.java:run(861)) - Ending block pool service for: Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid b3d1953c-f34b-4dbf-8548-6569241fdb1b) service to localhost/127.0.0.1:51315
2017-05-16 17:08:49,235 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-920202634-172.17.0.4-1494947327026 (Datanode Uuid b3d1953c-f34b-4dbf-8548-6569241fdb1b)
2017-05-16 17:08:49,235 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] datanode.DataBlockScanner (DataBlockScanner.java:removeBlockPool(273)) - Removed bpid=BP-920202634-172.17.0.4-1494947327026 from blockPoolScannerMap
2017-05-16 17:08:49,235 INFO  [DataNode: [[[DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data1/, [DISK]file:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/data/data2/]]  heartbeating to localhost/127.0.0.1:51315] impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2217)) - Removing block pool BP-920202634-172.17.0.4-1494947327026
2017-05-16 17:08:49,236 INFO  [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@3c4b326a] impl.FsDatasetImpl (FsDatasetImpl.java:run(2662)) - LazyWriter was interrupted, exiting
2017-05-16 17:08:49,236 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(172)) - Shutting down all async disk service threads
2017-05-16 17:08:49,236 INFO  [main] impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(180)) - All async disk service threads have been shut down
2017-05-16 17:08:49,236 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(161)) - Shutting down all async lazy persist service threads
2017-05-16 17:08:49,237 INFO  [main] impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(168)) - All async lazy persist service threads have been shut down
2017-05-16 17:08:49,237 INFO  [main] datanode.DataNode (DataNode.java:shutdown(1720)) - Shutdown complete.
2017-05-16 17:08:49,237 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:49,237 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@b16e202] namenode.FSNamesystem (FSNamesystem.java:run(5274)) - LazyPersistFileScrubber was interrupted, exiting
2017-05-16 17:08:49,237 INFO  [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@14fa92af] namenode.FSNamesystem (FSNamesystem.java:run(5207)) - NameNodeEditLogRoller was interrupted, exiting
2017-05-16 17:08:49,237 INFO  [main] namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1214)) - Ending log segment 1
2017-05-16 17:08:49,237 INFO  [main] namenode.FSEditLog (FSEditLog.java:printStatistics(691)) - Number of transactions: 8 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 1 2 
2017-05-16 17:08:49,238 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name1/current/edits_0000000000000000001-0000000000000000008
2017-05-16 17:08:49,238 INFO  [main] namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_inprogress_0000000000000000001 -> /root/workspace/apache/incubator-samoa/232818360/samoa-api/target/build/test/data/dfs/name2/current/edits_0000000000000000001-0000000000000000008
2017-05-16 17:08:49,239 INFO  [CacheReplicationMonitor(1217929608)] blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-05-16 17:08:49,239 INFO  [main] ipc.Server (Server.java:stop(2437)) - Stopping server on 51315
2017-05-16 17:08:49,240 INFO  [IPC Server listener on 51315] ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 51315
2017-05-16 17:08:49,241 INFO  [IPC Server Responder] ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
2017-05-16 17:08:49,241 INFO  [org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$ReplicationMonitor@44b194fe] blockmanagement.BlockManager (BlockManager.java:run(3533)) - Stopping ReplicationMonitor.
2017-05-16 17:08:49,241 WARN  [org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager$Monitor@68880c21] blockmanagement.DecommissionManager (DecommissionManager.java:run(78)) - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
2017-05-16 17:08:49,247 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1246)) - Stopping services started for active state
2017-05-16 17:08:49,248 INFO  [main] namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1334)) - Stopping services started for standby state
2017-05-16 17:08:49,262 INFO  [main] mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-05-16 17:08:49,363 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2017-05-16 17:08:49,364 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2017-05-16 17:08:49,364 INFO  [main] impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - DataNode metrics system shutdown complete.
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.581 sec - in org.apache.samoa.streams.fs.HDFSFileStreamSourceTest
Running org.apache.samoa.streams.kafka.KafkaUtilsTest
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:host.name=repairnator
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.version=1.8.0_121
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.vendor=Oracle Corporation
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.class.path=/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/test-classes:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/classes:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/github/javacliparser/javacliparser/0.5.0/javacliparser-0.5.0.jar:/root/workspace/apache/incubator-samoa/232818360/samoa-instances/target/classes:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/guava/guava/17.0/guava-17.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/ow2/asm/asm/4.0/asm-4.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/dreizak/miniball/1.0.3/miniball-1.0.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-annotations/2.6.0/hadoop-annotations-2.6.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-net/commons-net/3.1/commons-net-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/activation/activation/1.1/activation-1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/asm/asm/3.1/asm-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/httpcomponents/httpclient/4.1.2/httpclient-4.1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-auth/2.6.0/hadoop-auth-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/tukaani/xz/1.0/xz-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-minicluster/2.6.0/hadoop-minicluster-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-tests/2.6.0/hadoop-yarn-server-tests-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-common/2.6.0/hadoop-yarn-server-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.6.0/hadoop-yarn-server-nodemanager-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/inject/guice/3.0/guice-3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/inject/javax.inject/1/javax.inject-1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.6.0/hadoop-yarn-server-resourcemanager-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.6.0/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-common/2.6.0/hadoop-yarn-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.0/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-common/2.6.0/hadoop-mapreduce-client-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-client/2.6.0/hadoop-yarn-client-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.6.0/hadoop-mapreduce-client-shuffle-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-app/2.6.0/hadoop-mapreduce-client-app-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.6.0/hadoop-yarn-server-web-proxy-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-api/2.6.0/hadoop-yarn-api-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.0/hadoop-mapreduce-client-core-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.0/hadoop-mapreduce-client-jobclient-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.6.0/hadoop-mapreduce-client-hs-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka-clients/0.10.2.0/kafka-clients-0.10.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka-clients/0.10.2.0/kafka-clients-0.10.2.0-test.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka_2.11/0.10.2.0/kafka_2.11-0.10.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/sf/jopt-simple/jopt-simple/5.0.3/jopt-simple-5.0.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.4/scala-parser-combinators_2.11-1.0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka_2.11/0.10.2.0/kafka_2.11-0.10.2.0-test.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/jmockit/jmockit/1.13/jmockit-1.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/junit/junit/4.10/junit-4.10.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar:
2017-05-16 17:08:49,459 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.io.tmpdir=/tmp
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:java.compiler=<NA>
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:os.name=Linux
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:os.arch=amd64
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:os.version=3.16.0-4-amd64
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:user.name=root
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:user.home=/root
2017-05-16 17:08:49,460 INFO  [main] server.ZooKeeperServer (Environment.java:logEnv(100)) - Server environment:user.dir=/root/workspace/apache/incubator-samoa/232818360/samoa-api
2017-05-16 17:08:49,475 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:<init>(162)) - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /tmp/kafka-4605691622926080421/version-2 snapdir /tmp/kafka-1029349538126466625/version-2
2017-05-16 17:08:49,509 INFO  [main] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:configure(94)) - binding to port /127.0.0.1:0
2017-05-16 17:08:49,555 INFO  [ZkClient-EventThread-481-127.0.0.1:59567] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:08:49,559 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
2017-05-16 17:08:49,559 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:host.name=repairnator
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.version=1.8.0_121
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.vendor=Oracle Corporation
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.class.path=/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/test-classes:/root/workspace/apache/incubator-samoa/232818360/samoa-api/target/classes:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/jcip/jcip-annotations/1.0/jcip-annotations-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/github/javacliparser/javacliparser/0.5.0/javacliparser-0.5.0.jar:/root/workspace/apache/incubator-samoa/232818360/samoa-instances/target/classes:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/guava/guava/17.0/guava-17.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/ow2/asm/asm/4.0/asm-4.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/dreizak/miniball/1.0.3/miniball-1.0.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-annotations/2.6.0/hadoop-annotations-2.6.0.jar:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/tools.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-net/commons-net/3.1/commons-net-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-json/1.9/jersey-json-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/activation/activation/1.1/activation-1.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-jaxrs/1.8.3/jackson-jaxrs-1.8.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-xc/1.8.3/jackson-xc-1.8.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/asm/asm/3.1/asm-3.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/httpcomponents/httpclient/4.1.2/httpclient-4.1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/httpcomponents/httpcore/4.1.2/httpcore-4.1.2.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-auth/2.6.0/hadoop-auth-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/tukaani/xz/1.0/xz-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-minicluster/2.6.0/hadoop-minicluster-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-common/2.6.0/hadoop-common-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-hdfs/2.6.0/hadoop-hdfs-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-tests/2.6.0/hadoop-yarn-server-tests-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-common/2.6.0/hadoop-yarn-server-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.6.0/hadoop-yarn-server-nodemanager-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/inject/guice/3.0/guice-3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/javax/inject/javax.inject/1/javax.inject-1.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/sun/jersey/contribs/jersey-guice/1.9/jersey-guice-1.9.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-resourcemanager/2.6.0/hadoop-yarn-server-resourcemanager-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-applicationhistoryservice/2.6.0/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-common/2.6.0/hadoop-yarn-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.0/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-common/2.6.0/hadoop-mapreduce-client-common-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-client/2.6.0/hadoop-yarn-client-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.6.0/hadoop-mapreduce-client-shuffle-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-app/2.6.0/hadoop-mapreduce-client-app-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-server-web-proxy/2.6.0/hadoop-yarn-server-web-proxy-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-yarn-api/2.6.0/hadoop-yarn-api-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.0/hadoop-mapreduce-client-core-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.0/hadoop-mapreduce-client-jobclient-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/hadoop/hadoop-mapreduce-client-hs/2.6.0/hadoop-mapreduce-client-hs-2.6.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka-clients/0.10.2.0/kafka-clients-0.10.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka-clients/0.10.2.0/kafka-clients-0.10.2.0-test.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka_2.11/0.10.2.0/kafka_2.11-0.10.2.0.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/net/sf/jopt-simple/jopt-simple/5.0.3/jopt-simple-5.0.3.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/com/101tec/zkclient/0.10/zkclient-0.10.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.4/scala-parser-combinators_2.11-1.0.4.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/apache/kafka/kafka_2.11/0.10.2.0/kafka_2.11-0.10.2.0-test.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/jmockit/jmockit/1.13/jmockit-1.13.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/junit/junit/4.10/junit-4.10.jar:/root/./workspace/apache/incubator-samoa/232818360/.m2/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar:
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.io.tmpdir=/tmp
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:java.compiler=<NA>
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:os.name=Linux
2017-05-16 17:08:49,560 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:os.arch=amd64
2017-05-16 17:08:49,561 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:os.version=3.16.0-4-amd64
2017-05-16 17:08:49,561 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:user.name=root
2017-05-16 17:08:49,561 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:user.home=/root
2017-05-16 17:08:49,561 INFO  [main] zookeeper.ZooKeeper (Environment.java:logEnv(100)) - Client environment:user.dir=/root/workspace/apache/incubator-samoa/232818360/samoa-api
2017-05-16 17:08:49,562 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:59567 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@7601bc96
2017-05-16 17:08:49,577 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:08:49,599 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:59567. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:08:49,599 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:59567, initiating session
2017-05-16 17:08:49,599 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:56930
2017-05-16 17:08:49,605 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:56930
2017-05-16 17:08:49,607 INFO  [SyncThread:0] persistence.FileTxnLog (FileTxnLog.java:append(199)) - Creating new log file: log.1
2017-05-16 17:08:49,695 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11cdf5ea0000 with negotiated timeout 10000 for client /127.0.0.1:56930
2017-05-16 17:08:49,696 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:59567, sessionid = 0x15c11cdf5ea0000, negotiated timeout = 10000
2017-05-16 17:08:49,697 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:08:50,128 INFO  [main] server.KafkaConfig (AbstractConfig.java:logAll(180)) - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.10.2-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafkaUtils-4740112883560623834
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.2-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = 127.0.0.1:59567
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-05-16 17:08:50,194 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - starting
2017-05-16 17:08:50,196 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Connecting to zookeeper on 127.0.0.1:59567
2017-05-16 17:08:50,204 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:59567 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@9e54c59
2017-05-16 17:08:50,213 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:08:50,205 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:08:50,213 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:59567. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:08:50,214 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:59567, initiating session
2017-05-16 17:08:50,219 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:56931
2017-05-16 17:08:50,220 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:56931
2017-05-16 17:08:50,235 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11cdf5ea0001 with negotiated timeout 6000 for client /127.0.0.1:56931
2017-05-16 17:08:50,236 INFO  [main-SendThread(127.0.0.1:59567)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:59567, sessionid = 0x15c11cdf5ea0001, negotiated timeout = 6000
2017-05-16 17:08:50,236 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:08:50,266 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x5 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-05-16 17:08:50,296 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xb zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-05-16 17:08:50,338 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x13 zxid:0xd txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-05-16 17:08:50,410 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x1b zxid:0x12 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-05-16 17:08:50,437 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Cluster ID = EnONl8u8R-Ku32iHRlqTPw
2017-05-16 17:08:50,440 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafkaUtils-4740112883560623834/meta.properties
2017-05-16 17:08:50,478 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Starting 
2017-05-16 17:08:50,479 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Starting 
2017-05-16 17:08:50,508 INFO  [main] log.LogManager (Logging.scala:info(70)) - Loading logs.
2017-05-16 17:08:50,515 INFO  [main] log.LogManager (Logging.scala:info(70)) - Logs loading complete in 0 ms.
2017-05-16 17:08:50,557 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log cleanup with a period of 300000 ms.
2017-05-16 17:08:50,559 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log flusher with a default period of 9223372036854775807 ms.
2017-05-16 17:08:50,561 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Starting the log cleaner
2017-05-16 17:08:50,562 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Starting 
2017-05-16 17:08:50,598 INFO  [main] network.Acceptor (Logging.scala:info(70)) - Awaiting socket connections on 127.0.0.1:9092.
2017-05-16 17:08:50,605 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Started 1 acceptor threads
2017-05-16 17:08:50,625 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:08:50,626 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:08:50,656 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller starting up
2017-05-16 17:08:50,663 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /controller (is it secure? false)
2017-05-16 17:08:50,673 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:08:50,674 INFO  [main] server.ZookeeperLeaderElector (Logging.scala:info(70)) - 0 successfully elected as leader
2017-05-16 17:08:50,675 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 starting become controller state transition
2017-05-16 17:08:50,677 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:setData cxid:0x25 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-05-16 17:08:50,696 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller 0 incremented epoch to 1
2017-05-16 17:08:50,714 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions undergoing preferred replica election: 
2017-05-16 17:08:50,714 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions that completed preferred replica election: 
2017-05-16 17:08:50,715 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming preferred replica election for partitions: 
2017-05-16 17:08:50,719 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions being reassigned: Map()
2017-05-16 17:08:50,719 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions already reassigned: Set()
2017-05-16 17:08:50,721 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming reassignment of partitions: Map()
2017-05-16 17:08:50,724 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics to be deleted: 
2017-05-16 17:08:50,725 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics ineligible for deletion: 
2017-05-16 17:08:50,728 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently active brokers in the cluster: Set()
2017-05-16 17:08:50,728 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently shutting brokers in the cluster: Set()
2017-05-16 17:08:50,729 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Current list of topics in the cluster: Set()
2017-05-16 17:08:50,753 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Started replica state machine with initial state -> Map()
2017-05-16 17:08:50,755 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Started partition state machine with initial state -> Map()
2017-05-16 17:08:50,756 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 is ready to serve as the new controller with epoch 1
2017-05-16 17:08:50,757 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Starting preferred replica leader election for partitions 
2017-05-16 17:08:50,758 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions 
2017-05-16 17:08:50,761 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:delete cxid:0x36 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-05-16 17:08:50,771 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: starting the partition rebalance scheduler
2017-05-16 17:08:50,772 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller startup complete
2017-05-16 17:08:50,780 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:08:50,790 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:08:50,795 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:08:50,802 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Starting up.
2017-05-16 17:08:50,803 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Startup complete.
2017-05-16 17:08:50,808 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 2 milliseconds.
2017-05-16 17:08:50,837 INFO  [main] utils.Mx4jLoader$ (Logging.scala:info(70)) - Will not load MX4J, mx4j-tools.jar is not in the classpath
2017-05-16 17:08:50,862 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /brokers/ids/0 (is it secure? false)
2017-05-16 17:08:50,863 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x41 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-05-16 17:08:50,864 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-05-16 17:08:50,874 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] server.ZookeeperLeaderElector$LeaderChangeListener (Logging.scala:info(70)) - New leader is 0
2017-05-16 17:08:50,879 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:08:50,880 INFO  [main] utils.ZkUtils (Logging.scala:info(70)) - Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(127.0.0.1,9092,ListenerName(PLAINTEXT),PLAINTEXT)
2017-05-16 17:08:50,881 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafkaUtils-4740112883560623834/meta.properties
2017-05-16 17:08:50,885 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children 0
2017-05-16 17:08:50,944 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:50,944 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:50,945 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], started
2017-05-16 17:08:50,974 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Newly added brokers: 0, deleted brokers: , all live brokers: 0
2017-05-16 17:08:50,998 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Starting 
2017-05-16 17:08:50,996 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New broker startup callback for 0
2017-05-16 17:08:50,999 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0000 type:setData cxid:0x4 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/test-r Error:KeeperErrorCode = NoNode for /config/topics/test-r
2017-05-16 17:08:51,007 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Controller 0 connected to 127.0.0.1:9092 (id: 0 rack: null) for sending state change requests
2017-05-16 17:08:51,013 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0000 type:create cxid:0x5 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:08:51,033 INFO  [main] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:08:51,352 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0000 type:setData cxid:0xb zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/test-s Error:KeeperErrorCode = NoNode for /config/topics/test-s
2017-05-16 17:08:51,353 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(test-r)], deleted topics: [Set()], new partition replica assignment [Map([test-r,0] -> List(0))]
2017-05-16 17:08:51,353 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [test-r,0]
2017-05-16 17:08:51,362 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0000 type:create cxid:0xc zxid:0x21 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:08:51,363 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [test-r,0]
2017-05-16 17:08:51,364 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test-r,0]
2017-05-16 17:08:51,370 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test-r,Partition=0,Replica=0]
2017-05-16 17:08:51,378 INFO  [main] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:08:51,380 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test-r,0]
2017-05-16 17:08:51,389 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x4c zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-r/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/test-r/partitions/0
2017-05-16 17:08:51,395 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x4d zxid:0x25 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-r/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/test-r/partitions
2017-05-16 17:08:51,417 INFO  [Thread-426] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:51,417 INFO  [Thread-426] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:51,446 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test-r,Partition=0,Replica=0]
2017-05-16 17:08:51,448 INFO  [kafka-request-handler-7] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions test-r-0
2017-05-16 17:08:51,456 INFO  [Thread-426] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:51,456 INFO  [Thread-426] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:51,461 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(test-s)], deleted topics: [Set()], new partition replica assignment [Map([test-s,0] -> List(0))]
2017-05-16 17:08:51,461 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [test-s,0]
2017-05-16 17:08:51,462 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [test-s,0]
2017-05-16 17:08:51,462 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test-s,0]
2017-05-16 17:08:51,463 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test-s,Partition=0,Replica=0]
2017-05-16 17:08:51,464 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test-s,0]
2017-05-16 17:08:51,465 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x57 zxid:0x29 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions/0
2017-05-16 17:08:51,470 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x58 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions
2017-05-16 17:08:51,529 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test-s,Partition=0,Replica=0]
2017-05-16 17:08:51,532 WARN  [Thread-426] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 2 : {test-r=LEADER_NOT_AVAILABLE}
2017-05-16 17:08:51,547 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:setData cxid:0x63 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-05-16 17:08:51,547 INFO  [kafka-request-handler-7] log.Log (Logging.scala:info(70)) - Completed load of log test-r-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:51,550 INFO  [kafka-request-handler-7] log.LogManager (Logging.scala:info(70)) - Created log for partition [test-r,0] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:51,551 INFO  [kafka-request-handler-7] cluster.Partition (Logging.scala:info(70)) - Partition [test-r,0] on broker 0: No checkpointed highwatermark is found for partition test-r-0
2017-05-16 17:08:51,562 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x64 zxid:0x2f txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:08:51,579 INFO  [kafka-request-handler-4] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}}
2017-05-16 17:08:51,581 INFO  [kafka-request-handler-2] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions test-s-0
2017-05-16 17:08:51,623 INFO  [kafka-request-handler-4] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2017-05-16 17:08:51,681 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log test-s-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:51,682 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [test-s,0] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:51,684 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [test-s,0] on broker 0: No checkpointed highwatermark is found for partition test-s-0
2017-05-16 17:08:51,689 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map([__consumer_offsets,19] -> List(0), [__consumer_offsets,30] -> List(0), [__consumer_offsets,47] -> List(0), [__consumer_offsets,29] -> List(0), [__consumer_offsets,41] -> List(0), [__consumer_offsets,39] -> List(0), [__consumer_offsets,10] -> List(0), [__consumer_offsets,17] -> List(0), [__consumer_offsets,14] -> List(0), [__consumer_offsets,40] -> List(0), [__consumer_offsets,18] -> List(0), [__consumer_offsets,26] -> List(0), [__consumer_offsets,0] -> List(0), [__consumer_offsets,24] -> List(0), [__consumer_offsets,33] -> List(0), [__consumer_offsets,20] -> List(0), [__consumer_offsets,21] -> List(0), [__consumer_offsets,3] -> List(0), [__consumer_offsets,5] -> List(0), [__consumer_offsets,22] -> List(0), [__consumer_offsets,12] -> List(0), [__consumer_offsets,8] -> List(0), [__consumer_offsets,23] -> List(0), [__consumer_offsets,15] -> List(0), [__consumer_offsets,48] -> List(0), [__consumer_offsets,11] -> List(0), [__consumer_offsets,13] -> List(0), [__consumer_offsets,49] -> List(0), [__consumer_offsets,6] -> List(0), [__consumer_offsets,28] -> List(0), [__consumer_offsets,4] -> List(0), [__consumer_offsets,37] -> List(0), [__consumer_offsets,31] -> List(0), [__consumer_offsets,44] -> List(0), [__consumer_offsets,42] -> List(0), [__consumer_offsets,34] -> List(0), [__consumer_offsets,46] -> List(0), [__consumer_offsets,25] -> List(0), [__consumer_offsets,45] -> List(0), [__consumer_offsets,27] -> List(0), [__consumer_offsets,32] -> List(0), [__consumer_offsets,43] -> List(0), [__consumer_offsets,36] -> List(0), [__consumer_offsets,35] -> List(0), [__consumer_offsets,7] -> List(0), [__consumer_offsets,9] -> List(0), [__consumer_offsets,38] -> List(0), [__consumer_offsets,1] -> List(0), [__consumer_offsets,16] -> List(0), [__consumer_offsets,2] -> List(0))]
2017-05-16 17:08:51,691 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:08:51,694 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:08:51,700 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:08:51,707 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:08:51,736 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:08:51,737 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xa1 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-05-16 17:08:51,745 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xa3 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-05-16 17:08:51,779 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xa9 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-05-16 17:08:51,805 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xac zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-05-16 17:08:51,829 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xaf zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-05-16 17:08:51,857 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xb4 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-05-16 17:08:51,879 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xb8 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-05-16 17:08:51,904 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xbb zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-05-16 17:08:51,929 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xbe zxid:0x49 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-05-16 17:08:51,979 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xc3 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-05-16 17:08:52,004 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xc7 zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-05-16 17:08:52,029 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xca zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-05-16 17:08:52,058 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xcf zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-05-16 17:08:52,087 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xd3 zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-05-16 17:08:52,112 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xd6 zxid:0x5b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-05-16 17:08:52,137 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xd9 zxid:0x5e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-05-16 17:08:52,165 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xde zxid:0x61 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-05-16 17:08:52,187 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xe2 zxid:0x64 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-05-16 17:08:52,212 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xe5 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-05-16 17:08:52,255 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xea zxid:0x6a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-05-16 17:08:52,399 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xef zxid:0x6d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-05-16 17:08:52,888 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xf6 zxid:0x70 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-05-16 17:08:53,029 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0xfc zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-05-16 17:08:53,190 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x102 zxid:0x76 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-05-16 17:08:53,387 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x108 zxid:0x79 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-05-16 17:08:53,412 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x10e zxid:0x7c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-05-16 17:08:53,437 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x112 zxid:0x7f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-05-16 17:08:53,462 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x115 zxid:0x82 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-05-16 17:08:53,487 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x118 zxid:0x85 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-05-16 17:08:53,512 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x11e zxid:0x88 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-05-16 17:08:53,587 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x121 zxid:0x8b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-05-16 17:08:53,612 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x126 zxid:0x8e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-05-16 17:08:53,637 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x12a zxid:0x91 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-05-16 17:08:53,662 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x12d zxid:0x94 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-05-16 17:08:53,723 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x132 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-05-16 17:08:53,754 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x136 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-05-16 17:08:53,779 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x139 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-05-16 17:08:53,812 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x13e zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-05-16 17:08:53,837 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x142 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-05-16 17:08:53,902 INFO  [Thread-427] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:53,904 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x145 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-05-16 17:08:53,909 INFO  [Thread-427] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:53,911 INFO  [Thread-427] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:53,913 INFO  [Thread-427] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:53,956 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x14d zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-05-16 17:08:54,004 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x151 zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-05-16 17:08:54,029 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x158 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-05-16 17:08:54,054 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x15d zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-05-16 17:08:54,087 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x160 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-05-16 17:08:54,112 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x164 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-05-16 17:08:54,145 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x16c zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-05-16 17:08:54,179 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x16f zxid:0xbe txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-05-16 17:08:54,304 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x178 zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-05-16 17:08:54,345 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x180 zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-05-16 17:08:54,481 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11cdf5ea0001 type:create cxid:0x188 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-05-16 17:08:54,531 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:08:54,566 INFO  [kafka-request-handler-2] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2017-05-16 17:08:54,570 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,571 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,0] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,572 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-0
2017-05-16 17:08:54,575 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,577 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,29] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,578 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-29
2017-05-16 17:08:54,581 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,582 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,48] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,582 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-48
2017-05-16 17:08:54,585 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,586 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,10] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,587 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-10
2017-05-16 17:08:54,593 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,595 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,45] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,595 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-45
2017-05-16 17:08:54,600 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,601 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,26] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,601 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-26
2017-05-16 17:08:54,604 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,605 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,7] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,605 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-7
2017-05-16 17:08:54,608 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,609 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,42] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,610 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-42
2017-05-16 17:08:54,613 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,614 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,4] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,614 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-4
2017-05-16 17:08:54,618 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,619 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,23] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,619 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-23
2017-05-16 17:08:54,624 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,625 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,1] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,626 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-1
2017-05-16 17:08:54,632 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,633 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,20] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,634 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-20
2017-05-16 17:08:54,637 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,638 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,39] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,638 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-39
2017-05-16 17:08:54,641 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,644 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,17] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,645 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-17
2017-05-16 17:08:54,648 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,649 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,36] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,649 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-36
2017-05-16 17:08:54,652 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,653 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,14] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,654 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-14
2017-05-16 17:08:54,657 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,657 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,33] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,658 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-33
2017-05-16 17:08:54,661 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,662 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,49] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,662 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-49
2017-05-16 17:08:54,666 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,667 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,11] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,667 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-11
2017-05-16 17:08:54,671 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,672 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,30] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,672 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-30
2017-05-16 17:08:54,676 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,677 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,46] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,677 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-46
2017-05-16 17:08:54,680 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,681 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,27] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,682 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-27
2017-05-16 17:08:54,684 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,685 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,8] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,686 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-8
2017-05-16 17:08:54,696 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,697 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,24] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,698 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-24
2017-05-16 17:08:54,701 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,702 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,43] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,702 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-43
2017-05-16 17:08:54,705 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,706 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,5] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,707 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-5
2017-05-16 17:08:54,710 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,711 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,21] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,711 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-21
2017-05-16 17:08:54,714 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,716 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,2] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,716 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-2
2017-05-16 17:08:54,720 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,721 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,40] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,721 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-40
2017-05-16 17:08:54,724 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,725 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,37] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,726 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-37
2017-05-16 17:08:54,729 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,730 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,18] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,730 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-18
2017-05-16 17:08:54,733 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,735 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,34] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,735 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-34
2017-05-16 17:08:54,742 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,753 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,15] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,753 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-15
2017-05-16 17:08:54,763 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,767 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,12] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,768 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-12
2017-05-16 17:08:54,779 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,783 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,31] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,784 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-31
2017-05-16 17:08:54,791 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,793 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,9] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,794 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-9
2017-05-16 17:08:54,803 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,805 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,47] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,806 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-47
2017-05-16 17:08:54,813 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,815 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,19] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,816 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-19
2017-05-16 17:08:54,829 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,830 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,28] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,831 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-28
2017-05-16 17:08:54,834 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,835 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,38] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,835 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-38
2017-05-16 17:08:54,846 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,848 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,35] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,849 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-35
2017-05-16 17:08:54,854 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,857 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,44] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,858 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-44
2017-05-16 17:08:54,864 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,866 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,6] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,867 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-6
2017-05-16 17:08:54,872 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,873 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,25] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,874 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-25
2017-05-16 17:08:54,877 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,878 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,16] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,878 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-16
2017-05-16 17:08:54,881 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,884 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,22] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,884 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-22
2017-05-16 17:08:54,888 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,889 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,41] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,889 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-41
2017-05-16 17:08:54,892 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,893 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,32] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,893 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-32
2017-05-16 17:08:54,897 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,898 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,3] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,898 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-3
2017-05-16 17:08:54,901 INFO  [kafka-request-handler-2] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:08:54,902 INFO  [kafka-request-handler-2] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,13] in /tmp/kafkaUtils-4740112883560623834 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:08:54,902 INFO  [kafka-request-handler-2] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-13
2017-05-16 17:08:54,906 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-22
2017-05-16 17:08:54,908 INFO  [Thread-428] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:54,908 INFO  [Thread-428] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:54,917 INFO  [main] producer.ProducerConfig (AbstractConfig.java:logAll(180)) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.id = sendM-test
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-05-16 17:08:54,920 INFO  [Thread-428] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:54,920 INFO  [Thread-428] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:54,949 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:54,956 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-22 in 49 milliseconds.
2017-05-16 17:08:54,956 INFO  [Thread-427] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:08:54,958 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:54,959 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-25
2017-05-16 17:08:54,960 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-25 in 1 milliseconds.
2017-05-16 17:08:54,961 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-28
2017-05-16 17:08:54,963 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-28 in 1 milliseconds.
2017-05-16 17:08:54,963 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-31
2017-05-16 17:08:54,964 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-31 in 1 milliseconds.
2017-05-16 17:08:54,965 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-34
2017-05-16 17:08:54,966 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-34 in 1 milliseconds.
2017-05-16 17:08:54,967 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-37
2017-05-16 17:08:54,969 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-37 in 2 milliseconds.
2017-05-16 17:08:54,970 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-40
2017-05-16 17:08:54,972 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-40 in 1 milliseconds.
2017-05-16 17:08:54,972 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-43
2017-05-16 17:08:54,974 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:54,974 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-43 in 2 milliseconds.
2017-05-16 17:08:54,975 INFO  [Thread-428] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:08:54,981 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:54,981 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-46
2017-05-16 17:08:54,983 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-46 in 1 milliseconds.
2017-05-16 17:08:54,985 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-49
2017-05-16 17:08:54,986 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-49 in 1 milliseconds.
2017-05-16 17:08:54,986 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-41
2017-05-16 17:08:54,987 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:08:54,987 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-41 in 1 milliseconds.
2017-05-16 17:08:54,987 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-44
2017-05-16 17:08:54,989 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-44 in 2 milliseconds.
2017-05-16 17:08:54,989 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-47
2017-05-16 17:08:54,990 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:08:54,990 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-47 in 1 milliseconds.
2017-05-16 17:08:54,990 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-1
2017-05-16 17:08:54,992 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-1 in 1 milliseconds.
2017-05-16 17:08:54,992 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-4
2017-05-16 17:08:54,993 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-4 in 1 milliseconds.
2017-05-16 17:08:54,993 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-7
2017-05-16 17:08:54,994 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-7 in 1 milliseconds.
2017-05-16 17:08:54,994 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-10
2017-05-16 17:08:54,996 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-10 in 1 milliseconds.
2017-05-16 17:08:54,996 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-13
2017-05-16 17:08:54,997 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-13 in 1 milliseconds.
2017-05-16 17:08:54,997 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-16
2017-05-16 17:08:54,998 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-16 in 1 milliseconds.
2017-05-16 17:08:54,998 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-19
2017-05-16 17:08:54,999 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-19 in 1 milliseconds.
2017-05-16 17:08:55,000 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-2
2017-05-16 17:08:55,001 WARN  [main] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'group.id' was supplied but isn't a known config.
2017-05-16 17:08:55,001 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-2 in 1 milliseconds.
2017-05-16 17:08:55,001 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-5
2017-05-16 17:08:55,001 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:55,001 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:55,002 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-5 in 1 milliseconds.
2017-05-16 17:08:55,002 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-8
2017-05-16 17:08:55,004 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-8 in 1 milliseconds.
2017-05-16 17:08:55,004 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-11
2017-05-16 17:08:55,005 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-11 in 1 milliseconds.
2017-05-16 17:08:55,005 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-14
2017-05-16 17:08:55,007 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-14 in 2 milliseconds.
2017-05-16 17:08:55,007 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-17
2017-05-16 17:08:55,008 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-17 in 1 milliseconds.
2017-05-16 17:08:55,008 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-20
2017-05-16 17:08:55,010 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-20 in 1 milliseconds.
2017-05-16 17:08:55,010 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-23
2017-05-16 17:08:55,011 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-23 in 1 milliseconds.
2017-05-16 17:08:55,011 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-26
2017-05-16 17:08:55,014 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-26 in 2 milliseconds.
2017-05-16 17:08:55,014 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-29
2017-05-16 17:08:55,015 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-29 in 1 milliseconds.
2017-05-16 17:08:55,016 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-32
2017-05-16 17:08:55,017 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-32 in 1 milliseconds.
2017-05-16 17:08:55,017 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-35
2017-05-16 17:08:55,019 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-35 in 2 milliseconds.
2017-05-16 17:08:55,019 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-38
2017-05-16 17:08:55,022 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-38 in 3 milliseconds.
2017-05-16 17:08:55,022 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-0
2017-05-16 17:08:55,025 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:55,025 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-0 in 2 milliseconds.
2017-05-16 17:08:55,026 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-3
2017-05-16 17:08:55,028 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-3 in 2 milliseconds.
2017-05-16 17:08:55,028 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-6
2017-05-16 17:08:55,030 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-6 in 2 milliseconds.
2017-05-16 17:08:55,030 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-9
2017-05-16 17:08:55,033 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-9 in 3 milliseconds.
2017-05-16 17:08:55,033 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-12
2017-05-16 17:08:55,035 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-12 in 2 milliseconds.
2017-05-16 17:08:55,035 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-15
2017-05-16 17:08:55,037 INFO  [Thread-426] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:08:55,038 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:55,040 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-15 in 3 milliseconds.
2017-05-16 17:08:55,041 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-18
2017-05-16 17:08:55,041 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:08:55,043 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-18 in 2 milliseconds.
2017-05-16 17:08:55,043 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-21
2017-05-16 17:08:55,045 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-21 in 2 milliseconds.
2017-05-16 17:08:55,046 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-24
2017-05-16 17:08:55,048 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-24 in 2 milliseconds.
2017-05-16 17:08:55,049 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-27
2017-05-16 17:08:55,051 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-27 in 2 milliseconds.
2017-05-16 17:08:55,051 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-30
2017-05-16 17:08:55,053 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-30 in 2 milliseconds.
2017-05-16 17:08:55,053 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-33
2017-05-16 17:08:55,055 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-33 in 2 milliseconds.
2017-05-16 17:08:55,056 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-36
2017-05-16 17:08:55,058 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-36 in 2 milliseconds.
2017-05-16 17:08:55,059 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-39
2017-05-16 17:08:55,061 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-39 in 2 milliseconds.
2017-05-16 17:08:55,061 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-42
2017-05-16 17:08:55,063 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-42 in 2 milliseconds.
2017-05-16 17:08:55,063 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-45
2017-05-16 17:08:55,065 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-45 in 1 milliseconds.
2017-05-16 17:08:55,066 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-48
2017-05-16 17:08:55,068 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-48 in 2 milliseconds.
2017-05-16 17:08:55,089 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:55,089 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:55,108 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:55,108 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:55,110 INFO  [kafka-request-handler-1] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 0
2017-05-16 17:08:55,117 INFO  [kafka-request-handler-1] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 1
2017-05-16 17:08:55,143 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:08:55,143 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:55,161 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 1
2017-05-16 17:08:55,164 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:55,167 INFO  [kafka-request-handler-7] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 2
2017-05-16 17:08:55,172 INFO  [kafka-request-handler-1] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 2
2017-05-16 17:08:55,203 INFO  [Thread-427] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:08:55,204 INFO  [Thread-427] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [] for group test
2017-05-16 17:08:55,209 INFO  [Thread-426] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:08:55,211 INFO  [Thread-426] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [test-r-0] for group test
2017-05-16 17:08:55,216 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:08:55,218 INFO  [Thread-428] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [] for group test
2017-05-16 17:08:55,224 INFO  [main] producer.KafkaProducer (KafkaProducer.java:close(689)) - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-05-16 17:08:55,237 INFO  [kafka-request-handler-0] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 2
2017-05-16 17:08:58,226 INFO  [Thread-428] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:08:58,226 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:08:58,227 INFO  [kafka-request-handler-7] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 3
2017-05-16 17:08:58,233 INFO  [kafka-request-handler-0] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 3
2017-05-16 17:08:58,236 INFO  [Thread-428] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 3
2017-05-16 17:08:58,236 INFO  [Thread-428] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [test-r-0] for group test
2017-05-16 17:08:58,288 INFO  [main] producer.ProducerConfig (AbstractConfig.java:logAll(180)) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.id = rcv-test
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-05-16 17:08:58,296 WARN  [main] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'group.id' was supplied but isn't a known config.
2017-05-16 17:08:58,296 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:58,296 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:58,297 INFO  [main] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:58,297 INFO  [main] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-4
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:08:58,299 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:08:58,299 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:08:59,763 INFO  [kafka-request-handler-3] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 3
2017-05-16 17:08:59,765 INFO  [kafka-request-handler-3] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Group test with generation 4 is now empty
2017-05-16 17:09:01,441 INFO  [main] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:01,442 INFO  [main] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:09:01,442 INFO  [main] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:01,444 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 4
2017-05-16 17:09:01,444 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 5
2017-05-16 17:09:01,445 INFO  [kafka-request-handler-7] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 5
2017-05-16 17:09:01,446 INFO  [main] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 5
2017-05-16 17:09:01,447 INFO  [main] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [test-s-0] for group test
2017-05-16 17:09:01,477 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 5
2017-05-16 17:09:01,479 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Group test with generation 6 is now empty
2017-05-16 17:09:01,530 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shutting down
2017-05-16 17:09:01,531 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Starting controlled shutdown
2017-05-16 17:09:01,539 INFO  [kafka-request-handler-7] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Shutting down broker 0
2017-05-16 17:09:01,550 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Controlled shutdown succeeded
2017-05-16 17:09:01,551 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutting down
2017-05-16 17:09:01,558 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutdown completed
2017-05-16 17:09:01,559 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shutting down
2017-05-16 17:09:01,568 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shut down completely
2017-05-16 17:09:01,626 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutting down
2017-05-16 17:09:02,481 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Stopped 
2017-05-16 17:09:02,481 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutdown completed
2017-05-16 17:09:02,481 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutting down
2017-05-16 17:09:02,486 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Stopped 
2017-05-16 17:09:02,486 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutdown completed
2017-05-16 17:09:02,486 INFO  [main] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Shutdown complete.
2017-05-16 17:09:02,488 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shutting down
2017-05-16 17:09:02,488 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutting down
2017-05-16 17:09:02,490 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutdown completed
2017-05-16 17:09:02,490 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:02,576 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:02,576 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:02,576 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:02,749 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:02,749 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:02,819 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shut down completely
2017-05-16 17:09:02,819 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:02,944 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:02,945 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:02,946 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutting down.
2017-05-16 17:09:02,947 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:03,129 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:03,129 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:03,129 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:03,146 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:03,146 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:03,147 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutdown complete.
2017-05-16 17:09:03,148 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutting down.
2017-05-16 17:09:03,148 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Shutting down the log cleaner.
2017-05-16 17:09:03,149 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutting down
2017-05-16 17:09:03,149 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Stopped 
2017-05-16 17:09:03,149 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutdown completed
2017-05-16 17:09:03,849 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutdown complete.
2017-05-16 17:09:03,852 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Stopped partition state machine
2017-05-16 17:09:03,853 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Stopped replica state machine
2017-05-16 17:09:03,854 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutting down
2017-05-16 17:09:03,855 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Stopped 
2017-05-16 17:09:03,855 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutdown completed
2017-05-16 17:09:03,856 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 resigned as the controller
2017-05-16 17:09:03,856 INFO  [ZkClient-EventThread-485-127.0.0.1:59567] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:03,857 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11cdf5ea0001
2017-05-16 17:09:03,870 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11cdf5ea0001 closed
2017-05-16 17:09:03,870 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:03,871 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:56931 which had sessionid 0x15c11cdf5ea0001
2017-05-16 17:09:03,871 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shut down completed
2017-05-16 17:09:03,872 INFO  [ZkClient-EventThread-481-127.0.0.1:59567] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:03,872 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11cdf5ea0000
2017-05-16 17:09:03,886 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:03,886 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:56930 which had sessionid 0x15c11cdf5ea0000
2017-05-16 17:09:03,886 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11cdf5ea0000 closed
2017-05-16 17:09:03,887 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:03,887 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:03,887 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:03,887 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:run(143)) - PrepRequestProcessor exited loop!
2017-05-16 17:09:03,887 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:03,888 INFO  [SyncThread:0] server.SyncRequestProcessor (SyncRequestProcessor.java:run(187)) - SyncRequestProcessor exited!
2017-05-16 17:09:03,888 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
2017-05-16 17:09:03,889 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(224)) - NIOServerCnxn factory exited run method
2017-05-16 17:09:03,889 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:03,889 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:03,890 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:03,890 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:03,890 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.525 sec - in org.apache.samoa.streams.kafka.KafkaUtilsTest
Running org.apache.samoa.streams.kafka.KafkaEntranceProcessorTest
2017-05-16 17:09:03,896 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:<init>(162)) - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /tmp/kafka-1976118636815565164/version-2 snapdir /tmp/kafka-2946506844776707983/version-2
2017-05-16 17:09:03,897 INFO  [main] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:configure(94)) - binding to port /127.0.0.1:0
2017-05-16 17:09:03,899 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:58583 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2a50b32d
2017-05-16 17:09:03,899 INFO  [ZkClient-EventThread-541-127.0.0.1:58583] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:09:03,899 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:09:03,899 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:58583. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:09:03,900 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:41953
2017-05-16 17:09:03,900 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:58583, initiating session
2017-05-16 17:09:03,900 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:41953
2017-05-16 17:09:03,900 INFO  [SyncThread:0] persistence.FileTxnLog (FileTxnLog.java:append(199)) - Creating new log file: log.1
2017-05-16 17:09:03,949 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11ce2e190000 with negotiated timeout 10000 for client /127.0.0.1:41953
2017-05-16 17:09:03,949 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:58583, sessionid = 0x15c11ce2e190000, negotiated timeout = 10000
2017-05-16 17:09:03,949 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:09:03,950 INFO  [main] server.KafkaConfig (AbstractConfig.java:logAll(180)) - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.10.2-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-6039032718762417915
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.2-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = 127.0.0.1:58583
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-05-16 17:09:03,952 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - starting
2017-05-16 17:09:03,952 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Connecting to zookeeper on 127.0.0.1:58583
2017-05-16 17:09:03,952 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:58583 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@36c7cbe1
2017-05-16 17:09:03,952 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:09:03,953 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:58583. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:09:03,953 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:58583, initiating session
2017-05-16 17:09:03,953 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:41955
2017-05-16 17:09:03,953 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:09:03,954 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:41955
2017-05-16 17:09:03,972 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11ce2e190001 with negotiated timeout 6000 for client /127.0.0.1:41955
2017-05-16 17:09:03,972 INFO  [main-SendThread(127.0.0.1:58583)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:58583, sessionid = 0x15c11ce2e190001, negotiated timeout = 6000
2017-05-16 17:09:03,972 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:09:04,000 INFO  [SessionTracker] server.SessionTrackerImpl (SessionTrackerImpl.java:run(162)) - SessionTrackerImpl exited loop!
2017-05-16 17:09:04,014 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x4 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-05-16 17:09:04,231 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xa zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-05-16 17:09:04,331 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x12 zxid:0xd txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-05-16 17:09:04,415 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x1a zxid:0x12 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-05-16 17:09:04,438 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Cluster ID = dvvmO0dTSiCE_XkvVHnciA
2017-05-16 17:09:04,439 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafka-6039032718762417915/meta.properties
2017-05-16 17:09:04,440 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Starting 
2017-05-16 17:09:04,441 INFO  [main] log.LogManager (Logging.scala:info(70)) - Loading logs.
2017-05-16 17:09:04,441 INFO  [main] log.LogManager (Logging.scala:info(70)) - Logs loading complete in 0 ms.
2017-05-16 17:09:04,464 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Starting 
2017-05-16 17:09:04,465 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log cleanup with a period of 300000 ms.
2017-05-16 17:09:04,465 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log flusher with a default period of 9223372036854775807 ms.
2017-05-16 17:09:04,465 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Starting the log cleaner
2017-05-16 17:09:04,468 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Starting 
2017-05-16 17:09:04,469 INFO  [main] network.Acceptor (Logging.scala:info(70)) - Awaiting socket connections on 127.0.0.1:9092.
2017-05-16 17:09:04,470 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Started 1 acceptor threads
2017-05-16 17:09:04,478 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:04,478 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller starting up
2017-05-16 17:09:04,478 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:04,481 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /controller (is it secure? false)
2017-05-16 17:09:04,497 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:09:04,497 INFO  [main] server.ZookeeperLeaderElector (Logging.scala:info(70)) - 0 successfully elected as leader
2017-05-16 17:09:04,497 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 starting become controller state transition
2017-05-16 17:09:04,498 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:setData cxid:0x24 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-05-16 17:09:04,530 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller 0 incremented epoch to 1
2017-05-16 17:09:04,533 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions undergoing preferred replica election: 
2017-05-16 17:09:04,533 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions that completed preferred replica election: 
2017-05-16 17:09:04,533 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming preferred replica election for partitions: 
2017-05-16 17:09:04,534 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions being reassigned: Map()
2017-05-16 17:09:04,534 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions already reassigned: Set()
2017-05-16 17:09:04,534 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming reassignment of partitions: Map()
2017-05-16 17:09:04,534 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics to be deleted: 
2017-05-16 17:09:04,535 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics ineligible for deletion: 
2017-05-16 17:09:04,535 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently active brokers in the cluster: Set()
2017-05-16 17:09:04,535 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently shutting brokers in the cluster: Set()
2017-05-16 17:09:04,535 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Current list of topics in the cluster: Set()
2017-05-16 17:09:04,535 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Started replica state machine with initial state -> Map()
2017-05-16 17:09:04,535 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Started partition state machine with initial state -> Map()
2017-05-16 17:09:04,536 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 is ready to serve as the new controller with epoch 1
2017-05-16 17:09:04,536 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Starting preferred replica leader election for partitions 
2017-05-16 17:09:04,536 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions 
2017-05-16 17:09:04,536 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:delete cxid:0x35 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-05-16 17:09:04,555 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: starting the partition rebalance scheduler
2017-05-16 17:09:04,556 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller startup complete
2017-05-16 17:09:04,557 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:04,558 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] server.ZookeeperLeaderElector$LeaderChangeListener (Logging.scala:info(70)) - New leader is 0
2017-05-16 17:09:04,558 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:04,559 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Starting up.
2017-05-16 17:09:04,559 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Startup complete.
2017-05-16 17:09:04,564 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:04,559 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds.
2017-05-16 17:09:04,565 INFO  [main] utils.Mx4jLoader$ (Logging.scala:info(70)) - Will not load MX4J, mx4j-tools.jar is not in the classpath
2017-05-16 17:09:04,567 WARN  [kafka-producer-network-thread | rcv-test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 55 : {test-s=INVALID_REPLICATION_FACTOR}
2017-05-16 17:09:04,570 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /brokers/ids/0 (is it secure? false)
2017-05-16 17:09:04,570 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x41 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-05-16 17:09:04,570 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x42 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-05-16 17:09:04,597 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:09:04,597 INFO  [main] utils.ZkUtils (Logging.scala:info(70)) - Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(127.0.0.1,9092,ListenerName(PLAINTEXT),PLAINTEXT)
2017-05-16 17:09:04,597 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafka-6039032718762417915/meta.properties
2017-05-16 17:09:04,597 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children 0
2017-05-16 17:09:04,600 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Newly added brokers: 0, deleted brokers: , all live brokers: 0
2017-05-16 17:09:04,603 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New broker startup callback for 0
2017-05-16 17:09:04,604 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Starting 
2017-05-16 17:09:04,604 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Controller 0 connected to 127.0.0.1:9092 (id: 0 rack: null) for sending state change requests
2017-05-16 17:09:04,672 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:setData cxid:0x4a zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/test-s Error:KeeperErrorCode = NoNode for /config/topics/test-s
2017-05-16 17:09:04,705 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:04,706 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:04,706 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], started
2017-05-16 17:09:04,755 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x4b zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:04,788 INFO  [kafka-request-handler-3] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:04,789 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190000 type:setData cxid:0x5 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/samoa_test-avro Error:KeeperErrorCode = NoNode for /config/topics/samoa_test-avro
2017-05-16 17:09:04,830 INFO  [kafka-request-handler-3] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic test-s with 1 partitions and replication factor 1 is successful
2017-05-16 17:09:04,831 WARN  [kafka-producer-network-thread | rcv-test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 56 : {test-s=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:04,856 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190000 type:create cxid:0x6 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:04,865 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(test-s)], deleted topics: [Set()], new partition replica assignment [Map([test-s,0] -> List(0))]
2017-05-16 17:09:04,865 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [test-s,0]
2017-05-16 17:09:04,972 INFO  [main] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:04,972 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [test-s,0]
2017-05-16 17:09:04,972 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test-s,0]
2017-05-16 17:09:04,973 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test-s,Partition=0,Replica=0]
2017-05-16 17:09:04,980 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test-s,0]
2017-05-16 17:09:04,981 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x53 zxid:0x24 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions/0
2017-05-16 17:09:04,997 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x54 zxid:0x25 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions
2017-05-16 17:09:05,005 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190000 type:setData cxid:0xd zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics/samoa_test-json Error:KeeperErrorCode = NoNode for /config/topics/samoa_test-json
2017-05-16 17:09:05,156 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190000 type:create cxid:0xe zxid:0x29 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:05,247 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test-s,Partition=0,Replica=0]
2017-05-16 17:09:05,248 INFO  [kafka-request-handler-3] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions test-s-0
2017-05-16 17:09:05,255 INFO  [main] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:05,257 INFO  [kafka-request-handler-3] log.Log (Logging.scala:info(70)) - Completed load of log test-s-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:05,258 INFO  [kafka-request-handler-3] log.LogManager (Logging.scala:info(70)) - Created log for partition [test-s,0] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:05,259 INFO  [kafka-request-handler-3] cluster.Partition (Logging.scala:info(70)) - Partition [test-s,0] on broker 0: No checkpointed highwatermark is found for partition test-s-0
2017-05-16 17:09:05,540 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(samoa_test-avro)], deleted topics: [Set()], new partition replica assignment [Map([samoa_test-avro,0] -> List(0))]
2017-05-16 17:09:05,540 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [samoa_test-avro,0]
2017-05-16 17:09:05,541 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [samoa_test-avro,0]
2017-05-16 17:09:05,541 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [samoa_test-avro,0]
2017-05-16 17:09:05,541 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=samoa_test-avro,Partition=0,Replica=0]
2017-05-16 17:09:05,542 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [samoa_test-avro,0]
2017-05-16 17:09:05,543 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x5e zxid:0x2d txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-avro/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-avro/partitions/0
2017-05-16 17:09:05,546 INFO  [Thread-433] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:05,546 INFO  [Thread-433] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-5
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:05,547 INFO  [Thread-433] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:05,547 INFO  [Thread-433] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:05,548 INFO  [Thread-434] producer.ProducerConfig (AbstractConfig.java:logAll(180)) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.id = test
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-05-16 17:09:05,553 WARN  [Thread-434] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'group.id' was supplied but isn't a known config.
2017-05-16 17:09:05,553 INFO  [Thread-434] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:05,553 INFO  [Thread-434] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:05,556 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x60 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-avro/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-avro/partitions
2017-05-16 17:09:05,691 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 2 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:05,706 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 1 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:05,822 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=samoa_test-avro,Partition=0,Replica=0]
2017-05-16 17:09:05,823 INFO  [kafka-request-handler-6] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions samoa_test-avro-0
2017-05-16 17:09:05,825 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:setData cxid:0x73 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-05-16 17:09:05,827 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(samoa_test-json)], deleted topics: [Set()], new partition replica assignment [Map([samoa_test-json,0] -> List(0))]
2017-05-16 17:09:05,827 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [samoa_test-json,0]
2017-05-16 17:09:05,828 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log samoa_test-avro-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:05,829 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [samoa_test-avro,0] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:05,829 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [samoa_test-avro,0] on broker 0: No checkpointed highwatermark is found for partition samoa_test-avro-0
2017-05-16 17:09:05,847 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [samoa_test-json,0]
2017-05-16 17:09:05,847 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [samoa_test-json,0]
2017-05-16 17:09:05,847 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x76 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:05,847 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 3 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:05,847 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=samoa_test-json,Partition=0,Replica=0]
2017-05-16 17:09:05,872 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [samoa_test-json,0]
2017-05-16 17:09:05,872 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x79 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-json/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-json/partitions/0
2017-05-16 17:09:05,981 INFO  [kafka-request-handler-4] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}}
2017-05-16 17:09:06,081 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x7c zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-json/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-json/partitions
2017-05-16 17:09:06,172 INFO  [kafka-request-handler-4] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2017-05-16 17:09:06,231 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:06,231 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:06,339 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=samoa_test-json,Partition=0,Replica=0]
2017-05-16 17:09:06,341 INFO  [kafka-request-handler-7] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions samoa_test-json-0
2017-05-16 17:09:06,346 INFO  [kafka-request-handler-7] log.Log (Logging.scala:info(70)) - Completed load of log samoa_test-json-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:06,347 INFO  [kafka-request-handler-7] log.LogManager (Logging.scala:info(70)) - Created log for partition [samoa_test-json,0] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:06,347 INFO  [kafka-request-handler-7] cluster.Partition (Logging.scala:info(70)) - Partition [samoa_test-json,0] on broker 0: No checkpointed highwatermark is found for partition samoa_test-json-0
2017-05-16 17:09:06,348 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 5 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:06,359 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map([__consumer_offsets,19] -> List(0), [__consumer_offsets,30] -> List(0), [__consumer_offsets,47] -> List(0), [__consumer_offsets,29] -> List(0), [__consumer_offsets,41] -> List(0), [__consumer_offsets,39] -> List(0), [__consumer_offsets,10] -> List(0), [__consumer_offsets,17] -> List(0), [__consumer_offsets,14] -> List(0), [__consumer_offsets,40] -> List(0), [__consumer_offsets,18] -> List(0), [__consumer_offsets,26] -> List(0), [__consumer_offsets,0] -> List(0), [__consumer_offsets,24] -> List(0), [__consumer_offsets,33] -> List(0), [__consumer_offsets,20] -> List(0), [__consumer_offsets,21] -> List(0), [__consumer_offsets,3] -> List(0), [__consumer_offsets,5] -> List(0), [__consumer_offsets,22] -> List(0), [__consumer_offsets,12] -> List(0), [__consumer_offsets,8] -> List(0), [__consumer_offsets,23] -> List(0), [__consumer_offsets,15] -> List(0), [__consumer_offsets,48] -> List(0), [__consumer_offsets,11] -> List(0), [__consumer_offsets,13] -> List(0), [__consumer_offsets,49] -> List(0), [__consumer_offsets,6] -> List(0), [__consumer_offsets,28] -> List(0), [__consumer_offsets,4] -> List(0), [__consumer_offsets,37] -> List(0), [__consumer_offsets,31] -> List(0), [__consumer_offsets,44] -> List(0), [__consumer_offsets,42] -> List(0), [__consumer_offsets,34] -> List(0), [__consumer_offsets,46] -> List(0), [__consumer_offsets,25] -> List(0), [__consumer_offsets,45] -> List(0), [__consumer_offsets,27] -> List(0), [__consumer_offsets,32] -> List(0), [__consumer_offsets,43] -> List(0), [__consumer_offsets,36] -> List(0), [__consumer_offsets,35] -> List(0), [__consumer_offsets,7] -> List(0), [__consumer_offsets,9] -> List(0), [__consumer_offsets,38] -> List(0), [__consumer_offsets,1] -> List(0), [__consumer_offsets,16] -> List(0), [__consumer_offsets,2] -> List(0))]
2017-05-16 17:09:06,360 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:06,363 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 6 : {samoa_test-json=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:06,364 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:06,364 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:06,366 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:09:06,383 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:06,386 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xc8 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-05-16 17:09:06,397 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xc9 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-05-16 17:09:06,622 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xd0 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-05-16 17:09:06,939 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xd6 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-05-16 17:09:07,125 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xdc zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-05-16 17:09:07,333 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xe2 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-05-16 17:09:07,724 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xe8 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-05-16 17:09:07,848 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xee zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-05-16 17:09:07,901 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xf4 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-05-16 17:09:07,924 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xf7 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-05-16 17:09:07,956 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0xfb zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-05-16 17:09:07,981 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x100 zxid:0x5b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-05-16 17:09:08,006 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x103 zxid:0x5e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-05-16 17:09:08,391 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x108 zxid:0x61 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-05-16 17:09:08,414 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x10d zxid:0x64 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-05-16 17:09:08,439 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x112 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-05-16 17:09:08,464 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x115 zxid:0x6a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-05-16 17:09:08,523 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x11a zxid:0x6d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-05-16 17:09:08,547 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x11e zxid:0x70 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-05-16 17:09:08,573 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x121 zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-05-16 17:09:08,597 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x124 zxid:0x76 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-05-16 17:09:08,622 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x12a zxid:0x79 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-05-16 17:09:08,647 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x12d zxid:0x7c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-05-16 17:09:08,673 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x130 zxid:0x7f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-05-16 17:09:08,697 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x133 zxid:0x82 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-05-16 17:09:08,723 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x138 zxid:0x85 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-05-16 17:09:08,747 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x13c zxid:0x88 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-05-16 17:09:08,796 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x13f zxid:0x8b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-05-16 17:09:08,822 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x144 zxid:0x8e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-05-16 17:09:08,849 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x148 zxid:0x91 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-05-16 17:09:08,885 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x14b zxid:0x94 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-05-16 17:09:08,921 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x150 zxid:0x97 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-05-16 17:09:08,957 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x154 zxid:0x9a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-05-16 17:09:09,007 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x157 zxid:0x9d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-05-16 17:09:09,033 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x15d zxid:0xa0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-05-16 17:09:09,082 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x160 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-05-16 17:09:09,133 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x165 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-05-16 17:09:09,189 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x169 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-05-16 17:09:09,215 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x16c zxid:0xac txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-05-16 17:09:09,239 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x172 zxid:0xaf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-05-16 17:09:09,264 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x175 zxid:0xb2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-05-16 17:09:09,289 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x178 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-05-16 17:09:09,316 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x17b zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-05-16 17:09:09,339 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x181 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-05-16 17:09:09,364 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x184 zxid:0xbe txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-05-16 17:09:09,389 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x187 zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-05-16 17:09:09,414 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x18a zxid:0xc4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-05-16 17:09:09,439 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x190 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-05-16 17:09:09,489 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x193 zxid:0xca txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-05-16 17:09:09,522 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x197 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-05-16 17:09:09,547 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ce2e190001 type:create cxid:0x19c zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-05-16 17:09:09,585 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:09:09,603 INFO  [kafka-request-handler-6] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2017-05-16 17:09:09,608 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,609 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,0] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,610 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-0
2017-05-16 17:09:09,614 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,615 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,29] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,616 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-29
2017-05-16 17:09:09,620 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,621 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,48] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,621 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-48
2017-05-16 17:09:09,626 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,627 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,10] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,628 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-10
2017-05-16 17:09:09,633 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,633 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,45] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,633 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-45
2017-05-16 17:09:09,638 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,639 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,26] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,639 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-26
2017-05-16 17:09:09,643 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,644 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,7] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,644 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-7
2017-05-16 17:09:09,649 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,650 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,42] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,650 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-42
2017-05-16 17:09:09,656 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,658 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,4] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,659 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-4
2017-05-16 17:09:09,664 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,665 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,23] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,665 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-23
2017-05-16 17:09:09,669 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,670 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,1] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,670 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-1
2017-05-16 17:09:09,674 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,675 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,20] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,675 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-20
2017-05-16 17:09:09,679 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,680 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,39] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,680 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-39
2017-05-16 17:09:09,683 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,684 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,17] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,684 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-17
2017-05-16 17:09:09,688 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,689 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,36] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,689 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-36
2017-05-16 17:09:09,692 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,693 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,14] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,693 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-14
2017-05-16 17:09:09,699 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,700 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,33] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,701 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-33
2017-05-16 17:09:09,705 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,706 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,49] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,706 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-49
2017-05-16 17:09:09,711 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,712 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,11] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,712 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-11
2017-05-16 17:09:09,716 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,717 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,30] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,718 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-30
2017-05-16 17:09:09,730 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,733 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,46] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,742 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-46
2017-05-16 17:09:09,750 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,750 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,27] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,752 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-27
2017-05-16 17:09:09,760 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,761 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,8] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,763 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-8
2017-05-16 17:09:09,769 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,769 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,24] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,772 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-24
2017-05-16 17:09:09,775 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,777 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,43] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,778 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-43
2017-05-16 17:09:09,785 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,786 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,5] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,790 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-5
2017-05-16 17:09:09,804 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,804 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,21] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,805 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-21
2017-05-16 17:09:09,808 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,808 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,2] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,808 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-2
2017-05-16 17:09:09,813 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,818 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,40] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,818 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-40
2017-05-16 17:09:09,826 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,827 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,37] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,827 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-37
2017-05-16 17:09:09,831 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,832 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,18] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,832 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-18
2017-05-16 17:09:09,837 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,838 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,34] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,839 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-34
2017-05-16 17:09:09,843 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,844 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,15] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,844 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-15
2017-05-16 17:09:09,848 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,849 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,12] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,850 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-12
2017-05-16 17:09:09,855 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,858 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,31] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,861 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-31
2017-05-16 17:09:09,869 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,870 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,9] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,870 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-9
2017-05-16 17:09:09,878 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,879 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,47] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,881 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-47
2017-05-16 17:09:09,888 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,888 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,19] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,889 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-19
2017-05-16 17:09:09,891 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,892 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,28] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,896 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-28
2017-05-16 17:09:09,899 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,905 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,38] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,905 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-38
2017-05-16 17:09:09,908 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,908 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,35] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,909 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-35
2017-05-16 17:09:09,918 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,919 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,44] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,919 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-44
2017-05-16 17:09:09,922 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,923 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,6] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,923 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-6
2017-05-16 17:09:09,931 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,934 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,25] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,937 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-25
2017-05-16 17:09:09,950 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,952 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,16] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,955 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-16
2017-05-16 17:09:09,968 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,970 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,22] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,972 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-22
2017-05-16 17:09:09,980 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,982 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,41] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,984 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-41
2017-05-16 17:09:09,990 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:09,992 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,32] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:09,993 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-32
2017-05-16 17:09:10,000 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:10,011 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,3] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:10,013 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-3
2017-05-16 17:09:10,021 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:10,022 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,13] in /tmp/kafka-6039032718762417915 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:10,023 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-13
2017-05-16 17:09:10,029 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-22
2017-05-16 17:09:10,030 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-22 in 1 milliseconds.
2017-05-16 17:09:10,030 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-25
2017-05-16 17:09:10,031 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-25 in 1 milliseconds.
2017-05-16 17:09:10,031 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-28
2017-05-16 17:09:10,032 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-28 in 1 milliseconds.
2017-05-16 17:09:10,032 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-31
2017-05-16 17:09:10,033 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-31 in 1 milliseconds.
2017-05-16 17:09:10,034 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-34
2017-05-16 17:09:10,035 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-34 in 1 milliseconds.
2017-05-16 17:09:10,035 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-37
2017-05-16 17:09:10,039 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-37 in 4 milliseconds.
2017-05-16 17:09:10,039 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-40
2017-05-16 17:09:10,040 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-40 in 1 milliseconds.
2017-05-16 17:09:10,040 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-43
2017-05-16 17:09:10,041 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-43 in 1 milliseconds.
2017-05-16 17:09:10,042 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-46
2017-05-16 17:09:10,043 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-46 in 1 milliseconds.
2017-05-16 17:09:10,043 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-49
2017-05-16 17:09:10,044 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-49 in 1 milliseconds.
2017-05-16 17:09:10,044 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-41
2017-05-16 17:09:10,045 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-41 in 1 milliseconds.
2017-05-16 17:09:10,046 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-44
2017-05-16 17:09:10,047 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-44 in 1 milliseconds.
2017-05-16 17:09:10,047 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-47
2017-05-16 17:09:10,048 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-47 in 1 milliseconds.
2017-05-16 17:09:10,048 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-1
2017-05-16 17:09:10,056 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-1 in 8 milliseconds.
2017-05-16 17:09:10,056 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-4
2017-05-16 17:09:10,057 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-4 in 1 milliseconds.
2017-05-16 17:09:10,058 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-7
2017-05-16 17:09:10,059 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-7 in 1 milliseconds.
2017-05-16 17:09:10,059 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-10
2017-05-16 17:09:10,060 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-10 in 1 milliseconds.
2017-05-16 17:09:10,060 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-13
2017-05-16 17:09:10,061 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-13 in 1 milliseconds.
2017-05-16 17:09:10,062 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-16
2017-05-16 17:09:10,063 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-16 in 1 milliseconds.
2017-05-16 17:09:10,063 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-19
2017-05-16 17:09:10,064 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-19 in 1 milliseconds.
2017-05-16 17:09:10,066 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-2
2017-05-16 17:09:10,067 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-2 in 1 milliseconds.
2017-05-16 17:09:10,067 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-5
2017-05-16 17:09:10,068 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-5 in 1 milliseconds.
2017-05-16 17:09:10,069 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-8
2017-05-16 17:09:10,070 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-8 in 1 milliseconds.
2017-05-16 17:09:10,070 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-11
2017-05-16 17:09:10,073 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-11 in 3 milliseconds.
2017-05-16 17:09:10,073 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-14
2017-05-16 17:09:10,074 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-14 in 1 milliseconds.
2017-05-16 17:09:10,074 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-17
2017-05-16 17:09:10,075 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-17 in 1 milliseconds.
2017-05-16 17:09:10,076 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-20
2017-05-16 17:09:10,077 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-20 in 1 milliseconds.
2017-05-16 17:09:10,077 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-23
2017-05-16 17:09:10,078 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-23 in 1 milliseconds.
2017-05-16 17:09:10,078 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-26
2017-05-16 17:09:10,079 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-26 in 1 milliseconds.
2017-05-16 17:09:10,080 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-29
2017-05-16 17:09:10,081 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-29 in 1 milliseconds.
2017-05-16 17:09:10,081 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-32
2017-05-16 17:09:10,082 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-32 in 1 milliseconds.
2017-05-16 17:09:10,082 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-35
2017-05-16 17:09:10,083 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-35 in 1 milliseconds.
2017-05-16 17:09:10,083 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-38
2017-05-16 17:09:10,097 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-38 in 14 milliseconds.
2017-05-16 17:09:10,097 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-0
2017-05-16 17:09:10,099 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-0 in 1 milliseconds.
2017-05-16 17:09:10,099 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-3
2017-05-16 17:09:10,100 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-3 in 1 milliseconds.
2017-05-16 17:09:10,101 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-6
2017-05-16 17:09:10,103 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-6 in 2 milliseconds.
2017-05-16 17:09:10,103 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-9
2017-05-16 17:09:10,105 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-9 in 2 milliseconds.
2017-05-16 17:09:10,106 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-12
2017-05-16 17:09:10,108 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-12 in 2 milliseconds.
2017-05-16 17:09:10,108 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-15
2017-05-16 17:09:10,119 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-15 in 11 milliseconds.
2017-05-16 17:09:10,120 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-18
2017-05-16 17:09:10,122 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-18 in 2 milliseconds.
2017-05-16 17:09:10,122 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-21
2017-05-16 17:09:10,123 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:10,124 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:09:10,126 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:10,127 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-21 in 5 milliseconds.
2017-05-16 17:09:10,128 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:10,128 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-24
2017-05-16 17:09:10,130 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-24 in 2 milliseconds.
2017-05-16 17:09:10,130 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-27
2017-05-16 17:09:10,132 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-27 in 2 milliseconds.
2017-05-16 17:09:10,132 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-30
2017-05-16 17:09:10,140 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-30 in 8 milliseconds.
2017-05-16 17:09:10,141 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-33
2017-05-16 17:09:10,142 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-33 in 1 milliseconds.
2017-05-16 17:09:10,142 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-36
2017-05-16 17:09:10,143 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-36 in 1 milliseconds.
2017-05-16 17:09:10,144 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-39
2017-05-16 17:09:10,145 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-39 in 1 milliseconds.
2017-05-16 17:09:10,145 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-42
2017-05-16 17:09:10,146 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-42 in 1 milliseconds.
2017-05-16 17:09:10,146 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-45
2017-05-16 17:09:10,148 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-45 in 1 milliseconds.
2017-05-16 17:09:10,148 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-48
2017-05-16 17:09:10,149 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-48 in 1 milliseconds.
2017-05-16 17:09:10,229 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:10,229 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:10,229 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 0
2017-05-16 17:09:10,229 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 1
2017-05-16 17:09:10,230 INFO  [kafka-request-handler-0] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 1
2017-05-16 17:09:10,232 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 1
2017-05-16 17:09:10,233 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:16,922 INFO  [Thread-434] producer.KafkaProducer (KafkaProducer.java:close(689)) - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-05-16 17:09:16,938 INFO  [Thread-435] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:16,942 INFO  [Thread-435] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-6
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:16,943 INFO  [Thread-435] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:16,943 INFO  [Thread-435] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:16,947 INFO  [Thread-436] producer.ProducerConfig (AbstractConfig.java:logAll(180)) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.id = test
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-05-16 17:09:16,948 INFO  [Thread-435] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:16,954 INFO  [Thread-435] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:09:16,954 INFO  [Thread-435] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:16,956 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 1
2017-05-16 17:09:16,973 WARN  [Thread-436] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'group.id' was supplied but isn't a known config.
2017-05-16 17:09:16,973 INFO  [Thread-436] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:16,973 INFO  [Thread-436] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:19,349 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:19,349 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:19,351 INFO  [kafka-request-handler-4] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 2
2017-05-16 17:09:19,442 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 2
2017-05-16 17:09:19,443 INFO  [Thread-435] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:09:19,443 INFO  [Thread-435] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [samoa_test-avro-0] for group test
2017-05-16 17:09:19,445 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:09:19,446 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:34,828 INFO  [Thread-436] producer.KafkaProducer (KafkaProducer.java:close(689)) - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-05-16 17:09:34,829 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shutting down
2017-05-16 17:09:34,829 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Starting controlled shutdown
2017-05-16 17:09:34,838 INFO  [kafka-request-handler-0] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Shutting down broker 0
2017-05-16 17:09:34,839 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Controlled shutdown succeeded
2017-05-16 17:09:34,840 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutting down
2017-05-16 17:09:34,845 INFO  [kafka-coordinator-heartbeat-thread | test] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:34,846 INFO  [kafka-coordinator-heartbeat-thread | test] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:34,847 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutdown completed
2017-05-16 17:09:34,863 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shutting down
2017-05-16 17:09:34,864 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shut down completely
2017-05-16 17:09:34,866 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutting down
2017-05-16 17:09:35,601 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Stopped 
2017-05-16 17:09:35,601 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutdown completed
2017-05-16 17:09:35,602 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutting down
2017-05-16 17:09:36,597 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Stopped 
2017-05-16 17:09:36,597 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutdown completed
2017-05-16 17:09:36,597 INFO  [main] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Shutdown complete.
2017-05-16 17:09:36,598 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shutting down
2017-05-16 17:09:36,598 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutting down
2017-05-16 17:09:36,598 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutdown completed
2017-05-16 17:09:36,598 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:36,729 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:36,729 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:36,729 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:36,827 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:36,828 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:36,901 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shut down completely
2017-05-16 17:09:36,901 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:37,027 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:37,028 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:37,028 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutting down.
2017-05-16 17:09:37,028 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:37,131 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:37,131 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:37,131 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:37,227 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:37,228 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:37,228 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutdown complete.
2017-05-16 17:09:37,228 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutting down.
2017-05-16 17:09:37,228 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Shutting down the log cleaner.
2017-05-16 17:09:37,228 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutting down
2017-05-16 17:09:37,229 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Stopped 
2017-05-16 17:09:37,229 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutdown completed
2017-05-16 17:09:38,116 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutdown complete.
2017-05-16 17:09:38,117 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Stopped partition state machine
2017-05-16 17:09:38,117 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Stopped replica state machine
2017-05-16 17:09:38,118 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutting down
2017-05-16 17:09:38,119 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Stopped 
2017-05-16 17:09:38,119 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutdown completed
2017-05-16 17:09:38,120 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 resigned as the controller
2017-05-16 17:09:38,120 INFO  [ZkClient-EventThread-544-127.0.0.1:58583] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:38,121 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11ce2e190001
2017-05-16 17:09:38,129 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11ce2e190001 closed
2017-05-16 17:09:38,130 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:38,130 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:41955 which had sessionid 0x15c11ce2e190001
2017-05-16 17:09:38,130 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shut down completed
2017-05-16 17:09:38,130 INFO  [ZkClient-EventThread-541-127.0.0.1:58583] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:38,131 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11ce2e190000
2017-05-16 17:09:38,138 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:41953 which had sessionid 0x15c11ce2e190000
2017-05-16 17:09:38,138 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11ce2e190000 closed
2017-05-16 17:09:38,138 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:38,138 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:38,151 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:38,151 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:38,152 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:38,152 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:run(143)) - PrepRequestProcessor exited loop!
2017-05-16 17:09:38,152 INFO  [SyncThread:0] server.SyncRequestProcessor (SyncRequestProcessor.java:run(187)) - SyncRequestProcessor exited!
2017-05-16 17:09:38,153 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
2017-05-16 17:09:38,153 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(224)) - NIOServerCnxn factory exited run method
2017-05-16 17:09:38,154 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:38,154 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:38,154 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:38,154 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:38,154 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.26 sec - in org.apache.samoa.streams.kafka.KafkaEntranceProcessorTest
Running org.apache.samoa.streams.kafka.KafkaDestinationProcessorTest
2017-05-16 17:09:38,158 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:<init>(162)) - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /tmp/kafka-2362286142852770838/version-2 snapdir /tmp/kafka-1602015381081675581/version-2
2017-05-16 17:09:38,159 INFO  [main] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:configure(94)) - binding to port /127.0.0.1:0
2017-05-16 17:09:38,195 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:57003 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@129f1e9d
2017-05-16 17:09:38,196 INFO  [ZkClient-EventThread-597-127.0.0.1:57003] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:09:38,197 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:09:38,201 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:57003. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:09:38,201 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:55036
2017-05-16 17:09:38,202 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:57003, initiating session
2017-05-16 17:09:38,202 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:55036
2017-05-16 17:09:38,202 INFO  [SyncThread:0] persistence.FileTxnLog (FileTxnLog.java:append(199)) - Creating new log file: log.1
2017-05-16 17:09:38,243 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11ceb3ef0000 with negotiated timeout 10000 for client /127.0.0.1:55036
2017-05-16 17:09:38,249 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:57003, sessionid = 0x15c11ceb3ef0000, negotiated timeout = 10000
2017-05-16 17:09:38,249 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:09:38,254 INFO  [main] server.KafkaConfig (AbstractConfig.java:logAll(180)) - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 0.10.2-IV0
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
	listeners = PLAINTEXT://127.0.0.1:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-9108766503664821944
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.2-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = 127.0.0.1:57003
	zookeeper.connection.timeout.ms = null
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-05-16 17:09:38,256 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - starting
2017-05-16 17:09:38,256 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Connecting to zookeeper on 127.0.0.1:57003
2017-05-16 17:09:38,261 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:<init>(438)) - Initiating client connection, connectString=127.0.0.1:57003 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@1b01387a
2017-05-16 17:09:38,261 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] zkclient.ZkEventThread (ZkEventThread.java:run(65)) - Starting ZkClient event thread.
2017-05-16 17:09:38,262 INFO  [main] zkclient.ZkClient (ZkClient.java:waitForKeeperState(936)) - Waiting for keeper state SyncConnected
2017-05-16 17:09:38,262 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:logStartConnect(975)) - Opening socket connection to server 127.0.0.1/127.0.0.1:57003. Will not attempt to authenticate using SASL (unknown error)
2017-05-16 17:09:38,262 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(197)) - Accepted socket connection from /127.0.0.1:55040
2017-05-16 17:09:38,262 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:primeConnection(852)) - Socket connection established to 127.0.0.1/127.0.0.1:57003, initiating session
2017-05-16 17:09:38,263 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.ZooKeeperServer (ZooKeeperServer.java:processConnectRequest(868)) - Client attempting to establish new session at /127.0.0.1:55040
2017-05-16 17:09:38,279 INFO  [SyncThread:0] server.ZooKeeperServer (ZooKeeperServer.java:finishSessionInit(617)) - Established session 0x15c11ceb3ef0001 with negotiated timeout 6000 for client /127.0.0.1:55040
2017-05-16 17:09:38,279 INFO  [main-SendThread(127.0.0.1:57003)] zookeeper.ClientCnxn (ClientCnxn.java:onConnected(1235)) - Session establishment complete on server 127.0.0.1/127.0.0.1:57003, sessionid = 0x15c11ceb3ef0001, negotiated timeout = 6000
2017-05-16 17:09:38,279 INFO  [main-EventThread] zkclient.ZkClient (ZkClient.java:processStateChanged(713)) - zookeeper state changed (SyncConnected)
2017-05-16 17:09:38,309 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x4 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-05-16 17:09:38,337 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xa zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-05-16 17:09:38,379 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x12 zxid:0xd txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-05-16 17:09:38,421 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1a zxid:0x12 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-05-16 17:09:38,446 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - Cluster ID = IVEtF-uITMCKnFiumv_52w
2017-05-16 17:09:38,447 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafka-9108766503664821944/meta.properties
2017-05-16 17:09:38,449 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Starting 
2017-05-16 17:09:38,450 INFO  [main] log.LogManager (Logging.scala:info(70)) - Loading logs.
2017-05-16 17:09:38,450 INFO  [main] log.LogManager (Logging.scala:info(70)) - Logs loading complete in 0 ms.
2017-05-16 17:09:38,482 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Starting 
2017-05-16 17:09:38,483 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log cleanup with a period of 300000 ms.
2017-05-16 17:09:38,483 INFO  [main] log.LogManager (Logging.scala:info(70)) - Starting log flusher with a default period of 9223372036854775807 ms.
2017-05-16 17:09:38,487 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Starting the log cleaner
2017-05-16 17:09:38,490 INFO  [main] network.Acceptor (Logging.scala:info(70)) - Awaiting socket connections on 127.0.0.1:9092.
2017-05-16 17:09:38,500 INFO  [SessionTracker] server.SessionTrackerImpl (SessionTrackerImpl.java:run(162)) - SessionTrackerImpl exited loop!
2017-05-16 17:09:38,525 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Started 1 acceptor threads
2017-05-16 17:09:38,528 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller starting up
2017-05-16 17:09:38,556 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Starting 
2017-05-16 17:09:38,557 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:38,557 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:38,558 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /controller (is it secure? false)
2017-05-16 17:09:38,572 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:09:38,572 INFO  [main] server.ZookeeperLeaderElector (Logging.scala:info(70)) - 0 successfully elected as leader
2017-05-16 17:09:38,572 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 starting become controller state transition
2017-05-16 17:09:38,573 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x24 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-05-16 17:09:38,589 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller 0 incremented epoch to 1
2017-05-16 17:09:38,599 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions undergoing preferred replica election: 
2017-05-16 17:09:38,599 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions that completed preferred replica election: 
2017-05-16 17:09:38,600 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming preferred replica election for partitions: 
2017-05-16 17:09:38,600 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions being reassigned: Map()
2017-05-16 17:09:38,600 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Partitions already reassigned: Set()
2017-05-16 17:09:38,601 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Resuming reassignment of partitions: Map()
2017-05-16 17:09:38,605 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics to be deleted: 
2017-05-16 17:09:38,609 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: List of topics ineligible for deletion: 
2017-05-16 17:09:38,609 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently active brokers in the cluster: Set()
2017-05-16 17:09:38,609 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Currently shutting brokers in the cluster: Set()
2017-05-16 17:09:38,610 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Current list of topics in the cluster: Set()
2017-05-16 17:09:38,611 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Started replica state machine with initial state -> Map()
2017-05-16 17:09:38,617 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Started partition state machine with initial state -> Map()
2017-05-16 17:09:38,618 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 is ready to serve as the new controller with epoch 1
2017-05-16 17:09:38,618 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Starting preferred replica leader election for partitions 
2017-05-16 17:09:38,618 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions 
2017-05-16 17:09:38,619 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:delete cxid:0x35 zxid:0x18 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-05-16 17:09:38,629 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: starting the partition rebalance scheduler
2017-05-16 17:09:38,642 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Controller startup complete
2017-05-16 17:09:38,643 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] server.ZookeeperLeaderElector$LeaderChangeListener (Logging.scala:info(70)) - New leader is 0
2017-05-16 17:09:38,646 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:38,649 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Starting up.
2017-05-16 17:09:38,650 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Startup complete.
2017-05-16 17:09:38,659 INFO  [main] utils.Mx4jLoader$ (Logging.scala:info(70)) - Will not load MX4J, mx4j-tools.jar is not in the classpath
2017-05-16 17:09:38,661 WARN  [kafka-producer-network-thread | rcv-test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 58 : {test-s=INVALID_REPLICATION_FACTOR}
2017-05-16 17:09:38,666 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Creating /brokers/ids/0 (is it secure? false)
2017-05-16 17:09:38,653 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:38,667 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Starting 
2017-05-16 17:09:38,667 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 0 milliseconds.
2017-05-16 17:09:38,667 WARN  [Thread-435] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 8100 : {samoa_test-avro=INVALID_REPLICATION_FACTOR}
2017-05-16 17:09:38,668 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x44 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-05-16 17:09:38,668 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x45 zxid:0x1a txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-05-16 17:09:38,669 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4568 : {samoa_test-json=INVALID_REPLICATION_FACTOR, samoa_test-avro=INVALID_REPLICATION_FACTOR}
2017-05-16 17:09:38,687 INFO  [main] utils.ZKCheckedEphemeral (Logging.scala:info(70)) - Result of znode creation is: OK
2017-05-16 17:09:38,688 INFO  [main] utils.ZkUtils (Logging.scala:info(70)) - Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(127.0.0.1,9092,ListenerName(PLAINTEXT),PLAINTEXT)
2017-05-16 17:09:38,689 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Broker change listener fired for path /brokers/ids with children 0
2017-05-16 17:09:38,689 WARN  [main] server.BrokerMetadataCheckpoint (Logging.scala:warn(85)) - No meta.properties file under dir /tmp/kafka-9108766503664821944/meta.properties
2017-05-16 17:09:38,693 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine$BrokerChangeListener (Logging.scala:info(70)) - [BrokerChangeListener on Controller 0]: Newly added brokers: 0, deleted brokers: , all live brokers: 0
2017-05-16 17:09:38,701 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New broker startup callback for 0
2017-05-16 17:09:38,702 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Starting 
2017-05-16 17:09:38,702 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Controller 0 connected to 127.0.0.1:9092 (id: 0 rack: null) for sending state change requests
2017-05-16 17:09:38,727 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:38,727 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:38,727 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], started
2017-05-16 17:09:38,750 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0000 type:setData cxid:0x4 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/test-kdp Error:KeeperErrorCode = NoNode for /config/topics/test-kdp
2017-05-16 17:09:38,762 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0000 type:create cxid:0x5 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:38,781 INFO  [main] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:39,187 INFO  [main] producer.ProducerConfig (AbstractConfig.java:logAll(180)) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:9092]
	buffer.memory = 33554432
	client.id = test
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-05-16 17:09:39,193 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x55 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/test-s Error:KeeperErrorCode = NoNode for /config/topics/test-s
2017-05-16 17:09:39,196 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(test-kdp)], deleted topics: [Set()], new partition replica assignment [Map([test-kdp,0] -> List(0))]
2017-05-16 17:09:39,196 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [test-kdp,0]
2017-05-16 17:09:39,204 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x58 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:39,205 WARN  [main] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'group.id' was supplied but isn't a known config.
2017-05-16 17:09:39,205 WARN  [main] producer.ProducerConfig (AbstractConfig.java:logUnused(188)) - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2017-05-16 17:09:39,205 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:39,205 INFO  [main] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:39,206 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x5a zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/topics/samoa_test-avro Error:KeeperErrorCode = NoNode for /config/topics/samoa_test-avro
2017-05-16 17:09:39,234 INFO  [Thread-441] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:39,238 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x5e zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/samoa_test-json Error:KeeperErrorCode = NoNode for /config/topics/samoa_test-json
2017-05-16 17:09:39,244 INFO  [Thread-441] consumer.ConsumerConfig (AbstractConfig.java:logAll(180)) - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:9092]
	check.crcs = true
	client.id = consumer-7
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-05-16 17:09:39,248 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [test-kdp,0]
2017-05-16 17:09:39,249 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test-kdp,0]
2017-05-16 17:09:39,250 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test-kdp,Partition=0,Replica=0]
2017-05-16 17:09:39,246 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x5f zxid:0x25 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:39,252 INFO  [Thread-441] utils.AppInfoParser (AppInfoParser.java:<init>(83)) - Kafka version : 0.10.2.0
2017-05-16 17:09:39,252 INFO  [Thread-441] utils.AppInfoParser (AppInfoParser.java:<init>(84)) - Kafka commitId : 576d93a8dc0cf421
2017-05-16 17:09:39,254 INFO  [kafka-request-handler-7] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:39,254 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x63 zxid:0x27 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:39,262 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test-kdp,0]
2017-05-16 17:09:39,263 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x65 zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-kdp/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/test-kdp/partitions/0
2017-05-16 17:09:39,271 INFO  [kafka-request-handler-7] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic test-s with 1 partitions and replication factor 1 is successful
2017-05-16 17:09:39,273 WARN  [kafka-producer-network-thread | rcv-test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 59 : {test-s=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,279 INFO  [kafka-request-handler-4] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:39,281 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x6b zxid:0x2c txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-kdp/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/test-kdp/partitions
2017-05-16 17:09:39,284 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 1 : {test-kdp=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,288 INFO  [kafka-request-handler-5] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"0":[0]}}
2017-05-16 17:09:39,296 INFO  [kafka-request-handler-4] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic samoa_test-avro with 1 partitions and replication factor 1 is successful
2017-05-16 17:09:39,296 WARN  [Thread-435] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 8101 : {samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,297 WARN  [Thread-441] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 2 : {test-kdp=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,304 INFO  [kafka-request-handler-5] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic samoa_test-json with 1 partitions and replication factor 1 is successful
2017-05-16 17:09:39,371 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test-kdp,Partition=0,Replica=0]
2017-05-16 17:09:39,372 INFO  [kafka-request-handler-6] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions test-kdp-0
2017-05-16 17:09:39,373 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4569 : {samoa_test-json=LEADER_NOT_AVAILABLE, samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,376 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x7f zxid:0x31 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-05-16 17:09:39,378 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:setData cxid:0x82 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-05-16 17:09:39,378 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log test-kdp-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:39,379 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [test-kdp,0] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:39,379 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [test-kdp,0] on broker 0: No checkpointed highwatermark is found for partition test-kdp-0
2017-05-16 17:09:39,387 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x84 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:39,390 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x88 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-05-16 17:09:39,438 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x8b zxid:0x36 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NodeExists for /config/topics/__consumer_offsets
2017-05-16 17:09:39,447 INFO  [kafka-request-handler-1] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}}
2017-05-16 17:09:39,456 WARN  [kafka-producer-network-thread | test] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 3 : {test-kdp=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,463 INFO  [kafka-request-handler-7] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}}
2017-05-16 17:09:39,464 INFO  [kafka-request-handler-1] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful
2017-05-16 17:09:39,464 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x92 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets Error:KeeperErrorCode = NodeExists for /brokers/topics/__consumer_offsets
2017-05-16 17:09:39,471 INFO  [kafka-request-handler-0] admin.AdminUtils$ (Logging.scala:info(70)) - Topic creation {"version":1,"partitions":{"45":[0],"34":[0],"12":[0],"8":[0],"19":[0],"23":[0],"4":[0],"40":[0],"15":[0],"11":[0],"9":[0],"44":[0],"33":[0],"22":[0],"26":[0],"37":[0],"13":[0],"46":[0],"24":[0],"35":[0],"16":[0],"5":[0],"10":[0],"48":[0],"21":[0],"43":[0],"32":[0],"49":[0],"6":[0],"36":[0],"1":[0],"39":[0],"17":[0],"25":[0],"14":[0],"47":[0],"31":[0],"42":[0],"0":[0],"20":[0],"27":[0],"2":[0],"38":[0],"18":[0],"30":[0],"7":[0],"29":[0],"41":[0],"3":[0],"28":[0]}}
2017-05-16 17:09:39,472 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x94 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets Error:KeeperErrorCode = NodeExists for /brokers/topics/__consumer_offsets
2017-05-16 17:09:39,473 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(samoa_test-json, samoa_test-avro, test-s)], deleted topics: [Set()], new partition replica assignment [Map([test-s,0] -> List(0), [samoa_test-json,0] -> List(0), [samoa_test-avro,0] -> List(0))]
2017-05-16 17:09:39,473 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [test-s,0],[samoa_test-json,0],[samoa_test-avro,0]
2017-05-16 17:09:39,482 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [test-s,0],[samoa_test-json,0],[samoa_test-avro,0]
2017-05-16 17:09:39,482 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [test-s,0],[samoa_test-json,0],[samoa_test-avro,0]
2017-05-16 17:09:39,482 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=test-s,Partition=0,Replica=0],[Topic=samoa_test-json,Partition=0,Replica=0],[Topic=samoa_test-avro,Partition=0,Replica=0]
2017-05-16 17:09:39,483 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [test-s,0],[samoa_test-json,0],[samoa_test-avro,0]
2017-05-16 17:09:39,485 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xa2 zxid:0x3c txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions/0
2017-05-16 17:09:39,485 WARN  [Thread-435] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 8103 : {samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,496 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xa5 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/test-s/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/test-s/partitions
2017-05-16 17:09:39,521 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4571 : {samoa_test-json=LEADER_NOT_AVAILABLE, samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,531 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xb0 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-json/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-json/partitions/0
2017-05-16 17:09:39,538 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xb2 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-json/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-json/partitions
2017-05-16 17:09:39,579 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xb9 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-avro/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-avro/partitions/0
2017-05-16 17:09:39,588 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0xba zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/samoa_test-avro/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/samoa_test-avro/partitions
2017-05-16 17:09:39,605 WARN  [Thread-435] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 8105 : {samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,623 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=test-s,Partition=0,Replica=0],[Topic=samoa_test-json,Partition=0,Replica=0],[Topic=samoa_test-avro,Partition=0,Replica=0]
2017-05-16 17:09:39,626 INFO  [kafka-request-handler-7] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions samoa_test-json-0,samoa_test-avro-0,test-s-0
2017-05-16 17:09:39,640 INFO  [kafka-request-handler-7] log.Log (Logging.scala:info(70)) - Completed load of log samoa_test-json-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:39,645 INFO  [kafka-request-handler-7] log.LogManager (Logging.scala:info(70)) - Created log for partition [samoa_test-json,0] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:39,646 INFO  [kafka-request-handler-7] cluster.Partition (Logging.scala:info(70)) - Partition [samoa_test-json,0] on broker 0: No checkpointed highwatermark is found for partition samoa_test-json-0
2017-05-16 17:09:39,647 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine$TopicChangeListener (Logging.scala:info(70)) - [TopicChangeListener on Controller 0]: New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map([__consumer_offsets,19] -> List(0), [__consumer_offsets,30] -> List(0), [__consumer_offsets,47] -> List(0), [__consumer_offsets,29] -> List(0), [__consumer_offsets,41] -> List(0), [__consumer_offsets,39] -> List(0), [__consumer_offsets,10] -> List(0), [__consumer_offsets,17] -> List(0), [__consumer_offsets,14] -> List(0), [__consumer_offsets,40] -> List(0), [__consumer_offsets,18] -> List(0), [__consumer_offsets,26] -> List(0), [__consumer_offsets,0] -> List(0), [__consumer_offsets,24] -> List(0), [__consumer_offsets,33] -> List(0), [__consumer_offsets,20] -> List(0), [__consumer_offsets,21] -> List(0), [__consumer_offsets,3] -> List(0), [__consumer_offsets,5] -> List(0), [__consumer_offsets,22] -> List(0), [__consumer_offsets,12] -> List(0), [__consumer_offsets,8] -> List(0), [__consumer_offsets,23] -> List(0), [__consumer_offsets,15] -> List(0), [__consumer_offsets,48] -> List(0), [__consumer_offsets,11] -> List(0), [__consumer_offsets,13] -> List(0), [__consumer_offsets,49] -> List(0), [__consumer_offsets,6] -> List(0), [__consumer_offsets,28] -> List(0), [__consumer_offsets,4] -> List(0), [__consumer_offsets,37] -> List(0), [__consumer_offsets,31] -> List(0), [__consumer_offsets,44] -> List(0), [__consumer_offsets,42] -> List(0), [__consumer_offsets,34] -> List(0), [__consumer_offsets,46] -> List(0), [__consumer_offsets,25] -> List(0), [__consumer_offsets,45] -> List(0), [__consumer_offsets,27] -> List(0), [__consumer_offsets,32] -> List(0), [__consumer_offsets,43] -> List(0), [__consumer_offsets,36] -> List(0), [__consumer_offsets,35] -> List(0), [__consumer_offsets,7] -> List(0), [__consumer_offsets,9] -> List(0), [__consumer_offsets,38] -> List(0), [__consumer_offsets,1] -> List(0), [__consumer_offsets,16] -> List(0), [__consumer_offsets,2] -> List(0))]
2017-05-16 17:09:39,652 WARN  [Thread-433] clients.NetworkClient (NetworkClient.java:handleCompletedMetadataResponse(707)) - Error while fetching metadata with correlation id 4573 : {samoa_test-json=LEADER_NOT_AVAILABLE, samoa_test-avro=LEADER_NOT_AVAILABLE}
2017-05-16 17:09:39,656 INFO  [kafka-request-handler-7] log.Log (Logging.scala:info(70)) - Completed load of log samoa_test-avro-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:39,656 INFO  [kafka-request-handler-7] log.LogManager (Logging.scala:info(70)) - Created log for partition [samoa_test-avro,0] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:39,657 INFO  [kafka-request-handler-7] cluster.Partition (Logging.scala:info(70)) - Partition [samoa_test-avro,0] on broker 0: No checkpointed highwatermark is found for partition samoa_test-avro-0
2017-05-16 17:09:39,657 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New topic creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:39,666 INFO  [kafka-request-handler-7] log.Log (Logging.scala:info(70)) - Completed load of log test-s-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:39,667 INFO  [kafka-request-handler-7] log.LogManager (Logging.scala:info(70)) - Created log for partition [test-s,0] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:39,667 INFO  [kafka-request-handler-7] cluster.Partition (Logging.scala:info(70)) - Partition [test-s,0] on broker 0: No checkpointed highwatermark is found for partition test-s-0
2017-05-16 17:09:39,668 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: New partition creation callback for [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:39,668 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to NewPartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:39,673 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to NewReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:09:39,729 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Invoking state change to OnlinePartition for partitions [__consumer_offsets,19],[__consumer_offsets,30],[__consumer_offsets,47],[__consumer_offsets,29],[__consumer_offsets,41],[__consumer_offsets,39],[__consumer_offsets,10],[__consumer_offsets,17],[__consumer_offsets,14],[__consumer_offsets,40],[__consumer_offsets,18],[__consumer_offsets,26],[__consumer_offsets,0],[__consumer_offsets,24],[__consumer_offsets,33],[__consumer_offsets,20],[__consumer_offsets,21],[__consumer_offsets,3],[__consumer_offsets,5],[__consumer_offsets,22],[__consumer_offsets,12],[__consumer_offsets,8],[__consumer_offsets,23],[__consumer_offsets,15],[__consumer_offsets,48],[__consumer_offsets,11],[__consumer_offsets,13],[__consumer_offsets,49],[__consumer_offsets,6],[__consumer_offsets,28],[__consumer_offsets,4],[__consumer_offsets,37],[__consumer_offsets,31],[__consumer_offsets,44],[__consumer_offsets,42],[__consumer_offsets,34],[__consumer_offsets,46],[__consumer_offsets,25],[__consumer_offsets,45],[__consumer_offsets,27],[__consumer_offsets,32],[__consumer_offsets,43],[__consumer_offsets,36],[__consumer_offsets,35],[__consumer_offsets,7],[__consumer_offsets,9],[__consumer_offsets,38],[__consumer_offsets,1],[__consumer_offsets,16],[__consumer_offsets,2]
2017-05-16 17:09:39,734 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x10c zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-05-16 17:09:39,753 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x10d zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-05-16 17:09:39,822 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x119 zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-05-16 17:09:39,854 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x11d zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-05-16 17:09:39,889 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x125 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-05-16 17:09:39,912 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x12b zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-05-16 17:09:39,937 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x12f zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-05-16 17:09:39,963 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x133 zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-05-16 17:09:39,988 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x13b zxid:0x62 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-05-16 17:09:40,013 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x13e zxid:0x65 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-05-16 17:09:40,038 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x144 zxid:0x68 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-05-16 17:09:40,063 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x148 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-05-16 17:09:40,088 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x14f zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-05-16 17:09:40,146 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x156 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-05-16 17:09:40,173 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x15b zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-05-16 17:09:40,196 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x162 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-05-16 17:09:40,221 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x166 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-05-16 17:09:40,247 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x16b zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-05-16 17:09:40,271 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x170 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-05-16 17:09:40,296 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x177 zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-05-16 17:09:40,321 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x17b zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-05-16 17:09:40,346 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x180 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-05-16 17:09:40,371 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x183 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-05-16 17:09:40,415 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x18c zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-05-16 17:09:40,446 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x192 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-05-16 17:09:40,471 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x195 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-05-16 17:09:40,496 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x19e zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-05-16 17:09:40,523 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1a2 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-05-16 17:09:40,546 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1a7 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-05-16 17:09:40,571 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1aa zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-05-16 17:09:40,604 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1b3 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-05-16 17:09:40,629 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1b8 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-05-16 17:09:40,663 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1bc zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-05-16 17:09:40,708 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1c3 zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-05-16 17:09:40,738 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1cb zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-05-16 17:09:40,764 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1ce zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-05-16 17:09:40,789 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1d3 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-05-16 17:09:40,813 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1da zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-05-16 17:09:40,840 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1e0 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-05-16 17:09:40,865 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1e3 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-05-16 17:09:40,888 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1e8 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-05-16 17:09:40,918 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1ef zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-05-16 17:09:40,938 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1f5 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-05-16 17:09:40,963 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x1f8 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-05-16 17:09:41,014 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x200 zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-05-16 17:09:41,038 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x206 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-05-16 17:09:41,063 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x20a zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-05-16 17:09:41,088 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x20f zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-05-16 17:09:41,122 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x216 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-05-16 17:09:41,147 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x21c zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-05-16 17:09:41,180 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest(645)) - Got user-level KeeperException when processing sessionid:0x15c11ceb3ef0001 type:create cxid:0x21f zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-05-16 17:09:41,205 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Invoking state change to OnlineReplica for replicas [Topic=__consumer_offsets,Partition=25,Replica=0],[Topic=__consumer_offsets,Partition=12,Replica=0],[Topic=__consumer_offsets,Partition=31,Replica=0],[Topic=__consumer_offsets,Partition=40,Replica=0],[Topic=__consumer_offsets,Partition=35,Replica=0],[Topic=__consumer_offsets,Partition=9,Replica=0],[Topic=__consumer_offsets,Partition=43,Replica=0],[Topic=__consumer_offsets,Partition=2,Replica=0],[Topic=__consumer_offsets,Partition=11,Replica=0],[Topic=__consumer_offsets,Partition=29,Replica=0],[Topic=__consumer_offsets,Partition=30,Replica=0],[Topic=__consumer_offsets,Partition=4,Replica=0],[Topic=__consumer_offsets,Partition=42,Replica=0],[Topic=__consumer_offsets,Partition=26,Replica=0],[Topic=__consumer_offsets,Partition=34,Replica=0],[Topic=__consumer_offsets,Partition=17,Replica=0],[Topic=__consumer_offsets,Partition=37,Replica=0],[Topic=__consumer_offsets,Partition=27,Replica=0],[Topic=__consumer_offsets,Partition=10,Replica=0],[Topic=__consumer_offsets,Partition=41,Replica=0],[Topic=__consumer_offsets,Partition=20,Replica=0],[Topic=__consumer_offsets,Partition=28,Replica=0],[Topic=__consumer_offsets,Partition=46,Replica=0],[Topic=__consumer_offsets,Partition=39,Replica=0],[Topic=__consumer_offsets,Partition=47,Replica=0],[Topic=__consumer_offsets,Partition=49,Replica=0],[Topic=__consumer_offsets,Partition=22,Replica=0],[Topic=__consumer_offsets,Partition=1,Replica=0],[Topic=__consumer_offsets,Partition=24,Replica=0],[Topic=__consumer_offsets,Partition=6,Replica=0],[Topic=__consumer_offsets,Partition=36,Replica=0],[Topic=__consumer_offsets,Partition=8,Replica=0],[Topic=__consumer_offsets,Partition=38,Replica=0],[Topic=__consumer_offsets,Partition=16,Replica=0],[Topic=__consumer_offsets,Partition=21,Replica=0],[Topic=__consumer_offsets,Partition=18,Replica=0],[Topic=__consumer_offsets,Partition=0,Replica=0],[Topic=__consumer_offsets,Partition=48,Replica=0],[Topic=__consumer_offsets,Partition=5,Replica=0],[Topic=__consumer_offsets,Partition=13,Replica=0],[Topic=__consumer_offsets,Partition=3,Replica=0],[Topic=__consumer_offsets,Partition=44,Replica=0],[Topic=__consumer_offsets,Partition=15,Replica=0],[Topic=__consumer_offsets,Partition=7,Replica=0],[Topic=__consumer_offsets,Partition=19,Replica=0],[Topic=__consumer_offsets,Partition=33,Replica=0],[Topic=__consumer_offsets,Partition=45,Replica=0],[Topic=__consumer_offsets,Partition=23,Replica=0],[Topic=__consumer_offsets,Partition=32,Replica=0],[Topic=__consumer_offsets,Partition=14,Replica=0]
2017-05-16 17:09:41,226 INFO  [kafka-request-handler-6] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40
2017-05-16 17:09:41,246 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,249 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,0] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,250 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,0] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-0
2017-05-16 17:09:41,256 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,257 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,29] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,258 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,29] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-29
2017-05-16 17:09:41,272 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,273 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,48] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,273 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,48] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-48
2017-05-16 17:09:41,277 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,278 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,10] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,297 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,10] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-10
2017-05-16 17:09:41,304 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,305 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,45] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,312 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,45] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-45
2017-05-16 17:09:41,318 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,323 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,26] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,330 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,26] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-26
2017-05-16 17:09:41,336 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,341 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,7] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,342 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,7] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-7
2017-05-16 17:09:41,352 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,355 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,42] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,356 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,42] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-42
2017-05-16 17:09:41,361 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,365 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,4] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,366 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,4] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-4
2017-05-16 17:09:41,368 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,374 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,23] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,374 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,23] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-23
2017-05-16 17:09:41,377 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,378 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,1] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,378 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,1] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-1
2017-05-16 17:09:41,393 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,394 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,20] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,394 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,20] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-20
2017-05-16 17:09:41,397 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,398 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,39] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,398 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,39] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-39
2017-05-16 17:09:41,401 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,401 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,17] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,402 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,17] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-17
2017-05-16 17:09:41,405 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,406 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,36] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,406 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,36] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-36
2017-05-16 17:09:41,409 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,410 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,14] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,410 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,14] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-14
2017-05-16 17:09:41,413 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,413 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,33] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,414 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,33] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-33
2017-05-16 17:09:41,416 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,417 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,49] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,418 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,49] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-49
2017-05-16 17:09:41,422 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,423 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,11] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,424 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,11] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-11
2017-05-16 17:09:41,433 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,434 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,30] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,436 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,30] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-30
2017-05-16 17:09:41,449 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,452 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,46] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,454 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,46] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-46
2017-05-16 17:09:41,465 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,467 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,27] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,469 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,27] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-27
2017-05-16 17:09:41,476 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,477 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,8] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,477 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,8] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-8
2017-05-16 17:09:41,489 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,493 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,24] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,494 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,24] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-24
2017-05-16 17:09:41,509 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,510 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,43] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,511 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,43] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-43
2017-05-16 17:09:41,525 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,529 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,5] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,532 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,5] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-5
2017-05-16 17:09:41,542 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,546 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,21] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,547 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,21] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-21
2017-05-16 17:09:41,559 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,561 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,2] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,564 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,2] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-2
2017-05-16 17:09:41,571 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,572 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,40] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,573 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,40] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-40
2017-05-16 17:09:41,581 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,583 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,37] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,584 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,37] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-37
2017-05-16 17:09:41,592 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,594 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,18] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,594 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,18] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-18
2017-05-16 17:09:41,598 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,599 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,34] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,600 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,34] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-34
2017-05-16 17:09:41,611 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,613 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,15] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,614 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,15] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-15
2017-05-16 17:09:41,619 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,621 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,12] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,622 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,12] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-12
2017-05-16 17:09:41,625 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,628 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,31] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,629 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,31] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-31
2017-05-16 17:09:41,638 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,639 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,9] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,639 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,9] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-9
2017-05-16 17:09:41,643 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,644 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,47] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,644 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,47] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-47
2017-05-16 17:09:41,651 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,659 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,19] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,661 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,19] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-19
2017-05-16 17:09:41,665 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,669 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,28] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,671 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,28] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-28
2017-05-16 17:09:41,675 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,675 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,38] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,676 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,38] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-38
2017-05-16 17:09:41,679 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,680 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,35] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,680 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,35] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-35
2017-05-16 17:09:41,682 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,683 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,44] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,683 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,44] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-44
2017-05-16 17:09:41,685 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,686 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,6] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,686 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,6] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-6
2017-05-16 17:09:41,688 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,688 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,25] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,689 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,25] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-25
2017-05-16 17:09:41,691 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,691 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,16] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,692 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,16] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-16
2017-05-16 17:09:41,695 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,695 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,22] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,696 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,22] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-22
2017-05-16 17:09:41,707 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,708 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,41] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,708 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,41] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-41
2017-05-16 17:09:41,713 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,714 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,32] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,714 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,32] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-32
2017-05-16 17:09:41,722 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,722 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,3] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,723 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,3] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-3
2017-05-16 17:09:41,726 INFO  [kafka-request-handler-6] log.Log (Logging.scala:info(70)) - Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 0 ms
2017-05-16 17:09:41,727 INFO  [kafka-request-handler-6] log.LogManager (Logging.scala:info(70)) - Created log for partition [__consumer_offsets,13] in /tmp/kafka-9108766503664821944 with properties {compression.type -> producer, message.format.version -> 0.10.2-IV0, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> true, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
2017-05-16 17:09:41,727 INFO  [kafka-request-handler-6] cluster.Partition (Logging.scala:info(70)) - Partition [__consumer_offsets,13] on broker 0: No checkpointed highwatermark is found for partition __consumer_offsets-13
2017-05-16 17:09:41,757 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-22
2017-05-16 17:09:41,758 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-22 in 1 milliseconds.
2017-05-16 17:09:41,758 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-25
2017-05-16 17:09:41,759 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-25 in 1 milliseconds.
2017-05-16 17:09:41,759 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-28
2017-05-16 17:09:41,765 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-28 in 5 milliseconds.
2017-05-16 17:09:41,766 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-31
2017-05-16 17:09:41,767 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-31 in 1 milliseconds.
2017-05-16 17:09:41,767 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-34
2017-05-16 17:09:41,770 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-34 in 3 milliseconds.
2017-05-16 17:09:41,770 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-37
2017-05-16 17:09:41,777 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-37 in 7 milliseconds.
2017-05-16 17:09:41,778 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-40
2017-05-16 17:09:41,779 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-40 in 1 milliseconds.
2017-05-16 17:09:41,779 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-43
2017-05-16 17:09:41,785 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-43 in 6 milliseconds.
2017-05-16 17:09:41,785 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-46
2017-05-16 17:09:41,786 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-46 in 1 milliseconds.
2017-05-16 17:09:41,786 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-49
2017-05-16 17:09:41,787 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-49 in 1 milliseconds.
2017-05-16 17:09:41,788 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-41
2017-05-16 17:09:41,793 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:41,794 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-41 in 6 milliseconds.
2017-05-16 17:09:41,794 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-44
2017-05-16 17:09:41,798 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-44 in 4 milliseconds.
2017-05-16 17:09:41,798 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-47
2017-05-16 17:09:41,801 INFO  [Thread-441] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [] for group test
2017-05-16 17:09:41,801 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:41,801 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-47 in 3 milliseconds.
2017-05-16 17:09:41,801 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-1
2017-05-16 17:09:41,812 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-1 in 10 milliseconds.
2017-05-16 17:09:41,813 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-4
2017-05-16 17:09:41,817 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:41,818 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-4 in 5 milliseconds.
2017-05-16 17:09:41,819 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-7
2017-05-16 17:09:41,822 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-7 in 2 milliseconds.
2017-05-16 17:09:41,822 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-10
2017-05-16 17:09:41,824 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-10 in 2 milliseconds.
2017-05-16 17:09:41,824 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-13
2017-05-16 17:09:41,826 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-13 in 2 milliseconds.
2017-05-16 17:09:41,827 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-16
2017-05-16 17:09:41,829 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-16 in 2 milliseconds.
2017-05-16 17:09:41,830 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-19
2017-05-16 17:09:41,830 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:41,832 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-19 in 2 milliseconds.
2017-05-16 17:09:41,832 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-2
2017-05-16 17:09:41,834 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-2 in 2 milliseconds.
2017-05-16 17:09:41,834 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-5
2017-05-16 17:09:41,836 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-5 in 2 milliseconds.
2017-05-16 17:09:41,837 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-8
2017-05-16 17:09:41,838 INFO  [Thread-435] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:41,839 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-8 in 2 milliseconds.
2017-05-16 17:09:41,839 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-11
2017-05-16 17:09:41,841 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-11 in 2 milliseconds.
2017-05-16 17:09:41,842 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-14
2017-05-16 17:09:41,843 INFO  [Thread-433] internals.Fetcher (Fetcher.java:parseCompletedFetch(820)) - Fetch offset 11111 is out of range for partition samoa_test-json-0, resetting offset
2017-05-16 17:09:41,843 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-14 in 1 milliseconds.
2017-05-16 17:09:41,844 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-17
2017-05-16 17:09:41,844 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:41,845 WARN  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onComplete(622)) - Auto-commit of offsets {samoa_test-json-0=OffsetAndMetadata{offset=11111, metadata=''}} failed for group test: Offset commit failed with a retriable exception. You should retry committing offsets.
2017-05-16 17:09:41,846 INFO  [Thread-435] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:41,847 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-17 in 2 milliseconds.
2017-05-16 17:09:41,853 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-20
2017-05-16 17:09:41,855 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-20 in 2 milliseconds.
2017-05-16 17:09:41,856 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-23
2017-05-16 17:09:41,859 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-23 in 3 milliseconds.
2017-05-16 17:09:41,860 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-26
2017-05-16 17:09:41,862 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-26 in 2 milliseconds.
2017-05-16 17:09:41,862 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-29
2017-05-16 17:09:41,864 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-29 in 2 milliseconds.
2017-05-16 17:09:41,865 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-32
2017-05-16 17:09:41,867 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-32 in 2 milliseconds.
2017-05-16 17:09:41,868 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-35
2017-05-16 17:09:41,870 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-35 in 2 milliseconds.
2017-05-16 17:09:41,870 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-38
2017-05-16 17:09:41,873 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-38 in 3 milliseconds.
2017-05-16 17:09:41,874 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-0
2017-05-16 17:09:41,876 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-0 in 1 milliseconds.
2017-05-16 17:09:41,877 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-3
2017-05-16 17:09:41,879 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-3 in 2 milliseconds.
2017-05-16 17:09:41,880 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-6
2017-05-16 17:09:41,882 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-6 in 2 milliseconds.
2017-05-16 17:09:41,883 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-9
2017-05-16 17:09:41,885 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-9 in 2 milliseconds.
2017-05-16 17:09:41,885 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-12
2017-05-16 17:09:41,888 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-12 in 1 milliseconds.
2017-05-16 17:09:41,888 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-15
2017-05-16 17:09:41,890 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-15 in 2 milliseconds.
2017-05-16 17:09:41,891 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-18
2017-05-16 17:09:41,894 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-18 in 3 milliseconds.
2017-05-16 17:09:41,895 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-21
2017-05-16 17:09:41,897 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-21 in 2 milliseconds.
2017-05-16 17:09:41,898 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-24
2017-05-16 17:09:41,900 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-24 in 2 milliseconds.
2017-05-16 17:09:41,901 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-27
2017-05-16 17:09:41,904 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-27 in 1 milliseconds.
2017-05-16 17:09:41,904 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-30
2017-05-16 17:09:41,906 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-30 in 2 milliseconds.
2017-05-16 17:09:41,907 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-33
2017-05-16 17:09:41,909 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-33 in 2 milliseconds.
2017-05-16 17:09:41,910 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-36
2017-05-16 17:09:41,912 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-36 in 1 milliseconds.
2017-05-16 17:09:41,912 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-39
2017-05-16 17:09:41,915 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-39 in 3 milliseconds.
2017-05-16 17:09:41,915 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-42
2017-05-16 17:09:41,917 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-42 in 1 milliseconds.
2017-05-16 17:09:41,918 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:41,919 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:41,920 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:41,920 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-45
2017-05-16 17:09:41,922 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-45 in 1 milliseconds.
2017-05-16 17:09:41,923 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-48
2017-05-16 17:09:41,925 INFO  [group-metadata-manager-0] coordinator.GroupMetadataManager (Logging.scala:info(70)) - [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-48 in 2 milliseconds.
2017-05-16 17:09:42,021 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:42,021 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:42,022 INFO  [kafka-request-handler-3] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 0
2017-05-16 17:09:42,023 INFO  [kafka-request-handler-3] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 1
2017-05-16 17:09:42,025 INFO  [kafka-request-handler-3] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 1
2017-05-16 17:09:42,027 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 1
2017-05-16 17:09:42,027 INFO  [Thread-441] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [test-kdp-0] for group test
2017-05-16 17:09:42,350 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(573)) - Discovered coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) for group test.
2017-05-16 17:09:42,352 WARN  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onComplete(622)) - Auto-commit of offsets {samoa_test-json-0=OffsetAndMetadata{offset=0, metadata=''}} failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2017-05-16 17:09:42,353 WARN  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:maybeAutoCommitOffsetsSync(648)) - Auto-commit of offsets {samoa_test-json-0=OffsetAndMetadata{offset=0, metadata=''}} failed for group test: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
2017-05-16 17:09:42,354 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:42,354 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:42,355 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 1
2017-05-16 17:09:45,070 INFO  [Thread-441] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [test-kdp-0] for group test
2017-05-16 17:09:45,070 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:45,072 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 2
2017-05-16 17:09:45,075 INFO  [kafka-request-handler-5] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 2
2017-05-16 17:09:45,080 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:09:45,080 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:45,082 INFO  [Thread-441] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 2
2017-05-16 17:09:45,084 INFO  [Thread-441] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [test-kdp-0] for group test
2017-05-16 17:09:49,635 INFO  [kafka-request-handler-4] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Preparing to restabilize group test with old generation 2
2017-05-16 17:09:51,082 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinPrepare(393)) - Revoking previously assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:51,082 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:sendJoinGroupRequest(407)) - (Re-)joining group test
2017-05-16 17:09:51,083 INFO  [kafka-request-handler-0] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Stabilized group test generation 3
2017-05-16 17:09:51,083 INFO  [kafka-request-handler-6] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Assignment received from leader for group test for generation 3
2017-05-16 17:09:51,084 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:onSuccess(375)) - Successfully joined group test with generation 3
2017-05-16 17:09:51,084 INFO  [Thread-433] internals.ConsumerCoordinator (ConsumerCoordinator.java:onJoinComplete(252)) - Setting newly assigned partitions [samoa_test-json-0] for group test
2017-05-16 17:09:51,634 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shutting down
2017-05-16 17:09:51,634 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Starting controlled shutdown
2017-05-16 17:09:51,637 INFO  [kafka-request-handler-7] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Shutting down broker 0
2017-05-16 17:09:51,639 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], Controlled shutdown succeeded
2017-05-16 17:09:51,639 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutting down
2017-05-16 17:09:51,640 INFO  [Thread-433] internals.AbstractCoordinator (AbstractCoordinator.java:coordinatorDead(618)) - Marking the coordinator 127.0.0.1:9092 (id: 2147483647 rack: null) dead for group test
2017-05-16 17:09:51,643 INFO  [main] network.SocketServer (Logging.scala:info(70)) - [Socket Server on Broker 0], Shutdown completed
2017-05-16 17:09:51,643 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shutting down
2017-05-16 17:09:51,644 INFO  [main] server.KafkaRequestHandlerPool (Logging.scala:info(70)) - [Kafka Request Handler on Broker 0], shut down completely
2017-05-16 17:09:51,645 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutting down
2017-05-16 17:09:52,469 INFO  [ThrottledRequestReaper-Fetch] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Stopped 
2017-05-16 17:09:52,469 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Fetch], Shutdown completed
2017-05-16 17:09:52,469 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutting down
2017-05-16 17:09:52,496 INFO  [ThrottledRequestReaper-Produce] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Stopped 
2017-05-16 17:09:52,496 INFO  [main] server.ClientQuotaManager$ThrottledRequestReaper (Logging.scala:info(70)) - [ThrottledRequestReaper-Produce], Shutdown completed
2017-05-16 17:09:52,497 INFO  [main] server.KafkaApis (Logging.scala:info(70)) - [KafkaApi-0] Shutdown complete.
2017-05-16 17:09:52,497 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shutting down
2017-05-16 17:09:52,498 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutting down
2017-05-16 17:09:52,498 INFO  [main] server.ReplicaFetcherManager (Logging.scala:info(70)) - [ReplicaFetcherManager on broker 0] shutdown completed
2017-05-16 17:09:52,498 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:52,515 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:52,516 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:52,516 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:52,638 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:52,639 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:52,688 INFO  [main] server.ReplicaManager (Logging.scala:info(70)) - [Replica Manager on Broker 0]: Shut down completely
2017-05-16 17:09:52,688 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:52,830 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:52,831 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:52,831 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutting down.
2017-05-16 17:09:52,832 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:52,930 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:52,931 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:52,932 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutting down
2017-05-16 17:09:53,030 INFO  [ExpirationReaper-0] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Stopped 
2017-05-16 17:09:53,031 INFO  [main] server.DelayedOperationPurgatory$ExpiredOperationReaper (Logging.scala:info(70)) - [ExpirationReaper-0], Shutdown completed
2017-05-16 17:09:53,031 INFO  [main] coordinator.GroupCoordinator (Logging.scala:info(70)) - [GroupCoordinator 0]: Shutdown complete.
2017-05-16 17:09:53,032 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutting down.
2017-05-16 17:09:53,032 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - Shutting down the log cleaner.
2017-05-16 17:09:53,033 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutting down
2017-05-16 17:09:53,033 INFO  [kafka-log-cleaner-thread-0] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Stopped 
2017-05-16 17:09:53,034 INFO  [main] log.LogCleaner (Logging.scala:info(70)) - [kafka-log-cleaner-thread-0], Shutdown completed
2017-05-16 17:09:53,689 INFO  [main] log.LogManager (Logging.scala:info(70)) - Shutdown complete.
2017-05-16 17:09:53,690 INFO  [main] controller.PartitionStateMachine (Logging.scala:info(70)) - [Partition state machine on Controller 0]: Stopped partition state machine
2017-05-16 17:09:53,690 INFO  [main] controller.ReplicaStateMachine (Logging.scala:info(70)) - [Replica state machine on controller 0]: Stopped replica state machine
2017-05-16 17:09:53,695 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutting down
2017-05-16 17:09:53,695 INFO  [Controller-0-to-broker-0-send-thread] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Stopped 
2017-05-16 17:09:53,696 INFO  [main] controller.RequestSendThread (Logging.scala:info(70)) - [Controller-0-to-broker-0-send-thread], Shutdown completed
2017-05-16 17:09:53,696 INFO  [main] controller.KafkaController (Logging.scala:info(70)) - [Controller 0]: Broker 0 resigned as the controller
2017-05-16 17:09:53,696 INFO  [ZkClient-EventThread-600-127.0.0.1:57003] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:53,698 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11ceb3ef0001
2017-05-16 17:09:53,712 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11ceb3ef0001 closed
2017-05-16 17:09:53,713 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:53,712 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:55040 which had sessionid 0x15c11ceb3ef0001
2017-05-16 17:09:53,714 INFO  [main] server.KafkaServer (Logging.scala:info(70)) - [Kafka Server 0], shut down completed
2017-05-16 17:09:53,714 INFO  [ZkClient-EventThread-597-127.0.0.1:57003] zkclient.ZkEventThread (ZkEventThread.java:run(83)) - Terminate ZkClient event thread.
2017-05-16 17:09:53,714 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:pRequest2Txn(494)) - Processed session termination for sessionid: 0x15c11ceb3ef0000
2017-05-16 17:09:53,720 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxn (NIOServerCnxn.java:closeSock(1007)) - Closed socket connection for client /127.0.0.1:55036 which had sessionid 0x15c11ceb3ef0000
2017-05-16 17:09:53,720 INFO  [main] zookeeper.ZooKeeper (ZooKeeper.java:close(684)) - Session: 0x15c11ceb3ef0000 closed
2017-05-16 17:09:53,721 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:53,721 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:53,721 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:53,720 INFO  [main-EventThread] zookeeper.ClientCnxn (ClientCnxn.java:run(512)) - EventThread shut down
2017-05-16 17:09:53,721 INFO  [ProcessThread(sid:0 cport:-1):] server.PrepRequestProcessor (PrepRequestProcessor.java:run(143)) - PrepRequestProcessor exited loop!
2017-05-16 17:09:53,722 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:53,722 INFO  [SyncThread:0] server.SyncRequestProcessor (SyncRequestProcessor.java:run(187)) - SyncRequestProcessor exited!
2017-05-16 17:09:53,722 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
2017-05-16 17:09:53,723 INFO  [NIOServerCxn.Factory:/127.0.0.1:0] server.NIOServerCnxnFactory (NIOServerCnxnFactory.java:run(224)) - NIOServerCnxn factory exited run method
2017-05-16 17:09:53,723 INFO  [main] server.ZooKeeperServer (ZooKeeperServer.java:shutdown(441)) - shutting down
2017-05-16 17:09:53,723 INFO  [main] server.SessionTrackerImpl (SessionTrackerImpl.java:shutdown(225)) - Shutting down
2017-05-16 17:09:53,723 INFO  [main] server.PrepRequestProcessor (PrepRequestProcessor.java:shutdown(761)) - Shutting down
2017-05-16 17:09:53,723 INFO  [main] server.SyncRequestProcessor (SyncRequestProcessor.java:shutdown(209)) - Shutting down
2017-05-16 17:09:53,723 INFO  [main] server.FinalRequestProcessor (FinalRequestProcessor.java:shutdown(415)) - shutdown of request processor complete
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.568 sec - in org.apache.samoa.streams.kafka.KafkaDestinationProcessorTest
Running org.apache.samoa.streams.kafka.KafkaTaskTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.008 sec - in org.apache.samoa.streams.kafka.KafkaTaskTest
Running org.apache.samoa.streams.kafka.AvroSerializerDeserializerTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec - in org.apache.samoa.streams.kafka.AvroSerializerDeserializerTest
Running org.apache.samoa.core.DoubleVectorTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec - in org.apache.samoa.core.DoubleVectorTest

Results :

Tests run: 25, Failures: 0, Errors: 0, Skipped: 1

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building samoa-test 0.5.0-incubating-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- license-maven-plugin:1.8:update-file-header (first) @ samoa-test ---
[WARNING] No file to scan.
[INFO] 
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ samoa-test ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ samoa-test ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-test/src/main/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:compile (default-compile) @ samoa-test ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ samoa-test ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-test/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:testCompile (default-testCompile) @ samoa-test ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.18.1:test (default-test) @ samoa-test ---
[INFO] Surefire report directory: /root/workspace/apache/incubator-samoa/232818360/samoa-test/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------

Results :

Tests run: 0, Failures: 0, Errors: 0, Skipped: 0

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building samoa-local 0.5.0-incubating-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- license-maven-plugin:1.8:update-file-header (first) @ samoa-local ---
[WARNING] No file to scan.
[INFO] 
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ samoa-local ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ samoa-local ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:compile (default-compile) @ samoa-local ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ samoa-local ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/apache/incubator-samoa/232818360/samoa-local/src/test/resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.5:testCompile (default-testCompile) @ samoa-local ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.18:test (default-test) @ samoa-local ---
[INFO] Surefire report directory: /root/workspace/apache/incubator-samoa/232818360/samoa-local/target/surefire-reports
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18/surefire-junit4-2.18.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18/surefire-junit4-2.18.pom (3 KB at 97.3 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.18/surefire-providers-2.18.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.18/surefire-providers-2.18.pom (3 KB at 74.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18/surefire-junit4-2.18.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.18/surefire-junit4-2.18.jar (67 KB at 1507.4 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.samoa.topology.impl.SimpleTopologyTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.148 sec - in org.apache.samoa.topology.impl.SimpleTopologyTest
Running org.apache.samoa.topology.impl.SimpleComponentFactoryTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.034 sec - in org.apache.samoa.topology.impl.SimpleComponentFactoryTest
Running org.apache.samoa.topology.impl.SimpleStreamTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.122 sec - in org.apache.samoa.topology.impl.SimpleStreamTest
Running org.apache.samoa.topology.impl.SimpleProcessingItemTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.06 sec - in org.apache.samoa.topology.impl.SimpleProcessingItemTest
Running org.apache.samoa.topology.impl.SimpleEntranceProcessingItemTest
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.414 sec <<< FAILURE! - in org.apache.samoa.topology.impl.SimpleEntranceProcessingItemTest
testStartSendingEvents(org.apache.samoa.topology.impl.SimpleEntranceProcessingItemTest)  Time elapsed: 0.313 sec  <<< ERROR!
java.lang.IllegalStateException: Missing invocation to mocked type at this point; please make sure there is an associated mock field or mock parameter in scope
	at org.apache.samoa.topology.impl.SimpleEntranceProcessingItemTest$4.<init>(SimpleEntranceProcessingItemTest.java:159)
	at org.apache.samoa.topology.impl.SimpleEntranceProcessingItemTest.testStartSendingEvents(SimpleEntranceProcessingItemTest.java:155)

Running org.apache.samoa.topology.impl.SimpleEngineTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.157 sec - in org.apache.samoa.topology.impl.SimpleEngineTest
Running org.apache.samoa.AlgosTest
2017-05-16 17:09:59,771 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:53) - Starting test, output file is /tmp/test1909906520564753859test, test config is 
TestParams{
inputInstances=200000
samplingSize=20000
evaluationInstances=200000
classifiedInstances=200000
classificationsCorrect=75.0
kappaStat=0.0
kappaTempStat=0.0
cliStringTemplate='PrequentialEvaluation -d %s -i %d -f %d -w %d -l (org.apache.samoa.learners.classifiers.trees.VerticalHoeffdingTree -p 4) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 10 -u 10)'
pollTimeoutSeconds=10
prePollWait=10
taskClassName='org.apache.samoa.LocalDoTask'
inputDelayMicroSec=0
}
Command line string =  PrequentialEvaluation -d /tmp/test1909906520564753859test -i 200000 -f 20000 -w 0 -l (org.apache.samoa.learners.classifiers.trees.VerticalHoeffdingTree -p 4) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 10 -u 10)
2017-05-16 17:09:59,803 [pool-1-thread-1] INFO  org.apache.samoa.LocalDoTask (LocalDoTask.java:80) - Successfully instantiating org.apache.samoa.tasks.PrequentialEvaluation
2017-05-16 17:10:00,448 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:00,453 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 20,000
classified instances = 20,000
classifications correct (percent) = 65.645
Kappa Statistic (percent) = 27.592
Kappa Temporal Statistic (percent) = 30.173
2017-05-16 17:10:00,842 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:00,843 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 40,000
classified instances = 40,000
classifications correct (percent) = 70.69
Kappa Statistic (percent) = 39.422
Kappa Temporal Statistic (percent) = 40.272
2017-05-16 17:10:01,141 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:01,152 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 60,000
classified instances = 60,000
classifications correct (percent) = 73.663
Kappa Statistic (percent) = 45.786
Kappa Temporal Statistic (percent) = 46.436
2017-05-16 17:10:01,425 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:01,426 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 80,000
classified instances = 80,000
classifications correct (percent) = 75.545
Kappa Statistic (percent) = 49.77
Kappa Temporal Statistic (percent) = 50.387
2017-05-16 17:10:01,707 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:01,708 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 100,000
classified instances = 100,000
classifications correct (percent) = 77.083
Kappa Statistic (percent) = 53.033
Kappa Temporal Statistic (percent) = 53.669
2017-05-16 17:10:01,959 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:01,960 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 120,000
classified instances = 120,000
classifications correct (percent) = 78.397
Kappa Statistic (percent) = 55.776
Kappa Temporal Statistic (percent) = 56.372
2017-05-16 17:10:02,129 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:02,130 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 140,000
classified instances = 140,000
classifications correct (percent) = 79.531
Kappa Statistic (percent) = 58.117
Kappa Temporal Statistic (percent) = 58.646
2017-05-16 17:10:02,321 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:02,321 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 160,000
classified instances = 160,000
classifications correct (percent) = 80.527
Kappa Statistic (percent) = 60.173
Kappa Temporal Statistic (percent) = 60.566
2017-05-16 17:10:02,585 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:02,586 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 180,000
classified instances = 180,000
classifications correct (percent) = 81.387
Kappa Statistic (percent) = 61.939
Kappa Temporal Statistic (percent) = 62.332
2017-05-16 17:10:02,776 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:02,776 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 200,000
classified instances = 200,000
classifications correct (percent) = 82.144
Kappa Statistic (percent) = 63.505
Kappa Temporal Statistic (percent) = 63.842
2017-05-16 17:10:02,776 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:183) - last event is received!
2017-05-16 17:10:02,776 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:184) - total count: 200000
2017-05-16 17:10:02,777 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:187) - org.apache.samoa.evaluation.EvaluatorProcessorid = 0
evaluation instances,classified instances,classifications correct (percent),Kappa Statistic (percent),Kappa Temporal Statistic (percent)
20000.0,20000.0,65.645,27.592487187843105,30.172764227642272
40000.0,40000.0,70.69,39.42219140754782,40.27204646186763
60000.0,60000.0,73.66333333333334,45.78556998992169,46.43571404359175
80000.0,80000.0,75.545,49.770097068022935,50.386731925037395
100000.0,100000.0,77.083,53.033355520313066,53.66933527413876
120000.0,120000.0,78.3975,55.77588004396512,56.37180652327577
140000.0,140000.0,79.53071428571428,58.11662806596387,58.64611743654127
160000.0,160000.0,80.526875,60.17259494934151,60.56625026894989
180000.0,180000.0,81.38666666666666,61.93941888230634,62.3317780650964
200000.0,200000.0,82.1435,63.50464751569946,63.842259795484466

2017-05-16 17:10:02,777 [pool-1-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:191) - total evaluation time: 2 seconds for 200000 instances
2017-05-16 17:10:09,789 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:96) - Checking results file /tmp/test1909906520564753859test
2017-05-16 17:10:09,802 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:53) - Starting test, output file is /tmp/test2357407277225735482test, test config is 
TestParams{
inputInstances=200000
samplingSize=20000
evaluationInstances=200000
classifiedInstances=200000
classificationsCorrect=60.0
kappaStat=0.0
kappaTempStat=0.0
cliStringTemplate='PrequentialEvaluation -d %s -i %d -f %d -w %d -l (org.apache.samoa.learners.classifiers.ensemble.Bagging) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 0 -u 10)'
pollTimeoutSeconds=10
prePollWait=10
taskClassName='org.apache.samoa.LocalDoTask'
inputDelayMicroSec=0
}
Command line string =  PrequentialEvaluation -d /tmp/test2357407277225735482test -i 200000 -f 20000 -w 0 -l (org.apache.samoa.learners.classifiers.ensemble.Bagging) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 0 -u 10)
2017-05-16 17:10:09,809 [pool-4-thread-1] INFO  org.apache.samoa.LocalDoTask (LocalDoTask.java:80) - Successfully instantiating org.apache.samoa.tasks.PrequentialEvaluation
2017-05-16 17:10:10,598 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:10,599 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 20,000
classified instances = 20,000
classifications correct (percent) = 84.335
Kappa Statistic (percent) = 67.841
Kappa Temporal Statistic (percent) = 67.738
2017-05-16 17:10:11,147 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:11,148 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 40,000
classified instances = 40,000
classifications correct (percent) = 88.16
Kappa Statistic (percent) = 75.725
Kappa Temporal Statistic (percent) = 75.688
2017-05-16 17:10:11,803 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:11,804 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 60,000
classified instances = 60,000
classifications correct (percent) = 90.057
Kappa Statistic (percent) = 79.677
Kappa Temporal Statistic (percent) = 79.67
2017-05-16 17:10:12,411 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:12,412 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 80,000
classified instances = 80,000
classifications correct (percent) = 91.427
Kappa Statistic (percent) = 82.501
Kappa Temporal Statistic (percent) = 82.591
2017-05-16 17:10:12,990 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:12,990 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 100,000
classified instances = 100,000
classifications correct (percent) = 92.469
Kappa Statistic (percent) = 84.633
Kappa Temporal Statistic (percent) = 84.676
2017-05-16 17:10:13,578 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:13,578 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 120,000
classified instances = 120,000
classifications correct (percent) = 93.181
Kappa Statistic (percent) = 86.08
Kappa Temporal Statistic (percent) = 86.104
2017-05-16 17:10:14,152 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:14,152 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 140,000
classified instances = 140,000
classifications correct (percent) = 93.764
Kappa Statistic (percent) = 87.273
Kappa Temporal Statistic (percent) = 87.284
2017-05-16 17:10:14,701 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:14,702 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 160,000
classified instances = 160,000
classifications correct (percent) = 94.218
Kappa Statistic (percent) = 88.2
Kappa Temporal Statistic (percent) = 88.189
2017-05-16 17:10:15,241 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:15,242 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 180,000
classified instances = 180,000
classifications correct (percent) = 94.564
Kappa Statistic (percent) = 88.906
Kappa Temporal Statistic (percent) = 88.893
2017-05-16 17:10:15,810 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:15,810 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 200,000
classified instances = 200,000
classifications correct (percent) = 94.853
Kappa Statistic (percent) = 89.497
Kappa Temporal Statistic (percent) = 89.483
2017-05-16 17:10:15,811 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:183) - last event is received!
2017-05-16 17:10:15,811 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:184) - total count: 200000
2017-05-16 17:10:15,811 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:187) - org.apache.samoa.evaluation.EvaluatorProcessorid = 0
evaluation instances,classified instances,classifications correct (percent),Kappa Statistic (percent),Kappa Temporal Statistic (percent)
20000.0,20000.0,84.33500000000001,67.84106353554753,67.7376171352075
40000.0,40000.0,88.16000000000001,75.7249207061916,75.68788501026695
60000.0,60000.0,90.05666666666666,79.67736754776247,79.67014243849246
80000.0,80000.0,91.4275,82.50137840556397,82.59125755191144
100000.0,100000.0,92.469,84.63276153823094,84.67595889714111
120000.0,120000.0,93.18083333333334,86.07968325109412,86.10412987365848
140000.0,140000.0,93.76357142857142,87.27309611587,87.28353165644707
160000.0,160000.0,94.218125,88.19980990449899,88.18895627194382
180000.0,180000.0,94.56444444444443,88.9064714773274,88.89330351568265
200000.0,200000.0,94.853,89.49734199620914,89.48250319284801

2017-05-16 17:10:15,811 [pool-4-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:191) - total evaluation time: 5 seconds for 200000 instances
2017-05-16 17:10:19,804 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:96) - Checking results file /tmp/test2357407277225735482test
2017-05-16 17:10:19,806 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:53) - Starting test, output file is /tmp/test364440432581383950test, test config is 
TestParams{
inputInstances=200000
samplingSize=20000
evaluationInstances=200000
classifiedInstances=200000
classificationsCorrect=65.0
kappaStat=0.0
kappaTempStat=0.0
cliStringTemplate='PrequentialEvaluation -d %s -i %d -f %d -w %d -l (classifiers.SingleClassifier -l org.apache.samoa.learners.classifiers.NaiveBayes) -s (org.apache.samoa.streams.generators.HyperplaneGenerator -c 2)'
pollTimeoutSeconds=10
prePollWait=10
taskClassName='org.apache.samoa.LocalDoTask'
inputDelayMicroSec=0
}
Command line string =  PrequentialEvaluation -d /tmp/test364440432581383950test -i 200000 -f 20000 -w 0 -l (classifiers.SingleClassifier -l org.apache.samoa.learners.classifiers.NaiveBayes) -s (org.apache.samoa.streams.generators.HyperplaneGenerator -c 2)
2017-05-16 17:10:19,815 [pool-16-thread-1] INFO  org.apache.samoa.LocalDoTask (LocalDoTask.java:80) - Successfully instantiating org.apache.samoa.tasks.PrequentialEvaluation
2017-05-16 17:10:19,971 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:19,972 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 20,000
classified instances = 20,000
classifications correct (percent) = 84.275
Kappa Statistic (percent) = 68.502
Kappa Temporal Statistic (percent) = 68.778
2017-05-16 17:10:20,088 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,088 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 40,000
classified instances = 40,000
classifications correct (percent) = 83.803
Kappa Statistic (percent) = 67.594
Kappa Temporal Statistic (percent) = 67.819
2017-05-16 17:10:20,206 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,206 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 60,000
classified instances = 60,000
classifications correct (percent) = 83.59
Kappa Statistic (percent) = 67.214
Kappa Temporal Statistic (percent) = 67.392
2017-05-16 17:10:20,325 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,325 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 80,000
classified instances = 80,000
classifications correct (percent) = 83.546
Kappa Statistic (percent) = 67.127
Kappa Temporal Statistic (percent) = 67.269
2017-05-16 17:10:20,441 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,442 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 100,000
classified instances = 100,000
classifications correct (percent) = 83.559
Kappa Statistic (percent) = 67.135
Kappa Temporal Statistic (percent) = 67.209
2017-05-16 17:10:20,559 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,560 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 120,000
classified instances = 120,000
classifications correct (percent) = 83.531
Kappa Statistic (percent) = 67.072
Kappa Temporal Statistic (percent) = 67.151
2017-05-16 17:10:20,675 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,676 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 140,000
classified instances = 140,000
classifications correct (percent) = 83.504
Kappa Statistic (percent) = 67.03
Kappa Temporal Statistic (percent) = 67.054
2017-05-16 17:10:20,793 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,793 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 160,000
classified instances = 160,000
classifications correct (percent) = 83.518
Kappa Statistic (percent) = 67.05
Kappa Temporal Statistic (percent) = 67.065
2017-05-16 17:10:20,916 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:20,917 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 180,000
classified instances = 180,000
classifications correct (percent) = 83.54
Kappa Statistic (percent) = 67.089
Kappa Temporal Statistic (percent) = 67.126
2017-05-16 17:10:21,032 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:83) - 0 seconds for 20000 instances
2017-05-16 17:10:21,033 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:169) - evaluation instances = 200,000
classified instances = 200,000
classifications correct (percent) = 83.523
Kappa Statistic (percent) = 67.057
Kappa Temporal Statistic (percent) = 67.143
2017-05-16 17:10:21,033 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:183) - last event is received!
2017-05-16 17:10:21,033 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:184) - total count: 200000
2017-05-16 17:10:21,033 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:187) - org.apache.samoa.evaluation.EvaluatorProcessorid = 0
evaluation instances,classified instances,classifications correct (percent),Kappa Statistic (percent),Kappa Temporal Statistic (percent)
20000.0,20000.0,84.275,68.50233079747552,68.77792117541944
40000.0,40000.0,83.80250000000001,67.59439866955276,67.81900362588786
60000.0,60000.0,83.59,67.21382484118784,67.39195230998509
80000.0,80000.0,83.54625,67.12663795918682,67.26924607121543
100000.0,100000.0,83.55900000000001,67.13483590334214,67.20915853926087
120000.0,120000.0,83.53083333333333,67.07192304919516,67.15145269596435
140000.0,140000.0,83.50357142857143,67.02990305706534,67.05373828442632
160000.0,160000.0,83.518125,67.04964827201962,67.06465673356729
180000.0,180000.0,83.54,67.08882037897833,67.1260235670062
200000.0,200000.0,83.5235,67.05662351796806,67.142614990378

2017-05-16 17:10:21,033 [pool-16-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorProcessor (EvaluatorProcessor.java:191) - total evaluation time: 1 seconds for 200000 instances
2017-05-16 17:10:29,807 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:96) - Checking results file /tmp/test364440432581383950test
2017-05-16 17:10:29,809 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:53) - Starting test, output file is /tmp/test6976269486068171649test, test config is 
TestParams{
inputInstances=200000
samplingSize=20000
evaluationInstances=200000
classifiedInstances=200000
classificationsCorrect=75.0
kappaStat=0.0
kappaTempStat=0.0
cliStringTemplate='PrequentialCVEvaluation -d %s -i %d -f %d -w %d -l (org.apache.samoa.learners.classifiers.trees.VerticalHoeffdingTree -p 4) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 10 -u 10)'
pollTimeoutSeconds=10
prePollWait=10
taskClassName='org.apache.samoa.LocalDoTask'
inputDelayMicroSec=0
}
Command line string =  PrequentialCVEvaluation -d /tmp/test6976269486068171649test -i 200000 -f 20000 -w 0 -l (org.apache.samoa.learners.classifiers.trees.VerticalHoeffdingTree -p 4) -s (org.apache.samoa.streams.generators.RandomTreeGenerator -c 2 -o 10 -u 10)
2017-05-16 17:10:29,815 [pool-18-thread-1] INFO  org.apache.samoa.LocalDoTask (LocalDoTask.java:80) - Successfully instantiating org.apache.samoa.tasks.PrequentialCVEvaluation
2017-05-16 17:10:31,465 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:31,465 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 20,000
[avg] classified instances = 20,000
[err] classified instances = 0
[avg] classifications correct (percent) = 64.627
[err] classifications correct (percent) = 0.189
[avg] Kappa Statistic (percent) = 25.294
[err] Kappa Statistic (percent) = 0.352
[avg] Kappa Temporal Statistic (percent) = 28.104
[err] Kappa Temporal Statistic (percent) = 0.384
2017-05-16 17:10:33,384 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:33,384 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 40,000
[avg] classified instances = 40,000
[err] classified instances = 0
[avg] classifications correct (percent) = 70.032
[err] classifications correct (percent) = 0.203
[avg] Kappa Statistic (percent) = 38.074
[err] Kappa Statistic (percent) = 0.445
[avg] Kappa Temporal Statistic (percent) = 38.931
[err] Kappa Temporal Statistic (percent) = 0.414
2017-05-16 17:10:35,456 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 2 seconds for 20000 instances
2017-05-16 17:10:35,456 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 60,000
[avg] classified instances = 60,000
[err] classified instances = 0
[avg] classifications correct (percent) = 73.498
[err] classifications correct (percent) = 0.308
[avg] Kappa Statistic (percent) = 45.523
[err] Kappa Statistic (percent) = 0.671
[avg] Kappa Temporal Statistic (percent) = 46.1
[err] Kappa Temporal Statistic (percent) = 0.627
2017-05-16 17:10:37,252 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:37,252 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 80,000
[avg] classified instances = 80,000
[err] classified instances = 0
[avg] classifications correct (percent) = 75.64
[err] classifications correct (percent) = 0.397
[avg] Kappa Statistic (percent) = 50.074
[err] Kappa Statistic (percent) = 0.86
[avg] Kappa Temporal Statistic (percent) = 50.579
[err] Kappa Temporal Statistic (percent) = 0.806
2017-05-16 17:10:39,040 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:39,040 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 100,000
[avg] classified instances = 100,000
[err] classified instances = 0
[avg] classifications correct (percent) = 77.273
[err] classifications correct (percent) = 0.442
[avg] Kappa Statistic (percent) = 53.513
[err] Kappa Statistic (percent) = 0.947
[avg] Kappa Temporal Statistic (percent) = 54.053
[err] Kappa Temporal Statistic (percent) = 0.894
2017-05-16 17:10:40,976 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:40,977 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 120,000
[avg] classified instances = 120,000
[err] classified instances = 0
[avg] classifications correct (percent) = 78.553
[err] classifications correct (percent) = 0.464
[avg] Kappa Statistic (percent) = 56.166
[err] Kappa Statistic (percent) = 0.983
[avg] Kappa Temporal Statistic (percent) = 56.687
[err] Kappa Temporal Statistic (percent) = 0.938
2017-05-16 17:10:43,124 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 2 seconds for 20000 instances
2017-05-16 17:10:43,124 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 140,000
[avg] classified instances = 140,000
[err] classified instances = 0
[avg] classifications correct (percent) = 79.767
[err] classifications correct (percent) = 0.471
[avg] Kappa Statistic (percent) = 58.667
[err] Kappa Statistic (percent) = 0.991
[avg] Kappa Temporal Statistic (percent) = 59.123
[err] Kappa Temporal Statistic (percent) = 0.952
2017-05-16 17:10:44,802 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:44,803 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 160,000
[avg] classified instances = 160,000
[err] classified instances = 0
[avg] classifications correct (percent) = 80.8
[err] classifications correct (percent) = 0.464
[avg] Kappa Statistic (percent) = 60.79
[err] Kappa Statistic (percent) = 0.973
[avg] Kappa Temporal Statistic (percent) = 61.12
[err] Kappa Temporal Statistic (percent) = 0.939
2017-05-16 17:10:46,678 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 1 seconds for 20000 instances
2017-05-16 17:10:46,679 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 180,000
[avg] classified instances = 180,000
[err] classified instances = 0
[avg] classifications correct (percent) = 81.614
[err] classifications correct (percent) = 0.462
[avg] Kappa Statistic (percent) = 62.451
[err] Kappa Statistic (percent) = 0.969
[avg] Kappa Temporal Statistic (percent) = 62.792
[err] Kappa Temporal Statistic (percent) = 0.936
2017-05-16 17:10:49,232 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:108) - 2 seconds for 20000 instances
2017-05-16 17:10:49,233 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:201) - evaluation instances = 200,000
[avg] classified instances = 200,000.9
[err] classified instances = 0.9
[avg] classifications correct (percent) = 82.333
[err] classifications correct (percent) = 0.47
[avg] Kappa Statistic (percent) = 63.93
[err] Kappa Statistic (percent) = 0.984
[avg] Kappa Temporal Statistic (percent) = 64.226
[err] Kappa Temporal Statistic (percent) = 0.952
2017-05-16 17:10:49,233 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:215) - last event is received!
2017-05-16 17:10:49,233 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:216) - total count: 200001
2017-05-16 17:10:49,234 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:219) - org.apache.samoa.evaluation.EvaluatorCVProcessorid = 0
evaluation instances,[avg] classified instances,[err] classified instances,[avg] classifications correct (percent),[err] classifications correct (percent),[avg] Kappa Statistic (percent),[err] Kappa Statistic (percent),[avg] Kappa Temporal Statistic (percent),[err] Kappa Temporal Statistic (percent)
20000.0,20000.0,0.0,64.62700000000001,0.18916071943661472,25.293690418855896,0.3519627618187893,28.103658536585368,0.38447300698498993
40000.0,40000.0,0.0,70.032,0.20324410610560478,38.07419026287571,0.44506467062749777,38.931173264048084,0.4141710858537992
60000.0,60000.0,0.0,73.49833333333333,0.3080789741624503,45.52336429068201,0.6710378342453998,46.10013219890851,0.6265800633791055
80000.0,80000.0,0.0,75.63975,0.3973700346584335,50.07382624902415,0.8597101949765279,50.57895671138387,0.8061674935377634
100000.0,100000.0,0.0,77.27289999999999,0.4422633566854323,53.51347314843381,0.9469128869060368,54.05325084910237,0.8941115896115002
120000.0,120000.0,0.0,78.5535,0.4643362247656641,56.1661763049406,0.9830956362259596,56.68686256689892,0.9377688069588297
140000.0,140000.0,0.0,79.76700000000001,0.47139196346560175,58.66745091659613,0.9910982373644812,59.12348297906114,0.9523482240960528
160000.0,160000.0,0.0,80.80025000000002,0.4637947455202826,60.789541927185965,0.9729687801934683,61.11984407234435,0.9392003554346215
180000.0,180000.0,0.0,81.61388888888888,0.46241870972111077,62.451145738939225,0.9693840059052787,62.791612794423514,0.9358071589161842
200000.0,200000.9,0.8999999999996271,82.33328358598864,0.4701473780403362,63.930181311539584,0.9842393397954078,64.2263845297155,0.9520407427484003

2017-05-16 17:10:49,234 [pool-18-thread-1] INFO  org.apache.samoa.evaluation.EvaluatorCVProcessor (EvaluatorCVProcessor.java:223) - total evaluation time: 19 seconds for 200001 instances
2017-05-16 17:10:49,813 [main] INFO  org.apache.samoa.TestUtils (TestUtils.java:96) - Checking results file /tmp/test6976269486068171649test
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 50.281 sec - in org.apache.samoa.AlgosTest

Results :


Tests in error: 
  Missing invocation to mocked type at this point; please make sure there is an associated mock field or mock parameter in scope


Tests run: 28, Failures: 0, Errors: 1, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Apache SAMOA ....................................... SUCCESS [  4.284 s]
[INFO] samoa-instances .................................... SUCCESS [  4.024 s]
[INFO] samoa-api .......................................... SUCCESS [01:25 min]
[INFO] samoa-test ......................................... SUCCESS [  2.271 s]
[INFO] samoa-local ........................................ FAILURE [ 53.648 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 02:29 min
[INFO] Finished at: 2017-05-16T17:10:49+02:00
[INFO] Final Memory: 35M/737M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.18:test (default-test) on project samoa-local: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/apache/incubator-samoa/232818360/samoa-local/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :samoa-local
