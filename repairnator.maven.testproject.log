[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building elasticsearch-indexing-proxy 5.6.2-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-enforcer-plugin:1.2:enforce (enforce-maven) @ elasticsearch-indexing-proxy ---
[INFO] Skipping Rule Enforcement.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ elasticsearch-indexing-proxy ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.0:compile (default-compile) @ elasticsearch-indexing-proxy ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ elasticsearch-indexing-proxy ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/codelibs/elasticsearch-indexing-proxy/355015092/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.0:testCompile (default-testCompile) @ elasticsearch-indexing-proxy ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ elasticsearch-indexing-proxy ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19.1/surefire-junit4-2.19.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19.1/surefire-junit4-2.19.1.pom (4 KB at 9.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19.1/surefire-providers-2.19.1.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19.1/surefire-providers-2.19.1.pom (3 KB at 139.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19.1/surefire-junit4-2.19.1.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19.1/surefire-junit4-2.19.1.jar (74 KB at 2045.9 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.codelibs.elasticsearch.idxproxy.sender.RequestSenderTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.031 sec - in org.codelibs.elasticsearch.idxproxy.sender.RequestSenderTest
Running org.codelibs.elasticsearch.idxproxy.IndexingProxyPluginTest
idxproxy.data.path: /tmp/es-idxproxy1109635204088580346
----------------------------------------
Cluster Name: es-idxproxy-1521383774871
Base Path:    /tmp/es-cluster6839567815410739017
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster6839567815410739017/config/node_1
Creating /tmp/es-cluster6839567815410739017/logs/node_1
Creating /tmp/es-cluster6839567815410739017/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster6839567815410739017/data/node_1
Log Directory:  /tmp/es-cluster6839567815410739017/logs/node_1
----------------------------------------
Creating /tmp/es-cluster6839567815410739017/modules
Creating /tmp/es-cluster6839567815410739017/plugins
[2018-03-18T15:36:15,880][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:36:15,943][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:36:15,946][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:36:15,946][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [l0sCHkvPSNSu9o3eHlWhJA]
[2018-03-18T15:36:15,947][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:36:15,947][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:36:15,953][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:36:15,955][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:36:15,956][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:36:15,956][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:36:15,956][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:36:15,956][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:36:17,299][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:36:17,762][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:36:17,762][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:36:17,921][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:36:17,935][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:36:20,991][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:36:21,023][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:36:21,023][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster6839567815410739017/config/node_2
Creating /tmp/es-cluster6839567815410739017/logs/node_2
Creating /tmp/es-cluster6839567815410739017/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster6839567815410739017/data/node_2
Log Directory:  /tmp/es-cluster6839567815410739017/logs/node_2
----------------------------------------
[2018-03-18T15:36:21,027][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:36:21,068][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:36:21,072][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:36:21,073][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:36:21,073][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [oPbqV5mLQimtK2qPpcGQSw]
[2018-03-18T15:36:21,074][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:36:21,074][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:36:21,075][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:36:21,076][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:36:21,076][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:36:21,076][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:36:21,076][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:36:21,076][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:36:21,097][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:36:21,174][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:36:21,174][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:36:21,196][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:36:21,197][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:36:24,271][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:36:24,286][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:36:24,296][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:36:24,305][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:36:24,305][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster6839567815410739017/config/node_3
Creating /tmp/es-cluster6839567815410739017/logs/node_3
Creating /tmp/es-cluster6839567815410739017/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster6839567815410739017/data/node_3
Log Directory:  /tmp/es-cluster6839567815410739017/logs/node_3
----------------------------------------
[2018-03-18T15:36:24,309][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [l0sCHkvPSNSu9o3eHlWhJA][Node 1][/tmp/es-cluster6839567815410739017/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:24,310][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [oPbqV5mLQimtK2qPpcGQSw][Node 2][/tmp/es-cluster6839567815410739017/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:24,344][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:36:24,349][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:36:24,349][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:36:24,350][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [i-N4R-fvROmH6tnPvw7Bvw]
[2018-03-18T15:36:24,350][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:36:24,350][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:36:24,352][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:36:24,352][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:36:24,352][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:36:24,352][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:36:24,353][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:36:24,354][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:36:24,387][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:36:24,430][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:36:24,430][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:36:24,444][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:36:24,445][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:36:27,524][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{i-N4R-fvROmH6tnPvw7Bvw}{Fo8-0hezQAujCp5dwQuF4g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{i-N4R-fvROmH6tnPvw7Bvw}{Fo8-0hezQAujCp5dwQuF4g}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:36:27,535][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}, added {{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302},{Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:36:27,545][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{i-N4R-fvROmH6tnPvw7Bvw}{Fo8-0hezQAujCp5dwQuF4g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:36:27,566][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [i-N4R-fvROmH6tnPvw7Bvw][Node 3][/tmp/es-cluster6839567815410739017/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:27,567][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:36:27,567][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:36:27,567][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [l0sCHkvPSNSu9o3eHlWhJA][Node 1][/tmp/es-cluster6839567815410739017/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:27,567][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [oPbqV5mLQimtK2qPpcGQSw][Node 2][/tmp/es-cluster6839567815410739017/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:27,675][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:36:51,011][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:36:51,036][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [i-N4R-fvROmH6tnPvw7Bvw][Node 3][/tmp/es-cluster6839567815410739017/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:51,037][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [l0sCHkvPSNSu9o3eHlWhJA][Node 1][/tmp/es-cluster6839567815410739017/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:51,037][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [oPbqV5mLQimtK2qPpcGQSw][Node 2][/tmp/es-cluster6839567815410739017/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:36:51,097][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:36:52,226][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy1109635204088580346/0000000000000000001.tmp
[2018-03-18T15:36:53,252][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy1109635204088580346/0000000000000000001.dat
[2018-03-18T15:36:53,253][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy1109635204088580346/0000000000000000002.tmp
[2018-03-18T15:36:53,281][WARN ][r.suppressed             ] path: /sample1/_idxproxy/process, params: {index=sample1}
org.elasticsearch.ElasticsearchException: Node 1 is not a Sender node.
	at org.codelibs.elasticsearch.idxproxy.service.IndexingProxyService.startRequestSender(IndexingProxyService.java:789) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.rest.RestIndexingProxyProcessAction.lambda$preparePostRequest$11(RestIndexingProxyProcessAction.java:80) ~[classes/:?]
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:80) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:262) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:200) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.http.netty4.Netty4HttpServerTransport.dispatchRequest(Netty4HttpServerTransport.java:505) [transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.http.netty4.Netty4HttpRequestHandler.channelRead0(Netty4HttpRequestHandler.java:80) [transport-netty4-5.6.7.jar:5.6.7]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at org.elasticsearch.http.netty4.pipelining.HttpPipeliningHandler.channelRead(HttpPipeliningHandler.java:68) [transport-netty4-5.6.7.jar:5.6.7]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at org.elasticsearch.http.netty4.cors.Netty4CorsHandler.channelRead(Netty4CorsHandler.java:76) [transport-netty4-5.6.7.jar:5.6.7]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.MessageToMessageCodec.channelRead(MessageToMessageCodec.java:111) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284) [netty-codec-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Waiting for writer...
[2018-03-18T15:36:58,275][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample1] Indexing: /tmp/es-idxproxy1109635204088580346/0000000000000000001.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=1, timed_out=false}
[2018-03-18T15:36:58,310][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample1/JVbWeIbhQ4iV31rxMZjegw] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1007, id=1007}, _id=1007, _score=1.0}], total=2, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1003, id=1003}, _id=1003, _score=1.0}], total=3, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1004, id=1004}, _id=1004, _score=1.0}], total=3, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1001, id=1001}, _id=1001, _score=1.0}], total=3, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1002, id=1002}, _id=1002, _score=1.0}], total=4, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:37:07,570][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample1] Indexed:  /tmp/es-idxproxy1109635204088580346/0000000000000000001.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=5, max_score=1.0}, took=2, timed_out=false}
[2018-03-18T15:37:11,201][INFO ][o.e.m.j.JvmGcMonitorService] [Node 2] [gc][50] overhead, spent [256ms] collecting in the last [1s]
[2018-03-18T15:37:11,449][INFO ][o.e.m.j.JvmGcMonitorService] [Node 3] [gc][47] overhead, spent [256ms] collecting in the last [1s]
[2018-03-18T15:37:11,865][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:37:11,926][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [YELLOW] to [RED] (reason: [{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302} left]).
[2018-03-18T15:37:11,926][INFO ][o.e.c.s.ClusterService   ] [Node 1] removed {{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-left({Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302}), reason(left)[{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302} left]
[2018-03-18T15:37:11,931][INFO ][o.e.c.s.ClusterService   ] [Node 3] removed {{Node 2}{oPbqV5mLQimtK2qPpcGQSw}{yclWT86oQ6SHQ-P4Hme54w}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [master {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301} committed version [11]])
[2018-03-18T15:37:11,938][INFO ][o.e.c.r.DelayedAllocationService] [Node 1] scheduling reroute for delayed shards in [59.9s] (1 delayed shards)
[2018-03-18T15:37:11,958][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:37:11,958][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:37:11,965][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy1109635204088580346/0000000000000000002.dat
[2018-03-18T15:37:11,969][INFO ][o.e.n.Node               ] [Node 2] closed
Waiting for closing node2...
[2018-03-18T15:37:12,243][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:12,245][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:13,247][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:13,248][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:14,250][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:14,251][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:15,252][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:15,253][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:16,254][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:16,255][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:17,257][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:17,258][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:18,260][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:18,261][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:19,263][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:19,264][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:20,266][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:20,267][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:21,040][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [l0sCHkvPSNSu9o3eHlWhJA][Node 1][/tmp/es-cluster6839567815410739017/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:21,041][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [i-N4R-fvROmH6tnPvw7Bvw][Node 3][/tmp/es-cluster6839567815410739017/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:21,269][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:21,269][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:22,271][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:22,272][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:23,274][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:23,274][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:24,276][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:24,277][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:25,278][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:25,279][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:26,281][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:26,281][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:27,283][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:27,284][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:28,285][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:28,286][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:29,288][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:29,288][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:30,290][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:30,290][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:31,293][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:31,294][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:32,296][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:32,297][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:33,299][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:33,300][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:34,302][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:34,303][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:35,304][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:35,305][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:36,306][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:36,307][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:37,309][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:37,310][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:38,311][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:38,312][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:39,314][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:39,315][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:40,316][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:40,317][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:41,319][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:41,320][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:42,321][DEBUG][o.e.a.s.TransportSearchAction] [Node 1] All shards failed for phase: [query]
[2018-03-18T15:37:42,322][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Monitor(Node 1) could not access .idxproxy
org.elasticsearch.action.search.SearchPhaseExecutionException: all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseFailure(AbstractSearchAsyncAction.java:272) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.executeNextPhase(AbstractSearchAsyncAction.java:130) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onPhaseDone(AbstractSearchAsyncAction.java:241) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.onShardFailure(InitialSearchPhase.java:107) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase.lambda$performPhaseOnShard$4(InitialSearchPhase.java:205) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.search.InitialSearchPhase$1.doRun(InitialSearchPhase.java:184) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:37:42,975][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:37:42,990][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:37:42,992][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}, master
   {Node 3}{i-N4R-fvROmH6tnPvw7Bvw}{Fo8-0hezQAujCp5dwQuF4g}{127.0.0.1}{127.0.0.1:9303}, local

[2018-03-18T15:37:43,008][WARN ][o.e.c.NodeConnectionsService] [Node 3] failed to connect to node {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:37:43,021][WARN ][o.e.t.n.Netty4Transport  ] [Node 3] write and flush on the network layer failed (channel: [id: 0x5a1912b0, L:0.0.0.0/0.0.0.0:9303 ! R:/127.0.0.1:53788])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:37:43,033][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:37:43,034][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:37:43,039][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:37:43,039][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:37:43,059][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:37:43,059][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:37:43,061][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster6839567815410739017
idxproxy.data.path: /tmp/es-idxproxy220217343375154435
----------------------------------------
Cluster Name: es-idxproxy-1521383863084
Base Path:    /tmp/es-cluster6065725020468634731
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster6065725020468634731/config/node_1
Creating /tmp/es-cluster6065725020468634731/logs/node_1
Creating /tmp/es-cluster6065725020468634731/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster6065725020468634731/data/node_1
Log Directory:  /tmp/es-cluster6065725020468634731/logs/node_1
----------------------------------------
Creating /tmp/es-cluster6065725020468634731/modules
Creating /tmp/es-cluster6065725020468634731/plugins
[2018-03-18T15:37:43,109][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:37:43,113][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:37:43,113][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:37:43,113][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [EUbDFLCBQ5eenjP2Ka5Evg]
[2018-03-18T15:37:43,113][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:37:43,114][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:37:43,114][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:37:43,114][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:37:43,114][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:37:43,114][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:37:43,115][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:37:43,128][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:37:43,154][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:37:43,154][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:37:43,166][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:37:43,167][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:37:46,171][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:37:46,177][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:37:46,183][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:37:46,184][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster6065725020468634731/config/node_2
Creating /tmp/es-cluster6065725020468634731/logs/node_2
Creating /tmp/es-cluster6065725020468634731/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster6065725020468634731/data/node_2
Log Directory:  /tmp/es-cluster6065725020468634731/logs/node_2
----------------------------------------
[2018-03-18T15:37:46,218][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:37:46,223][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:37:46,223][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:37:46,223][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [G6Qxd4m6T2OPBumn2BY-dA]
[2018-03-18T15:37:46,223][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:37:46,224][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:37:46,224][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:37:46,225][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:37:46,226][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:37:46,246][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:37:46,276][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:37:46,276][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:37:46,288][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:37:46,289][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:37:49,317][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{G6Qxd4m6T2OPBumn2BY-dA}{BwFMpXllSHqmZqvYiutPng}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{G6Qxd4m6T2OPBumn2BY-dA}{BwFMpXllSHqmZqvYiutPng}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:37:49,321][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:37:49,327][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:37:49,331][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [EUbDFLCBQ5eenjP2Ka5Evg][Node 1][/tmp/es-cluster6065725020468634731/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:49,332][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [G6Qxd4m6T2OPBumn2BY-dA][Node 2][/tmp/es-cluster6065725020468634731/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:49,342][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:37:49,342][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster6065725020468634731/config/node_3
Creating /tmp/es-cluster6065725020468634731/logs/node_3
Creating /tmp/es-cluster6065725020468634731/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster6065725020468634731/data/node_3
Log Directory:  /tmp/es-cluster6065725020468634731/logs/node_3
----------------------------------------
[2018-03-18T15:37:49,372][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:37:49,376][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:37:49,376][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:37:49,377][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [aIl8qoyqS765gL2TYPgc1Q]
[2018-03-18T15:37:49,377][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:37:49,377][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:37:49,378][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:37:49,378][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:37:49,378][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:37:49,378][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:37:49,378][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:37:49,379][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:37:49,379][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:37:49,379][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:37:49,380][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:37:49,380][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:37:49,381][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:37:49,399][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:37:49,430][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:37:49,431][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:37:49,444][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:37:49,445][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:37:52,474][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{aIl8qoyqS765gL2TYPgc1Q}{cIpuD3DzQyS-tayJLwmIMg}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{aIl8qoyqS765gL2TYPgc1Q}{cIpuD3DzQyS-tayJLwmIMg}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:37:52,478][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{aIl8qoyqS765gL2TYPgc1Q}{cIpuD3DzQyS-tayJLwmIMg}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:37:52,479][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301},{Node 2}{G6Qxd4m6T2OPBumn2BY-dA}{BwFMpXllSHqmZqvYiutPng}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [master {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:37:52,504][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [aIl8qoyqS765gL2TYPgc1Q][Node 3][/tmp/es-cluster6065725020468634731/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:52,505][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [EUbDFLCBQ5eenjP2Ka5Evg][Node 1][/tmp/es-cluster6065725020468634731/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:52,505][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [G6Qxd4m6T2OPBumn2BY-dA][Node 2][/tmp/es-cluster6065725020468634731/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:37:52,509][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:37:52,509][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:37:52,519][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:38:16,174][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:38:16,186][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:38:16,193][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [aIl8qoyqS765gL2TYPgc1Q][Node 3][/tmp/es-cluster6065725020468634731/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:38:16,193][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [EUbDFLCBQ5eenjP2Ka5Evg][Node 1][/tmp/es-cluster6065725020468634731/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:38:16,193][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [G6Qxd4m6T2OPBumn2BY-dA][Node 2][/tmp/es-cluster6065725020468634731/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:38:17,217][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy220217343375154435/0000000000000000001.tmp
[2018-03-18T15:38:18,232][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy220217343375154435/0000000000000000001.dat
[2018-03-18T15:38:18,233][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy220217343375154435/0000000000000000002.tmp
[2018-03-18T15:38:19,247][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexing: /tmp/es-idxproxy220217343375154435/0000000000000000001.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=3, timed_out=false}
[2018-03-18T15:38:19,264][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample1/uDarWq0LRyaalUXdLX9GFQ] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1007, id=1007}, _id=1007, _score=1.0}], total=2, max_score=1.0}, took=5, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1003, id=1003}, _id=1003, _score=1.0}], total=3, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1004, id=1004}, _id=1004, _score=1.0}], total=3, max_score=1.0}, took=7, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1001, id=1001}, _id=1001, _score=1.0}], total=3, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1002, id=1002}, _id=1002, _score=1.0}], total=4, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:38:28,498][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexed:  /tmp/es-idxproxy220217343375154435/0000000000000000001.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=5, max_score=1.0}, took=4, timed_out=false}
index {[sample][data][1006], source[{"id":1006,"msg":"test 1006"}]}
index {[sample][data][1007], source[{"id":1007,"msg":"test 1007"}]}
bulk [index {[sample][data][1005], source[{"id":1005,"msg":"test 1005"}]},update {[sample][data][1006] source[{"doc":{"msg":"test 1306"}}]},delete {[sample][data][1007]}]
index {[sample][data][1003], source[{"id":1003,"msg":"test 1003"}]}
delete {[sample][data][1003]}
index {[sample][data][1004], source[{"id":1004,"msg":"test 1004"}]}
delete-by-query [sample][data] SearchRequest{searchType=QUERY_THEN_FETCH, indices=[sample], indicesOptions=IndicesOptions[id=38, ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_alisases_to_multiple_indices=true, forbid_closed_indices=true], types=[data], routing='null', preference='null', requestCache=null, scroll=Scroll{keepAlive=5m}, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, source={  "size" : 1000,  "query" : {    "term" : {      "id" : {        "value" : 1004,        "boost" : 1.0      }    }  },  "_source" : false}}
index {[sample][data][1001], source[{"id":1001,"msg":"test 1001"}]}
update {[sample][data][1001] source[{"doc":{"msg":"test 1101"}}]}
index {[sample][data][1002], source[{"id":1002,"msg":"test 1002"}]}
update-by-query [sample][data] updated with Script{type=inline, lang='painless', idOrCode='ctx._source.msg='test 1202'', options={}, params={}} SearchRequest{searchType=QUERY_THEN_FETCH, indices=[sample], indicesOptions=IndicesOptions[id=38, ignore_unavailable=false, allow_no_indices=true, expand_wildcards_open=true, expand_wildcards_closed=false, allow_alisases_to_multiple_indices=true, forbid_closed_indices=true], types=[data], routing='null', preference='null', requestCache=null, scroll=Scroll{keepAlive=5m}, maxConcurrentShardRequests=0, batchedReduceSize=512, preFilterShardSize=128, source={  "size" : 1000,  "query" : {    "term" : {      "id" : {        "value" : 1002,        "boost" : 1.0      }    }  }}}
index {[sample][data][1000], source[{"id":1000,"msg":"test 1000"}]}

[2018-03-18T15:38:30,282][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy220217343375154435/0000000000000000002.dat
[2018-03-18T15:38:30,284][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy220217343375154435/0000000000000000003.tmp
[2018-03-18T15:38:30,297][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexing: /tmp/es-idxproxy220217343375154435/0000000000000000002.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=5, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2006, id=2006}, _id=2006, _score=1.0}], total=6, max_score=1.0}, took=5, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2006, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2007, id=2007}, _id=2007, _score=1.0}], total=7, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}], total=7, max_score=1.0}, took=5, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2003, id=2003}, _id=2003, _score=1.0}], total=8, max_score=1.0}, took=7, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}], total=7, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2004, id=2004}, _id=2004, _score=1.0}], total=8, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2001, id=2001}, _id=2001, _score=1.0}], total=8, max_score=1.0}, took=5, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2002, id=2002}, _id=2002, _score=1.0}], total=9, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:38:38,532][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexed:  /tmp/es-idxproxy220217343375154435/0000000000000000002.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=10, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:38:39,558][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample2] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:38:40,310][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexing: /tmp/es-idxproxy220217343375154435/0000000000000000001.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
[2018-03-18T15:38:40,326][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample2/jfSfKR2ES_qX9pZhcSh_vg] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}], total=1, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1007, id=1007}, _id=1007, _score=1.0}], total=2, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1003, id=1003}, _id=1003, _score=1.0}], total=3, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:38:46,197][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [EUbDFLCBQ5eenjP2Ka5Evg][Node 1][/tmp/es-cluster6065725020468634731/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:38:46,198][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [aIl8qoyqS765gL2TYPgc1Q][Node 3][/tmp/es-cluster6065725020468634731/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:38:46,198][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [G6Qxd4m6T2OPBumn2BY-dA][Node 2][/tmp/es-cluster6065725020468634731/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1004, id=1004}, _id=1004, _score=1.0}], total=3, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1001, id=1001}, _id=1001, _score=1.0}], total=3, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1002, id=1002}, _id=1002, _score=1.0}], total=4, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:38:49,511][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexed:  /tmp/es-idxproxy220217343375154435/0000000000000000001.dat 12 1286
[2018-03-18T15:38:50,323][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexing: /tmp/es-idxproxy220217343375154435/0000000000000000002.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=5, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2006, id=2006}, _id=2006, _score=1.0}], total=6, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2006, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2007, id=2007}, _id=2007, _score=1.0}], total=7, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}], total=7, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2003, id=2003}, _id=2003, _score=1.0}], total=8, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}], total=7, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2004, id=2004}, _id=2004, _score=1.0}], total=8, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2001, id=2001}, _id=2001, _score=1.0}], total=8, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2002, id=2002}, _id=2002, _score=1.0}], total=9, max_score=1.0}, took=2, timed_out=false}
[2018-03-18T15:38:58,675][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexed:  /tmp/es-idxproxy220217343375154435/0000000000000000002.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=10, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:39:00,670][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Stopped RequestSender because of working in [].
[2018-03-18T15:39:01,352][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy220217343375154435/0000000000000000003.dat
[2018-03-18T15:39:01,352][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy220217343375154435/0000000000000000004.tmp
[2018-03-18T15:39:01,368][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexing: /tmp/es-idxproxy220217343375154435/0000000000000000003.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=10, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=11, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=12, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=12, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=13, max_score=1.0}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=12, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=13, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=13, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=14, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:39:09,522][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample2] Indexed:  /tmp/es-idxproxy220217343375154435/0000000000000000003.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample2, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2005, id=2005}, _id=2005, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2306, id=2006}, _id=2006, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2101, id=2001}, _id=2001, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2202, id=2002}, _id=2002, _score=1.0}, {_index=sample2, _type=data, _source={msg=test 2000, id=2000}, _id=2000, _score=1.0}], total=15, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:39:10,547][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:39:10,560][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:39:10,560][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:39:10,564][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}, master
   {Node 3}{aIl8qoyqS765gL2TYPgc1Q}{cIpuD3DzQyS-tayJLwmIMg}{127.0.0.1}{127.0.0.1:9303}, local
   {Node 2}{G6Qxd4m6T2OPBumn2BY-dA}{BwFMpXllSHqmZqvYiutPng}{127.0.0.1}{127.0.0.1:9302}

[2018-03-18T15:39:10,564][WARN ][o.e.d.z.ZenDiscovery     ] [Node 2] master left (reason = shut_down), current nodes: nodes: 
   {Node 1}{EUbDFLCBQ5eenjP2Ka5Evg}{REpPdrPiQAOBUh1u-WpbZA}{127.0.0.1}{127.0.0.1:9301}, master
   {Node 3}{aIl8qoyqS765gL2TYPgc1Q}{cIpuD3DzQyS-tayJLwmIMg}{127.0.0.1}{127.0.0.1:9303}
   {Node 2}{G6Qxd4m6T2OPBumn2BY-dA}{BwFMpXllSHqmZqvYiutPng}{127.0.0.1}{127.0.0.1:9302}, local

[2018-03-18T15:39:10,564][WARN ][o.e.t.n.Netty4Transport  ] [Node 2] write and flush on the network layer failed (channel: [id: 0xd7664819, L:0.0.0.0/0.0.0.0:9302 ! R:/127.0.0.1:38432])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:39:10,618][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:39:10,618][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:39:10,619][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy220217343375154435/0000000000000000004.dat
[2018-03-18T15:39:10,625][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:39:10,625][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:39:10,662][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:39:10,662][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:39:10,667][INFO ][o.e.n.Node               ] [Node 2] closed
[2018-03-18T15:39:10,667][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:39:10,703][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:39:10,703][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:39:10,707][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster6065725020468634731
idxproxy.data.path: /tmp/es-idxproxy1341937561042679954
----------------------------------------
Cluster Name: es-idxproxy-1521383950721
Base Path:    /tmp/es-cluster7391646856114890174
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster7391646856114890174/config/node_1
Creating /tmp/es-cluster7391646856114890174/logs/node_1
Creating /tmp/es-cluster7391646856114890174/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster7391646856114890174/data/node_1
Log Directory:  /tmp/es-cluster7391646856114890174/logs/node_1
----------------------------------------
Creating /tmp/es-cluster7391646856114890174/modules
Creating /tmp/es-cluster7391646856114890174/plugins
[2018-03-18T15:39:10,744][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:39:10,748][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:10,748][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:10,748][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [cjKwZmjGQaqZ5Gc4FbsKBA]
[2018-03-18T15:39:10,748][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:10,748][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:10,749][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:10,761][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:39:10,783][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:39:10,783][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:39:10,793][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:39:10,793][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:39:13,797][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:39:13,804][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:39:13,808][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:39:13,808][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster7391646856114890174/config/node_2
Creating /tmp/es-cluster7391646856114890174/logs/node_2
Creating /tmp/es-cluster7391646856114890174/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster7391646856114890174/data/node_2
Log Directory:  /tmp/es-cluster7391646856114890174/logs/node_2
----------------------------------------
[2018-03-18T15:39:13,844][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:39:13,850][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:13,850][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:13,851][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [k_2jq7zIS6WNlm_-iYVgNA]
[2018-03-18T15:39:13,851][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:13,851][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:39:13,851][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:13,852][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:13,867][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:39:13,894][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:39:13,894][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:39:13,908][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:39:13,909][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:39:16,933][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{k_2jq7zIS6WNlm_-iYVgNA}{_eCJEC-0QcabkEsP9d1IRw}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{k_2jq7zIS6WNlm_-iYVgNA}{_eCJEC-0QcabkEsP9d1IRw}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:39:16,938][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:39:16,942][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:39:16,945][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [k_2jq7zIS6WNlm_-iYVgNA][Node 2][/tmp/es-cluster7391646856114890174/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:16,945][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [cjKwZmjGQaqZ5Gc4FbsKBA][Node 1][/tmp/es-cluster7391646856114890174/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:16,949][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:39:16,950][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster7391646856114890174/config/node_3
Creating /tmp/es-cluster7391646856114890174/logs/node_3
Creating /tmp/es-cluster7391646856114890174/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster7391646856114890174/data/node_3
Log Directory:  /tmp/es-cluster7391646856114890174/logs/node_3
----------------------------------------
[2018-03-18T15:39:16,972][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:39:16,976][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:16,976][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:16,976][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [ZPeI3GRaR9meDlaEltofsg]
[2018-03-18T15:39:16,977][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:16,977][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:39:16,977][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:39:16,977][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:16,977][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:16,977][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:16,977][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:16,978][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:16,992][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:39:17,016][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:39:17,016][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:39:17,026][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:39:17,027][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:39:20,051][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{ZPeI3GRaR9meDlaEltofsg}{AUB0s4qCSy-7q5QWUgOniA}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{ZPeI3GRaR9meDlaEltofsg}{AUB0s4qCSy-7q5QWUgOniA}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:39:20,055][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{ZPeI3GRaR9meDlaEltofsg}{AUB0s4qCSy-7q5QWUgOniA}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:39:20,056][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}, added {{Node 2}{k_2jq7zIS6WNlm_-iYVgNA}{_eCJEC-0QcabkEsP9d1IRw}{127.0.0.1}{127.0.0.1:9302},{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:39:20,078][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [ZPeI3GRaR9meDlaEltofsg][Node 3][/tmp/es-cluster7391646856114890174/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:20,078][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [k_2jq7zIS6WNlm_-iYVgNA][Node 2][/tmp/es-cluster7391646856114890174/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:20,079][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [cjKwZmjGQaqZ5Gc4FbsKBA][Node 1][/tmp/es-cluster7391646856114890174/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:20,084][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:39:20,084][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:39:20,093][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:39:43,800][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:39:43,804][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [ZPeI3GRaR9meDlaEltofsg][Node 3][/tmp/es-cluster7391646856114890174/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:43,804][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [k_2jq7zIS6WNlm_-iYVgNA][Node 2][/tmp/es-cluster7391646856114890174/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:43,804][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [cjKwZmjGQaqZ5Gc4FbsKBA][Node 1][/tmp/es-cluster7391646856114890174/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:43,809][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:39:44,826][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy1341937561042679954/0000000000000000001.tmp
[2018-03-18T15:39:45,835][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy1341937561042679954/0000000000000000001.dat
[2018-03-18T15:39:45,835][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy1341937561042679954/0000000000000000002.tmp
[2018-03-18T15:39:45,849][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:39:45,861][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:39:45,861][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:39:45,874][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 3}{ZPeI3GRaR9meDlaEltofsg}{AUB0s4qCSy-7q5QWUgOniA}{127.0.0.1}{127.0.0.1:9303}, local
   {Node 2}{k_2jq7zIS6WNlm_-iYVgNA}{_eCJEC-0QcabkEsP9d1IRw}{127.0.0.1}{127.0.0.1:9302}
   {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:39:45,875][WARN ][o.e.d.z.ZenDiscovery     ] [Node 2] master left (reason = shut_down), current nodes: nodes: 
   {Node 3}{ZPeI3GRaR9meDlaEltofsg}{AUB0s4qCSy-7q5QWUgOniA}{127.0.0.1}{127.0.0.1:9303}
   {Node 2}{k_2jq7zIS6WNlm_-iYVgNA}{_eCJEC-0QcabkEsP9d1IRw}{127.0.0.1}{127.0.0.1:9302}, local
   {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:39:45,874][WARN ][o.e.t.n.Netty4Transport  ] [Node 3] write and flush on the network layer failed (channel: [id: 0xbd8d02c5, L:0.0.0.0/0.0.0.0:9303 ! R:/127.0.0.1:54192])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:39:45,875][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}], reason [transport disconnected]
[2018-03-18T15:39:45,875][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301}], reason [transport disconnected]
[2018-03-18T15:39:45,890][WARN ][o.e.c.NodeConnectionsService] [Node 2] failed to connect to node {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:39:45,891][WARN ][o.e.c.NodeConnectionsService] [Node 3] failed to connect to node {Node 1}{cjKwZmjGQaqZ5Gc4FbsKBA}{bVOh7Pr2T12FSWEWDxhv3Q}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:39:45,899][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:39:45,900][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:39:45,901][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy1341937561042679954/0000000000000000002.dat
[2018-03-18T15:39:45,902][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:39:45,902][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:39:45,926][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:39:45,926][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:39:45,928][INFO ][o.e.n.Node               ] [Node 2] closed
[2018-03-18T15:39:45,929][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:39:45,946][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:39:45,947][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:39:45,948][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster7391646856114890174
idxproxy.data.path: /tmp/es-idxproxy6512091743478013885
----------------------------------------
Cluster Name: es-idxproxy-1521383985956
Base Path:    /tmp/es-cluster291449913035921706
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster291449913035921706/config/node_1
Creating /tmp/es-cluster291449913035921706/logs/node_1
Creating /tmp/es-cluster291449913035921706/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster291449913035921706/data/node_1
Log Directory:  /tmp/es-cluster291449913035921706/logs/node_1
----------------------------------------
Creating /tmp/es-cluster291449913035921706/modules
Creating /tmp/es-cluster291449913035921706/plugins
[2018-03-18T15:39:45,975][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:39:45,979][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:45,979][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:45,979][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [Im5-OJ8HQm-SspEJHXdNfw]
[2018-03-18T15:39:45,979][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:45,979][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:39:45,979][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:45,980][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:45,989][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:39:46,008][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:39:46,008][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:39:46,017][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:39:46,018][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:39:49,021][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:39:49,032][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:39:49,032][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster291449913035921706/config/node_2
Creating /tmp/es-cluster291449913035921706/logs/node_2
Creating /tmp/es-cluster291449913035921706/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster291449913035921706/data/node_2
Log Directory:  /tmp/es-cluster291449913035921706/logs/node_2
----------------------------------------
[2018-03-18T15:39:49,035][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:39:49,055][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:39:49,060][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:49,060][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:49,061][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [gBGkqffIRM22M5iki2pqsg]
[2018-03-18T15:39:49,061][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:49,061][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:49,062][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:49,076][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:39:49,099][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:39:49,100][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:39:49,110][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:39:49,111][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:39:52,138][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{gBGkqffIRM22M5iki2pqsg}{zQwbWfCIQaymVrqTVRXEWg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{gBGkqffIRM22M5iki2pqsg}{zQwbWfCIQaymVrqTVRXEWg}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:39:52,143][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:39:52,235][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:39:52,239][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [gBGkqffIRM22M5iki2pqsg][Node 2][/tmp/es-cluster291449913035921706/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:52,240][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [Im5-OJ8HQm-SspEJHXdNfw][Node 1][/tmp/es-cluster291449913035921706/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:52,243][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:39:52,243][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster291449913035921706/config/node_3
Creating /tmp/es-cluster291449913035921706/logs/node_3
Creating /tmp/es-cluster291449913035921706/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster291449913035921706/data/node_3
Log Directory:  /tmp/es-cluster291449913035921706/logs/node_3
----------------------------------------
[2018-03-18T15:39:52,268][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:39:52,273][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:39:52,273][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:39:52,274][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [6pePeiETQ3qMe01b4aQxRg]
[2018-03-18T15:39:52,274][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:39:52,274][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:39:52,275][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:39:52,291][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:39:52,316][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:39:52,316][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:39:52,328][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:39:52,329][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:39:55,354][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{6pePeiETQ3qMe01b4aQxRg}{NNXmoj8WQqeW-7kW6n2k6g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{6pePeiETQ3qMe01b4aQxRg}{NNXmoj8WQqeW-7kW6n2k6g}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:39:55,358][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{6pePeiETQ3qMe01b4aQxRg}{NNXmoj8WQqeW-7kW6n2k6g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:39:55,359][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}, added {{Node 2}{gBGkqffIRM22M5iki2pqsg}{zQwbWfCIQaymVrqTVRXEWg}{127.0.0.1}{127.0.0.1:9302},{Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:39:55,385][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [gBGkqffIRM22M5iki2pqsg][Node 2][/tmp/es-cluster291449913035921706/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:55,385][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [6pePeiETQ3qMe01b4aQxRg][Node 3][/tmp/es-cluster291449913035921706/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:55,385][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [Im5-OJ8HQm-SspEJHXdNfw][Node 1][/tmp/es-cluster291449913035921706/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:39:55,389][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:39:55,389][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:39:55,399][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:40:19,024][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:40:19,026][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [gBGkqffIRM22M5iki2pqsg][Node 2][/tmp/es-cluster291449913035921706/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:19,026][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [6pePeiETQ3qMe01b4aQxRg][Node 3][/tmp/es-cluster291449913035921706/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:19,026][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [Im5-OJ8HQm-SspEJHXdNfw][Node 1][/tmp/es-cluster291449913035921706/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:19,035][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:40:20,178][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy6512091743478013885/0000000000000000001.dat
[2018-03-18T15:40:21,189][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy6512091743478013885/0000000000000000002.tmp
[2018-03-18T15:40:22,199][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy6512091743478013885/0000000000000000002.dat
[2018-03-18T15:40:22,200][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy6512091743478013885/0000000000000000003.tmp
[2018-03-18T15:40:23,208][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexing: /tmp/es-idxproxy6512091743478013885/0000000000000000001.dat
[2018-03-18T15:40:23,208][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexed:  /tmp/es-idxproxy6512091743478013885/0000000000000000001.dat 0 0
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
[2018-03-18T15:40:24,219][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexing: /tmp/es-idxproxy6512091743478013885/0000000000000000002.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
[2018-03-18T15:40:24,232][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample1/NkXZi-FlTiajG92sJPWGbw] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=3, timed_out=false}
[2018-03-18T15:40:25,245][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Sender][sample1] Indexed:  /tmp/es-idxproxy6512091743478013885/0000000000000000002.dat 1 87
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:40:26,253][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:40:26,265][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:40:26,268][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:40:26,269][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 2}{gBGkqffIRM22M5iki2pqsg}{zQwbWfCIQaymVrqTVRXEWg}{127.0.0.1}{127.0.0.1:9302}
   {Node 3}{6pePeiETQ3qMe01b4aQxRg}{NNXmoj8WQqeW-7kW6n2k6g}{127.0.0.1}{127.0.0.1:9303}, local
   {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:40:26,280][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}], reason [transport disconnected]
[2018-03-18T15:40:26,280][WARN ][o.e.d.z.ZenDiscovery     ] [Node 2] master left (reason = shut_down), current nodes: nodes: 
   {Node 2}{gBGkqffIRM22M5iki2pqsg}{zQwbWfCIQaymVrqTVRXEWg}{127.0.0.1}{127.0.0.1:9302}, local
   {Node 3}{6pePeiETQ3qMe01b4aQxRg}{NNXmoj8WQqeW-7kW6n2k6g}{127.0.0.1}{127.0.0.1:9303}
   {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:40:26,280][WARN ][o.e.t.n.Netty4Transport  ] [Node 2] write and flush on the network layer failed (channel: [id: 0xc95344f7, L:0.0.0.0/0.0.0.0:9302 ! R:/127.0.0.1:38844])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:40:26,279][WARN ][o.e.t.n.Netty4Transport  ] [Node 3] write and flush on the network layer failed (channel: [id: 0x66f3d218, L:0.0.0.0/0.0.0.0:57120 ! R:127.0.0.1/127.0.0.1:9301])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:40:26,287][WARN ][o.e.c.NodeConnectionsService] [Node 2] failed to connect to node {Node 1}{Im5-OJ8HQm-SspEJHXdNfw}{XxiP7CwRTIuKAnK1dW7Q0w}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:40:26,318][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:40:26,318][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:40:26,319][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy6512091743478013885/0000000000000000003.dat
[2018-03-18T15:40:26,322][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:40:26,322][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:40:26,341][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:40:26,341][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:40:26,342][INFO ][o.e.n.Node               ] [Node 2] closed
[2018-03-18T15:40:26,342][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:40:26,366][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:40:26,366][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:40:26,368][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster291449913035921706
idxproxy.data.path: /tmp/es-idxproxy4772632530322115277
----------------------------------------
Cluster Name: es-idxproxy-1521384026377
Base Path:    /tmp/es-cluster6544759769313744669
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster6544759769313744669/config/node_1
Creating /tmp/es-cluster6544759769313744669/logs/node_1
Creating /tmp/es-cluster6544759769313744669/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster6544759769313744669/data/node_1
Log Directory:  /tmp/es-cluster6544759769313744669/logs/node_1
----------------------------------------
Creating /tmp/es-cluster6544759769313744669/modules
Creating /tmp/es-cluster6544759769313744669/plugins
[2018-03-18T15:40:26,396][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:40:26,400][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:40:26,400][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:40:26,400][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [USbsYPFFQEuXHMQQYF-PMw]
[2018-03-18T15:40:26,400][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:40:26,400][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:40:26,401][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:40:26,410][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:40:26,428][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:40:26,428][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:40:26,438][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:40:26,438][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:40:29,441][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:40:29,454][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:40:29,454][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster6544759769313744669/config/node_2
Creating /tmp/es-cluster6544759769313744669/logs/node_2
Creating /tmp/es-cluster6544759769313744669/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster6544759769313744669/data/node_2
Log Directory:  /tmp/es-cluster6544759769313744669/logs/node_2
----------------------------------------
[2018-03-18T15:40:29,472][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:40:29,489][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:40:29,497][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:40:29,497][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:40:29,498][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [VFALIvuCSFCltaT6SQV9sQ]
[2018-03-18T15:40:29,498][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:40:29,498][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:40:29,499][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:40:29,500][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:40:29,500][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:40:29,500][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:40:29,518][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:40:29,557][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:40:29,557][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:40:29,588][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:40:29,589][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:40:32,619][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:40:32,624][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:40:32,644][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:40:32,649][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [USbsYPFFQEuXHMQQYF-PMw][Node 1][/tmp/es-cluster6544759769313744669/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:32,649][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [VFALIvuCSFCltaT6SQV9sQ][Node 2][/tmp/es-cluster6544759769313744669/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:32,652][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:40:32,652][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster6544759769313744669/config/node_3
Creating /tmp/es-cluster6544759769313744669/logs/node_3
Creating /tmp/es-cluster6544759769313744669/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster6544759769313744669/data/node_3
Log Directory:  /tmp/es-cluster6544759769313744669/logs/node_3
----------------------------------------
[2018-03-18T15:40:32,679][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:40:32,686][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [21.3gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:40:32,686][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:40:32,686][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [NdKChwgwQg2M17SBc8cPow]
[2018-03-18T15:40:32,686][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:40:32,686][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:40:32,687][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:40:32,702][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:40:32,725][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:40:32,725][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:40:32,737][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:40:32,737][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:40:35,769][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:40:35,773][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:40:35,775][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301},{Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:40:35,798][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [VFALIvuCSFCltaT6SQV9sQ][Node 2][/tmp/es-cluster6544759769313744669/data/node_2/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:35,799][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [USbsYPFFQEuXHMQQYF-PMw][Node 1][/tmp/es-cluster6544759769313744669/data/node_1/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:35,799][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] low disk watermark [85%] exceeded on [NdKChwgwQg2M17SBc8cPow][Node 3][/tmp/es-cluster6544759769313744669/data/node_3/nodes/0] free: 21.3gb[14.2%], replicas will not be assigned to this node
[2018-03-18T15:40:35,804][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:40:35,804][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:40:35,813][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:40:59,445][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:40:59,453][INFO ][o.e.c.r.a.DiskThresholdMonitor] [Node 1] rerouting shards: [one or more nodes has gone under the high or low watermark]
[2018-03-18T15:40:59,459][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:41:00,080][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.idxproxy][0]] ...]).
[2018-03-18T15:41:00,499][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy4772632530322115277/0000000000000000001.tmp
[2018-03-18T15:41:01,530][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy4772632530322115277/0000000000000000001.dat
[2018-03-18T15:41:01,531][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy4772632530322115277/0000000000000000002.tmp
[2018-03-18T15:41:02,540][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexing: /tmp/es-idxproxy4772632530322115277/0000000000000000001.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=3, timed_out=false}
[2018-03-18T15:41:02,552][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample1/v50f8lWzR_G8xmdNvYMTWA] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
[2018-03-18T15:41:03,594][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexed:  /tmp/es-idxproxy4772632530322115277/0000000000000000001.dat 1 87
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:41:05,573][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Stopped RequestSender because of working in [].
[2018-03-18T15:41:07,565][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy4772632530322115277/0000000000000000002.dat
[2018-03-18T15:41:07,566][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy4772632530322115277/0000000000000000003.tmp
[2018-03-18T15:41:08,577][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexing: /tmp/es-idxproxy4772632530322115277/0000000000000000002.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=1, max_score=1.0}, took=4, timed_out=false}
[2018-03-18T15:41:08,589][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:41:08,628][WARN ][o.e.a.b.TransportShardBulkAction] [Node 3] [[sample1][0]] failed to perform indices:data/write/bulk[s] on replica [sample1][0], node[VFALIvuCSFCltaT6SQV9sQ], [R], s[STARTED], a[id=BqHFnp4wSW2yqARmje-8Xw]
org.elasticsearch.transport.NodeDisconnectedException: [Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected
[2018-03-18T15:41:08,634][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [GREEN] to [YELLOW] (reason: [{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303} left]).
[2018-03-18T15:41:08,634][INFO ][o.e.c.s.ClusterService   ] [Node 1] removed {{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-left({Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303}), reason(left)[{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303} left]
[2018-03-18T15:41:08,638][WARN ][o.e.c.a.s.ShardStateAction] [Node 3] [sample1][0] node closed while execution action [internal:cluster/shard/failure] for shard entry [shard id [[sample1][0]], allocation id [BqHFnp4wSW2yqARmje-8Xw], primary term [1], message [failed to perform indices:data/write/bulk[s] on replica [sample1][0], node[VFALIvuCSFCltaT6SQV9sQ], [R], s[STARTED], a[id=BqHFnp4wSW2yqARmje-8Xw]], failure [NodeDisconnectedException[[Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected]]]
org.elasticsearch.transport.NodeDisconnectedException: [Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected
[2018-03-18T15:41:08,639][INFO ][o.e.c.s.ClusterService   ] [Node 2] removed {{Node 3}{NdKChwgwQg2M17SBc8cPow}{j_EKNYviS0ORVmG3HpDzHQ}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [15]])
[2018-03-18T15:41:08,648][INFO ][o.e.c.r.DelayedAllocationService] [Node 1] scheduling reroute for delayed shards in [958.2ms] (2 delayed shards)
[2018-03-18T15:41:08,662][ERROR][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1][4] Failed to index [sample1][data][1000]
org.elasticsearch.transport.SendRequestTransportException: [Node 3][127.0.0.1:9303][indices:data/write/bulk[s][p]]
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:606) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:529) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:517) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performAction(TransportReplicationAction.java:780) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.performLocalAction(TransportReplicationAction.java:698) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:686) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:143) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction.doExecute(TransportReplicationAction.java:92) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:359) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:474) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:171) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:85) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:408) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:80) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.executeIndexRequest(RequestSender.java:412) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.lambda$executeIndexRequest$24(RequestSender.java:431) ~[classes/:?]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.lambda$wrapBulkResponse$0(TransportSingleItemBulkWriteAction.java:118) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:59) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.finishHim(TransportBulkAction.java:389) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.onFailure(TransportBulkAction.java:384) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishAsFailed(TransportReplicationAction.java:857) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleException(TransportReplicationAction.java:812) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1077) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService$6.doRun(TransportService.java:627) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: org.elasticsearch.transport.TransportException: TransportService is closed stopped can't send request
	at org.elasticsearch.transport.TransportService.sendRequestInternal(TransportService.java:590) ~[elasticsearch-5.6.7.jar:5.6.7]
	... 51 more
[2018-03-18T15:41:08,667][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] Saving /tmp/es-idxproxy4772632530322115277/0000000000000000004_1.err
[2018-03-18T15:41:08,675][WARN ][o.e.t.TransportService   ] [Node 3] Transport response handler not found of id [91]
[2018-03-18T15:41:08,678][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:41:08,678][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:41:08,682][INFO ][o.e.n.Node               ] [Node 3] closed
[2018-03-18T15:41:10,177][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.idxproxy][0]] ...]).
[2018-03-18T15:41:14,629][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] Remove Node 3 from RequestSender(sample1)
[2018-03-18T15:41:15,639][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy4772632530322115277/0000000000000000003.dat
[2018-03-18T15:41:15,639][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Opening　 /tmp/es-idxproxy4772632530322115277/0000000000000000004.tmp
[2018-03-18T15:41:15,660][WARN ][o.e.t.n.Netty4Transport  ] [Node 2] write and flush on the network layer failed (channel: [id: 0xcdf457b8, L:0.0.0.0/0.0.0.0:9302 ! R:/127.0.0.1:39136])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:41:15,674][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:41:15,686][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [26.1gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:41:15,686][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:41:15,696][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [NdKChwgwQg2M17SBc8cPow]
[2018-03-18T15:41:15,696][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:41:15,696][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:41:15,701][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:41:15,722][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:41:15,815][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:41:15,815][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:41:15,829][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:41:15,829][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:41:18,862][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{NdKChwgwQg2M17SBc8cPow}{tlIxTaOzRQuK0ae8Va3i0g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{NdKChwgwQg2M17SBc8cPow}{tlIxTaOzRQuK0ae8Va3i0g}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:41:18,866][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{NdKChwgwQg2M17SBc8cPow}{tlIxTaOzRQuK0ae8Va3i0g}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [19]])
[2018-03-18T15:41:18,868][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301},{Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-receive(from master [master {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} committed version [19]])
[2018-03-18T15:41:18,913][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:41:18,913][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:41:19,591][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexing: /tmp/es-idxproxy4772632530322115277/0000000000000000002.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:41:19,644][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexed:  /tmp/es-idxproxy4772632530322115277/0000000000000000002.dat 1 87
[2018-03-18T15:41:20,598][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexing: /tmp/es-idxproxy4772632530322115277/0000000000000000003.dat
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=1, max_score=1.0}, took=2, timed_out=false}
[2018-03-18T15:41:20,681][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexed:  /tmp/es-idxproxy4772632530322115277/0000000000000000003.dat 1 87
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1001, id=1001}, _id=1001, _score=1.0}], total=2, max_score=1.0}, took=7, timed_out=false}
[2018-03-18T15:41:21,696][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:41:21,711][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:41:21,711][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:41:21,722][WARN ][o.e.d.z.ZenDiscovery     ] [Node 2] master left (reason = shut_down), current nodes: nodes: 
   {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, master
   {Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302}, local
   {Node 3}{NdKChwgwQg2M17SBc8cPow}{tlIxTaOzRQuK0ae8Va3i0g}{127.0.0.1}{127.0.0.1:9303}

[2018-03-18T15:41:21,722][WARN ][o.e.t.n.Netty4Transport  ] [Node 2] write and flush on the network layer failed (channel: [id: 0x9cc9f866, L:0.0.0.0/0.0.0.0:9302 ! R:/127.0.0.1:39062])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
[2018-03-18T15:41:21,730][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301}, master
   {Node 2}{VFALIvuCSFCltaT6SQV9sQ}{ryjdL1CEQzeKRT8L7GY1EQ}{127.0.0.1}{127.0.0.1:9302}
   {Node 3}{NdKChwgwQg2M17SBc8cPow}{tlIxTaOzRQuK0ae8Va3i0g}{127.0.0.1}{127.0.0.1:9303}, local

[2018-03-18T15:41:21,750][WARN ][o.e.c.NodeConnectionsService] [Node 3] failed to connect to node {Node 1}{USbsYPFFQEuXHMQQYF-PMw}{D5M80vtkQxmb4qEbDpqY1Q}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:41:21,782][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:41:21,782][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:41:21,789][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:41:21,790][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:41:21,828][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:41:21,828][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:41:21,829][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Writer] Finalized /tmp/es-idxproxy4772632530322115277/0000000000000000004.dat
[2018-03-18T15:41:21,833][INFO ][o.e.n.Node               ] [Node 2] closed
[2018-03-18T15:41:21,833][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:41:21,863][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:41:21,864][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:41:21,866][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster6544759769313744669
idxproxy.data.path: /tmp/es-idxproxy2722689286675571661
----------------------------------------
Cluster Name: es-idxproxy-1521384081879
Base Path:    /tmp/es-cluster7878617533358675965
Num Of Node:  3
----------------------------------------
Creating /tmp/es-cluster7878617533358675965/config/node_1
Creating /tmp/es-cluster7878617533358675965/logs/node_1
Creating /tmp/es-cluster7878617533358675965/data/node_1
Node Name:      Node 1
HTTP Port:      9201
Transport Port: 9301
Data Directory: /tmp/es-cluster7878617533358675965/data/node_1
Log Directory:  /tmp/es-cluster7878617533358675965/logs/node_1
----------------------------------------
Creating /tmp/es-cluster7878617533358675965/modules
Creating /tmp/es-cluster7878617533358675965/plugins
[2018-03-18T15:41:21,903][INFO ][o.e.n.Node               ] [Node 1] initializing ...
[2018-03-18T15:41:21,907][INFO ][o.e.e.NodeEnvironment    ] [Node 1] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [26.1gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:41:21,908][INFO ][o.e.e.NodeEnvironment    ] [Node 1] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:41:21,908][INFO ][o.e.n.Node               ] [Node 1] node name [Node 1], node ID [C1xNVdRiTUSELQV0R8oDPw]
[2018-03-18T15:41:21,908][INFO ][o.e.n.Node               ] [Node 1] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:41:21,908][INFO ][o.e.n.Node               ] [Node 1] JVM arguments []
[2018-03-18T15:41:21,908][INFO ][o.e.p.PluginsService     ] [Node 1] no modules loaded
[2018-03-18T15:41:21,908][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:41:21,909][INFO ][o.e.p.PluginsService     ] [Node 1] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:41:21,918][INFO ][o.e.d.DiscoveryModule    ] [Node 1] using discovery type [zen]
[2018-03-18T15:41:21,938][INFO ][o.e.n.Node               ] [Node 1] initialized
[2018-03-18T15:41:21,939][INFO ][o.e.n.Node               ] [Node 1] starting ...
[2018-03-18T15:41:21,949][INFO ][o.e.t.TransportService   ] [Node 1] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}
[2018-03-18T15:41:21,949][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 1] no known master node, scheduling a retry
[2018-03-18T15:41:24,952][INFO ][o.e.c.s.ClusterService   ] [Node 1] new_master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2018-03-18T15:41:24,959][INFO ][o.e.g.GatewayService     ] [Node 1] recovered [0] indices into cluster_state
[2018-03-18T15:41:24,970][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 1] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}
[2018-03-18T15:41:24,970][INFO ][o.e.n.Node               ] [Node 1] started
Creating /tmp/es-cluster7878617533358675965/config/node_2
Creating /tmp/es-cluster7878617533358675965/logs/node_2
Creating /tmp/es-cluster7878617533358675965/data/node_2
Node Name:      Node 2
HTTP Port:      9202
Transport Port: 9302
Data Directory: /tmp/es-cluster7878617533358675965/data/node_2
Log Directory:  /tmp/es-cluster7878617533358675965/logs/node_2
----------------------------------------
[2018-03-18T15:41:24,993][INFO ][o.e.n.Node               ] [Node 2] initializing ...
[2018-03-18T15:41:24,998][INFO ][o.e.e.NodeEnvironment    ] [Node 2] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [26.1gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:41:24,998][INFO ][o.e.e.NodeEnvironment    ] [Node 2] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:41:24,998][INFO ][o.e.n.Node               ] [Node 2] node name [Node 2], node ID [3Nv4OkFUR2mGTuqZ6XLn7A]
[2018-03-18T15:41:24,998][INFO ][o.e.n.Node               ] [Node 2] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:41:24,999][INFO ][o.e.n.Node               ] [Node 2] JVM arguments []
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] no modules loaded
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:41:24,999][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:41:25,000][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:41:25,000][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:41:25,000][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:41:25,000][INFO ][o.e.p.PluginsService     ] [Node 2] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:41:25,016][INFO ][o.e.d.DiscoveryModule    ] [Node 2] using discovery type [zen]
[2018-03-18T15:41:25,043][INFO ][o.e.n.Node               ] [Node 2] initialized
[2018-03-18T15:41:25,043][INFO ][o.e.n.Node               ] [Node 2] starting ...
[2018-03-18T15:41:25,055][INFO ][o.e.t.TransportService   ] [Node 2] publish_address {127.0.0.1:9302}, bound_addresses {127.0.0.1:9302}
[2018-03-18T15:41:25,055][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 2] no known master node, scheduling a retry
[2018-03-18T15:41:28,082][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302},}, reason: zen-disco-node-join[{Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302}]
[2018-03-18T15:41:28,086][INFO ][o.e.c.s.ClusterService   ] [Node 2] detected_master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}, added {{Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301} committed version [3]])
[2018-03-18T15:41:28,091][WARN ][o.e.d.z.ElectMasterService] [Node 1] value for setting "discovery.zen.minimum_master_nodes" is too low. This can result in data loss! Please set it to at least a quorum of master-eligible nodes (current value: [-1], total number of master-eligible nodes used for publishing in this round: [2])
[2018-03-18T15:41:28,099][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 2] publish_address {127.0.0.1:9202}, bound_addresses {127.0.0.1:9202}
[2018-03-18T15:41:28,099][INFO ][o.e.n.Node               ] [Node 2] started
Creating /tmp/es-cluster7878617533358675965/config/node_3
Creating /tmp/es-cluster7878617533358675965/logs/node_3
Creating /tmp/es-cluster7878617533358675965/data/node_3
Node Name:      Node 3
HTTP Port:      9203
Transport Port: 9303
Data Directory: /tmp/es-cluster7878617533358675965/data/node_3
Log Directory:  /tmp/es-cluster7878617533358675965/logs/node_3
----------------------------------------
[2018-03-18T15:41:28,122][INFO ][o.e.n.Node               ] [Node 3] initializing ...
[2018-03-18T15:41:28,127][INFO ][o.e.e.NodeEnvironment    ] [Node 3] using [1] data paths, mounts [[/ (rootfs)]], net usable_space [26.1gb], net total_space [149.1gb], spins? [unknown], types [rootfs]
[2018-03-18T15:41:28,128][INFO ][o.e.e.NodeEnvironment    ] [Node 3] heap size [13.9gb], compressed ordinary object pointers [true]
[2018-03-18T15:41:28,128][INFO ][o.e.n.Node               ] [Node 3] node name [Node 3], node ID [nRywDU8kRzqHGIjuDngDFA]
[2018-03-18T15:41:28,128][INFO ][o.e.n.Node               ] [Node 3] version[5.6.7], pid[337], build[4669214/2018-01-25T21:14:50.776Z], OS[Linux/3.10.0-693.21.1.el7.x86_64/amd64], JVM[Oracle Corporation/OpenJDK 64-Bit Server VM/1.8.0_121/25.121-b13]
[2018-03-18T15:41:28,129][INFO ][o.e.n.Node               ] [Node 3] JVM arguments []
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] no modules loaded
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.codelibs.elasticsearch.idxproxy.IndexingProxyPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.index.reindex.ReindexPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.ingest.common.IngestCommonPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.painless.PainlessPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.percolator.PercolatorPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.groovy.GroovyPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.search.aggregations.matrix.MatrixAggregationPlugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty3Plugin]
[2018-03-18T15:41:28,129][INFO ][o.e.p.PluginsService     ] [Node 3] loaded plugin [org.elasticsearch.transport.Netty4Plugin]
[2018-03-18T15:41:28,141][INFO ][o.e.d.DiscoveryModule    ] [Node 3] using discovery type [zen]
[2018-03-18T15:41:28,159][INFO ][o.e.n.Node               ] [Node 3] initialized
[2018-03-18T15:41:28,159][INFO ][o.e.n.Node               ] [Node 3] starting ...
[2018-03-18T15:41:28,171][INFO ][o.e.t.TransportService   ] [Node 3] publish_address {127.0.0.1:9303}, bound_addresses {127.0.0.1:9303}
[2018-03-18T15:41:28,171][DEBUG][o.e.a.a.c.h.TransportClusterHealthAction] [Node 3] no known master node, scheduling a retry
[2018-03-18T15:41:31,199][INFO ][o.e.c.s.ClusterService   ] [Node 1] added {{Node 3}{nRywDU8kRzqHGIjuDngDFA}{xC_yaH0BQbKWBTBO-z3IOg}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-node-join[{Node 3}{nRywDU8kRzqHGIjuDngDFA}{xC_yaH0BQbKWBTBO-z3IOg}{127.0.0.1}{127.0.0.1:9303}]
[2018-03-18T15:41:31,205][INFO ][o.e.c.s.ClusterService   ] [Node 2] added {{Node 3}{nRywDU8kRzqHGIjuDngDFA}{xC_yaH0BQbKWBTBO-z3IOg}{127.0.0.1}{127.0.0.1:9303},}, reason: zen-disco-receive(from master [master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:41:31,207][INFO ][o.e.c.s.ClusterService   ] [Node 3] detected_master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}, added {{Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302},{Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301},}, reason: zen-disco-receive(from master [master {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301} committed version [4]])
[2018-03-18T15:41:31,237][INFO ][o.e.h.n.Netty4HttpServerTransport] [Node 3] publish_address {127.0.0.1:9203}, bound_addresses {127.0.0.1:9203}
[2018-03-18T15:41:31,237][INFO ][o.e.n.Node               ] [Node 3] started
[2018-03-18T15:41:31,244][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [sample1] creating index, cause [api], templates [], shards [1]/[1], mappings []
[2018-03-18T15:41:31,306][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[sample1][0]] ...]).
[2018-03-18T15:41:54,955][WARN ][o.c.e.i.s.IndexingProxyService] [Node 1] Cluster service was timeouted.
[2018-03-18T15:41:54,967][INFO ][o.e.c.m.MetaDataCreateIndexService] [Node 1] [.idxproxy] creating index, cause [api], templates [], shards [1]/[1], mappings [config]
[2018-03-18T15:41:55,551][INFO ][o.e.c.r.a.AllocationService] [Node 1] Cluster health status changed from [YELLOW] to [GREEN] (reason: [shards started [[.idxproxy][0]] ...]).
[2018-03-18T15:41:56,017][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy2722689286675571661/0000000000000000001.tmp
[2018-03-18T15:41:57,026][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy2722689286675571661/0000000000000000001.dat
[2018-03-18T15:41:57,027][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Opening　 /tmp/es-idxproxy2722689286675571661/0000000000000000002.tmp
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=2, timed_out=false}
[2018-03-18T15:41:59,042][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] Started RequestSender(sample1) in Node 3
[2018-03-18T15:41:59,043][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexing: /tmp/es-idxproxy2722689286675571661/0000000000000000001.dat
[2018-03-18T15:41:59,055][INFO ][o.e.c.m.MetaDataMappingService] [Node 1] [sample1/ypellMGRTia3JuLFd-oHNw] create_mapping [data]
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[], total=0, max_score=null}, took=4, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}], total=1, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1006, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1007, id=1007}, _id=1007, _score=1.0}], total=2, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1003, id=1003}, _id=1003, _score=1.0}], total=3, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}], total=2, max_score=1.0}, took=5, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1004, id=1004}, _id=1004, _score=1.0}], total=3, max_score=1.0}, took=2, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1001, id=1001}, _id=1001, _score=1.0}], total=3, max_score=1.0}, took=3, timed_out=false}
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1002, id=1002}, _id=1002, _score=1.0}], total=4, max_score=1.0}, took=2, timed_out=false}
[2018-03-18T15:42:07,426][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Indexed:  /tmp/es-idxproxy2722689286675571661/0000000000000000001.dat 12 1286
response: {_shards={total=1, failed=0, successful=1, skipped=0}, hits={hits=[{_index=sample1, _type=data, _source={msg=test 1005, id=1005}, _id=1005, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1306, id=1006}, _id=1006, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1101, id=1001}, _id=1001, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1202, id=1002}, _id=1002, _score=1.0}, {_index=sample1, _type=data, _source={msg=test 1000, id=1000}, _id=1000, _score=1.0}], total=5, max_score=1.0}, took=3, timed_out=false}
[2018-03-18T15:42:12,141][INFO ][o.c.e.i.s.IndexingProxyService] [Node 3] [Sender][sample1] Stopped RequestSender because of working in [Node 2].
[2018-03-18T15:42:13,048][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] Started RequestSender(sample1) in Node 2
[2018-03-18T15:42:13,050][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample1] Indexing: /tmp/es-idxproxy2722689286675571661/0000000000000000001.dat
[2018-03-18T15:42:17,605][INFO ][o.e.n.Node               ] [Node 1] stopping ...
[2018-03-18T15:42:17,622][INFO ][o.e.d.z.ZenDiscovery     ] [Node 3] master_left [{Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:42:17,622][INFO ][o.e.d.z.ZenDiscovery     ] [Node 2] master_left [{Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}], reason [shut_down]
[2018-03-18T15:42:17,623][WARN ][o.e.t.TransportService   ] [Node 1] Transport response handler not found of id [287]
[2018-03-18T15:42:17,624][WARN ][o.e.d.z.ZenDiscovery     ] [Node 3] master left (reason = shut_down), current nodes: nodes: 
   {Node 3}{nRywDU8kRzqHGIjuDngDFA}{xC_yaH0BQbKWBTBO-z3IOg}{127.0.0.1}{127.0.0.1:9303}, local
   {Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302}
   {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:42:17,624][WARN ][o.e.d.z.ZenDiscovery     ] [Node 2] master left (reason = shut_down), current nodes: nodes: 
   {Node 3}{nRywDU8kRzqHGIjuDngDFA}{xC_yaH0BQbKWBTBO-z3IOg}{127.0.0.1}{127.0.0.1:9303}
   {Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302}, local
   {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301}, master

[2018-03-18T15:42:17,642][WARN ][o.e.c.NodeConnectionsService] [Node 3] failed to connect to node {Node 1}{C1xNVdRiTUSELQV0R8oDPw}{rE06GgqQTRqcSu_ZLLW80g}{127.0.0.1}{127.0.0.1:9301} (tried [1] times)
org.elasticsearch.transport.ConnectTransportException: [Node 1][127.0.0.1:9301] connect_timeout[30s]
	at org.elasticsearch.transport.netty4.Netty4Transport.connectToChannels(Netty4Transport.java:363) ~[transport-netty4-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.openConnection(TcpTransport.java:570) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TcpTransport.connectToNode(TcpTransport.java:473) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:342) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService.connectToNode(TransportService.java:329) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService.validateAndConnectIfNeeded(NodeConnectionsService.java:154) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.NodeConnectionsService$1.doRun(NodeConnectionsService.java:107) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) [elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: 127.0.0.1/127.0.0.1:9301
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_121]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_121]
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:352) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:340) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:632) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:579) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:496) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	... 1 more
[2018-03-18T15:42:17,674][INFO ][o.e.n.Node               ] [Node 1] stopped
[2018-03-18T15:42:17,675][INFO ][o.e.n.Node               ] [Node 1] closing ...
[2018-03-18T15:42:17,676][INFO ][o.c.e.i.s.IndexingProxyService] [Node 1] [Writer] Finalized /tmp/es-idxproxy2722689286675571661/0000000000000000002.dat
[2018-03-18T15:42:17,683][INFO ][o.e.n.Node               ] [Node 1] closed
[2018-03-18T15:42:17,683][INFO ][o.e.n.Node               ] [Node 2] stopping ...
[2018-03-18T15:42:17,695][WARN ][o.e.a.b.TransportShardBulkAction] [Node 3] [[sample1][0]] failed to perform indices:data/write/bulk[s] on replica [sample1][0], node[3Nv4OkFUR2mGTuqZ6XLn7A], [R], s[STARTED], a[id=mD9cjiXtR1Cjp1z4fgBvIw]
org.elasticsearch.transport.NodeDisconnectedException: [Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected
[2018-03-18T15:42:17,697][WARN ][o.e.c.a.s.ShardStateAction] [Node 3] [sample1][0] no master known for action [internal:cluster/shard/failure] for shard entry [shard id [[sample1][0]], allocation id [mD9cjiXtR1Cjp1z4fgBvIw], primary term [1], message [failed to perform indices:data/write/bulk[s] on replica [sample1][0], node[3Nv4OkFUR2mGTuqZ6XLn7A], [R], s[STARTED], a[id=mD9cjiXtR1Cjp1z4fgBvIw]], failure [NodeDisconnectedException[[Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected]]]
[2018-03-18T15:42:17,701][ERROR][o.c.e.i.s.IndexingProxyService] [Node 2] [Sender][sample1][4] Failed to index [sample1][data][1003]
org.elasticsearch.node.NodeClosedException: node closed {Node 2}{3Nv4OkFUR2mGTuqZ6XLn7A}{G1YWfXs9RoK2ffaMWpJovg}{127.0.0.1}{127.0.0.1:9302}
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$2.onClusterServiceClose(TransportBulkAction.java:426) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onClusterServiceClose(ClusterStateObserver.java:304) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:224) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.service.ClusterService.addTimeoutListener(ClusterService.java:386) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:166) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.retry(TransportBulkAction.java:417) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.handleBlockExceptions(TransportBulkAction.java:400) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:280) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:474) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:171) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:85) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:408) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:80) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.executeIndexRequest(RequestSender.java:412) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.lambda$executeIndexRequest$24(RequestSender.java:431) ~[classes/:?]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.onFailure(TransportBulkAction.java:274) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$2.onClusterServiceClose(TransportBulkAction.java:426) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onClusterServiceClose(ClusterStateObserver.java:304) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:224) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.service.ClusterService.addTimeoutListener(ClusterService.java:386) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:166) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.retry(TransportBulkAction.java:417) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.handleBlockExceptions(TransportBulkAction.java:400) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:280) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:474) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:171) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:85) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:408) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:80) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.executeIndexRequest(RequestSender.java:412) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.lambda$executeIndexRequest$24(RequestSender.java:431) ~[classes/:?]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.onFailure(TransportBulkAction.java:274) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$2.onClusterServiceClose(TransportBulkAction.java:426) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onClusterServiceClose(ClusterStateObserver.java:304) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:224) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.service.ClusterService.addTimeoutListener(ClusterService.java:386) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:166) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.retry(TransportBulkAction.java:417) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.handleBlockExceptions(TransportBulkAction.java:400) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:280) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:474) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:171) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:85) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:408) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:80) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.executeIndexRequest(RequestSender.java:412) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.lambda$executeIndexRequest$24(RequestSender.java:431) ~[classes/:?]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.onFailure(TransportBulkAction.java:274) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$2.onClusterServiceClose(TransportBulkAction.java:426) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onClusterServiceClose(ClusterStateObserver.java:304) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:224) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.service.ClusterService.addTimeoutListener(ClusterService.java:386) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:166) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.retry(TransportBulkAction.java:417) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.handleBlockExceptions(TransportBulkAction.java:400) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation.doRun(TransportBulkAction.java:280) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.executeBulk(TransportBulkAction.java:474) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:171) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction.doExecute(TransportBulkAction.java:85) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:69) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.doExecute(TransportSingleItemBulkWriteAction.java:44) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:170) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.action.ProxyActionFilter.apply(ProxyActionFilter.java:201) ~[classes/:?]
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:168) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:142) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:84) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.executeLocally(NodeClient.java:83) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:72) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:408) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:80) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.executeIndexRequest(RequestSender.java:412) ~[classes/:?]
	at org.codelibs.elasticsearch.idxproxy.sender.RequestSender.lambda$executeIndexRequest$24(RequestSender.java:431) ~[classes/:?]
	at org.elasticsearch.action.ActionListener$1.onFailure(ActionListener.java:67) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportSingleItemBulkWriteAction.lambda$wrapBulkResponse$0(TransportSingleItemBulkWriteAction.java:118) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.ActionListener$1.onResponse(ActionListener.java:59) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.finishHim(TransportBulkAction.java:389) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.bulk.TransportBulkAction$BulkOperation$1.onFailure(TransportBulkAction.java:384) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.TransportAction$1.onFailure(TransportAction.java:94) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.finishAsFailed(TransportReplicationAction.java:857) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onClusterServiceClose(TransportReplicationAction.java:840) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onClusterServiceClose(ClusterStateObserver.java:304) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.onClose(ClusterStateObserver.java:224) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.service.ClusterService.addTimeoutListener(ClusterService.java:386) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:166) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retry(TransportReplicationAction.java:832) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.handleBlockException(TransportReplicationAction.java:772) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.handleBlockExceptions(TransportReplicationAction.java:754) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.doRun(TransportReplicationAction.java:660) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$2.onNewClusterState(TransportReplicationAction.java:835) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver$ContextPreservingListener.onNewClusterState(ClusterStateObserver.java:297) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:159) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:111) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.cluster.ClusterStateObserver.waitForNextChange(ClusterStateObserver.java:103) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase.retry(TransportReplicationAction.java:832) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.action.support.replication.TransportReplicationAction$ReroutePhase$1.handleException(TransportReplicationAction.java:810) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1077) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.transport.TransportService$Adapter.lambda$onConnectionClosed$6(TransportService.java:903) ~[elasticsearch-5.6.7.jar:5.6.7]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.7.jar:5.6.7]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]
[2018-03-18T15:42:17,711][INFO ][o.c.e.i.s.IndexingProxyService] [Node 2] Saving /tmp/es-idxproxy2722689286675571661/0000000000000000005_4.err
[2018-03-18T15:42:17,742][INFO ][o.e.n.Node               ] [Node 2] stopped
[2018-03-18T15:42:17,742][INFO ][o.e.n.Node               ] [Node 2] closing ...
[2018-03-18T15:42:17,747][INFO ][o.e.n.Node               ] [Node 2] closed
[2018-03-18T15:42:17,747][INFO ][o.e.n.Node               ] [Node 3] stopping ...
[2018-03-18T15:42:17,757][WARN ][o.e.c.a.s.ShardStateAction] [Node 3] [sample1][0] node closed while execution action [internal:cluster/shard/failure] for shard entry [shard id [[sample1][0]], allocation id [mD9cjiXtR1Cjp1z4fgBvIw], primary term [1], message [failed to perform indices:data/write/bulk[s] on replica [sample1][0], node[3Nv4OkFUR2mGTuqZ6XLn7A], [R], s[STARTED], a[id=mD9cjiXtR1Cjp1z4fgBvIw]], failure [NodeDisconnectedException[[Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected]]]
org.elasticsearch.transport.NodeDisconnectedException: [Node 2][127.0.0.1:9302][indices:data/write/bulk[s][r]] disconnected
[2018-03-18T15:42:17,786][WARN ][o.e.t.TransportService   ] [Node 3] Transport response handler not found of id [156]
[2018-03-18T15:42:17,791][INFO ][o.e.n.Node               ] [Node 3] stopped
[2018-03-18T15:42:17,791][INFO ][o.e.n.Node               ] [Node 3] closing ...
[2018-03-18T15:42:17,796][INFO ][o.e.n.Node               ] [Node 3] closed
Closed all nodes.
Deleted /tmp/es-cluster7878617533358675965
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 362.99 sec <<< FAILURE! - in org.codelibs.elasticsearch.idxproxy.IndexingProxyPluginTest
test_switchnodes(org.codelibs.elasticsearch.idxproxy.IndexingProxyPluginTest)  Time elapsed: 88.264 sec  <<< ERROR!
org.codelibs.elasticsearch.runner.ClusterRunnerException: 
ensureYellow timed out, cluster state:

cluster uuid: a9HRduiUS4uQ21Qh7AElfg
version: 12
state uuid: GH0sRcOnRACbQMdZpLuU2Q
from_diff: false
meta data version: 8
   [.idxproxy/n46ZL-xUQUOY21HsuAZYjA]: v[4]
      0: p_term [2], isa_ids [llX76Mn0Q4-xVoeDFLjxow]
   [sample1/JVbWeIbhQ4iV31rxMZjegw]: v[5]
      0: p_term [1], isa_ids [tdCzKjuRTBugOtd9aQSH4A]
nodes: 
   {Node 1}{l0sCHkvPSNSu9o3eHlWhJA}{INehSNVjRYuM1LS0vvL6GA}{127.0.0.1}{127.0.0.1:9301}, local, master
   {Node 3}{i-N4R-fvROmH6tnPvw7Bvw}{Fo8-0hezQAujCp5dwQuF4g}{127.0.0.1}{127.0.0.1:9303}
routing_table (version 7):
-- index [[.idxproxy/n46ZL-xUQUOY21HsuAZYjA]]
----shard_id [.idxproxy][0]
--------[.idxproxy][0], node[null], [P], recovery_source[existing recovery], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2018-03-18T14:37:11.910Z], delayed=true, details[node_left[oPbqV5mLQimtK2qPpcGQSw]], allocation_status[no_valid_shard_copy]]
--------[.idxproxy][0], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2018-03-18T14:36:51.097Z], delayed=false, allocation_status[no_attempt]]

-- index [[sample1/JVbWeIbhQ4iV31rxMZjegw]]
----shard_id [sample1][0]
--------[sample1][0], node[l0sCHkvPSNSu9o3eHlWhJA], [P], s[STARTED], a[id=tdCzKjuRTBugOtd9aQSH4A]
--------[sample1][0], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2018-03-18T14:36:27.677Z], delayed=false, allocation_status[no_attempt]]

routing_nodes:
-----node_id[l0sCHkvPSNSu9o3eHlWhJA][V]
--------[sample1][0], node[l0sCHkvPSNSu9o3eHlWhJA], [P], s[STARTED], a[id=tdCzKjuRTBugOtd9aQSH4A]
-----node_id[i-N4R-fvROmH6tnPvw7Bvw][V]
---- unassigned
--------[.idxproxy][0], node[null], [P], recovery_source[existing recovery], s[UNASSIGNED], unassigned_info[[reason=NODE_LEFT], at[2018-03-18T14:37:11.910Z], delayed=true, details[node_left[oPbqV5mLQimtK2qPpcGQSw]], allocation_status[no_valid_shard_copy]]
--------[.idxproxy][0], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2018-03-18T14:36:51.097Z], delayed=false, allocation_status[no_attempt]]
--------[sample1][0], node[null], [R], recovery_source[peer recovery], s[UNASSIGNED], unassigned_info[[reason=INDEX_CREATED], at[2018-03-18T14:36:27.677Z], delayed=false, allocation_status[no_attempt]]

tasks: (0):

	at org.codelibs.elasticsearch.idxproxy.IndexingProxyPluginTest.test_switchnodes(IndexingProxyPluginTest.java:435)


Results :

Tests in error: 
  IndexingProxyPluginTest.test_switchnodes:435 » ClusterRunner ensureYellow time...

Tests run: 7, Failures: 0, Errors: 1, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 06:05 min
[INFO] Finished at: 2018-03-18T15:42:18+01:00
[INFO] Final Memory: 25M/947M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19.1:test (default-test) on project elasticsearch-indexing-proxy: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/codelibs/elasticsearch-indexing-proxy/355015092/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
