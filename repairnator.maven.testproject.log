[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Singularity
[INFO] SingularityBase
[INFO] SingularityUI
[INFO] SingularityMesosClient
[INFO] SingularitySwagger
[INFO] SingularityService
[INFO] SingularityRunnerBase
[INFO] SingularityS3Base
[INFO] SingularityClient
[INFO] SingularityExecutor
[INFO] SingularityExecutorCleanup
[INFO] SingularityS3Uploader
[INFO] SingularityS3Downloader
[INFO] EmbedSingularityExample
[INFO] SingularityServiceIntegrationTests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Singularity 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ Singularity ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ Singularity ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ Singularity ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ Singularity ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ Singularity ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ Singularity ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ Singularity ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/target/jacoco.exec
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/RequestCleanupType.java:12:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/SlaveMatchState.java:18:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/TaskCleanupType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/RequestType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/HealthcheckProtocol.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/RequestState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/java/com/hubspot/singularity/DeployState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/SingularityBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityUI 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityUI ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityUI ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityUI ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityUI ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityUI ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityUI ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityUI ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/SingularityUI/target/jacoco.exec
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:install-node-and-npm (install node and npm) @ SingularityUI ---
[INFO] Node v6.2.1 is already installed.
[INFO] Found NPM version 3.9.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm install) @ SingularityUI ---
[INFO] Running 'npm install --color=false' in /root/workspace/HubSpot/Singularity/329502843/SingularityUI
[ERROR] npm WARN optional Skipping failed optional dependency /chokidar/fsevents:
[ERROR] npm WARN notsup Not compatible with your operating system or architecture: fsevents@1.1.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm test) @ SingularityUI ---
[INFO] Running 'npm test --color=false' in /root/workspace/HubSpot/Singularity/329502843/SingularityUI
[INFO] 
[INFO] > SingularityUI@0.3.0 test /root/workspace/HubSpot/Singularity/329502843/SingularityUI
[INFO] > mocha --compilers js:babel-core/register test/index.test
[INFO] 
[ERROR] Warning: Accessing PropTypes via the main React package is deprecated, and will be removed in  React v16.0. Use the latest available v15.* prop-types package from npm instead. For info on usage, compatibility, migration and more, see https://fb.me/prop-types-docs
[INFO] 
[INFO] 
[INFO]   Utils
[INFO]     getTaskDataFromTaskId()
[INFO]       âœ“ should grab all fields from a valid task id
[INFO] 
[INFO]   Reducers
[INFO]     tailerView
[INFO]       âœ“ should be properly initialized
[INFO]       âœ“ should populate the tailerId field
[INFO]       âœ“ should auto-populate the requestIds, taskIds, and paths fields
[INFO]       âœ“ should add tailer groups
[INFO]       âœ“ should remove tailer groups
[INFO]       âœ“ should pick an individual tailer group
[INFO] 
[INFO] 
[INFO]   7 passing (40ms)
[INFO] 
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:gulp (gulp build) @ SingularityUI ---
[INFO] Running 'gulp build --no-color' in /root/workspace/HubSpot/Singularity/329502843/SingularityUI
[INFO] [16:29:39] Using gulpfile ~/workspace/HubSpot/Singularity/329502843/SingularityUI/gulpfile.js
[INFO] [16:29:39] Starting 'clean'...
[INFO] [16:29:39] Finished 'clean' after 82 ms
[INFO] [16:29:39] Starting 'static'...
[INFO] [16:29:39] Finished 'static' after 103 ms
[INFO] [16:29:39] Starting 'html'...
[INFO] [16:29:40] Finished 'html' after 31 ms
[INFO] [16:29:40] Starting 'build'...
[INFO] [16:32:13] Version: webpack [1m1.13.1[22m
[INFO] Time: [1m151528[22mms
[INFO]                                [1mAsset[22m     [1mSize[22m  [1mChunks[22m  [1m[22m           [1mChunk Names[22m
[INFO] [1m[32m89889688147bd7575d6327160d64e760.svg[39m[22m   109 kB        [1m[22m  [1m[32m[emitted][39m[22m  
[INFO]                  [1m[32mjs/vendor.bundle.js[39m[22m   622 kB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                     [1m[32mjs/app.bundle.js[39m[22m  2.21 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                          [1m[32mcss/app.css[39m[22m   350 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]              [1m[32mjs/vendor.bundle.js.map[39m[22m  4.64 MB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                 [1m[32mjs/app.bundle.js.map[39m[22m  10.5 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                      [1m[32mcss/app.css.map[39m[22m   419 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] [16:32:13] Finished 'build' after 2.55 min
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-index.html-template) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-ui) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 17 resources
[INFO] 
[INFO] --- build-helper-maven-plugin:1.10:add-resource (add-generated-resources) @ SingularityUI ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityUI/src/main/resources
[INFO] Copying 18 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityUI/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityUI ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityMesosClient 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityMesosClient ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityMesosClient ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:29:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:31:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:33:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:35:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:37:3: Redundant 'public' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityMesosClient ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityMesosClient ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityMesosClient ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularityMesosClient/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityMesosClient ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityMesosClient ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularitySwagger 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularitySwagger ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularitySwagger ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularitySwagger ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularitySwagger ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/SingularitySwagger/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularitySwagger/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularitySwagger ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/329502843/SingularitySwagger/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularitySwagger ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularitySwagger ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityService 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityService ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityService ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityService ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityService ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/hooks/LoadBalancerClientImpl.java:114:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:18:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:20:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:22:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:24:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:26:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:175:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:224:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:249:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:289:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:315:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/config/UIConfiguration.java:22:10: Redundant 'static' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorManager.java:64:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityCmdLineArgsMigration.java:57:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:84:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:139:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/history/SingularityHistoryModule.java:126:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorAsyncManager.java:46:5: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/329502843/SingularityService/src/main/java/com/hubspot/singularity/smtp/SmtpMailer.java:370:5: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityService ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityService ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityService ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/329502843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/329502843/SingularityService/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- swagger-maven-plugin:2.3.2:generate (build-embedded-documentation) @ SingularityService ---
[INFO] Reflections took 81 ms to scan 1 urls, producing 12 keys and 79 values 
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TestResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskTrackerResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DisastersResource
[INFO] Detect Resource:com.hubspot.singularity.resources.SandboxResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.SlaveResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.S3LogResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RackResource
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.HistoryResource
[INFO] Detect Resource:com.hubspot.singularity.resources.StateResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.PriorityResource
[INFO] Detect Resource:com.hubspot.singularity.resources.InactiveSlaveResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UsageResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.WebhookResource
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestResource
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DeployResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UserResource
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestGroupResource
[INFO] Writing doc to /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/index.html...
[INFO] Done!
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/service.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_tasks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_test.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_track.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_disasters.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_sandbox.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_slaves.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_logs.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_racks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_history.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_state.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_priority.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_inactive.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_usage.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_webhooks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_requests.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_deploys.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_users.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/classes/assets/api-docs/api_groups.json
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityService ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom (4 KB at 6.9 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom (3 KB at 113.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar (75 KB at 1042.4 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hubspot.singularity.scheduler.SingularityHealthchecksTest
Running com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
Running com.hubspot.singularity.mesos.SingularityStartupTest
Running com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
Running com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.data.BlendedHistoryTest
Running com.hubspot.singularity.data.InactiveSlaveManagerTest
16:32:55.426 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 681394938)
16:32:55.538 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:32:56.644 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 574925565)
16:32:56.788 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:32:56.866 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 932450261)
16:32:56.957 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:32:57.198 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 446889718)
16:32:57.299 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:32:57.508 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1781611294)
16:32:57.653 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:32:58.622 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 477520748)
16:32:58.784 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.933 sec - in com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.SingularityAuthorizationHelperTest
16:33:02.358 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:02.373 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @12024ms
16:33:02.510 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@838a35e
16:33:02.604 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@38fbefe9{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5738ef21,MANAGED}
16:33:02.608 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@5a38c2d7
16:33:02.609 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@118d63b4{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@3c7e9510,MANAGED}
16:33:02.789 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@3c7e9510 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:02.803 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@3c7e9510 added {[/tasks/*]=>tasks,POJO}
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 9.959 sec - in com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
16:33:03.288 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:03.301 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @12950ms
16:33:03.441 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@377887e4
16:33:03.509 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7e6203b0{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7668eb4,MANAGED}
16:33:03.521 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@142c71a0
16:33:03.521 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@73ce3c02{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@41275a48,MANAGED}
16:33:03.690 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@41275a48 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:03.720 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@41275a48 added {[/tasks/*]=>tasks,POJO}
16:33:03.788 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:03.792 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:03.814 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13445ms
16:33:03.823 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13442ms
16:33:03.996 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@43c3092c
16:33:03.985 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@31e79c73
16:33:04.103 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:04.113 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@1e595351{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@61c1759b,MANAGED}
16:33:04.120 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7f146e49{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@663b6647,MANAGED}
16:33:04.131 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@760a5e48
16:33:04.136 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13731ms
16:33:04.138 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3cda7f8d
16:33:04.138 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@6e24ece0{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@69add6a4,MANAGED}
16:33:04.158 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@49b3d43c{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@495e506f,MANAGED}
16:33:04.125 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1847560617)
16:33:04.204 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:33:04.270 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3f6c2d27
16:33:04.338 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@746e92cb{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@566e071f,MANAGED}
16:33:04.352 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@495e506f added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:04.358 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@50927dfa
16:33:04.358 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@14981430{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2e1a8969,MANAGED}
16:33:04.396 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@495e506f added {[/tasks/*]=>tasks,POJO}
16:33:04.440 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@69add6a4 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:04.459 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@69add6a4 added {[/tasks/*]=>tasks,POJO}
16:33:04.582 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2e1a8969 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:04.592 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2e1a8969 added {[/tasks/*]=>tasks,POJO}
16:33:04.708 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:04.732 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14322ms
16:33:04.910 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3a3980aa
16:33:05.044 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@70b03a82{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@3f4fcecd,MANAGED}
16:33:05.050 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1bc5ee4e
16:33:05.051 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@53eff1f7{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@1f6e0c22,MANAGED}
16:33:05.267 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:05.312 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14946ms
16:33:05.323 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1f6e0c22 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:05.360 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1f6e0c22 added {[/tasks/*]=>tasks,POJO}
16:33:05.459 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6250b311
16:33:05.567 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@15083e4{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@61f72768,MANAGED}
16:33:05.586 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@78b936ed
16:33:05.587 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@195e5599{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@335ed1,MANAGED}
16:33:05.835 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@335ed1 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:05.865 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@335ed1 added {[/tasks/*]=>tasks,POJO}
Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.976 sec - in com.hubspot.singularity.SingularityAuthorizationHelperTest
Running com.hubspot.singularity.scheduler.SingularityUsageTest
16:33:13.724 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 2082361213)
16:33:13.766 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
16:33:17.753 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
16:33:17.791 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @27441ms
16:33:17.894 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1ece6ec8
16:33:17.919 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@70f750e{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@53ec2c1c,MANAGED}
16:33:17.927 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6e6b7519
16:33:17.927 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@6a3d24de{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7be97f52,MANAGED}
16:33:18.063 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7be97f52 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
16:33:18.079 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7be97f52 added {[/tasks/*]=>tasks,POJO}
16:33:25.743 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:25.880 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 31.627 sec <<< FAILURE! - in com.hubspot.singularity.data.BlendedHistoryTest
testBlendedRequestHistory(com.hubspot.singularity.data.BlendedHistoryTest)  Time elapsed: 30.044 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
16:33:26.370 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:26.881 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:26.883 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:27.169 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:27.781 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:27.833 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:28.337 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:28.546 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:29.406 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120408008-1-host1-rack1'}), timestamp=Optional.of(1.516120408E9)}), taskId=test-request-firstDeployId-1516120408008-1-host1-rack1, serverTimestamp=1516120409229, serverId='2d9730d1-7a28-4cb0-bf61-b3e4c11b5461', slaveId=Optional.absent()}
16:33:30.130 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r1-d1-23-3-BOUNCE-1, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
16:33:30.149 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120408008-1-host1-rack1
16:33:30.162 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
16:33:30.201 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r2-d3-231-1-UNPAUSED-23, cmdLineArgsList=Optional.of([cmd line args]), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120408008-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120408008-1-host1-rack1, serverTimestamp=1516120410118, serverId='2d9730d1-7a28-4cb0-bf61-b3e4c11b5461', slaveId=Optional.absent()}
16:33:30.287 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:30.368 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r2-de, already correct
16:33:30.370 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r1-d1, already correct
16:33:30.370 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 0 requests in 00:00.083
16:33:30.492 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:49251] WARN org.apache.zookeeper.server.NIOServerCnxnFactory - Ignoring unexpected runtime exception
java.nio.channels.CancelledKeyException: null
	at sun.nio.ch.SelectionKeyImpl.ensureValid(SelectionKeyImpl.java:73)
	at sun.nio.ch.SelectionKeyImpl.readyOps(SelectionKeyImpl.java:87)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:187)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120408838-1-host1-rack1'}), timestamp=Optional.of(1.516120408E9)}), taskId=test-request-firstDeployId-1516120408838-1-host1-rack1, serverTimestamp=1516120410014, serverId='71175675-e58f-49db-a70d-9df7e1b82c24', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120410907-1-host1-rack1'}), timestamp=Optional.of(1.51612041E9)}), taskId=test-request-firstDeployId-1516120410907-1-host1-rack1, serverTimestamp=1516120410982, serverId='71175675-e58f-49db-a70d-9df7e1b82c24', slaveId=Optional.absent()}
16:33:31.100 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:31.211 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120408838-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120408838-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120408838-1-host1-rack1, serverTimestamp=1516120411178, serverId='71175675-e58f-49db-a70d-9df7e1b82c24', slaveId=Optional.absent()}
16:33:31.371 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.465 sec - in com.hubspot.singularity.data.InactiveSlaveManagerTest
Running com.hubspot.singularity.SingularityS3Test
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.033 sec - in com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.data.ValidatorTest
[oneOffRequest-oneOffDeploy1516120412103, immediateRequest-immediateDeploy, newDeployRequest-newDeploy]
16:33:32.215 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:32.219 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path oneOffRequest-oneOffDeploy1516120412103, already correct
16:33:32.221 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Rewriting path immediateRequest-immediateDeploy to immediateRequest-immediateDeploy1516120412103
16:33:32.235 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path newDeployRequest-newDeploy, already correct
16:33:32.236 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 1 requests in 00:00.020
[oneOffRequest-oneOffDeploy1516120412103, immediateRequest-immediateDeploy1516120412103, newDeployRequest-newDeploy]
16:33:32.291 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:32.481 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 39.43 sec <<< FAILURE! - in com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
testMigrationRunner(com.hubspot.singularity.data.zkmigrations.ZkMigrationTest)  Time elapsed: 30.05 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.StateManagerTest
16:33:32.754 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:37281] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd189710000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:33.007 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120410907-1-IMMEDIATE-1516120410907, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer424'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120410907-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:33:33.014 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120410907-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:33.019 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120410907-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@720bc625 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@56b36bec[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:33.453 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:34.044 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44504] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd18fc70000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:34.067 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:34.150 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:34.303 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:34.651 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:34.949 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:35.017 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415127-1-host1-rack1'}), timestamp=Optional.of(1.516120415E9)}), taskId=test-request-firstDeployId-1516120415127-1-host1-rack1, serverTimestamp=1516120415261, serverId='bd20a798-ab5d-4014-b19b-259cd9b6f5c6', slaveId=Optional.absent()}
16:33:35.842 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415200-1-host1-rack1'}), timestamp=Optional.of(1.516120415E9)}), taskId=test-request-firstDeployId-1516120415200-1-host1-rack1, serverTimestamp=1516120415466, serverId='cfa8437d-9e01-4796-ba56-27b957748d67', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415791-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120415791-1-host1-DEFAULT, serverTimestamp=1516120415877, serverId='bd20a798-ab5d-4014-b19b-259cd9b6f5c6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415127-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120415127-1-host1-rack1, serverTimestamp=1516120415986, serverId='bd20a798-ab5d-4014-b19b-259cd9b6f5c6', slaveId=Optional.absent()}
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.149 sec - in com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
Running com.hubspot.singularity.helpers.RFC5545ScheduleTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.199 sec - in com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.data.SandboxManagerTest
16:33:36.356 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:36.438 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415910-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120415910-1-host1-DEFAULT, serverTimestamp=1516120416396, serverId='127bc0a2-97ba-4fc3-8238-a7d8cec1f549', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120416422-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120416422-1-host1-DEFAULT, serverTimestamp=1516120416658, serverId='cfa8437d-9e01-4796-ba56-27b957748d67', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120416612-4-host1-rack1'}), timestamp=Optional.of(1.516120416E9)}), taskId=test-request-firstDeployId-1516120416612-4-host1-rack1, serverTimestamp=1516120416683, serverId='127bc0a2-97ba-4fc3-8238-a7d8cec1f549', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120416725-5-host1-rack1'}), timestamp=Optional.of(1.516120416E9)}), taskId=test-request-firstDeployId-1516120416725-5-host1-rack1, serverTimestamp=1516120416805, serverId='127bc0a2-97ba-4fc3-8238-a7d8cec1f549', slaveId=Optional.absent()}
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 43.769 sec <<< FAILURE! - in com.hubspot.singularity.mesos.SingularityStartupTest
testScheduledTasksDontGetRescheduledDuringRun(com.hubspot.singularity.mesos.SingularityStartupTest)  Time elapsed: 30.042 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.SingularityHistoryTest
16:33:37.197 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:37.509 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.303 sec - in com.hubspot.singularity.data.StateManagerTest
Running com.hubspot.singularity.config.MergingSourceProviderTest
16:33:38.452 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:38.505 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:39.444 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:39.464 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
16:33:39.720 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120419734-1-host1-rack1'}), timestamp=Optional.of(1.516120419E9)}), taskId=test-request-firstDeployId-1516120419734-1-host1-rack1, serverTimestamp=1516120419809, serverId='a265b3c2-7553-4ce5-a3cf-fea2fe7fb586', slaveId=Optional.absent()}
16:33:39.931 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:39.939 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:40.220 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:40.680 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:40.909 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120415200-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120415200-1-host1-rack1, serverTimestamp=1516120421694, serverId='cfa8437d-9e01-4796-ba56-27b957748d67', slaveId=Optional.absent()}
16:33:42.436 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:42.463 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
16:33:42.486 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:42.541 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:42.790 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120422776-1-host1-rack1'}), timestamp=Optional.of(1.516120422E9)}), taskId=test-request-firstDeployId-1516120422776-1-host1-rack1, serverTimestamp=1516120423030, serverId='0535d2b8-7b72-4017-8b3b-4d1c62064eb5', slaveId=Optional.absent()}
16:33:43.258 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.438 sec - in com.hubspot.singularity.config.MergingSourceProviderTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120423265-2-host1-rack1'}), timestamp=Optional.of(1.516120423E9)}), taskId=test-request-firstDeployId-1516120423265-2-host1-rack1, serverTimestamp=1516120423302, serverId='0535d2b8-7b72-4017-8b3b-4d1c62064eb5', slaveId=Optional.absent()}
Running com.hubspot.singularity.scheduler.SingularitySchedulerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120423333-3-host1-rack1'}), timestamp=Optional.of(1.516120423E9)}), taskId=test-request-firstDeployId-1516120423333-3-host1-rack1, serverTimestamp=1516120423374, serverId='0535d2b8-7b72-4017-8b3b-4d1c62064eb5', slaveId=Optional.absent()}
16:33:43.681 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40157] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1b26c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:43.682 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:43.847 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120423771-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120423771-1-host2-DEFAULT, serverTimestamp=1516120423956, serverId='0535d2b8-7b72-4017-8b3b-4d1c62064eb5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120423333-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120423333-3-host1-rack1, serverTimestamp=1516120423980, serverId='0535d2b8-7b72-4017-8b3b-4d1c62064eb5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120424274-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120424274-1-host1-DEFAULT, serverTimestamp=1516120424373, serverId='f1ed2e82-74e0-4fda-99b0-7e0c2bd43d7b', slaveId=Optional.absent()}
16:33:44.764 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:44.929 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:45.321 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:45.830 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:46.351 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120426452-1-host1-rack1'}), timestamp=Optional.of(1.516120426E9)}), taskId=test-request-firstDeployId-1516120426452-1-host1-rack1, serverTimestamp=1516120426533, serverId='7e24d1c3-9b4d-442a-a135-7abb65817fd5', slaveId=Optional.absent()}
16:33:46.687 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120424274-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:46.694 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120424274-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@51d480ad rejected from java.util.concurrent.ScheduledThreadPoolExecutor@5f1364e7[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120426652-2-host1-rack1'}), timestamp=Optional.of(1.516120426E9)}), taskId=test-request-firstDeployId-1516120426652-2-host1-rack1, serverTimestamp=1516120426686, serverId='7e24d1c3-9b4d-442a-a135-7abb65817fd5', slaveId=Optional.absent()}
16:33:46.742 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:46.755 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120426729-3-host1-rack1'}), timestamp=Optional.of(1.516120426E9)}), taskId=test-request-firstDeployId-1516120426729-3-host1-rack1, serverTimestamp=1516120426766, serverId='7e24d1c3-9b4d-442a-a135-7abb65817fd5', slaveId=Optional.absent()}
16:33:46.852 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120426924-4-host1-rack1'}), timestamp=Optional.of(1.516120426E9)}), taskId=test-request-firstDeployId-1516120426924-4-host1-rack1, serverTimestamp=1516120426968, serverId='7e24d1c3-9b4d-442a-a135-7abb65817fd5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120426652-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120426652-2-host1-rack1, serverTimestamp=1516120427119, serverId='7e24d1c3-9b4d-442a-a135-7abb65817fd5', slaveId=Optional.absent()}
16:33:47.169 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:47.419 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:47.435 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:47.448 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:49742] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1c57e0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.125 sec - in com.hubspot.singularity.data.SandboxManagerTest
Running com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
16:33:47.648 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1516120427687, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1516120427936, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1516120428035, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120427814-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120427814-1-host1-DEFAULT, serverTimestamp=1516120428003, serverId='15d320f6-0cc6-42c6-932f-e284e6376bbc', slaveId=Optional.absent()}
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 54.83 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
testExpiringSkipHealthchecks(com.hubspot.singularity.scheduler.SingularityExpiringActionsTest)  Time elapsed: 30.048 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.scheduler.SingularityExpiringActionsTest.testExpiringSkipHealthchecks(SingularityExpiringActionsTest.java:209)

Running com.hubspot.singularity.scheduler.SingularityDeploysTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1516120428262, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.316 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:48.328 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1516120428335, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120427976-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120427976-2-host1-DEFAULT, serverTimestamp=1516120428343, serverId='5990700a-08fe-40b0-a3b4-04a1d7cc04b2', slaveId=Optional.absent()}
16:33:48.424 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1516120428415, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1516120428305-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1516120428305-1-host1-DEFAULT, serverTimestamp=1516120428365, serverId='15d320f6-0cc6-42c6-932f-e284e6376bbc', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1516120428500, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.524 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1516120428513, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.589 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-2-firstDeployId-15000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1516120428577, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.611 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-2-firstDeployId-35000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1516120428601, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.686 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-2-firstDeployId-25000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1516120428654, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120428745-1-host1-rack1'}), timestamp=Optional.of(1.516120428E9)}), taskId=test-request-firstDeployId-1516120428745-1-host1-rack1, serverTimestamp=1516120428861, serverId='148b3211-4453-4e9d-8745-84f16b9e367b', slaveId=Optional.absent()}
16:33:48.931 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1516120428919, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:48.967 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
16:33:48.968 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1516120428952, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:49.005 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-2-firstDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1516120428995, serverId='0e1fb7b7-2a49-4589-b70b-2acfd348d13b', slaveId=Optional.absent()}
16:33:49.060 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:49.404 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120424056-1-UPDATED_REQUEST-1516120423952, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer876'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120424274-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1516120424274-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:49.408 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120424056-1-UPDATED_REQUEST-1516120423952, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer876'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120424274-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1516120424274-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7f80a502 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7bbf2e2a[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Max healthcheck time cannot be greater than 100, (was startup timeout: 50, interval: 5, attempts: 10)
16:33:49.878 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:49.958 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:50.060 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120429300-1-host1-rack1'}), timestamp=Optional.of(1.516120429E9)}), taskId=test-request-firstDeployId-1516120429300-1-host1-rack1, serverTimestamp=1516120430048, serverId='f63e4499-df84-4649-9bd8-cf1e8972776a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-test_new_request_data-1516120430270-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-test_new_request_data-1516120430270-1-host1-DEFAULT, serverTimestamp=1516120430456, serverId='c7861692-c09b-42e5-897b-7d905659f7ab', slaveId=Optional.absent()}
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 37.451 sec - in com.hubspot.singularity.scheduler.SingularityUsageTest
Running com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120430596-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120430596-1-host1-DEFAULT, serverTimestamp=1516120430815, serverId='e6e2920b-e730-43c1-b45f-b02cd0fad27e', slaveId=Optional.absent()}
16:33:50.970 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120428745-1-IMMEDIATE-1516120428745, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer795'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120428745-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:33:51.074 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120428745-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120428745-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120428745-1-host1-rack1, serverTimestamp=1516120431061, serverId='148b3211-4453-4e9d-8745-84f16b9e367b', slaveId=Optional.absent()}
16:33:51.231 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:51.464 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.123 sec - in com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
Running com.hubspot.singularity.scheduler.SingularityMachineStatesTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120431772-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120431772-1-host2-DEFAULT, serverTimestamp=1516120431890, serverId='d0b8ec18-7fad-4bef-b18f-7d921c458190', slaveId=Optional.absent()}
16:33:52.117 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:50057] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1d2a00000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:52.279 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:52.497 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120432813-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120432813-1-host1-DEFAULT, serverTimestamp=1516120432932, serverId='8f02ac5b-5b05-4ca5-bd40-60f96e69191d', slaveId=Optional.absent()}
16:33:53.111 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60670] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1da860000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:53.140 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:53.199 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120433247-1-host1-rack1'}), timestamp=Optional.of(1.516120433E9)}), taskId=test-request-firstDeployId-1516120433247-1-host1-rack1, serverTimestamp=1516120433344, serverId='e33afeb2-e8f8-4919-9f11-d453140428fe', slaveId=Optional.absent()}
16:33:53.571 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:53.574 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120433247-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120433247-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120433247-1-host1-rack1, serverTimestamp=1516120433564, serverId='e33afeb2-e8f8-4919-9f11-d453140428fe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1516120433756, serverId='21d2f774-6d9b-4c1e-970c-1de5f1a98029', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1516120433851, serverId='21d2f774-6d9b-4c1e-970c-1de5f1a98029', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1516120433907, serverId='21d2f774-6d9b-4c1e-970c-1de5f1a98029', slaveId=Optional.absent()}
16:33:53.954 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40492] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1de1f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:33:54.067 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:54.102 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:54.408 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434209-1-host1-rack1'}), timestamp=Optional.of(1.516120434E9)}), taskId=test-request-firstDeployId-1516120434209-1-host1-rack1, serverTimestamp=1516120434339, serverId='097d43b3-fa37-4205-8f92-d505067ae611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434336-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120434336-1-host1-DEFAULT, serverTimestamp=1516120434520, serverId='19405674-4977-4884-bb6e-82d820ceb8cd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434451-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120434451-2-host2-DEFAULT, serverTimestamp=1516120434553, serverId='19405674-4977-4884-bb6e-82d820ceb8cd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434677-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120434677-1-host2-DEFAULT, serverTimestamp=1516120434757, serverId='19405674-4977-4884-bb6e-82d820ceb8cd', slaveId=Optional.absent()}
16:33:54.819 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434746-1-host1-rack1'}), timestamp=Optional.of(1.516120434E9)}), taskId=test-request-firstDeployId-1516120434746-1-host1-rack1, serverTimestamp=1516120434847, serverId='097d43b3-fa37-4205-8f92-d505067ae611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434336-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120434336-1-host1-DEFAULT, serverTimestamp=1516120434825, serverId='19405674-4977-4884-bb6e-82d820ceb8cd', slaveId=Optional.absent()}
16:33:54.951 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:54.999 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120432813-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:55.000 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120432813-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@79913778 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7756c63a[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120434935-1-host1-rack1'}), timestamp=Optional.of(1.516120434E9)}), taskId=test-request-firstDeployId-1516120434935-1-host1-rack1, serverTimestamp=1516120435049, serverId='41d0808a-d28c-49b6-8a01-555d8be6a41d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120435115-2-host1-rack1'}), timestamp=Optional.of(1.516120435E9)}), taskId=test-request-firstDeployId-1516120435115-2-host1-rack1, serverTimestamp=1516120435146, serverId='41d0808a-d28c-49b6-8a01-555d8be6a41d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120435157-3-host1-rack1'}), timestamp=Optional.of(1.516120435E9)}), taskId=test-request-firstDeployId-1516120435157-3-host1-rack1, serverTimestamp=1516120435189, serverId='41d0808a-d28c-49b6-8a01-555d8be6a41d', slaveId=Optional.absent()}
16:33:55.233 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:33:55.238 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120435140-1-host1-rack1
16:33:55.253 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120435115-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120435140-1-host1-rack1'}), timestamp=Optional.of(1.516120435E9)}), taskId=test-request-firstDeployId-1516120435140-1-host1-rack1, serverTimestamp=1516120435223, serverId='6c8b3494-bfea-41dc-bfa0-9bc4885bedb5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120435115-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120435115-2-host1-rack1, serverTimestamp=1516120435246, serverId='41d0808a-d28c-49b6-8a01-555d8be6a41d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120435287-1-host1-rack1'}), timestamp=Optional.of(1.516120435E9)}), taskId=test-request-firstDeployId-1516120435287-1-host1-rack1, serverTimestamp=1516120435326, serverId='6c8b3494-bfea-41dc-bfa0-9bc4885bedb5', slaveId=Optional.absent()}
16:33:55.495 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
16:33:55.983 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.524 sec - in com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
Running com.hubspot.singularity.scheduler.HistoryPersisterTest
16:33:56.251 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:56.470 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120436361-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120436361-2-host2-DEFAULT, serverTimestamp=1516120436473, serverId='62025e40-45d0-47c9-acad-3bb4ab90031a', slaveId=Optional.absent()}
16:33:56.626 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:53802] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1e8830000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 53.611 sec - in com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120436455-1-host1-rack1'}), timestamp=Optional.of(1.516120256E9)}), taskId=test-request-firstDeployId-1516120436455-1-host1-rack1, serverTimestamp=1516120436617, serverId='080936bd-572b-4a51-bd74-ecd0517a2aff', slaveId=Optional.absent()}
16:33:56.780 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120436455-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120436455-1-host1-rack1'}), timestamp=Optional.of(1.516120316E9)}), taskId=test-request-firstDeployId-1516120436455-1-host1-rack1, serverTimestamp=1516120436769, serverId='080936bd-572b-4a51-bd74-ecd0517a2aff', slaveId=Optional.absent()}
16:33:56.855 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-new_task_healthcheck-1516120436627-1-host1-rack1'}), timestamp=Optional.of(1.516120436E9)}), taskId=test-request-new_task_healthcheck-1516120436627-1-host1-rack1, serverTimestamp=1516120436745, serverId='a5169199-0720-4b17-af23-f5bb0a20a7a4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120436952-1-host1-rack1'}), timestamp=Optional.of(1.516120436E9)}), taskId=test-request-firstDeployId-1516120436952-1-host1-rack1, serverTimestamp=1516120437028, serverId='e3b1c57d-b028-42ff-ba08-1f6ddd3c40b2', slaveId=Optional.absent()}
16:33:57.232 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120437264-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120437264-1-host2-DEFAULT, serverTimestamp=1516120437299, serverId='e3b1c57d-b028-42ff-ba08-1f6ddd3c40b2', slaveId=Optional.absent()}
16:33:57.346 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

16:33:57.458 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

16:33:57.474 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

16:33:57.558 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:57.943 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120432732-1-UPDATED_REQUEST-1516120432673, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer592'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120432813-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=0.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1516120432813-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:57.946 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120432732-1-UPDATED_REQUEST-1516120432673, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer592'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120432813-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=0.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1516120432813-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4e3e5c7 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@dc6183[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:58.030 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:33:58.034 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:58.174 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:33:58.232 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638338-1-host1-rack1'}), timestamp=Optional.of(1.516120438E9)}), taskId=test-request-firstDeployId-1516109638338-1-host1-rack1, serverTimestamp=1516120438449, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:58.552 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109638338-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638338-1-host1-rack1'}), timestamp=Optional.of(1.516113238E9)}), taskId=test-request-firstDeployId-1516109638338-1-host1-rack1, serverTimestamp=1516120438543, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638598-1-host1-rack1'}), timestamp=Optional.of(1.516120438E9)}), taskId=test-request-firstDeployId-1516109638598-1-host1-rack1, serverTimestamp=1516120438655, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:58.700 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109638598-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638598-1-host1-rack1'}), timestamp=Optional.of(1.516113238E9)}), taskId=test-request-firstDeployId-1516109638598-1-host1-rack1, serverTimestamp=1516120438670, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638740-1-host1-rack1'}), timestamp=Optional.of(1.516120438E9)}), taskId=test-request-firstDeployId-1516109638740-1-host1-rack1, serverTimestamp=1516120438793, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:58.837 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109638740-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638740-1-host1-rack1'}), timestamp=Optional.of(1.516113238E9)}), taskId=test-request-firstDeployId-1516109638740-1-host1-rack1, serverTimestamp=1516120438821, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:58.873 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='new_task_healthcheck', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.absent(), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-new_task_healthcheck-1516120436627-1-IMMEDIATE-1516120436627, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer293'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-new_task_healthcheck-1516120436627-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:33:58.874 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-new_task_healthcheck-1516120436627-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:33:58.876 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-new_task_healthcheck-1516120436627-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638888-1-host1-rack1'}), timestamp=Optional.of(1.516120438E9)}), taskId=test-request-firstDeployId-1516109638888-1-host1-rack1, serverTimestamp=1516120438937, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:58.960 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109638888-1-host1-rack1
16:33:58.970 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109638888-1-host1-rack1'}), timestamp=Optional.of(1.516113238E9)}), taskId=test-request-firstDeployId-1516109638888-1-host1-rack1, serverTimestamp=1516120438951, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.060 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639023-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639023-1-host1-rack1, serverTimestamp=1516120439100, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.160 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639023-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639023-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639023-1-host1-rack1, serverTimestamp=1516120439131, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639221-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639221-1-host1-rack1, serverTimestamp=1516120439268, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.307 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639221-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639221-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639221-1-host1-rack1, serverTimestamp=1516120439294, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639349-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639349-1-host1-rack1, serverTimestamp=1516120439391, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.441 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639349-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639349-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639349-1-host1-rack1, serverTimestamp=1516120439418, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639483-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639483-1-host1-rack1, serverTimestamp=1516120439529, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.568 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639483-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120439416-1-host2-DEFAULT'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516120439416-1-host2-DEFAULT, serverTimestamp=1516120439547, serverId='9e884bb5-dc61-40a2-a723-6b9fdc952dd5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639483-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639483-1-host1-rack1, serverTimestamp=1516120439541, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639614-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639614-1-host1-rack1, serverTimestamp=1516120439658, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.682 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639614-1-host1-rack1
16:33:59.690 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639614-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639614-1-host1-rack1, serverTimestamp=1516120439675, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639706-1-host1-rack1'}), timestamp=Optional.of(1.516120439E9)}), taskId=test-request-firstDeployId-1516109639706-1-host1-rack1, serverTimestamp=1516120439755, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.803 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109639706-1-host1-rack1
16:33:59.813 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='timeout_test', timestamp=1516116839721, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1516116839721}), updatedRequest=Optional.absent()} is overdue (duration: 01:00:00.092), allowed: 00:01:00.000
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109639706-1-host1-rack1'}), timestamp=Optional.of(1.516113239E9)}), taskId=test-request-firstDeployId-1516109639706-1-host1-rack1, serverTimestamp=1516120439777, serverId='3545822e-be5d-4601-b2ba-70e7138ff82a', slaveId=Optional.absent()}
16:33:59.994 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:56817] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd1ed330000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:00.203 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:00.269 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
16:34:00.281 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:00.369 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-hc_test-1516120440405-1-host1-rack1'}), timestamp=Optional.of(1.51612044E9)}), taskId=test-request-hc_test-1516120440405-1-host1-rack1, serverTimestamp=1516120440472, serverId='4e6ba358-612f-422a-ac36-220fd9e907ad', slaveId=Optional.absent()}
16:34:00.808 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:00.914 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120440900-1-host1-rack1'}), timestamp=Optional.of(1.51612044E9)}), taskId=test-request-firstDeployId-1516120440900-1-host1-rack1, serverTimestamp=1516120440968, serverId='a2a447af-abf4-48ef-94fc-a9c8e63c5783', slaveId=Optional.absent()}
16:34:01.053 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120440900-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120440900-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120440900-1-host1-rack1, serverTimestamp=1516120441043, serverId='a2a447af-abf4-48ef-94fc-a9c8e63c5783', slaveId=Optional.absent()}
16:34:01.197 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120441136-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120441136-1-host1-DEFAULT, serverTimestamp=1516120441296, serverId='a2a447af-abf4-48ef-94fc-a9c8e63c5783', slaveId=Optional.absent()}
16:34:01.424 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120441361-1-host1-rack1'}), timestamp=Optional.of(1.516120441E9)}), taskId=test-request-firstDeployId-1516120441361-1-host1-rack1, serverTimestamp=1516120441444, serverId='e215d866-6273-481c-a036-3b36ca378a9e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120441534-2-host1-rack1'}), timestamp=Optional.of(1.516120441E9)}), taskId=test-request-firstDeployId-1516120441534-2-host1-rack1, serverTimestamp=1516120441581, serverId='e215d866-6273-481c-a036-3b36ca378a9e', slaveId=Optional.absent()}
16:34:01.598 [Time-limited test] WARN com.hubspot.singularity.data.history.SingularityRequestHistoryPersister - Failed to persist SingularityRequestHistory{createdAt=1516109641568, user=Optional.absent(), eventType=CREATED, request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, message=Optional.absent()} into History
java.lang.UnsupportedOperationException: NoopHistoryManager can not save
	at com.hubspot.singularity.data.history.NoopHistoryManager.saveRequestHistoryUpdate(NoopHistoryManager.java:26)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:144)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:26)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurgeAndShouldDelete(SingularityHistoryPersister.java:63)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurge(SingularityHistoryPersister.java:52)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.runActionOnPoll(SingularityRequestHistoryPersister.java:122)
	at com.hubspot.singularity.scheduler.HistoryPersisterTest.testPurgingDoesntApplyIfDatabasePresent(HistoryPersisterTest.java:211)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120441773-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120441773-2-host1-DEFAULT, serverTimestamp=1516120441808, serverId='e215d866-6273-481c-a036-3b36ca378a9e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120441731-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120441731-1-host1-DEFAULT, serverTimestamp=1516120441822, serverId='e215d866-6273-481c-a036-3b36ca378a9e', slaveId=Optional.absent()}
16:34:01.841 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:02.484 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='hc_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-hc_test-1516120440405-1-IMMEDIATE-1516120440405, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer959'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-hc_test-1516120440405-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:02.485 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-hc_test-1516120440405-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:02.487 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-hc_test-1516120440405-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:02.552 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120442625-1-host1-rack1'}), timestamp=Optional.of(1.516120442E9)}), taskId=test-request-firstDeployId-1516120442625-1-host1-rack1, serverTimestamp=1516120442683, serverId='e271a9e0-d90d-444c-a3d6-fb7b91f68a98', slaveId=Optional.absent()}
16:34:02.936 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:02.953 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120442951-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120442951-1-host1-DEFAULT, serverTimestamp=1516120443000, serverId='e271a9e0-d90d-444c-a3d6-fb7b91f68a98', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120442625-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120442625-1-host1-rack1, serverTimestamp=1516120443118, serverId='e271a9e0-d90d-444c-a3d6-fb7b91f68a98', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-timeout_test-1516116842996-1-host1-rack1'}), timestamp=Optional.of(1.516116842E9)}), taskId=test-request-timeout_test-1516116842996-1-host1-rack1, serverTimestamp=1516120443224, serverId='4b49c741-af13-4b6b-98be-32f5da0e0ce4', slaveId=Optional.absent()}
16:34:03.259 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:03.516 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.527 sec - in com.hubspot.singularity.data.ValidatorTest
16:34:03.568 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:04.126 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120444201-1-host1-rack1'}), timestamp=Optional.of(1.516120444E9)}), taskId=test-request-firstDeployId-1516120444201-1-host1-rack1, serverTimestamp=1516120444257, serverId='e4e1ae27-e9f0-4939-8f08-7c5eac7a42c3', slaveId=Optional.absent()}
16:34:04.463 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120444410-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120444410-1-host2-DEFAULT, serverTimestamp=1516120444453, serverId='e4e1ae27-e9f0-4939-8f08-7c5eac7a42c3', slaveId=Optional.absent()}
16:34:04.775 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:39685] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd209830000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:04.835 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:04.981 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1516120445112, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1516120445187, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1516120445228, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.234 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='timeout_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.of(86400000), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-timeout_test-1516116842996-1-IMMEDIATE-1516116842996, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer443'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-timeout_test-1516116842996-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:05.236 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-timeout_test-1516116842996-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:05.238 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-timeout_test-1516116842996-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1516120445312, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1516120445368, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.390 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1516120445410, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1516120445465, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.529 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(20.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1516120445496, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.554 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-2-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(21.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1516120445547, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.586 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120445499-1-host1-rack1'}), timestamp=Optional.of(1.516120445E9)}), taskId=test-request-firstDeployId-1516120445499-1-host1-rack1, serverTimestamp=1516120445567, serverId='9c5e15a4-596d-4733-95b1-6461462a1f73', slaveId=Optional.absent()}
16:34:05.608 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-6-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(22.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1516120445584, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.630 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-4-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(23.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1516120445621, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.656 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-3-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(24.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1516120445648, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.687 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120445499-1-host1-rack1
16:34:05.690 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
16:34:05.691 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-5-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120445499-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120445499-1-host1-rack1, serverTimestamp=1516120445681, serverId='9c5e15a4-596d-4733-95b1-6461462a1f73', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(25.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1516120445683, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
16:34:05.710 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-7-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(26.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1516120445703, serverId='b1f98c7d-b5ae-4bb1-aa84-ac773d77554f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1516120445724-1-host1-rack1'}), timestamp=Optional.of(1.516120445E9)}), taskId=test-request-retry_test-1516120445724-1-host1-rack1, serverTimestamp=1516120445808, serverId='08995f65-487d-4864-9944-b0bc62c5db68', slaveId=Optional.absent()}
16:34:05.978 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:06.172 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109646055-1-host1-rack1'}), timestamp=Optional.of(1.516120446E9)}), taskId=test-request-firstDeployId-1516109646055-1-host1-rack1, serverTimestamp=1516120446139, serverId='d4cdfd62-9895-4b9d-9d0f-6fd5db258a92', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109646218-2-host1-rack1'}), timestamp=Optional.of(1.516120446E9)}), taskId=test-request-firstDeployId-1516109646218-2-host1-rack1, serverTimestamp=1516120446246, serverId='d4cdfd62-9895-4b9d-9d0f-6fd5db258a92', slaveId=Optional.absent()}
16:34:06.284 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109646055-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109646055-1-host1-rack1'}), timestamp=Optional.of(1.516113246E9)}), taskId=test-request-firstDeployId-1516109646055-1-host1-rack1, serverTimestamp=1516120446278, serverId='d4cdfd62-9895-4b9d-9d0f-6fd5db258a92', slaveId=Optional.absent()}
16:34:06.349 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57655] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd20f800000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:06.661 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:07.015 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1516120447178, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.252 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516109646218-2-IMMEDIATE-1516109646218, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer22'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516109646218-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:07.256 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516109646218-2-IMMEDIATE-1516109646218, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer22'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516109646218-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@ea017b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@651a4773[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1516120447249, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1516120447294, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1516120447383, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.408 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1516120447416, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1516120447456, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1516120447506, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.521 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(80.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1516120447515, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.549 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(90.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1516120447541, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.567 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-60000-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(100.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1516120447561, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.581 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-40000-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(110.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1516120447576, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.732 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(120.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1516120447726, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.748 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-50000-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(130.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1516120447742, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.775 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(140.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1516120447759, serverId='027e10ad-9c03-4080-8533-a7c5d44e8d87', slaveId=Optional.absent()}
16:34:07.818 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(3), failureStatusCodes=Optional.of([404])}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1516120445724-1-IMMEDIATE-1516120445724, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer914'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1516120445724-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:07.819 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1516120445724-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:07.820 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1516120445724-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.793 sec - in com.hubspot.singularity.SingularityHistoryTest
16:34:08.147 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:08.166 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:08.279 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120448272-1-host1-rack1'}), timestamp=Optional.of(1.516120448E9)}), taskId=test-request-firstDeployId-1516120448272-1-host1-rack1, serverTimestamp=1516120448375, serverId='e8ed79c0-d72c-4484-892b-3e7734d54ae1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1516120448340-1-host1-rack1'}), timestamp=Optional.of(1.516120448E9)}), taskId=test-request-retry_test-1516120448340-1-host1-rack1, serverTimestamp=1516120448475, serverId='a235a76c-1a0f-4bff-9f6e-57e17777dfcd', slaveId=Optional.absent()}
16:34:08.550 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:34:08.588 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:08.615 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120448272-1-host1-rack1
16:34:08.620 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120448272-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120448272-1-host1-rack1, serverTimestamp=1516120448594, serverId='e8ed79c0-d72c-4484-892b-3e7734d54ae1', slaveId=Optional.absent()}
16:34:08.756 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.763 sec - in com.hubspot.singularity.scheduler.HistoryPersisterTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120448951-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120448951-2-host1-rack1, serverTimestamp=1516120449125, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449020-1-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449020-1-host2-rack1, serverTimestamp=1516120449139, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449244-2-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449244-2-host4-rack2, serverTimestamp=1516120449310, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449270-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449270-3-host3-rack2, serverTimestamp=1516120449321, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120448951-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120448951-2-host1-rack1, serverTimestamp=1516120449358, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449459-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449459-3-host1-rack1, serverTimestamp=1516120449538, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449508-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449508-2-host2-rack1, serverTimestamp=1516120449552, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449270-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449270-3-host3-rack2, serverTimestamp=1516120449592, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120449244-2-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120449244-2-host4-rack2, serverTimestamp=1516120449639, serverId='917fd955-5ad9-4fe6-8c2e-a5cc473ef740', slaveId=Optional.absent()}
16:34:09.941 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120450011-1-host1-rack1'}), timestamp=Optional.of(1.51612045E9)}), taskId=test-request-firstDeployId-1516120450011-1-host1-rack1, serverTimestamp=1516120450067, serverId='6f922c76-d008-477a-8e7a-1662ed9b34db', slaveId=Optional.absent()}
16:34:10.128 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120450176-1-host1-rack1'}), timestamp=Optional.of(1.51612045E9)}), taskId=test-request-secondDeployId-1516120450176-1-host1-rack1, serverTimestamp=1516120450211, serverId='6f922c76-d008-477a-8e7a-1662ed9b34db', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d3-1516120450386-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d3-1516120450386-1-host1-DEFAULT, serverTimestamp=1516120450433, serverId='b21a7623-9abb-4344-8957-4b6b27612fa8', slaveId=Optional.absent()}
16:34:10.489 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1516120448340-1-IMMEDIATE-1516120448340, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer683'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1516120448340-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:10.490 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1516120448340-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:10.491 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1516120448340-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d4-1516120450541-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d4-1516120450541-1-host1-DEFAULT, serverTimestamp=1516120450575, serverId='b21a7623-9abb-4344-8957-4b6b27612fa8', slaveId=Optional.absent()}
16:34:10.845 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-startup_timeout_test-1516116850869-1-host1-rack1'}), timestamp=Optional.of(1.51611685E9)}), taskId=test-request-startup_timeout_test-1516116850869-1-host1-rack1, serverTimestamp=1516120451012, serverId='90dfbe5a-8505-4b8b-9d84-c41d8081910b', slaveId=Optional.absent()}
16:34:11.784 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:11.873 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:11.977 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120451887-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120451887-1-host1-rack1'}), timestamp=Optional.of(1.516120451E9)}), taskId=test-request-firstDeployId-1516120451887-1-host1-rack1, serverTimestamp=1516120451966, serverId='aeb2b79b-3950-4fa9-bfda-004c3a3b1ed0', slaveId=Optional.absent()}
16:34:12.043 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120452005-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120452005-1-host1-rack1'}), timestamp=Optional.of(1.516120452E9)}), taskId=test-request-firstDeployId-1516120452005-1-host1-rack1, serverTimestamp=1516120452038, serverId='aeb2b79b-3950-4fa9-bfda-004c3a3b1ed0', slaveId=Optional.absent()}
Tests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 79.092 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityHealthchecksTest
testMaxHealthcheckRetries(com.hubspot.singularity.scheduler.SingularityHealthchecksTest)  Time elapsed: 30.074 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

16:34:12.452 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120453544-1-host1-rack1'}), timestamp=Optional.of(1.516120454E9)}), taskId=test-request-firstDeployId-1516120453544-1-host1-rack1, serverTimestamp=1516120452633, serverId='974b2927-a793-44d1-8238-88190ba2626f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456544-2-host1-rack1'}), timestamp=Optional.of(1.516120457E9)}), taskId=test-request-firstDeployId-1516120456544-2-host1-rack1, serverTimestamp=1516120452716, serverId='974b2927-a793-44d1-8238-88190ba2626f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456544-3-host1-rack1'}), timestamp=Optional.of(1.516120457E9)}), taskId=test-request-firstDeployId-1516120456544-3-host1-rack1, serverTimestamp=1516120452777, serverId='974b2927-a793-44d1-8238-88190ba2626f', slaveId=Optional.absent()}
16:34:12.829 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60743] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd228eb0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:13.128 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:13.304 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120453394-1-host1-rack1'}), timestamp=Optional.of(1.516120453E9)}), taskId=test-request-firstDeployId-1516120453394-1-host1-rack1, serverTimestamp=1516120453450, serverId='c2d7a6a2-d8d9-4a4c-b905-1af0a2884611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120453482-2-host1-rack1'}), timestamp=Optional.of(1.516120453E9)}), taskId=test-request-firstDeployId-1516120453482-2-host1-rack1, serverTimestamp=1516120453511, serverId='c2d7a6a2-d8d9-4a4c-b905-1af0a2884611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120453628-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120453628-1-host2-DEFAULT, serverTimestamp=1516120453660, serverId='c2d7a6a2-d8d9-4a4c-b905-1af0a2884611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120453394-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120453394-1-host1-rack1, serverTimestamp=1516120453705, serverId='c2d7a6a2-d8d9-4a4c-b905-1af0a2884611', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120453743-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120453743-2-host1-DEFAULT, serverTimestamp=1516120453775, serverId='c2d7a6a2-d8d9-4a4c-b905-1af0a2884611', slaveId=Optional.absent()}
16:34:14.387 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:14.675 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120453544-1-IMMEDIATE-1516120453544, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer375'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120453544-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:14.676 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120453544-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:14.680 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120453544-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7ac87068 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@559d1bca[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:14.722 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120456544-2-IMMEDIATE-1516120456544, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer838'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120456544-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:14.722 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120456544-2-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:14.724 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120456544-2-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4e7ba403 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@559d1bca[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:14.781 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120456544-3-IMMEDIATE-1516120456544, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer894'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120456544-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:34:14.782 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120456544-3-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:14.783 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120456544-3-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@a796b16 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@559d1bca[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:15.595 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:16.033 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:16.087 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456142-1-host1-rack1'}), timestamp=Optional.of(1.516120456E9)}), taskId=test-request-firstDeployId-1516120456142-1-host1-rack1, serverTimestamp=1516120456214, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456414-2-host1-rack1'}), timestamp=Optional.of(1.516120456E9)}), taskId=test-request-firstDeployId-1516120456414-2-host1-rack1, serverTimestamp=1516120456445, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456169-1-host1-rack1'}), timestamp=Optional.of(1.516120456E9)}), taskId=test-request-firstDeployId-1516120456169-1-host1-rack1, serverTimestamp=1516120456401, serverId='9f3c3920-9c4f-4b92-8e6b-0a1b0e2883dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456455-3-host1-rack1'}), timestamp=Optional.of(1.516120456E9)}), taskId=test-request-firstDeployId-1516120456455-3-host1-rack1, serverTimestamp=1516120456485, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120456634-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120456634-1-host2-DEFAULT, serverTimestamp=1516120456684, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456169-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120456169-1-host1-rack1, serverTimestamp=1516120456698, serverId='9f3c3920-9c4f-4b92-8e6b-0a1b0e2883dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456142-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120456142-1-host1-rack1, serverTimestamp=1516120456704, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120456760-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120456760-2-host1-DEFAULT, serverTimestamp=1516120456814, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120456414-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120456414-2-host1-rack1, serverTimestamp=1516120456879, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120456934-3-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120456934-3-host1-DEFAULT, serverTimestamp=1516120456994, serverId='66732cd5-cf43-429d-b9a4-ce838fb1c488', slaveId=Optional.absent()}
16:34:17.069 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47770] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd236cd0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:17.168 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:17.900 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:18.647 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.05 sec - in com.hubspot.singularity.scheduler.SingularityMachineStatesTest
16:34:19.253 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:19.349 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120459361-1-host1-rack1'}), timestamp=Optional.of(1.516120459E9)}), taskId=test-request-firstDeployId-1516120459361-1-host1-rack1, serverTimestamp=1516120459418, serverId='c2eabeb5-5cbb-44ef-9e85-a8d6bbe82619', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120459458-2-host1-rack1'}), timestamp=Optional.of(1.516120459E9)}), taskId=test-request-firstDeployId-1516120459458-2-host1-rack1, serverTimestamp=1516120459489, serverId='c2eabeb5-5cbb-44ef-9e85-a8d6bbe82619', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120459604-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120459604-1-host1-DEFAULT, serverTimestamp=1516120459650, serverId='9d841d4f-ef7f-403e-80b0-8577f54ff64f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120459656-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120459656-1-host1-DEFAULT, serverTimestamp=1516120459707, serverId='c2eabeb5-5cbb-44ef-9e85-a8d6bbe82619', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120459361-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120459361-1-host1-rack1, serverTimestamp=1516120459821, serverId='c2eabeb5-5cbb-44ef-9e85-a8d6bbe82619', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120459879-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120459879-2-host2-DEFAULT, serverTimestamp=1516120459899, serverId='c2eabeb5-5cbb-44ef-9e85-a8d6bbe82619', slaveId=Optional.absent()}
16:34:20.504 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120459458-2-IMMEDIATE-1516120459458, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer81'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120459458-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:20.506 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120459458-2-IMMEDIATE-1516120459458, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer81'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120459458-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@959cf58 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2e38c496[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:34:20.867 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120460960-1-host1-rack1'}), timestamp=Optional.of(1.51612046E9)}), taskId=test-request-firstDeployId-1516120460960-1-host1-rack1, serverTimestamp=1516120461014, serverId='71efbb65-0d57-480d-8a1f-cf41fd63775a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120461049-2-host1-rack1'}), timestamp=Optional.of(1.516120461E9)}), taskId=test-request-firstDeployId-1516120461049-2-host1-rack1, serverTimestamp=1516120461077, serverId='71efbb65-0d57-480d-8a1f-cf41fd63775a', slaveId=Optional.absent()}
16:34:21.136 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:34:21.148 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:34:21.163 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120460960-1-host1-rack1
16:34:21.166 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120460960-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120460960-1-host1-rack1, serverTimestamp=1516120461158, serverId='71efbb65-0d57-480d-8a1f-cf41fd63775a', slaveId=Optional.absent()}
16:34:21.194 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120461049-2-host1-rack1
16:34:21.200 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120461049-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120461049-2-host1-rack1, serverTimestamp=1516120461186, serverId='71efbb65-0d57-480d-8a1f-cf41fd63775a', slaveId=Optional.absent()}
16:34:21.687 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:22.423 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:23.006 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120463191-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120463191-1-host2-DEFAULT, serverTimestamp=1516120463228, serverId='7776db6b-2a83-4838-96ef-29bca475c47b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120463191-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120463191-1-host2-DEFAULT, serverTimestamp=1516120463249, serverId='7776db6b-2a83-4838-96ef-29bca475c47b', slaveId=Optional.absent()}
16:34:24.002 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120464080-1-host1-rack1'}), timestamp=Optional.of(1.516120464E9)}), taskId=test-request-firstDeployId-1516120464080-1-host1-rack1, serverTimestamp=1516120464134, serverId='d5eaabc6-1dad-4c6d-b310-20336ab42a30', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120464166-2-host1-rack1'}), timestamp=Optional.of(1.516120464E9)}), taskId=test-request-firstDeployId-1516120464166-2-host1-rack1, serverTimestamp=1516120464193, serverId='d5eaabc6-1dad-4c6d-b310-20336ab42a30', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120464202-3-host1-rack1'}), timestamp=Optional.of(1.516120464E9)}), taskId=test-request-firstDeployId-1516120464202-3-host1-rack1, serverTimestamp=1516120464233, serverId='d5eaabc6-1dad-4c6d-b310-20336ab42a30', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120464348-5-host1-rack1'}), timestamp=Optional.of(1.516120464E9)}), taskId=test-request-firstDeployId-1516120464348-5-host1-rack1, serverTimestamp=1516120464384, serverId='d5eaabc6-1dad-4c6d-b310-20336ab42a30', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120464348-5-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120464348-5-host1-rack1, serverTimestamp=1516120464401, serverId='d5eaabc6-1dad-4c6d-b310-20336ab42a30', slaveId=Optional.absent()}
16:34:24.470 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120464568-1-host1-rack1'}), timestamp=Optional.of(1.516120464E9)}), taskId=test-request-secondDeployId-1516120464568-1-host1-rack1, serverTimestamp=1516120464608, serverId='89eace4e-ebdb-4fd4-8715-ebc5be5a27f5', slaveId=Optional.absent()}
16:34:24.686 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41231] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd257c40000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:25.841 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-deploy_test-1516120465939-1-host1-rack1'}), timestamp=Optional.of(1.516120465E9)}), taskId=test-request-deploy_test-1516120465939-1-host1-rack1, serverTimestamp=1516120465990, serverId='6e9c2f4f-69b4-4fed-aad1-62d9bf3963c5', slaveId=Optional.absent()}
16:34:26.031 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60693] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd25d3f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:26.646 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:26.755 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='firstDeployId', timestamp=1516120466651, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1516120466651}), updatedRequest=Optional.absent()} request was MISSING, removing deploy
16:34:26.770 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:58931] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd260490000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:27.223 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120467309-1-host1-rack1'}), timestamp=Optional.of(1.516120467E9)}), taskId=test-request-firstDeployId-1516120467309-1-host1-rack1, serverTimestamp=1516120467354, serverId='1774e40f-6b45-4a75-8cb9-f549448d630b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120467382-2-host1-rack1'}), timestamp=Optional.of(1.516120467E9)}), taskId=test-request-firstDeployId-1516120467382-2-host1-rack1, serverTimestamp=1516120467405, serverId='1774e40f-6b45-4a75-8cb9-f549448d630b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120467509-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120467509-1-host2-DEFAULT, serverTimestamp=1516120467539, serverId='1774e40f-6b45-4a75-8cb9-f549448d630b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120467309-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120467309-1-host1-rack1, serverTimestamp=1516120467581, serverId='1774e40f-6b45-4a75-8cb9-f549448d630b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120467649-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120467649-2-host1-DEFAULT, serverTimestamp=1516120467674, serverId='1774e40f-6b45-4a75-8cb9-f549448d630b', slaveId=Optional.absent()}
16:34:27.915 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120467983-1-host1-rack1'}), timestamp=Optional.of(1.516120467E9)}), taskId=test-request-firstDeployId-1516120467983-1-host1-rack1, serverTimestamp=1516120468034, serverId='ea7f03f7-cec8-45f6-b25d-4cb98dc5b495', slaveId=Optional.absent()}
16:34:28.125 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120467983-1-host1-rack1
16:34:28.127 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120467983-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120467983-1-host1-rack1, serverTimestamp=1516120468118, serverId='ea7f03f7-cec8-45f6-b25d-4cb98dc5b495', slaveId=Optional.absent()}
16:34:29.295 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:29.894 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120469952-1-host1-rack1'}), timestamp=Optional.of(1.516120469E9)}), taskId=test-request-firstDeployId-1516120469952-1-host1-rack1, serverTimestamp=1516120469998, serverId='8082b67e-57b6-4416-a30c-058686c84be9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120470045-1-host1-rack1'}), timestamp=Optional.of(1.51612047E9)}), taskId=test-request-secondDeployId-1516120470045-1-host1-rack1, serverTimestamp=1516120470094, serverId='8082b67e-57b6-4416-a30c-058686c84be9', slaveId=Optional.absent()}
16:34:30.137 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-secondDeployId-1516120470045-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120470045-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120470045-1-host1-rack1, serverTimestamp=1516120470130, serverId='8082b67e-57b6-4416-a30c-058686c84be9', slaveId=Optional.absent()}
16:34:30.158 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120469952-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120469952-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120469952-1-host1-rack1, serverTimestamp=1516120470153, serverId='8082b67e-57b6-4416-a30c-058686c84be9', slaveId=Optional.absent()}
16:34:30.719 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120470920-1-host1-rack1'}), timestamp=Optional.of(1.51612047E9)}), taskId=test-request-firstDeployId-1516120470920-1-host1-rack1, serverTimestamp=1516120470970, serverId='899bf638-88ac-420d-b7bc-24e1b1a18075', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120471006-2-host1-rack1'}), timestamp=Optional.of(1.516120471E9)}), taskId=test-request-firstDeployId-1516120471006-2-host1-rack1, serverTimestamp=1516120471029, serverId='899bf638-88ac-420d-b7bc-24e1b1a18075', slaveId=Optional.absent()}
16:34:31.347 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120471440-1-host1-rack1'}), timestamp=Optional.of(1.516120471E9)}), taskId=test-request-firstDeployId-1516120471440-1-host1-rack1, serverTimestamp=1516120471486, serverId='b65bc49b-83b5-4a0e-bcca-08d75d56c036', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120471518-2-host1-rack1'}), timestamp=Optional.of(1.516120471E9)}), taskId=test-request-firstDeployId-1516120471518-2-host1-rack1, serverTimestamp=1516120471549, serverId='b65bc49b-83b5-4a0e-bcca-08d75d56c036', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120471687-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120471687-2-host2-DEFAULT, serverTimestamp=1516120471712, serverId='b65bc49b-83b5-4a0e-bcca-08d75d56c036', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120471656-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120471656-1-host2-DEFAULT, serverTimestamp=1516120471721, serverId='b65bc49b-83b5-4a0e-bcca-08d75d56c036', slaveId=Optional.absent()}
16:34:33.516 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:33.980 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474064-1-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474064-1-host1-rack1, serverTimestamp=1516120474109, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474141-2-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474141-2-host1-rack1, serverTimestamp=1516120474169, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474178-3-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474178-3-host1-rack1, serverTimestamp=1516120474205, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474213-4-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474213-4-host1-rack1, serverTimestamp=1516120474236, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120474338-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120474338-1-host1-DEFAULT, serverTimestamp=1516120474400, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120474367-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120474367-2-host1-DEFAULT, serverTimestamp=1516120474409, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474064-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120474064-1-host1-rack1, serverTimestamp=1516120474458, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474141-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120474141-2-host1-rack1, serverTimestamp=1516120474487, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120474558-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120474558-4-host2-DEFAULT, serverTimestamp=1516120474593, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120474542-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120474542-3-host2-DEFAULT, serverTimestamp=1516120474606, serverId='a0dc6697-281d-41bb-9d48-8c504906b5e3', slaveId=Optional.absent()}
16:34:34.842 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474904-1-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474904-1-host1-rack1, serverTimestamp=1516120474958, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474998-1-host1-rack1'}), timestamp=Optional.of(1.516120474E9)}), taskId=test-request-firstDeployId-1516120474998-1-host1-rack1, serverTimestamp=1516120475025, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
16:34:35.041 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120474904-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474904-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120474904-1-host1-rack1, serverTimestamp=1516120475036, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
16:34:35.059 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120474998-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120474998-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120474998-1-host1-rack1, serverTimestamp=1516120475053, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120475122-1-host1-rack1'}), timestamp=Optional.of(1.516120475E9)}), taskId=test-request-firstDeployId-1516120475122-1-host1-rack1, serverTimestamp=1516120475149, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
16:34:35.164 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120475122-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120475122-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120475122-1-host1-rack1, serverTimestamp=1516120475159, serverId='97391622-b372-47e6-bfb5-429485984929', slaveId=Optional.absent()}
16:34:36.333 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:36.828 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:36.954 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='secondDeployId', timestamp=1516120476900, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=0, stepComplete=false, autoAdvanceDeploySteps=false, failedDeployTasks=[], timestamp=1516120476900}), updatedRequest=Optional.absent()} request was PAUSED, removing deploy
16:34:37.604 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:37.869 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:36256] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd28b390000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:38.117 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120478200-1-host1-rack1'}), timestamp=Optional.of(1.516120478E9)}), taskId=test-request-firstDeployId-1516120478200-1-host1-rack1, serverTimestamp=1516120478246, serverId='be884157-716c-40c0-b7ef-da7ce8f8f160', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120478271-2-host1-rack1'}), timestamp=Optional.of(1.516120478E9)}), taskId=test-request-firstDeployId-1516120478271-2-host1-rack1, serverTimestamp=1516120478301, serverId='be884157-716c-40c0-b7ef-da7ce8f8f160', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120478404-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120478404-1-host2-DEFAULT, serverTimestamp=1516120478434, serverId='be884157-716c-40c0-b7ef-da7ce8f8f160', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120478200-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120478200-1-host1-rack1, serverTimestamp=1516120478477, serverId='be884157-716c-40c0-b7ef-da7ce8f8f160', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120478563-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120478563-1-host2-DEFAULT, serverTimestamp=1516120478598, serverId='be884157-716c-40c0-b7ef-da7ce8f8f160', slaveId=Optional.absent()}
16:34:39.005 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:40.456 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:40.542 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44818] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd296560000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:40.771 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120480852-1-host1-rack1'}), timestamp=Optional.of(1.51612048E9)}), taskId=test-request-firstDeployId-1516120480852-1-host1-rack1, serverTimestamp=1516120480902, serverId='a8949c0f-ae53-4f95-991f-106f20222583', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120480928-2-host1-rack1'}), timestamp=Optional.of(1.51612048E9)}), taskId=test-request-firstDeployId-1516120480928-2-host1-rack1, serverTimestamp=1516120480953, serverId='a8949c0f-ae53-4f95-991f-106f20222583', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120481058-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1516120481058-1-host2-DEFAULT, serverTimestamp=1516120481086, serverId='a8949c0f-ae53-4f95-991f-106f20222583', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120480852-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120480852-1-host1-rack1, serverTimestamp=1516120481129, serverId='a8949c0f-ae53-4f95-991f-106f20222583', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120481237-1-host1-rack1'}), timestamp=Optional.of(1.516120481E9)}), taskId=test-request-firstDeployId-1516120481237-1-host1-rack1, serverTimestamp=1516120481266, serverId='a8949c0f-ae53-4f95-991f-106f20222583', slaveId=Optional.absent()}
16:34:41.731 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120481788-1-host1-rack1'}), timestamp=Optional.of(1.516120481E9)}), taskId=test-request-firstDeployId-1516120481788-1-host1-rack1, serverTimestamp=1516120481834, serverId='6cf690af-0c56-4c64-ae24-e1d71bb884ab', slaveId=Optional.absent()}
16:34:41.895 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:34:41.927 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120481788-1-host1-rack1
16:34:41.934 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120481788-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120481788-1-host1-rack1, serverTimestamp=1516120481921, serverId='6cf690af-0c56-4c64-ae24-e1d71bb884ab', slaveId=Optional.absent()}
Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 54.066 sec - in com.hubspot.singularity.scheduler.SingularityDeploysTest
16:34:43.161 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120483220-1-host1-rack1'}), timestamp=Optional.of(1.516120483E9)}), taskId=test-request-firstDeployId-1516120483220-1-host1-rack1, serverTimestamp=1516120483270, serverId='5910e520-a954-48a9-955e-1aced7f05de3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120483384-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120483384-1-host1-DEFAULT, serverTimestamp=1516120483411, serverId='5910e520-a954-48a9-955e-1aced7f05de3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120483220-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120483220-1-host1-rack1, serverTimestamp=1516120483429, serverId='5910e520-a954-48a9-955e-1aced7f05de3', slaveId=Optional.absent()}
16:34:45.588 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:46.933 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:48.295 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:48.579 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:46091] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd2b4ec0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:49.709 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:51.171 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:52.502 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120492708-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120492708-2-host2-DEFAULT, serverTimestamp=1516120492811, serverId='04d4e745-69b9-4776-b7da-314759b81308', slaveId=Optional.absent()}
[test-request-firstDeployId-1516120492819-2-TASK_DONE-1516120492819]
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120492749-5-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120492749-5-host2-DEFAULT, serverTimestamp=1516120492889, serverId='04d4e745-69b9-4776-b7da-314759b81308', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120492778-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120492778-4-host2-DEFAULT, serverTimestamp=1516120492919, serverId='04d4e745-69b9-4776-b7da-314759b81308', slaveId=Optional.absent()}
16:34:54.122 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120494184-1-host1-rack1'}), timestamp=Optional.of(1.516120494E9)}), taskId=test-request-firstDeployId-1516120494184-1-host1-rack1, serverTimestamp=1516120494230, serverId='7e189598-3306-4655-ae6e-bfcc732e7658', slaveId=Optional.absent()}
16:34:56.449 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496523-1-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496523-1-host1-rack1, serverTimestamp=1516120496569, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496602-2-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496602-2-host1-rack1, serverTimestamp=1516120496629, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496639-3-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496639-3-host1-rack1, serverTimestamp=1516120496665, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496674-4-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496674-4-host1-rack1, serverTimestamp=1516120496701, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.717 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496523-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496523-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496523-1-host1-rack1, serverTimestamp=1516120496711, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.747 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496602-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496602-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496602-2-host1-rack1, serverTimestamp=1516120496731, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.769 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496639-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496639-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496639-3-host1-rack1, serverTimestamp=1516120496765, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496807-1-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496807-1-host1-rack1, serverTimestamp=1516120496836, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496843-2-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496843-2-host1-rack1, serverTimestamp=1516120496872, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496879-3-host1-rack1'}), timestamp=Optional.of(1.516120496E9)}), taskId=test-request-firstDeployId-1516120496879-3-host1-rack1, serverTimestamp=1516120496908, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.920 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496807-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496807-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496807-1-host1-rack1, serverTimestamp=1516120496916, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.955 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496843-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496843-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496843-2-host1-rack1, serverTimestamp=1516120496951, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:56.987 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496879-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496879-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496879-3-host1-rack1, serverTimestamp=1516120496971, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:57.029 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120496674-4-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120496674-4-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120496674-4-host1-rack1, serverTimestamp=1516120497021, serverId='989a734f-b1c2-4f33-9ba4-c5a45ae6673f', slaveId=Optional.absent()}
16:34:58.208 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:34:58.301 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB delete request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1516120498298, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-1516120498291-DELETE-1} (test-request-1516120498291-DELETE-1) got unexpected response FAILED
16:34:58.317 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:54706] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd2dbc60000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:34:59.476 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120499540-1-host1-rack1'}), timestamp=Optional.of(1.516120499E9)}), taskId=test-request-firstDeployId-1516120499540-1-host1-rack1, serverTimestamp=1516120499590, serverId='c477ff89-bacc-4b54-8679-e5d08618dae6', slaveId=Optional.absent()}
16:35:01.892 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:04.356 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120504420-1-host1-rack1'}), timestamp=Optional.of(1.516120504E9)}), taskId=test-request-firstDeployId-1516120504420-1-host1-rack1, serverTimestamp=1516120504468, serverId='e63b1b54-c471-43d1-8be0-46834f671383', slaveId=Optional.absent()}
16:35:04.522 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120504420-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120504420-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120504420-1-host1-rack1, serverTimestamp=1516120504518, serverId='e63b1b54-c471-43d1-8be0-46834f671383', slaveId=Optional.absent()}
16:35:05.737 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120505792-1-host1-rack1'}), timestamp=Optional.of(1.516120505E9)}), taskId=test-request-firstDeployId-1516120505792-1-host1-rack1, serverTimestamp=1516120505834, serverId='1f4c316c-2cbf-40de-ae1c-78f1429439f6', slaveId=Optional.absent()}
16:35:05.875 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120505792-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120505792-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120505792-1-host1-rack1, serverTimestamp=1516120505869, serverId='1f4c316c-2cbf-40de-ae1c-78f1429439f6', slaveId=Optional.absent()}
16:35:05.913 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB removal request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1516120505907, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-firstDeployId-1516120505792-1-host1-rack1-REMOVE-1} (test-request-firstDeployId-1516120505792-1-host1-rack1-REMOVE-1) got unexpected response FAILED
16:35:07.064 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:08.306 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:08.490 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52609] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd303340000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:09.641 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120509756-1-host1-rack1'}), timestamp=Optional.of(1.516120509E9)}), taskId=test-request-firstDeployId-1516120509756-1-host1-rack1, serverTimestamp=1516120509825, serverId='216c3175-e886-42d6-9a89-6fe993c589f7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120509756-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120509756-1-host1-rack1, serverTimestamp=1516120509913, serverId='216c3175-e886-42d6-9a89-6fe993c589f7', slaveId=Optional.absent()}
16:35:11.090 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120511261-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120511261-1-host1-DEFAULT, serverTimestamp=1516120511300, serverId='6e11e26b-385f-49b5-9f05-049e1b90a1a7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120511339-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120511339-1-host2-DEFAULT, serverTimestamp=1516120511354, serverId='6e11e26b-385f-49b5-9f05-049e1b90a1a7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1516120511389-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1516120511389-1-host2-DEFAULT, serverTimestamp=1516120511414, serverId='6e11e26b-385f-49b5-9f05-049e1b90a1a7', slaveId=Optional.absent()}
16:35:11.443 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:56040] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd30e0a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:12.571 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120512628-1-host1-rack1'}), timestamp=Optional.of(1.516120512E9)}), taskId=test-request-firstDeployId-1516120512628-1-host1-rack1, serverTimestamp=1516120512685, serverId='f9cc452b-a965-4824-a994-47d5f9abe34a', slaveId=Optional.absent()}
16:35:12.720 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120512628-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120512628-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120512628-1-host1-rack1, serverTimestamp=1516120512715, serverId='f9cc452b-a965-4824-a994-47d5f9abe34a', slaveId=Optional.absent()}
16:35:14.019 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:14.144 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:45832] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd3198a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:15.300 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:16.801 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:18.082 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120518213-1-host1-rack1'}), timestamp=Optional.of(1.516120518E9)}), taskId=test-request-firstDeployId-1516120518213-1-host1-rack1, serverTimestamp=1516120518262, serverId='284b577f-f4e6-488a-9e21-5c7cb9fba515', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120518295-2-host2-rack1'}), timestamp=Optional.of(1.516120518E9)}), taskId=test-request-firstDeployId-1516120518295-2-host2-rack1, serverTimestamp=1516120518316, serverId='284b577f-f4e6-488a-9e21-5c7cb9fba515', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120518403-1-host3-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1516120518403-1-host3-DEFAULT, serverTimestamp=1516120518419, serverId='284b577f-f4e6-488a-9e21-5c7cb9fba515', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120518213-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120518213-1-host1-rack1, serverTimestamp=1516120518475, serverId='284b577f-f4e6-488a-9e21-5c7cb9fba515', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120518514-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1516120518514-2-host1-DEFAULT, serverTimestamp=1516120518529, serverId='284b577f-f4e6-488a-9e21-5c7cb9fba515', slaveId=Optional.absent()}
16:35:20.319 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120518295-2-IMMEDIATE-1516120518295, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host2', id=SingularityMesosIdObject{value='offer729'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120518295-2-host2-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
16:35:20.320 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120518295-2-host2-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:20.321 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120518295-2-host2-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7d020189 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@73c5e059[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:20.423 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120518383-1-BOUNCE-1516120518333, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host3', id=SingularityMesosIdObject{value='offer65'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120518403-1-host3-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host3}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1516120518403-1-host3-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
16:35:20.423 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120518403-1-host3-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:20.424 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120518403-1-host3-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@77fa6af9 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@73c5e059[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:20.532 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120518485-2-TASK_DONE-1516120518482, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer400'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120518514-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1516120518514-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
16:35:20.533 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1516120518514-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:20.534 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1516120518514-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7e54c35 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@73c5e059[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:21.698 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:23.014 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120523076-1-host1-rack1'}), timestamp=Optional.of(1.516120523E9)}), taskId=test-request-firstDeployId-1516120523076-1-host1-rack1, serverTimestamp=1516120523117, serverId='42efee9d-5ff3-488b-9b24-df9e4a600ffc', slaveId=Optional.absent()}
16:35:25.397 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:25.403 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Unexpected taskId task 
com.hubspot.singularity.data.transcoders.SingularityTranscoderException: java.lang.reflect.InvocationTargetException
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:44)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.getTaskId(SingularityMesosStatusUpdateHandler.java:137)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:185)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:268)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:276)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testTaskOddities(SingularitySchedulerTest.java:1514)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException: null
	at sun.reflect.GeneratedMethodAccessor226.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:42)
	... 19 common frames omitted
Caused by: com.hubspot.singularity.InvalidSingularityTaskIdException: TaskId task was invalid (There must be at least 5 instances of - (there were 0))
	at com.hubspot.singularity.SingularityTaskId.valueOf(SingularityTaskId.java:114)
	... 23 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120525456-1-host1-rack1'}), timestamp=Optional.of(1.516120525E9)}), taskId=test-request-firstDeployId-1516120525456-1-host1-rack1, serverTimestamp=1516120525502, serverId='5ce227b1-efd3-4f99-bd14-843897c3aa62', slaveId=Optional.absent()}
16:35:25.545 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Task test-request-firstDeployId-1516120525456-1-host1-rack1 is active but is missing task data
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120525456-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120525456-1-host1-rack1, serverTimestamp=1516120525544, serverId='5ce227b1-efd3-4f99-bd14-843897c3aa62', slaveId=Optional.absent()}
16:35:25.561 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120525456-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120525456-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120525456-1-host1-rack1, serverTimestamp=1516120525557, serverId='5ce227b1-efd3-4f99-bd14-843897c3aa62', slaveId=Optional.absent()}
[SingularityTaskHistoryUpdate[timestamp=1516120525544, taskState=TASK_RUNNING, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]], SingularityTaskHistoryUpdate[timestamp=1516120525557, taskState=TASK_FAILED, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]]]
16:35:25.594 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40532] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd345d30000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:26.716 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:28.436 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528507-1-host1-rack1'}), timestamp=Optional.of(1.516120528E9)}), taskId=test-request-firstDeployId-1516120528507-1-host1-rack1, serverTimestamp=1516120528550, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528575-2-host1-rack1'}), timestamp=Optional.of(1.516120528E9)}), taskId=test-request-firstDeployId-1516120528575-2-host1-rack1, serverTimestamp=1516120528603, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528610-3-host1-rack1'}), timestamp=Optional.of(1.516120528E9)}), taskId=test-request-firstDeployId-1516120528610-3-host1-rack1, serverTimestamp=1516120528633, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528807-1-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1516120528807-1-host2-DEFAULT, serverTimestamp=1516120528852, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528829-2-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1516120528829-2-host2-DEFAULT, serverTimestamp=1516120528873, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120528772-3-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1516120528772-3-host2-DEFAULT, serverTimestamp=1516120528880, serverId='c41a5bf6-ddf1-4aa5-9ec7-8ffc9cf9b2c5', slaveId=Optional.absent()}
16:35:31.062 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:32.247 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:32.369 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:54999] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd360b20000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:33.502 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109733561-1-host1-rack1'}), timestamp=Optional.of(1.516120533E9)}), taskId=test-request-firstDeployId-1516109733561-1-host1-rack1, serverTimestamp=1516120533606, serverId='f1ec1de6-8a98-4c42-9dab-7a14ef95e57f', slaveId=Optional.absent()}
16:35:33.662 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516109733561-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516109733561-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516109733561-1-host1-rack1, serverTimestamp=1516120533658, serverId='f1ec1de6-8a98-4c42-9dab-7a14ef95e57f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120533061-1-host1-rack1'}), timestamp=Optional.of(1.516120533E9)}), taskId=test-request-firstDeployId-1516120533061-1-host1-rack1, serverTimestamp=1516120533702, serverId='f1ec1de6-8a98-4c42-9dab-7a14ef95e57f', slaveId=Optional.absent()}
16:35:33.727 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120533061-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120533061-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120533061-1-host1-rack1, serverTimestamp=1516120533710, serverId='f1ec1de6-8a98-4c42-9dab-7a14ef95e57f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120533059-1-host1-rack1'}), timestamp=Optional.of(1.516120533E9)}), taskId=test-request-firstDeployId-1516120533059-1-host1-rack1, serverTimestamp=1516120533781, serverId='f1ec1de6-8a98-4c42-9dab-7a14ef95e57f', slaveId=Optional.absent()}
16:35:35.961 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:37.444 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120537500-1-host1-rack1'}), timestamp=Optional.of(1.516120537E9)}), taskId=test-request-firstDeployId-1516120537500-1-host1-rack1, serverTimestamp=1516120537545, serverId='abc3fe54-b869-47b2-a43b-890f7a33c958', slaveId=Optional.absent()}
16:35:37.598 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:35:37.625 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120537500-1-host1-rack1
16:35:37.632 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120537500-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120537500-1-host1-rack1, serverTimestamp=1516120537621, serverId='abc3fe54-b869-47b2-a43b-890f7a33c958', slaveId=Optional.absent()}
16:35:37.709 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120416612-4-IMMEDIATE-1516120416612, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer531'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120416612-4-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:37.710 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120416612-4-IMMEDIATE-1516120416612, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer531'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120416612-4-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6d69f6b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@618d33a1[Shutting down, pool size = 2, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:37.715 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:59445] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd374f00000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:37.812 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120416725-5-IMMEDIATE-1516120416725, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer981'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120416725-5-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:37.814 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120416725-5-IMMEDIATE-1516120416725, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer981'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120416725-5-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@a9a314e rejected from java.util.concurrent.ScheduledThreadPoolExecutor@618d33a1[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:38.838 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:40.066 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120540124-1-host1-rack1'}), timestamp=Optional.of(1.51612054E9)}), taskId=test-request-firstDeployId-1516120540124-1-host1-rack1, serverTimestamp=1516120540169, serverId='52df52d9-5ed9-46bd-a88e-19bfc1e865af', slaveId=Optional.absent()}
16:35:40.202 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120540124-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120540124-1-host1-rack1'}), timestamp=Optional.of(1.51610254E9)}), taskId=test-request-firstDeployId-1516120540124-1-host1-rack1, serverTimestamp=1516120540198, serverId='52df52d9-5ed9-46bd-a88e-19bfc1e865af', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120540213-1-host1-rack1'}), timestamp=Optional.of(1.51612054E9)}), taskId=test-request-firstDeployId-1516120540213-1-host1-rack1, serverTimestamp=1516120540243, serverId='52df52d9-5ed9-46bd-a88e-19bfc1e865af', slaveId=Optional.absent()}
16:35:40.257 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120540213-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120540213-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120540213-1-host1-rack1, serverTimestamp=1516120540251, serverId='52df52d9-5ed9-46bd-a88e-19bfc1e865af', slaveId=Optional.absent()}
16:35:41.411 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1516120541589-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1516120541589-1-host2-DEFAULT, serverTimestamp=1516120541619, serverId='61877777-d749-48c4-8791-03152b05c4c5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1516120541675-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1516120541675-1-host2-DEFAULT, serverTimestamp=1516120541697, serverId='61877777-d749-48c4-8791-03152b05c4c5', slaveId=Optional.absent()}
16:35:42.847 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:44.130 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.of(1.516120544E9)}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1516120544300, serverId='a5c98e1b-b9b2-4350-b6dd-f268f459a065', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1'}), timestamp=Optional.of(1.516120544E9)}), taskId=mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1, serverTimestamp=1516120544355, serverId='a5c98e1b-b9b2-4350-b6dd-f268f459a065', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='highPriorityRequest-highPriorityDeploy-10-1-host1-rack1'}), timestamp=Optional.of(1.516120544E9)}), taskId=highPriorityRequest-highPriorityDeploy-10-1-host1-rack1, serverTimestamp=1516120544393, serverId='a5c98e1b-b9b2-4350-b6dd-f268f459a065', slaveId=Optional.absent()}
16:35:44.444 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1516120544440, serverId='a5c98e1b-b9b2-4350-b6dd-f268f459a065', slaveId=Optional.absent()}
16:35:46.703 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:48.067 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120548140-1-host1-rack1'}), timestamp=Optional.of(1.516120548E9)}), taskId=test-request-firstDeployId-1516120548140-1-host1-rack1, serverTimestamp=1516120548181, serverId='53ac3d34-770f-40b2-83aa-5dac25379da3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120548207-2-host1-rack1'}), timestamp=Optional.of(1.516120548E9)}), taskId=test-request-firstDeployId-1516120548207-2-host1-rack1, serverTimestamp=1516120548243, serverId='53ac3d34-770f-40b2-83aa-5dac25379da3', slaveId=Optional.absent()}
16:35:48.268 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120548140-1-host1-rack1
16:35:48.271 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120548140-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120548140-1-host1-rack1, serverTimestamp=1516120548263, serverId='53ac3d34-770f-40b2-83aa-5dac25379da3', slaveId=Optional.absent()}
16:35:48.302 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
16:35:48.316 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1516120548207-2-host1-rack1
16:35:48.319 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120548207-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1516120548207-2-host1-rack1, serverTimestamp=1516120548311, serverId='53ac3d34-770f-40b2-83aa-5dac25379da3', slaveId=Optional.absent()}
16:35:48.393 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44151] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd39e8c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:49.520 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:50.956 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:52.298 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1516120552360-1-host1-rack1'}), timestamp=Optional.of(1.516120552E9)}), taskId=test-request-firstDeployId-1516120552360-1-host1-rack1, serverTimestamp=1516120552401, serverId='9de9fccd-39c4-4223-889a-c26238116354', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1516120552447-1-host1-rack1'}), timestamp=Optional.of(1.516120552E9)}), taskId=test-request-secondDeployId-1516120552447-1-host1-rack1, serverTimestamp=1516120552478, serverId='9de9fccd-39c4-4223-889a-c26238116354', slaveId=Optional.absent()}
16:35:52.566 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:38070] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160ffd3af110000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
16:35:53.423 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120552360-1-IMMEDIATE-1516120552360, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer828'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120552360-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:53.426 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120552360-1-IMMEDIATE-1516120552360, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer828'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120552360-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@77eae93d rejected from java.util.concurrent.ScheduledThreadPoolExecutor@792d19b0[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:54.553 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:55.960 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
16:35:56.109 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120434935-1-IMMEDIATE-1516120434935, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer182'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120434935-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:56.110 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120434935-1-IMMEDIATE-1516120434935, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer182'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120434935-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@418e3b6b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4f49dd2a[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:56.193 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120435157-3-IMMEDIATE-1516120435157, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer927'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120435157-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:56.195 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1516120435157-3-IMMEDIATE-1516120435157, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), s3UploaderAdditionalFiles=[], runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer927'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1516120435157-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@25f9d280 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4f49dd2a[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
16:35:57.291 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 76, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 134.097 sec - in com.hubspot.singularity.scheduler.SingularitySchedulerTest

Results :

Tests in error: 
  BlendedHistoryTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut t...
  ZkMigrationTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut test...
  SingularityStartupTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut
  SingularityExpiringActionsTest.testExpiringSkipHealthchecks:209->SingularitySchedulerTestBase.initRequest:516->SingularitySchedulerTestBase.protectedInitRequest:512->SingularitySchedulerTestBase.initRequestWithType:491->SingularitySchedulerTestBase.saveRequest:443 Â» TestTimedOut
  SingularityHealthchecksTest>SingularityCuratorTestBase.curatorSetup:37->Object.getClass:-2 Â» TestTimedOut

Tests run: 257, Failures: 0, Errors: 5, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Singularity ........................................ SUCCESS [  8.694 s]
[INFO] SingularityBase .................................... SUCCESS [  6.361 s]
[INFO] SingularityUI ...................................... SUCCESS [03:18 min]
[INFO] SingularityMesosClient ............................. SUCCESS [  3.038 s]
[INFO] SingularitySwagger ................................. SUCCESS [  1.717 s]
[INFO] SingularityService ................................. FAILURE [03:36 min]
[INFO] SingularityRunnerBase .............................. SKIPPED
[INFO] SingularityS3Base .................................. SKIPPED
[INFO] SingularityClient .................................. SKIPPED
[INFO] SingularityExecutor ................................ SKIPPED
[INFO] SingularityExecutorCleanup ......................... SKIPPED
[INFO] SingularityS3Uploader .............................. SKIPPED
[INFO] SingularityS3Downloader ............................ SKIPPED
[INFO] EmbedSingularityExample ............................ SKIPPED
[INFO] SingularityServiceIntegrationTests ................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 07:15 min
[INFO] Finished at: 2018-01-16T17:35:57+01:00
[INFO] Final Memory: 150M/1884M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project SingularityService: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/HubSpot/Singularity/329502843/SingularityService/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :SingularityService
