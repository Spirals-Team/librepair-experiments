[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for net.mguenther.kafka:kafka-junit:jar:0.2.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-compiler-plugin is missing. @ line 236, column 21
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Kafka JUnit Integration 0.2.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ kafka-junit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/mguenther/kafka-junit/395139958/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ kafka-junit ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ kafka-junit ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ kafka-junit ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ kafka-junit ---
[INFO] Surefire report directory: /root/workspace/mguenther/kafka-junit/395139958/target/surefire-reports
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.pom (3 KB at 5.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.12.4/surefire-providers-2.12.4.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.12.4/surefire-providers-2.12.4.pom (3 KB at 109.2 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.jar (37 KB at 767.2 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running net.mguenther.kafka.junit.RecordProducerTest
2018-06-21 19:59:21 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:21 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:39371 which is assigned to the temporary directory /tmp/1529603961626-0.
2018-06-21 19:59:21 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:22 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8044739544622301639/junit2870412100219179465/meta.properties
2018-06-21 19:59:22 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8044739544622301639/junit2870412100219179465/meta.properties
2018-06-21 19:59:22 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:22 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:22 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit8044739544622301639/junit2870412100219179465.
2018-06-21 19:59:22 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:37203]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:22 INFO  KafkaProducer:336 - [Producer clientId=producer-1] Instantiated an idempotent producer.
2018-06-21 19:59:22 INFO  KafkaProducer:341 - [Producer clientId=producer-1] Overriding the default retries config to the recommended value of 2147483647 since the idempotent producer is enabled.
2018-06-21 19:59:22 INFO  KafkaProducer:341 - [Producer clientId=producer-1] Overriding the default acks to all since idempotence is enabled.
2018-06-21 19:59:22 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:22 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:22 WARN  NetworkClient:246 - [Producer clientId=producer-1] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:22 INFO  TransactionManager:346 - [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
2018-06-21 19:59:23 INFO  KafkaProducer:341 - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:23 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:37203]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 85c39327-8894-4a56-8c15-f813c8f2ac10
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:23 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:23 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:23 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-1, groupId=85c39327-8894-4a56-8c15-f813c8f2ac10] Discovered coordinator spirals-vortex.lille.inria.fr:37203 (id: 2147482646 rack: null)
2018-06-21 19:59:23 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-1, groupId=85c39327-8894-4a56-8c15-f813c8f2ac10] Revoking previously assigned partitions []
2018-06-21 19:59:23 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-1, groupId=85c39327-8894-4a56-8c15-f813c8f2ac10] (Re-)joining group
2018-06-21 19:59:23 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-1, groupId=85c39327-8894-4a56-8c15-f813c8f2ac10] Successfully joined group with generation 1
2018-06-21 19:59:23 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-1, groupId=85c39327-8894-4a56-8c15-f813c8f2ac10] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:23 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:24 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@30ed9c6c. This directory contains Kafka logs as well.
2018-06-21 19:59:24 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:24 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:39371 is stopping.
2018-06-21 19:59:24 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:39371 has been shut down.
2018-06-21 19:59:24 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:24 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:38326 which is assigned to the temporary directory /tmp/1529603964928-0.
2018-06-21 19:59:24 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:24 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit9073158811044311226/junit8340335324557824678/meta.properties
2018-06-21 19:59:25 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit9073158811044311226/junit8340335324557824678/meta.properties
2018-06-21 19:59:25 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:25 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:25 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit9073158811044311226/junit8340335324557824678.
2018-06-21 19:59:25 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:45008]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = 8ecd4a99-b32e-409a-ad9f-5b932f0da905
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:25 INFO  KafkaProducer:336 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] Instantiated a transactional producer.
2018-06-21 19:59:25 INFO  KafkaProducer:341 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] Overriding the default acks to all since idempotence is enabled.
2018-06-21 19:59:25 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:25 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:25 INFO  TransactionManager:346 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] ProducerId set to -1 with epoch -1
2018-06-21 19:59:25 INFO  TransactionManager:346 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] ProducerId set to 0 with epoch 0
2018-06-21 19:59:25 WARN  NetworkClient:246 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] Error while fetching metadata with correlation id 8 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:25 INFO  KafkaProducer:341 - [Producer clientId=producer-2, transactionalId=8ecd4a99-b32e-409a-ad9f-5b932f0da905] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:25 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:45008]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:25 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:25 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:26 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-2, groupId=8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd] Discovered coordinator spirals-vortex.lille.inria.fr:45008 (id: 2147482646 rack: null)
2018-06-21 19:59:26 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-2, groupId=8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd] Revoking previously assigned partitions []
2018-06-21 19:59:26 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-2, groupId=8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd] (Re-)joining group
2018-06-21 19:59:26 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-2, groupId=8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd] Successfully joined group with generation 1
2018-06-21 19:59:26 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-2, groupId=8b643fdb-53e2-40d0-992c-bcbbe5e5b1cd] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:26 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:27 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@59a67c3a. This directory contains Kafka logs as well.
2018-06-21 19:59:27 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:27 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:38326 is stopping.
2018-06-21 19:59:27 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:38326 has been shut down.
2018-06-21 19:59:27 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:27 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:42784 which is assigned to the temporary directory /tmp/1529603967800-0.
2018-06-21 19:59:27 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:27 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8901114627959197564/junit7635920759561331201/meta.properties
2018-06-21 19:59:27 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8901114627959197564/junit7635920759561331201/meta.properties
2018-06-21 19:59:27 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:27 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:27 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit8901114627959197564/junit7635920759561331201.
2018-06-21 19:59:27 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:45545]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:27 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:27 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:27 WARN  NetworkClient:246 - [Producer clientId=producer-3] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:28 INFO  KafkaProducer:341 - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:28 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:45545]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = d42ac759-7ea9-462b-983b-c594210173f0
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:28 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:28 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:28 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-3, groupId=d42ac759-7ea9-462b-983b-c594210173f0] Discovered coordinator spirals-vortex.lille.inria.fr:45545 (id: 2147482646 rack: null)
2018-06-21 19:59:28 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-3, groupId=d42ac759-7ea9-462b-983b-c594210173f0] Revoking previously assigned partitions []
2018-06-21 19:59:28 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-3, groupId=d42ac759-7ea9-462b-983b-c594210173f0] (Re-)joining group
2018-06-21 19:59:28 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-3, groupId=d42ac759-7ea9-462b-983b-c594210173f0] Successfully joined group with generation 1
2018-06-21 19:59:28 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-3, groupId=d42ac759-7ea9-462b-983b-c594210173f0] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:28 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:29 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@411341bd. This directory contains Kafka logs as well.
2018-06-21 19:59:29 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:29 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:42784 is stopping.
2018-06-21 19:59:29 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:42784 has been shut down.
2018-06-21 19:59:29 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:29 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:40091 which is assigned to the temporary directory /tmp/1529603969142-0.
2018-06-21 19:59:29 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:29 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8746547909418683635/junit8439069019678424501/meta.properties
2018-06-21 19:59:29 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8746547909418683635/junit8439069019678424501/meta.properties
2018-06-21 19:59:29 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:29 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:29 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit8746547909418683635/junit8439069019678424501.
2018-06-21 19:59:29 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:34155]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:29 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:29 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:29 WARN  NetworkClient:246 - [Producer clientId=producer-4] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:29 INFO  KafkaProducer:341 - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:29 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:34155]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 63d76156-241b-43fd-b441-f23ddb6dd217
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:29 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:29 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:29 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-4, groupId=63d76156-241b-43fd-b441-f23ddb6dd217] Discovered coordinator spirals-vortex.lille.inria.fr:34155 (id: 2147482646 rack: null)
2018-06-21 19:59:29 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-4, groupId=63d76156-241b-43fd-b441-f23ddb6dd217] Revoking previously assigned partitions []
2018-06-21 19:59:29 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-4, groupId=63d76156-241b-43fd-b441-f23ddb6dd217] (Re-)joining group
2018-06-21 19:59:29 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-4, groupId=63d76156-241b-43fd-b441-f23ddb6dd217] Successfully joined group with generation 1
2018-06-21 19:59:29 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-4, groupId=63d76156-241b-43fd-b441-f23ddb6dd217] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:29 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:30 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@fac80. This directory contains Kafka logs as well.
2018-06-21 19:59:30 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:30 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:40091 is stopping.
2018-06-21 19:59:30 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:40091 has been shut down.
2018-06-21 19:59:30 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:30 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:43365 which is assigned to the temporary directory /tmp/1529603970978-0.
2018-06-21 19:59:30 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:30 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit5461654563146395573/junit5498883280736662222/meta.properties
2018-06-21 19:59:31 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit5461654563146395573/junit5498883280736662222/meta.properties
2018-06-21 19:59:31 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:31 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:31 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit5461654563146395573/junit5498883280736662222.
2018-06-21 19:59:31 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:42517]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:31 INFO  KafkaProducer:336 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] Instantiated a transactional producer.
2018-06-21 19:59:31 INFO  KafkaProducer:341 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] Overriding the default acks to all since idempotence is enabled.
2018-06-21 19:59:31 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:31 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:31 INFO  TransactionManager:346 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] ProducerId set to -1 with epoch -1
2018-06-21 19:59:31 INFO  TransactionManager:346 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] ProducerId set to 0 with epoch 0
2018-06-21 19:59:31 WARN  NetworkClient:246 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] Error while fetching metadata with correlation id 6 : {test-topic-1=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:31 WARN  NetworkClient:246 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] Error while fetching metadata with correlation id 11 : {test-topic-2=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:31 INFO  KafkaProducer:341 - [Producer clientId=producer-5, transactionalId=e5ea1768-f4a8-4bea-a14a-b74e1e6ecb7c] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:31 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:42517]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f9df4d15-341f-4a82-9319-c2ff59347cae
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:31 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:31 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:32 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-5, groupId=f9df4d15-341f-4a82-9319-c2ff59347cae] Discovered coordinator spirals-vortex.lille.inria.fr:42517 (id: 2147482646 rack: null)
2018-06-21 19:59:32 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-5, groupId=f9df4d15-341f-4a82-9319-c2ff59347cae] Revoking previously assigned partitions []
2018-06-21 19:59:32 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-5, groupId=f9df4d15-341f-4a82-9319-c2ff59347cae] (Re-)joining group
2018-06-21 19:59:32 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-5, groupId=f9df4d15-341f-4a82-9319-c2ff59347cae] Successfully joined group with generation 1
2018-06-21 19:59:32 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-5, groupId=f9df4d15-341f-4a82-9319-c2ff59347cae] Setting newly assigned partitions [test-topic-1-0]
2018-06-21 19:59:32 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:42517]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 99f622e6-bf60-43e0-81f0-f08196cd90b1
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:32 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:32 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:32 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-6, groupId=99f622e6-bf60-43e0-81f0-f08196cd90b1] Discovered coordinator spirals-vortex.lille.inria.fr:42517 (id: 2147482646 rack: null)
2018-06-21 19:59:32 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-6, groupId=99f622e6-bf60-43e0-81f0-f08196cd90b1] Revoking previously assigned partitions []
2018-06-21 19:59:32 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-6, groupId=99f622e6-bf60-43e0-81f0-f08196cd90b1] (Re-)joining group
2018-06-21 19:59:32 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-6, groupId=99f622e6-bf60-43e0-81f0-f08196cd90b1] Successfully joined group with generation 1
2018-06-21 19:59:32 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-6, groupId=99f622e6-bf60-43e0-81f0-f08196cd90b1] Setting newly assigned partitions [test-topic-2-0]
2018-06-21 19:59:32 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:33 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@4cc61eb1. This directory contains Kafka logs as well.
2018-06-21 19:59:33 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:33 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:43365 is stopping.
2018-06-21 19:59:33 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:43365 has been shut down.
2018-06-21 19:59:33 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:33 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:45722 which is assigned to the temporary directory /tmp/1529603973355-0.
2018-06-21 19:59:33 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:33 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3577184896458184242/junit644158217570716372/meta.properties
2018-06-21 19:59:33 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3577184896458184242/junit644158217570716372/meta.properties
2018-06-21 19:59:33 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:33 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:33 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit3577184896458184242/junit644158217570716372.
2018-06-21 19:59:33 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:40151]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:33 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:33 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:33 WARN  NetworkClient:246 - [Producer clientId=producer-6] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:33 INFO  KafkaProducer:341 - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:33 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:40151]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 2ced6653-c8b6-4451-b933-fa5d53f8260f
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:33 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:33 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:34 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-7, groupId=2ced6653-c8b6-4451-b933-fa5d53f8260f] Discovered coordinator spirals-vortex.lille.inria.fr:40151 (id: 2147482646 rack: null)
2018-06-21 19:59:34 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-7, groupId=2ced6653-c8b6-4451-b933-fa5d53f8260f] Revoking previously assigned partitions []
2018-06-21 19:59:34 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-7, groupId=2ced6653-c8b6-4451-b933-fa5d53f8260f] (Re-)joining group
2018-06-21 19:59:34 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-7, groupId=2ced6653-c8b6-4451-b933-fa5d53f8260f] Successfully joined group with generation 1
2018-06-21 19:59:34 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-7, groupId=2ced6653-c8b6-4451-b933-fa5d53f8260f] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:35 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:36 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@32c0915e. This directory contains Kafka logs as well.
2018-06-21 19:59:36 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:36 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:45722 is stopping.
2018-06-21 19:59:36 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:45722 has been shut down.
2018-06-21 19:59:36 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:36 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:35375 which is assigned to the temporary directory /tmp/1529603976726-0.
2018-06-21 19:59:36 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:36 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit2353333054463260872/junit8181193994474009439/meta.properties
2018-06-21 19:59:36 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit2353333054463260872/junit8181193994474009439/meta.properties
2018-06-21 19:59:36 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:36 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:36 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit2353333054463260872/junit8181193994474009439.
2018-06-21 19:59:36 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:35291]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = true
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = 86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:36 INFO  KafkaProducer:336 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] Instantiated a transactional producer.
2018-06-21 19:59:36 INFO  KafkaProducer:341 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] Overriding the default acks to all since idempotence is enabled.
2018-06-21 19:59:36 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:36 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:36 INFO  TransactionManager:346 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] ProducerId set to -1 with epoch -1
2018-06-21 19:59:37 INFO  TransactionManager:346 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] ProducerId set to 0 with epoch 0
2018-06-21 19:59:37 WARN  NetworkClient:246 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] Error while fetching metadata with correlation id 6 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:37 INFO  KafkaProducer:341 - [Producer clientId=producer-7, transactionalId=86fb15ba-8d48-4dc0-8d64-ebca8fb8ec83] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:37 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:35291]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 238d1366-711b-4b27-a386-52c0dea17506
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:37 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:37 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:37 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-8, groupId=238d1366-711b-4b27-a386-52c0dea17506] Discovered coordinator spirals-vortex.lille.inria.fr:35291 (id: 2147482646 rack: null)
2018-06-21 19:59:37 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-8, groupId=238d1366-711b-4b27-a386-52c0dea17506] Revoking previously assigned partitions []
2018-06-21 19:59:37 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-8, groupId=238d1366-711b-4b27-a386-52c0dea17506] (Re-)joining group
2018-06-21 19:59:37 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-8, groupId=238d1366-711b-4b27-a386-52c0dea17506] Successfully joined group with generation 1
2018-06-21 19:59:37 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-8, groupId=238d1366-711b-4b27-a386-52c0dea17506] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:37 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:38 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@704b2127. This directory contains Kafka logs as well.
2018-06-21 19:59:38 WARN  NIOServerCnxn:368 - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x16423806e180000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:239)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203)
	at java.lang.Thread.run(Thread.java:745)
2018-06-21 19:59:38 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:38 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:35375 is stopping.
2018-06-21 19:59:38 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:35375 has been shut down.
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 17.143 sec
Running net.mguenther.kafka.junit.RecordConsumerTest
2018-06-21 19:59:38 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:38 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:39161 which is assigned to the temporary directory /tmp/1529603978251-0.
2018-06-21 19:59:38 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8080163182715872010/junit5678858084660306452/meta.properties
2018-06-21 19:59:38 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit8080163182715872010/junit5678858084660306452/meta.properties
2018-06-21 19:59:38 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:38 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:38 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit8080163182715872010/junit5678858084660306452.
2018-06-21 19:59:38 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:44807]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:38 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:38 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:38 WARN  NetworkClient:246 - [Producer clientId=producer-8] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:38 INFO  KafkaProducer:341 - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:38 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:44807]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bd7f9a35-94b4-4801-9479-c366abda684b
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:38 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:38 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:38 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-9, groupId=bd7f9a35-94b4-4801-9479-c366abda684b] Discovered coordinator spirals-vortex.lille.inria.fr:44807 (id: 2147482646 rack: null)
2018-06-21 19:59:38 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-9, groupId=bd7f9a35-94b4-4801-9479-c366abda684b] Revoking previously assigned partitions []
2018-06-21 19:59:38 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-9, groupId=bd7f9a35-94b4-4801-9479-c366abda684b] (Re-)joining group
2018-06-21 19:59:38 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-9, groupId=bd7f9a35-94b4-4801-9479-c366abda684b] Successfully joined group with generation 1
2018-06-21 19:59:38 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-9, groupId=bd7f9a35-94b4-4801-9479-c366abda684b] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:40 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:42 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@232024b9. This directory contains Kafka logs as well.
2018-06-21 19:59:42 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:42 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:39161 is stopping.
2018-06-21 19:59:42 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:39161 has been shut down.
2018-06-21 19:59:42 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:42 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:42498 which is assigned to the temporary directory /tmp/1529603982868-0.
2018-06-21 19:59:42 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:42 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3904673738683645103/junit470646693823403521/meta.properties
2018-06-21 19:59:42 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3904673738683645103/junit470646693823403521/meta.properties
2018-06-21 19:59:42 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:42 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:42 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit3904673738683645103/junit470646693823403521.
2018-06-21 19:59:42 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:40137]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:42 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:42 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:42 WARN  NetworkClient:246 - [Producer clientId=producer-9] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:43 INFO  KafkaProducer:341 - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:43 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:40137]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 9423a60b-49ff-45be-b903-ba197fffb1d4
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:43 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:43 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:43 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-10, groupId=9423a60b-49ff-45be-b903-ba197fffb1d4] Discovered coordinator spirals-vortex.lille.inria.fr:40137 (id: 2147482646 rack: null)
2018-06-21 19:59:43 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-10, groupId=9423a60b-49ff-45be-b903-ba197fffb1d4] Revoking previously assigned partitions []
2018-06-21 19:59:43 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-10, groupId=9423a60b-49ff-45be-b903-ba197fffb1d4] (Re-)joining group
2018-06-21 19:59:43 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-10, groupId=9423a60b-49ff-45be-b903-ba197fffb1d4] Successfully joined group with generation 1
2018-06-21 19:59:43 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-10, groupId=9423a60b-49ff-45be-b903-ba197fffb1d4] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:45 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:46 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@6a078481. This directory contains Kafka logs as well.
2018-06-21 19:59:46 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:46 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:42498 is stopping.
2018-06-21 19:59:46 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:42498 has been shut down.
2018-06-21 19:59:46 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:46 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:35896 which is assigned to the temporary directory /tmp/1529603986594-0.
2018-06-21 19:59:46 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:46 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3525249461223639539/junit1887455874121920290/meta.properties
2018-06-21 19:59:46 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit3525249461223639539/junit1887455874121920290/meta.properties
2018-06-21 19:59:46 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:46 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:46 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit3525249461223639539/junit1887455874121920290.
2018-06-21 19:59:46 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:46289]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:46 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:46 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:46 WARN  NetworkClient:246 - [Producer clientId=producer-10] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:46 INFO  KafkaProducer:341 - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:46 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:46289]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 1bfa1991-5c4c-42c5-87be-8c0e493229cd
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:46 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:46 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:47 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-11, groupId=1bfa1991-5c4c-42c5-87be-8c0e493229cd] Discovered coordinator spirals-vortex.lille.inria.fr:46289 (id: 2147482646 rack: null)
2018-06-21 19:59:47 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-11, groupId=1bfa1991-5c4c-42c5-87be-8c0e493229cd] Revoking previously assigned partitions []
2018-06-21 19:59:47 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-11, groupId=1bfa1991-5c4c-42c5-87be-8c0e493229cd] (Re-)joining group
2018-06-21 19:59:47 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-11, groupId=1bfa1991-5c4c-42c5-87be-8c0e493229cd] Successfully joined group with generation 1
2018-06-21 19:59:47 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-11, groupId=1bfa1991-5c4c-42c5-87be-8c0e493229cd] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:47 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:48 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@c7a977f. This directory contains Kafka logs as well.
2018-06-21 19:59:48 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:48 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:35896 is stopping.
2018-06-21 19:59:48 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:35896 has been shut down.
2018-06-21 19:59:48 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:48 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:45128 which is assigned to the temporary directory /tmp/1529603988404-0.
2018-06-21 19:59:48 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4757316151636284081/junit7158417681999201858/meta.properties
2018-06-21 19:59:48 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4757316151636284081/junit7158417681999201858/meta.properties
2018-06-21 19:59:48 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:48 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:48 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit4757316151636284081/junit7158417681999201858.
2018-06-21 19:59:48 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:38159]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:48 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:48 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:48 WARN  NetworkClient:246 - [Producer clientId=producer-11] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:48 INFO  KafkaProducer:341 - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:48 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:38159]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

2018-06-21 19:59:48 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:48 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:48 WARN  NetworkClient:246 - [Producer clientId=producer-12] Error while fetching metadata with correlation id 1 : {test-topic-key-value-types=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:48 INFO  KafkaProducer:341 - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:48 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:38159]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = f054bb43-92f0-4c39-8f07-44354dba921b
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer

2018-06-21 19:59:48 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:48 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:49 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-12, groupId=f054bb43-92f0-4c39-8f07-44354dba921b] Discovered coordinator spirals-vortex.lille.inria.fr:38159 (id: 2147482646 rack: null)
2018-06-21 19:59:49 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-12, groupId=f054bb43-92f0-4c39-8f07-44354dba921b] Revoking previously assigned partitions []
2018-06-21 19:59:49 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-12, groupId=f054bb43-92f0-4c39-8f07-44354dba921b] (Re-)joining group
2018-06-21 19:59:49 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-12, groupId=f054bb43-92f0-4c39-8f07-44354dba921b] Successfully joined group with generation 1
2018-06-21 19:59:49 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-12, groupId=f054bb43-92f0-4c39-8f07-44354dba921b] Setting newly assigned partitions [test-topic-key-value-types-0]
2018-06-21 19:59:49 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:50 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@99a65d3. This directory contains Kafka logs as well.
2018-06-21 19:59:50 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:50 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:45128 is stopping.
2018-06-21 19:59:50 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:45128 has been shut down.
2018-06-21 19:59:50 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:50 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:33228 which is assigned to the temporary directory /tmp/1529603990143-0.
2018-06-21 19:59:50 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit6205613403777123631/junit4541566682907022688/meta.properties
2018-06-21 19:59:50 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit6205613403777123631/junit4541566682907022688/meta.properties
2018-06-21 19:59:50 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:50 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:50 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit6205613403777123631/junit4541566682907022688.
2018-06-21 19:59:50 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:43114]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:50 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:50 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:50 WARN  NetworkClient:246 - [Producer clientId=producer-13] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:50 INFO  KafkaProducer:341 - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:50 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:43114]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.IntegerSerializer

2018-06-21 19:59:50 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:50 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:50 WARN  NetworkClient:246 - [Producer clientId=producer-14] Error while fetching metadata with correlation id 1 : {test-topic-key-value-filter=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:50 INFO  KafkaProducer:341 - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:50 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:43114]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b4c6acc9-fb5d-431c-8311-8ff311147bd8
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 19:59:50 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:50 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:50 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-13, groupId=b4c6acc9-fb5d-431c-8311-8ff311147bd8] Discovered coordinator spirals-vortex.lille.inria.fr:43114 (id: 2147482646 rack: null)
2018-06-21 19:59:50 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-13, groupId=b4c6acc9-fb5d-431c-8311-8ff311147bd8] Revoking previously assigned partitions []
2018-06-21 19:59:50 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-13, groupId=b4c6acc9-fb5d-431c-8311-8ff311147bd8] (Re-)joining group
2018-06-21 19:59:50 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-13, groupId=b4c6acc9-fb5d-431c-8311-8ff311147bd8] Successfully joined group with generation 1
2018-06-21 19:59:50 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-13, groupId=b4c6acc9-fb5d-431c-8311-8ff311147bd8] Setting newly assigned partitions [test-topic-key-value-filter-0]
2018-06-21 19:59:50 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:51 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@2fb5fe30. This directory contains Kafka logs as well.
2018-06-21 19:59:51 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:51 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:33228 is stopping.
2018-06-21 19:59:51 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:33228 has been shut down.
2018-06-21 19:59:51 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:51 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:42684 which is assigned to the temporary directory /tmp/1529603991927-0.
2018-06-21 19:59:51 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:51 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit6427333716173571296/junit7669079506895795792/meta.properties
2018-06-21 19:59:52 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit6427333716173571296/junit7669079506895795792/meta.properties
2018-06-21 19:59:52 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:52 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:52 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit6427333716173571296/junit7669079506895795792.
2018-06-21 19:59:52 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:44223]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:52 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:52 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:52 WARN  NetworkClient:246 - [Producer clientId=producer-15] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:52 INFO  KafkaProducer:341 - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:52 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:44223]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

2018-06-21 19:59:52 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:52 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:52 WARN  NetworkClient:246 - [Producer clientId=producer-16] Error while fetching metadata with correlation id 1 : {test-topic-value-types=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:52 INFO  KafkaProducer:341 - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:52 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:44223]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ec65358b-6c05-46f0-8a1e-2b80d390c744
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer

2018-06-21 19:59:52 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:52 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:53 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-14, groupId=ec65358b-6c05-46f0-8a1e-2b80d390c744] Discovered coordinator spirals-vortex.lille.inria.fr:44223 (id: 2147482646 rack: null)
2018-06-21 19:59:53 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-14, groupId=ec65358b-6c05-46f0-8a1e-2b80d390c744] Revoking previously assigned partitions []
2018-06-21 19:59:53 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-14, groupId=ec65358b-6c05-46f0-8a1e-2b80d390c744] (Re-)joining group
2018-06-21 19:59:53 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-14, groupId=ec65358b-6c05-46f0-8a1e-2b80d390c744] Successfully joined group with generation 1
2018-06-21 19:59:53 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-14, groupId=ec65358b-6c05-46f0-8a1e-2b80d390c744] Setting newly assigned partitions [test-topic-value-types-0]
2018-06-21 19:59:53 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 19:59:57 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@7c2a69b4. This directory contains Kafka logs as well.
2018-06-21 19:59:57 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 19:59:57 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:42684 is stopping.
2018-06-21 19:59:57 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:42684 has been shut down.
2018-06-21 19:59:57 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 19:59:57 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:37967 which is assigned to the temporary directory /tmp/1529603997268-0.
2018-06-21 19:59:57 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 19:59:57 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit5019492070230100439/junit642385124112413613/meta.properties
2018-06-21 19:59:57 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit5019492070230100439/junit642385124112413613/meta.properties
2018-06-21 19:59:57 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:57 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:57 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit5019492070230100439/junit642385124112413613.
2018-06-21 19:59:57 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:45109]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 19:59:57 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:57 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:57 WARN  NetworkClient:246 - [Producer clientId=producer-17] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 19:59:57 INFO  KafkaProducer:341 - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 19:59:57 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:45109]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fa73cb93-5905-4bbe-ad8f-57eef90a6d30
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:57 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:57 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:57 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-15, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Discovered coordinator spirals-vortex.lille.inria.fr:45109 (id: 2147482646 rack: null)
2018-06-21 19:59:57 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-15, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Revoking previously assigned partitions []
2018-06-21 19:59:57 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-15, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] (Re-)joining group
2018-06-21 19:59:57 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-15, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Successfully joined group with generation 1
2018-06-21 19:59:57 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-15, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Setting newly assigned partitions [test-topic-0]
2018-06-21 19:59:59 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:45109]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fa73cb93-5905-4bbe-ad8f-57eef90a6d30
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 19:59:59 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 19:59:59 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 19:59:59 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-16, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Discovered coordinator spirals-vortex.lille.inria.fr:45109 (id: 2147482646 rack: null)
2018-06-21 19:59:59 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-16, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Revoking previously assigned partitions []
2018-06-21 19:59:59 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-16, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] (Re-)joining group
2018-06-21 19:59:59 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-16, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Successfully joined group with generation 3
2018-06-21 19:59:59 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-16, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Setting newly assigned partitions [test-topic-0]
2018-06-21 20:00:01 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:45109]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = fa73cb93-5905-4bbe-ad8f-57eef90a6d30
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-06-21 20:00:01 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:01 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:01 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-17, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Discovered coordinator spirals-vortex.lille.inria.fr:45109 (id: 2147482646 rack: null)
2018-06-21 20:00:01 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-17, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Revoking previously assigned partitions []
2018-06-21 20:00:01 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-17, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] (Re-)joining group
2018-06-21 20:00:01 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-17, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Successfully joined group with generation 5
2018-06-21 20:00:01 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-17, groupId=fa73cb93-5905-4bbe-ad8f-57eef90a6d30] Setting newly assigned partitions [test-topic-0]
2018-06-21 20:00:03 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:05 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@1dab9dd6. This directory contains Kafka logs as well.
2018-06-21 20:00:05 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:05 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:37967 is stopping.
2018-06-21 20:00:05 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:37967 has been shut down.
2018-06-21 20:00:05 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:05 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:45065 which is assigned to the temporary directory /tmp/1529604005030-0.
2018-06-21 20:00:05 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:05 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7927897002379468845/junit7141483668728523203/meta.properties
2018-06-21 20:00:05 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7927897002379468845/junit7141483668728523203/meta.properties
2018-06-21 20:00:05 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:05 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:05 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit7927897002379468845/junit7141483668728523203.
2018-06-21 20:00:05 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:38021]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:05 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:05 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:05 WARN  NetworkClient:246 - [Producer clientId=producer-18] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:05 INFO  KafkaProducer:341 - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:05 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:38021]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

2018-06-21 20:00:05 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:05 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:05 WARN  NetworkClient:246 - [Producer clientId=producer-19] Error while fetching metadata with correlation id 1 : {test-topic-value-types=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:05 INFO  KafkaProducer:341 - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:05 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:38021]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = bf6f9052-cdb1-4959-acfd-b5ab89065a51
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer

2018-06-21 20:00:05 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:05 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:05 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-18, groupId=bf6f9052-cdb1-4959-acfd-b5ab89065a51] Discovered coordinator spirals-vortex.lille.inria.fr:38021 (id: 2147482646 rack: null)
2018-06-21 20:00:05 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-18, groupId=bf6f9052-cdb1-4959-acfd-b5ab89065a51] Revoking previously assigned partitions []
2018-06-21 20:00:05 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-18, groupId=bf6f9052-cdb1-4959-acfd-b5ab89065a51] (Re-)joining group
2018-06-21 20:00:05 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-18, groupId=bf6f9052-cdb1-4959-acfd-b5ab89065a51] Successfully joined group with generation 1
2018-06-21 20:00:05 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-18, groupId=bf6f9052-cdb1-4959-acfd-b5ab89065a51] Setting newly assigned partitions [test-topic-value-types-0]
2018-06-21 20:00:07 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:08 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@27aae97b. This directory contains Kafka logs as well.
2018-06-21 20:00:08 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:08 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:45065 is stopping.
2018-06-21 20:00:08 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:45065 has been shut down.
2018-06-21 20:00:08 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:08 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:43189 which is assigned to the temporary directory /tmp/1529604008739-0.
2018-06-21 20:00:08 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:08 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7668838179740813054/junit7451285937640513945/meta.properties
2018-06-21 20:00:08 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7668838179740813054/junit7451285937640513945/meta.properties
2018-06-21 20:00:08 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:08 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:08 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit7668838179740813054/junit7451285937640513945.
2018-06-21 20:00:08 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:43190]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:08 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:08 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:08 WARN  NetworkClient:246 - [Producer clientId=producer-20] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:08 INFO  KafkaProducer:341 - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:08 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:43190]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.IntegerSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.LongSerializer

2018-06-21 20:00:08 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:08 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:08 WARN  NetworkClient:246 - [Producer clientId=producer-21] Error while fetching metadata with correlation id 1 : {test-topic-key-value-types=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:09 INFO  KafkaProducer:341 - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:09 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:43190]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 26067c20-8a06-4d06-9d63-e28cfce90112
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.LongDeserializer

2018-06-21 20:00:09 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:09 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:09 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-19, groupId=26067c20-8a06-4d06-9d63-e28cfce90112] Discovered coordinator spirals-vortex.lille.inria.fr:43190 (id: 2147482646 rack: null)
2018-06-21 20:00:09 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-19, groupId=26067c20-8a06-4d06-9d63-e28cfce90112] Revoking previously assigned partitions []
2018-06-21 20:00:09 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-19, groupId=26067c20-8a06-4d06-9d63-e28cfce90112] (Re-)joining group
2018-06-21 20:00:09 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-19, groupId=26067c20-8a06-4d06-9d63-e28cfce90112] Successfully joined group with generation 1
2018-06-21 20:00:09 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-19, groupId=26067c20-8a06-4d06-9d63-e28cfce90112] Setting newly assigned partitions [test-topic-key-value-types-0]
2018-06-21 20:00:11 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:13 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@5965844d. This directory contains Kafka logs as well.
2018-06-21 20:00:13 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:13 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:43189 is stopping.
2018-06-21 20:00:13 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:43189 has been shut down.
2018-06-21 20:00:13 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:13 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:41095 which is assigned to the temporary directory /tmp/1529604013437-0.
2018-06-21 20:00:13 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:13 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7184443818877275939/junit1779554372666350126/meta.properties
2018-06-21 20:00:13 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit7184443818877275939/junit1779554372666350126/meta.properties
2018-06-21 20:00:13 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:13 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:13 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit7184443818877275939/junit1779554372666350126.
2018-06-21 20:00:13 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:40452]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:13 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:13 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:13 WARN  NetworkClient:246 - [Producer clientId=producer-22] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:13 INFO  KafkaProducer:341 - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:13 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:40452]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.IntegerSerializer

2018-06-21 20:00:13 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:13 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:13 WARN  NetworkClient:246 - [Producer clientId=producer-23] Error while fetching metadata with correlation id 1 : {test-topic-key-value-filter=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:13 INFO  KafkaProducer:341 - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:13 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:40452]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 4cded241-9d6d-46e4-aae5-e321559dea61
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:13 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:13 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:14 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-20, groupId=4cded241-9d6d-46e4-aae5-e321559dea61] Discovered coordinator spirals-vortex.lille.inria.fr:40452 (id: 2147482646 rack: null)
2018-06-21 20:00:14 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-20, groupId=4cded241-9d6d-46e4-aae5-e321559dea61] Revoking previously assigned partitions []
2018-06-21 20:00:14 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-20, groupId=4cded241-9d6d-46e4-aae5-e321559dea61] (Re-)joining group
2018-06-21 20:00:14 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-20, groupId=4cded241-9d6d-46e4-aae5-e321559dea61] Successfully joined group with generation 1
2018-06-21 20:00:14 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-20, groupId=4cded241-9d6d-46e4-aae5-e321559dea61] Setting newly assigned partitions [test-topic-key-value-filter-0]
2018-06-21 20:00:16 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:17 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@28d79cba. This directory contains Kafka logs as well.
2018-06-21 20:00:17 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:17 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:41095 is stopping.
2018-06-21 20:00:17 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:41095 has been shut down.
2018-06-21 20:00:17 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:17 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:44691 which is assigned to the temporary directory /tmp/1529604017212-0.
2018-06-21 20:00:17 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:17 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit2269090280647064808/junit1796463379037990867/meta.properties
2018-06-21 20:00:17 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit2269090280647064808/junit1796463379037990867/meta.properties
2018-06-21 20:00:17 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:17 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:17 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit2269090280647064808/junit1796463379037990867.
2018-06-21 20:00:17 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:37383]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:17 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:17 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:17 WARN  NetworkClient:246 - [Producer clientId=producer-24] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:17 INFO  KafkaProducer:341 - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:17 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:37383]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.IntegerSerializer

2018-06-21 20:00:17 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:17 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:17 WARN  NetworkClient:246 - [Producer clientId=producer-25] Error while fetching metadata with correlation id 1 : {test-topic-value-filter=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:17 INFO  KafkaProducer:341 - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:17 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:37383]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = de5bd51f-5a8a-4f07-a5ae-b17c346b8f09
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:17 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:17 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:17 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-21, groupId=de5bd51f-5a8a-4f07-a5ae-b17c346b8f09] Discovered coordinator spirals-vortex.lille.inria.fr:37383 (id: 2147482646 rack: null)
2018-06-21 20:00:17 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-21, groupId=de5bd51f-5a8a-4f07-a5ae-b17c346b8f09] Revoking previously assigned partitions []
2018-06-21 20:00:17 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-21, groupId=de5bd51f-5a8a-4f07-a5ae-b17c346b8f09] (Re-)joining group
2018-06-21 20:00:17 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-21, groupId=de5bd51f-5a8a-4f07-a5ae-b17c346b8f09] Successfully joined group with generation 1
2018-06-21 20:00:17 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-21, groupId=de5bd51f-5a8a-4f07-a5ae-b17c346b8f09] Setting newly assigned partitions [test-topic-value-filter-0]
2018-06-21 20:00:19 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:20 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@6be25526. This directory contains Kafka logs as well.
2018-06-21 20:00:20 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:20 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:44691 is stopping.
2018-06-21 20:00:20 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:44691 has been shut down.
2018-06-21 20:00:20 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:20 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:41860 which is assigned to the temporary directory /tmp/1529604020747-0.
2018-06-21 20:00:20 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:20 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4192652856694493934/junit8307630870801429247/meta.properties
2018-06-21 20:00:20 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4192652856694493934/junit8307630870801429247/meta.properties
2018-06-21 20:00:20 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:20 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:20 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit4192652856694493934/junit8307630870801429247.
2018-06-21 20:00:20 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:34091]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:20 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:20 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:20 WARN  NetworkClient:246 - [Producer clientId=producer-26] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:20 INFO  KafkaProducer:341 - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:20 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:34091]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.IntegerSerializer

2018-06-21 20:00:20 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:20 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:20 WARN  NetworkClient:246 - [Producer clientId=producer-27] Error while fetching metadata with correlation id 1 : {test-topic-key-value-filter=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:21 INFO  KafkaProducer:341 - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:21 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:34091]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b7f36da7-f16c-4caf-976c-43f9a4de8b73
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:21 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:21 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:21 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-22, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Discovered coordinator spirals-vortex.lille.inria.fr:34091 (id: 2147482646 rack: null)
2018-06-21 20:00:21 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-22, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Revoking previously assigned partitions []
2018-06-21 20:00:21 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-22, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] (Re-)joining group
2018-06-21 20:00:21 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-22, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Successfully joined group with generation 1
2018-06-21 20:00:21 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-22, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Setting newly assigned partitions [test-topic-key-value-filter-0]
2018-06-21 20:00:23 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:34091]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b7f36da7-f16c-4caf-976c-43f9a4de8b73
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:23 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:23 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:23 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-23, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Discovered coordinator spirals-vortex.lille.inria.fr:34091 (id: 2147482646 rack: null)
2018-06-21 20:00:23 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-23, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Revoking previously assigned partitions []
2018-06-21 20:00:23 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-23, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] (Re-)joining group
2018-06-21 20:00:23 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-23, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Successfully joined group with generation 3
2018-06-21 20:00:23 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-23, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Setting newly assigned partitions [test-topic-key-value-filter-0]
2018-06-21 20:00:25 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:34091]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = b7f36da7-f16c-4caf-976c-43f9a4de8b73
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:25 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:25 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:25 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-24, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Discovered coordinator spirals-vortex.lille.inria.fr:34091 (id: 2147482646 rack: null)
2018-06-21 20:00:25 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-24, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Revoking previously assigned partitions []
2018-06-21 20:00:25 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-24, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] (Re-)joining group
2018-06-21 20:00:25 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-24, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Successfully joined group with generation 5
2018-06-21 20:00:25 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-24, groupId=b7f36da7-f16c-4caf-976c-43f9a4de8b73] Setting newly assigned partitions [test-topic-key-value-filter-0]
2018-06-21 20:00:27 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:30 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@67c277a0. This directory contains Kafka logs as well.
2018-06-21 20:00:30 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:30 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:41860 is stopping.
2018-06-21 20:00:30 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:41860 has been shut down.
2018-06-21 20:00:30 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:30 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:39435 which is assigned to the temporary directory /tmp/1529604030295-0.
2018-06-21 20:00:30 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:30 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4364625488331728392/junit2584602425081128974/meta.properties
2018-06-21 20:00:30 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit4364625488331728392/junit2584602425081128974/meta.properties
2018-06-21 20:00:30 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:30 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:30 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit4364625488331728392/junit2584602425081128974.
2018-06-21 20:00:30 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:33135]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2018-06-21 20:00:30 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:30 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:30 WARN  NetworkClient:246 - [Producer clientId=producer-28] Error while fetching metadata with correlation id 1 : {test-topic=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:30 INFO  KafkaProducer:341 - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:30 INFO  ProducerConfig:223 - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [:33135]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.IntegerSerializer

2018-06-21 20:00:30 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:30 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:30 WARN  NetworkClient:246 - [Producer clientId=producer-29] Error while fetching metadata with correlation id 1 : {test-topic-key-filter=LEADER_NOT_AVAILABLE}
2018-06-21 20:00:30 INFO  KafkaProducer:341 - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2018-06-21 20:00:30 INFO  ConsumerConfig:223 - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [:33135]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 425cd033-4f1a-444c-86d4-bb1ee21b05ce
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 100
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer

2018-06-21 20:00:30 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:30 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:30 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-25, groupId=425cd033-4f1a-444c-86d4-bb1ee21b05ce] Discovered coordinator spirals-vortex.lille.inria.fr:33135 (id: 2147482646 rack: null)
2018-06-21 20:00:30 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-25, groupId=425cd033-4f1a-444c-86d4-bb1ee21b05ce] Revoking previously assigned partitions []
2018-06-21 20:00:30 INFO  AbstractCoordinator:336 - [Consumer clientId=consumer-25, groupId=425cd033-4f1a-444c-86d4-bb1ee21b05ce] (Re-)joining group
2018-06-21 20:00:30 INFO  AbstractCoordinator:341 - [Consumer clientId=consumer-25, groupId=425cd033-4f1a-444c-86d4-bb1ee21b05ce] Successfully joined group with generation 1
2018-06-21 20:00:30 INFO  ConsumerCoordinator:341 - [Consumer clientId=consumer-25, groupId=425cd033-4f1a-444c-86d4-bb1ee21b05ce] Setting newly assigned partitions [test-topic-key-filter-0]
2018-06-21 20:00:32 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:34 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@3a2b2322. This directory contains Kafka logs as well.
2018-06-21 20:00:34 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:34 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:39435 is stopping.
2018-06-21 20:00:34 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:39435 has been shut down.
Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.416 sec
Running net.mguenther.kafka.junit.SendValuesTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running net.mguenther.kafka.junit.EmbeddedConnectConfigTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running net.mguenther.kafka.junit.EmbeddedZooKeeperConfigTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running net.mguenther.kafka.junit.KeyValueTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running net.mguenther.kafka.junit.ReadKeyValuesTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running net.mguenther.kafka.junit.SendKeyValuesTransactionalTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec
Running net.mguenther.kafka.junit.ObserveKeyValuesTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running net.mguenther.kafka.junit.SendValuesTransactionalTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running net.mguenther.kafka.junit.SendKeyValuesTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running net.mguenther.kafka.junit.ExternalKafkaClusterTest
2018-06-21 20:00:34 INFO  DockerClientProviderStrategy:182 - Will use 'netty' transport
2018-06-21 20:00:45 ERROR EnvironmentAndSystemPropertyClientProviderStrategy:44 - ping failed with configuration Environment variables, system properties and defaults. Resolved: 
    dockerHost=unix:///var/run/docker.sock
    apiVersion='{UNKNOWN_VERSION}'
    registryUrl='https://index.docker.io/v1/'
    registryUsername='root'
    registryPassword='null'
    registryEmail='null'
    dockerConfig='DefaultDockerClientConfig[dockerHost=unix:///var/run/docker.sock,registryUsername=root,registryPassword=<null>,registryEmail=<null>,registryUrl=https://index.docker.io/v1/,dockerConfigPath=/root/.docker,sslConfig=<null>,apiVersion={UNKNOWN_VERSION},dockerConfig=<null>]'
 due to org.rnorth.ducttape.TimeoutException: Timeout waiting for result with exception
org.rnorth.ducttape.TimeoutException: Timeout waiting for result with exception
	at org.rnorth.ducttape.unreliables.Unreliables.retryUntilSuccess(Unreliables.java:51)
	at org.testcontainers.dockerclient.DockerClientProviderStrategy.ping(DockerClientProviderStrategy.java:189)
	at org.testcontainers.dockerclient.EnvironmentAndSystemPropertyClientProviderStrategy.test(EnvironmentAndSystemPropertyClientProviderStrategy.java:42)
	at org.testcontainers.dockerclient.DockerClientProviderStrategy.lambda$getFirstValidStrategy$2(DockerClientProviderStrategy.java:112)
	at java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:267)
	at java.util.stream.StreamSpliterators$WrappingSpliterator.tryAdvance(StreamSpliterators.java:302)
	at java.util.stream.Streams$ConcatSpliterator.tryAdvance(Streams.java:731)
	at java.util.stream.ReferencePipeline.forEachWithCancel(ReferencePipeline.java:126)
	at java.util.stream.AbstractPipeline.copyIntoWithCancel(AbstractPipeline.java:498)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:485)
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
	at java.util.stream.FindOps$FindOp.evaluateSequential(FindOps.java:152)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.util.stream.ReferencePipeline.findAny(ReferencePipeline.java:469)
	at org.testcontainers.dockerclient.DockerClientProviderStrategy.getFirstValidStrategy(DockerClientProviderStrategy.java:147)
	at org.testcontainers.DockerClientFactory.client(DockerClientFactory.java:100)
	at org.testcontainers.containers.GenericContainer.<init>(GenericContainer.java:149)
	at org.testcontainers.containers.KafkaContainer.<init>(KafkaContainer.java:27)
	at org.testcontainers.containers.KafkaContainer.<init>(KafkaContainer.java:23)
	at net.mguenther.kafka.junit.ExternalKafkaClusterTest.<init>(ExternalKafkaClusterTest.java:14)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
Caused by: org.testcontainers.shaded.io.netty.channel.AbstractChannel$AnnotatedConnectException: connect(..) failed: No such file or directory: /var/run/docker.sock
	at org.testcontainers.shaded.io.netty.channel.unix.Errors.throwConnectException(Errors.java:107)
	at org.testcontainers.shaded.io.netty.channel.unix.Socket.connect(Socket.java:243)
	at org.testcontainers.shaded.io.netty.channel.epoll.AbstractEpollStreamChannel.doConnect(AbstractEpollStreamChannel.java:734)
	at org.testcontainers.shaded.io.netty.channel.epoll.EpollDomainSocketChannel.doConnect(EpollDomainSocketChannel.java:87)
	at org.testcontainers.shaded.io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.connect(AbstractEpollStreamChannel.java:797)
	at org.testcontainers.shaded.io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1274)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)
	at org.testcontainers.shaded.io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.connect(CombinedChannelDuplexHandler.java:497)
	at org.testcontainers.shaded.io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at org.testcontainers.shaded.io.netty.channel.CombinedChannelDuplexHandler.connect(CombinedChannelDuplexHandler.java:298)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:545)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:530)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:512)
	at org.testcontainers.shaded.io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:993)
	at org.testcontainers.shaded.io.netty.channel.AbstractChannel.connect(AbstractChannel.java:255)
	at org.testcontainers.shaded.io.netty.bootstrap.Bootstrap$3.run(Bootstrap.java:252)
	at org.testcontainers.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)
	at org.testcontainers.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403)
	at org.testcontainers.shaded.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:312)
	at org.testcontainers.shaded.io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at org.testcontainers.shaded.io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: connect(..) failed: No such file or directory
	... 23 more
2018-06-21 20:00:45 ERROR DockerClientProviderStrategy:149 - Could not find a valid Docker environment. Please check configuration. Attempted configurations were:
2018-06-21 20:00:45 ERROR DockerClientProviderStrategy:151 -     EnvironmentAndSystemPropertyClientProviderStrategy: failed with exception InvalidConfigurationException (ping failed)
2018-06-21 20:00:45 ERROR DockerClientProviderStrategy:151 -     UnixSocketClientProviderStrategy: failed with exception InvalidConfigurationException (ping failed). Root cause NoSuchFileException (/var/run/docker.sock)
2018-06-21 20:00:45 ERROR DockerClientProviderStrategy:153 - As no valid configuration was found, execution cannot continue
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 10.437 sec <<< FAILURE!
externalKafkaClusterShouldWorkWithExternalResources(net.mguenther.kafka.junit.ExternalKafkaClusterTest)  Time elapsed: 0.004 sec  <<< ERROR!
java.lang.IllegalStateException: Could not find a valid Docker environment. Please see logs and check configuration
	at org.testcontainers.dockerclient.DockerClientProviderStrategy.lambda$getFirstValidStrategy$3(DockerClientProviderStrategy.java:156)
	at java.util.Optional.orElseThrow(Optional.java:290)
	at org.testcontainers.dockerclient.DockerClientProviderStrategy.getFirstValidStrategy(DockerClientProviderStrategy.java:148)
	at org.testcontainers.DockerClientFactory.client(DockerClientFactory.java:100)
	at org.testcontainers.containers.GenericContainer.<init>(GenericContainer.java:149)
	at org.testcontainers.containers.KafkaContainer.<init>(KafkaContainer.java:27)
	at org.testcontainers.containers.KafkaContainer.<init>(KafkaContainer.java:23)
	at net.mguenther.kafka.junit.ExternalKafkaClusterTest.<init>(ExternalKafkaClusterTest.java:14)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:217)
	at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:266)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running net.mguenther.kafka.junit.TopicManagerTest
2018-06-21 20:00:45 INFO  EmbeddedZooKeeper:24 - Embedded ZooKeeper is starting.
2018-06-21 20:00:45 INFO  EmbeddedZooKeeper:26 - Successfully started an embedded ZooKeeper instance at 127.0.0.1:35367 which is assigned to the temporary directory /tmp/1529604045139-0.
2018-06-21 20:00:45 INFO  EmbeddedKafka:48 - Embedded Kafka broker is starting.
2018-06-21 20:00:45 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit1470044941942179204/junit7933794682330507747/meta.properties
2018-06-21 20:00:45 WARN  BrokerMetadataCheckpoint:87 - No meta.properties file under dir /tmp/junit1470044941942179204/junit7933794682330507747/meta.properties
2018-06-21 20:00:45 INFO  AppInfoParser:109 - Kafka version : 1.0.0
2018-06-21 20:00:45 INFO  AppInfoParser:110 - Kafka commitId : aaa7af6d4a11b29d
2018-06-21 20:00:45 INFO  EmbeddedKafka:53 - The embedded Kafka broker has been started. Its logs can be found at /tmp/junit1470044941942179204/junit7933794682330507747.
2018-06-21 20:00:45 INFO  DefaultTopicManager:35 - Created topic 'test-topic' with settings TopicConfig(topic=test-topic, numberOfPartitions=1, numberOfReplicas=1, properties={delete.retention.ms=86400000, min.insync.replicas=1, cleanup.policy=delete}).
2018-06-21 20:00:45 INFO  DefaultTopicManager:55 - Marked topic 'test-topic' for deletion.
2018-06-21 20:00:45 INFO  EmbeddedKafka:67 - The embedded Kafka broker is stopping.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001 epoch 1 fails to send request (type=StopReplicaRequest, controllerId=1001, controllerEpoch=1, deletePartitions=true, partitions=test-topic-0) to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null). Reconnecting to broker.
java.io.IOException: Connection to 1001 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:95)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:230)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:45 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:45 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:46 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:46 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:47 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:47 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:48 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:48 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:48 WARN  NetworkClient:241 - [Controller id=1001, targetBrokerId=1001] Connection to node 1001 could not be established. Broker may not be available.
2018-06-21 20:00:48 WARN  RequestSendThread:93 - [Controller-1001-to-broker-1001-send-thread]: Controller 1001's connection to broker spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) was unsuccessful
java.io.IOException: Connection to spirals-vortex.lille.inria.fr:34731 (id: 1001 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:68)
	at kafka.controller.RequestSendThread.brokerReady(ControllerChannelManager.scala:269)
	at kafka.controller.RequestSendThread.doWork(ControllerChannelManager.scala:223)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:64)
2018-06-21 20:00:48 INFO  EmbeddedKafka:70 - Removing working directory at org.junit.rules.TemporaryFolder@2b2f5fcf. This directory contains Kafka logs as well.
2018-06-21 20:00:48 INFO  EmbeddedKafka:72 - The embedded Kafka broker has been stopped.
2018-06-21 20:00:48 INFO  EmbeddedZooKeeper:43 - The embedded ZooKeeper instance at 127.0.0.1:35367 is stopping.
2018-06-21 20:00:48 INFO  EmbeddedZooKeeper:45 - The embedded ZooKeeper instance at 127.0.0.1:35367 has been shut down.
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.177 sec
Running net.mguenther.kafka.junit.EmbeddedKafkaConfigTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 sec

Results :

Tests in error: 
  externalKafkaClusterShouldWorkWithExternalResources(net.mguenther.kafka.junit.ExternalKafkaClusterTest): Could not find a valid Docker environment. Please see logs and check configuration

Tests run: 64, Failures: 0, Errors: 1, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 01:29 min
[INFO] Finished at: 2018-06-21T20:00:48+02:00
[INFO] Final Memory: 22M/907M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test (default-test) on project kafka-junit: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/mguenther/kafka-junit/395139958/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
