[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Archives Unleashed Toolkit 0.15.1-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ aut ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-scala-plugin:2.15.2:add-source (default) @ aut ---
[INFO] Add Source directory: /root/workspace/archivesunleashed/aut/371645613/src/main/scala
[INFO] Add Test Source directory: /root/workspace/archivesunleashed/aut/371645613/src/test/scala
[INFO] 
[INFO] --- maven-scala-plugin:2.15.2:compile (default) @ aut ---
[INFO] Checking for multiple versions of scala
[INFO] includes = [**/*.java,**/*.scala,]
[INFO] excludes = []
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-compiler-plugin:3.7.0:compile (default-compile) @ aut ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 5 source files to /root/workspace/archivesunleashed/aut/371645613/target/classes
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ aut ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 5 resources
[INFO] 
[INFO] --- maven-scala-plugin:2.15.2:testCompile (scala-test-compile) @ aut ---
[INFO] Checking for multiple versions of scala
[INFO] includes = [**/*.java,**/*.scala,]
[INFO] excludes = []
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-compiler-plugin:3.7.0:testCompile (default-testCompile) @ aut ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ aut ---
[INFO] Surefire report directory: /root/workspace/archivesunleashed/aut/371645613/target/surefire-reports
Downloading: https://oss.sonatype.org/content/repositories/releases/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.pom

Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.pom
3/3 KB   
         
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.pom (3 KB at 25.3 KB/sec)
Downloading: https://oss.sonatype.org/content/repositories/releases/org/apache/maven/surefire/surefire-providers/2.12.4/surefire-providers-2.12.4.pom
         
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.12.4/surefire-providers-2.12.4.pom
3/3 KB   
3/3 KB   
         
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.12.4/surefire-providers-2.12.4.pom (3 KB at 104.2 KB/sec)
Downloading: https://oss.sonatype.org/content/repositories/releases/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.jar
         
Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.jar
3/37 KB   
5/37 KB   
8/37 KB   
11/37 KB   
13/37 KB   
16/37 KB   
19/37 KB   
21/37 KB   
24/37 KB   
27/37 KB   
29/37 KB   
32/37 KB   
35/37 KB   
37/37 KB   
           
Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.12.4/surefire-junit4-2.12.4.jar (37 KB at 680.3 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running io.archivesunleashed.ArcTest
2018-04-26 18:36:27,428 [main-ScalaTest-running-ArcTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:27,941 [main-ScalaTest-running-ArcTest] WARN  NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-04-26 18:36:28,116 [main-ScalaTest-running-ArcTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:28,179 [main-ScalaTest-running-ArcTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:28,180 [main-ScalaTest-running-ArcTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:28,180 [main-ScalaTest-running-ArcTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:28,181 [main-ScalaTest-running-ArcTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:28,181 [main-ScalaTest-running-ArcTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:28,521 [main-ScalaTest-running-ArcTest] INFO  Utils - Successfully started service 'sparkDriver' on port 37251.
2018-04-26 18:36:28,549 [main-ScalaTest-running-ArcTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:28,570 [main-ScalaTest-running-ArcTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:28,574 [main-ScalaTest-running-ArcTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:28,575 [main-ScalaTest-running-ArcTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:28,597 [main-ScalaTest-running-ArcTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-70d2237e-bd65-4243-992e-af4fe8cb5038
2018-04-26 18:36:28,623 [main-ScalaTest-running-ArcTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:28,636 [main-ScalaTest-running-ArcTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:28,718 [main-ScalaTest-running-ArcTest] INFO  log - Logging initialized @2339ms
2018-04-26 18:36:28,784 [main-ScalaTest-running-ArcTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:28,799 [main-ScalaTest-running-ArcTest] INFO  Server - Started @2422ms
2018-04-26 18:36:28,816 [main-ScalaTest-running-ArcTest] INFO  AbstractConnector - Started ServerConnector@1556f2dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-26 18:36:28,816 [main-ScalaTest-running-ArcTest] INFO  Utils - Successfully started service 'SparkUI' on port 4040.
2018-04-26 18:36:28,840 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1e34c607{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,842 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a8b5227{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,842 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@54f5f647{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,843 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,844 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a67318f{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,844 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@315ba14a{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,845 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17f9344b{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,847 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38d5b107{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,848 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6650813a{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,849 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@44ea608c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,850 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@50cf5a23{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,850 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@450794b4{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,851 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@273c947f{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,852 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30457e14{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,853 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1af1347d{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,853 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@632aa1a3{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,854 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@20765ed5{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,855 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b582111{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,855 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2899a8db{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,856 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1e8823d2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,863 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@c1a4620{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,863 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@29b732a2{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,864 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1b70203f{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,865 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@b09fac1{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,866 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@62df0ff3{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:28,868 [main-ScalaTest-running-ArcTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4040
2018-04-26 18:36:29,014 [main-ScalaTest-running-ArcTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:29,041 [main-ScalaTest-running-ArcTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34472.
2018-04-26 18:36:29,042 [main-ScalaTest-running-ArcTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:34472
2018-04-26 18:36:29,043 [main-ScalaTest-running-ArcTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:29,045 [main-ScalaTest-running-ArcTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34472, None)
2018-04-26 18:36:29,048 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:34472 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34472, None)
2018-04-26 18:36:29,050 [main-ScalaTest-running-ArcTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34472, None)
2018-04-26 18:36:29,051 [main-ScalaTest-running-ArcTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34472, None)
2018-04-26 18:36:29,271 [main-ScalaTest-running-ArcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b2a3ff8{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:29,756 [main-ScalaTest-running-ArcTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:29,838 [main-ScalaTest-running-ArcTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:29,841 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:34472 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:29,844 [main-ScalaTest-running-ArcTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.059 sec <<< FAILURE!
io.archivesunleashed.ArcTest  Time elapsed: 0.679 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1162)
	at io.archivesunleashed.ArcTest$$anonfun$5.apply(ArcTest.scala:43)
	at io.archivesunleashed.ArcTest$$anonfun$5.apply(ArcTest.scala:43)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.ArcTest.org$scalatest$BeforeAndAfter$$super$runTest(ArcTest.scala:28)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.ArcTest.runTest(ArcTest.scala:28)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.ArcTest.org$scalatest$BeforeAndAfter$$super$run(ArcTest.scala:28)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.ArcTest.run(ArcTest.scala:28)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.ArchiveRecordTest
2018-04-26 18:36:29,975 [main-ScalaTest-running-ArchiveRecordTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.ArcTest$$anonfun$1.apply$mcV$sp(ArcTest.scala:39)
io.archivesunleashed.ArcTest$$anonfun$1.apply(ArcTest.scala:34)
io.archivesunleashed.ArcTest$$anonfun$1.apply(ArcTest.scala:34)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.ArcTest.runTest(ArcTest.scala:28)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply$mcV$sp(ArchiveRecordTest.scala:39)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.ArchiveRecordTest.org$scalatest$BeforeAndAfter$$super$run(ArchiveRecordTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.ArchiveRecordTest.run(ArchiveRecordTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:29,979 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:29,979 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:29,981 [main-ScalaTest-running-ArchiveRecordTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:29,982 [main-ScalaTest-running-ArchiveRecordTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:29,982 [main-ScalaTest-running-ArchiveRecordTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:29,982 [main-ScalaTest-running-ArchiveRecordTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:29,982 [main-ScalaTest-running-ArchiveRecordTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:29,992 [main-ScalaTest-running-ArchiveRecordTest] INFO  Utils - Successfully started service 'sparkDriver' on port 38444.
2018-04-26 18:36:29,998 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:29,999 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,000 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,000 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,001 [main-ScalaTest-running-ArchiveRecordTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-e4adc2d8-dd9c-4be1-a33d-169a9bf349de
2018-04-26 18:36:30,002 [main-ScalaTest-running-ArchiveRecordTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,005 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,015 [main-ScalaTest-running-ArchiveRecordTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,019 [main-ScalaTest-running-ArchiveRecordTest] INFO  Server - Started @3641ms
2018-04-26 18:36:30,020 [main-ScalaTest-running-ArchiveRecordTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,021 [main-ScalaTest-running-ArchiveRecordTest] INFO  AbstractConnector - Started ServerConnector@77a074b4{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-04-26 18:36:30,021 [main-ScalaTest-running-ArchiveRecordTest] INFO  Utils - Successfully started service 'SparkUI' on port 4041.
2018-04-26 18:36:30,022 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@333c8791{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,022 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6c0e13b7{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,023 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@22eaa86e{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,023 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@561b7d53{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,024 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1cc680e{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,024 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dc3502b{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,025 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6a1d3225{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,025 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@67e13bd0{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,026 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@50fb33a{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,026 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2cae9b8{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,027 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1457fde{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,027 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f94fb9d{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,028 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17fa1336{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,028 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4228bf58{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,029 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68b9834c{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,029 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@20b9d5d5{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,030 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@671d1157{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,030 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@60c8a093{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,031 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@44cffc25{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,032 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2a369e14{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,032 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@25aeb5ac{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,033 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@c755b2{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,034 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3bd2af5b{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,034 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@75d982d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,035 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f89331f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,035 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4041
2018-04-26 18:36:30,071 [main-ScalaTest-running-ArchiveRecordTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,077 [main-ScalaTest-running-ArchiveRecordTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33396.
2018-04-26 18:36:30,077 [main-ScalaTest-running-ArchiveRecordTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:33396
2018-04-26 18:36:30,077 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,077 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 33396, None)
2018-04-26 18:36:30,078 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:33396 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 33396, None)
2018-04-26 18:36:30,078 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 33396, None)
2018-04-26 18:36:30,078 [main-ScalaTest-running-ArchiveRecordTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 33396, None)
2018-04-26 18:36:30,079 [main-ScalaTest-running-ArchiveRecordTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@32130e61{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,083 [main-ScalaTest-running-ArchiveRecordTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.ArcTest$$anonfun$1.apply$mcV$sp(ArcTest.scala:39)
io.archivesunleashed.ArcTest$$anonfun$1.apply(ArcTest.scala:34)
io.archivesunleashed.ArcTest$$anonfun$1.apply(ArcTest.scala:34)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.ArcTest.runTest(ArcTest.scala:28)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply$mcV$sp(ArchiveRecordTest.scala:39)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.ArchiveRecordTest.org$scalatest$BeforeAndAfter$$super$run(ArchiveRecordTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.ArchiveRecordTest.run(ArchiveRecordTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,090 [main-ScalaTest-running-ArchiveRecordTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,135 [main-ScalaTest-running-ArchiveRecordTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,136 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:33396 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,137 [main-ScalaTest-running-ArchiveRecordTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.14 sec <<< FAILURE!
io.archivesunleashed.ArchiveRecordTest  Time elapsed: 0.058 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1162)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$2.apply(ArchiveRecordTest.scala:43)
	at io.archivesunleashed.ArchiveRecordTest$$anonfun$2.apply(ArchiveRecordTest.scala:42)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.ArchiveRecordTest.org$scalatest$BeforeAndAfter$$super$runTest(ArchiveRecordTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.ArchiveRecordTest.org$scalatest$BeforeAndAfter$$super$run(ArchiveRecordTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.ArchiveRecordTest.run(ArchiveRecordTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.CountableRDDTest
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.004 sec <<< FAILURE!
io.archivesunleashed.CountableRDDTest  Time elapsed: 0.004 sec  <<< ERROR!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply$mcV$sp(ArchiveRecordTest.scala:39)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.CountableRDDTest$$anonfun$1.apply$mcV$sp(CountableRDDTest.scala:38)
	at io.archivesunleashed.CountableRDDTest$$anonfun$1.apply(CountableRDDTest.scala:34)
	at io.archivesunleashed.CountableRDDTest$$anonfun$1.apply(CountableRDDTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.CountableRDDTest.runTest(CountableRDDTest.scala:28)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.CountableRDDTest.org$scalatest$BeforeAndAfter$$super$run(CountableRDDTest.scala:28)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.CountableRDDTest.run(CountableRDDTest.scala:28)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.RecordLoaderTest
2018-04-26 18:36:30,153 [main-ScalaTest-running-RecordLoaderTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply$mcV$sp(ArchiveRecordTest.scala:39)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply$mcV$sp(RecordLoaderTest.scala:43)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.RecordLoaderTest.runTest(RecordLoaderTest.scala:30)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordLoaderTest.org$scalatest$BeforeAndAfter$$super$run(RecordLoaderTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordLoaderTest.run(RecordLoaderTest.scala:30)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,154 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,154 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,156 [main-ScalaTest-running-RecordLoaderTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,156 [main-ScalaTest-running-RecordLoaderTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,156 [main-ScalaTest-running-RecordLoaderTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,156 [main-ScalaTest-running-RecordLoaderTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,156 [main-ScalaTest-running-RecordLoaderTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,163 [main-ScalaTest-running-RecordLoaderTest] INFO  Utils - Successfully started service 'sparkDriver' on port 35540.
2018-04-26 18:36:30,170 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,170 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,170 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,170 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,171 [main-ScalaTest-running-RecordLoaderTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-d253c3fa-907e-4e3c-b0a8-4455004aed7b
2018-04-26 18:36:30,172 [main-ScalaTest-running-RecordLoaderTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,174 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,181 [main-ScalaTest-running-RecordLoaderTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,185 [main-ScalaTest-running-RecordLoaderTest] INFO  Server - Started @3808ms
2018-04-26 18:36:30,185 [main-ScalaTest-running-RecordLoaderTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,186 [main-ScalaTest-running-RecordLoaderTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,186 [main-ScalaTest-running-RecordLoaderTest] INFO  AbstractConnector - Started ServerConnector@17461db{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2018-04-26 18:36:30,187 [main-ScalaTest-running-RecordLoaderTest] INFO  Utils - Successfully started service 'SparkUI' on port 4042.
2018-04-26 18:36:30,187 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3fd9e827{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,187 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4e682398{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,188 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@670b3ca{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,188 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@24a86066{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,189 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@54402c04{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,189 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5b3bb1f7{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,189 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58d6b7b9{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,190 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3f1a4795{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,190 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6a6f6c7e{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,190 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6c5ddccd{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,191 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1dbd580{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,191 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6c101cc1{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,192 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7d0d91a1{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,192 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7fb48179{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,193 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@201c3cda{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,193 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4c86da0c{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,193 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d97caa4{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,194 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6732726{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,194 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@474821de{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,195 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3d64c581{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,196 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ec5ea63{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,196 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4190bc8a{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,197 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@47d023b7{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,197 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2d64c100{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,198 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@69d45cca{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,198 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4042
2018-04-26 18:36:30,228 [main-ScalaTest-running-RecordLoaderTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,233 [main-ScalaTest-running-RecordLoaderTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45717.
2018-04-26 18:36:30,233 [main-ScalaTest-running-RecordLoaderTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:45717
2018-04-26 18:36:30,233 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,234 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 45717, None)
2018-04-26 18:36:30,234 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:45717 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 45717, None)
2018-04-26 18:36:30,235 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 45717, None)
2018-04-26 18:36:30,235 [main-ScalaTest-running-RecordLoaderTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 45717, None)
2018-04-26 18:36:30,236 [main-ScalaTest-running-RecordLoaderTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2e5b7fba{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,239 [main-ScalaTest-running-RecordLoaderTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply$mcV$sp(ArchiveRecordTest.scala:39)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
io.archivesunleashed.ArchiveRecordTest$$anonfun$1.apply(ArchiveRecordTest.scala:34)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.ArchiveRecordTest.runTest(ArchiveRecordTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply$mcV$sp(RecordLoaderTest.scala:43)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.RecordLoaderTest.runTest(RecordLoaderTest.scala:30)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordLoaderTest.org$scalatest$BeforeAndAfter$$super$run(RecordLoaderTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordLoaderTest.run(RecordLoaderTest.scala:30)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,247 [main-ScalaTest-running-RecordLoaderTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,291 [main-ScalaTest-running-RecordLoaderTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,292 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:45717 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,294 [main-ScalaTest-running-RecordLoaderTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.155 sec <<< FAILURE!
io.archivesunleashed.RecordLoaderTest  Time elapsed: 0.067 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1337)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.take(RDD.scala:1331)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$2.apply(RecordLoaderTest.scala:50)
	at io.archivesunleashed.RecordLoaderTest$$anonfun$2.apply(RecordLoaderTest.scala:46)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.RecordLoaderTest.org$scalatest$BeforeAndAfter$$super$runTest(RecordLoaderTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.RecordLoaderTest.runTest(RecordLoaderTest.scala:30)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordLoaderTest.org$scalatest$BeforeAndAfter$$super$run(RecordLoaderTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordLoaderTest.run(RecordLoaderTest.scala:30)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.RecordRDDTest
2018-04-26 18:36:30,319 [main-ScalaTest-running-RecordRDDTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply$mcV$sp(RecordLoaderTest.scala:43)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.RecordLoaderTest.runTest(RecordLoaderTest.scala:30)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply$mcV$sp(RecordRDDTest.scala:44)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.RecordRDDTest.runTest(RecordRDDTest.scala:31)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordRDDTest.org$scalatest$BeforeAndAfter$$super$run(RecordRDDTest.scala:31)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordRDDTest.run(RecordRDDTest.scala:31)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,321 [main-ScalaTest-running-RecordRDDTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,321 [main-ScalaTest-running-RecordRDDTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,323 [main-ScalaTest-running-RecordRDDTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,323 [main-ScalaTest-running-RecordRDDTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,323 [main-ScalaTest-running-RecordRDDTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,324 [main-ScalaTest-running-RecordRDDTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,324 [main-ScalaTest-running-RecordRDDTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,334 [main-ScalaTest-running-RecordRDDTest] INFO  Utils - Successfully started service 'sparkDriver' on port 38264.
2018-04-26 18:36:30,340 [main-ScalaTest-running-RecordRDDTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,341 [main-ScalaTest-running-RecordRDDTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,341 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,341 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,342 [main-ScalaTest-running-RecordRDDTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-d6ad0f94-2ec9-4dcb-a45e-18a32bcb4e01
2018-04-26 18:36:30,343 [main-ScalaTest-running-RecordRDDTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,345 [main-ScalaTest-running-RecordRDDTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,350 [main-ScalaTest-running-RecordRDDTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,354 [main-ScalaTest-running-RecordRDDTest] INFO  Server - Started @3977ms
2018-04-26 18:36:30,355 [main-ScalaTest-running-RecordRDDTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,355 [main-ScalaTest-running-RecordRDDTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,355 [main-ScalaTest-running-RecordRDDTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:30,357 [main-ScalaTest-running-RecordRDDTest] INFO  AbstractConnector - Started ServerConnector@4d6ccc97{HTTP/1.1,[http/1.1]}{0.0.0.0:4043}
2018-04-26 18:36:30,357 [main-ScalaTest-running-RecordRDDTest] INFO  Utils - Successfully started service 'SparkUI' on port 4043.
2018-04-26 18:36:30,358 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6a12c7a8{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,358 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@161aa04a{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,359 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@436bd4df{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,360 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6848a051{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,360 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@149b0577{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,361 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5740ff5e{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,361 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a901445{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,362 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@67f77f6e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,362 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2b0b7e5a{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,363 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7be1ce6a{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,363 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3119cf6f{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,363 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6dc9da2d{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,364 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1d408060{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,364 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@68a78f3c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,365 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17ba57f0{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,365 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3481ff98{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,365 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2ddb3ae8{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,366 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79518e00{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,366 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3c91530d{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,367 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7d70638{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,367 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@732f6050{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,368 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6fbc1bb{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,368 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@30c4e352{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,369 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@73809e7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,369 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5f96f6a2{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,369 [main-ScalaTest-running-RecordRDDTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4043
2018-04-26 18:36:30,398 [main-ScalaTest-running-RecordRDDTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,403 [main-ScalaTest-running-RecordRDDTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32769.
2018-04-26 18:36:30,403 [main-ScalaTest-running-RecordRDDTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:32769
2018-04-26 18:36:30,403 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,404 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 32769, None)
2018-04-26 18:36:30,404 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:32769 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 32769, None)
2018-04-26 18:36:30,404 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 32769, None)
2018-04-26 18:36:30,405 [main-ScalaTest-running-RecordRDDTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 32769, None)
2018-04-26 18:36:30,406 [main-ScalaTest-running-RecordRDDTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@119b0892{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,409 [main-ScalaTest-running-RecordRDDTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply$mcV$sp(RecordLoaderTest.scala:43)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
io.archivesunleashed.RecordLoaderTest$$anonfun$1.apply(RecordLoaderTest.scala:38)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.RecordLoaderTest.runTest(RecordLoaderTest.scala:30)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply$mcV$sp(RecordRDDTest.scala:44)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
	at io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.RecordRDDTest.runTest(RecordRDDTest.scala:31)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordRDDTest.org$scalatest$BeforeAndAfter$$super$run(RecordRDDTest.scala:31)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordRDDTest.run(RecordRDDTest.scala:31)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,415 [main-ScalaTest-running-RecordRDDTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,462 [main-ScalaTest-running-RecordRDDTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,464 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:32769 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,465 [main-ScalaTest-running-RecordRDDTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.16 sec <<< FAILURE!
io.archivesunleashed.RecordRDDTest  Time elapsed: 0.062 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1337)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.take(RDD.scala:1331)
	at io.archivesunleashed.RecordRDDTest$$anonfun$2.apply(RecordRDDTest.scala:49)
	at io.archivesunleashed.RecordRDDTest$$anonfun$2.apply(RecordRDDTest.scala:47)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.RecordRDDTest.org$scalatest$BeforeAndAfter$$super$runTest(RecordRDDTest.scala:31)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.RecordRDDTest.runTest(RecordRDDTest.scala:31)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.RecordRDDTest.org$scalatest$BeforeAndAfter$$super$run(RecordRDDTest.scala:31)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.RecordRDDTest.run(RecordRDDTest.scala:31)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.WarcTest
2018-04-26 18:36:30,477 [main-ScalaTest-running-WarcTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply$mcV$sp(RecordRDDTest.scala:44)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.RecordRDDTest.runTest(RecordRDDTest.scala:31)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply$mcV$sp(WarcTest.scala:40)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.WarcTest.runTest(WarcTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.WarcTest.org$scalatest$BeforeAndAfter$$super$run(WarcTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.WarcTest.run(WarcTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,478 [main-ScalaTest-running-WarcTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,479 [main-ScalaTest-running-WarcTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,480 [main-ScalaTest-running-WarcTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,481 [main-ScalaTest-running-WarcTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,481 [main-ScalaTest-running-WarcTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,481 [main-ScalaTest-running-WarcTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,481 [main-ScalaTest-running-WarcTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,488 [main-ScalaTest-running-WarcTest] INFO  Utils - Successfully started service 'sparkDriver' on port 46582.
2018-04-26 18:36:30,496 [main-ScalaTest-running-WarcTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,497 [main-ScalaTest-running-WarcTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,498 [main-ScalaTest-running-WarcTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,499 [main-ScalaTest-running-WarcTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,500 [main-ScalaTest-running-WarcTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-2d3c7538-5969-4ad6-abb3-d14413431d89
2018-04-26 18:36:30,500 [main-ScalaTest-running-WarcTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,503 [main-ScalaTest-running-WarcTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,509 [main-ScalaTest-running-WarcTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,514 [main-ScalaTest-running-WarcTest] INFO  Server - Started @4137ms
2018-04-26 18:36:30,514 [main-ScalaTest-running-WarcTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,514 [main-ScalaTest-running-WarcTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,515 [main-ScalaTest-running-WarcTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:30,515 [main-ScalaTest-running-WarcTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:30,515 [main-ScalaTest-running-WarcTest] INFO  AbstractConnector - Started ServerConnector@49e4c2d5{HTTP/1.1,[http/1.1]}{0.0.0.0:4044}
2018-04-26 18:36:30,516 [main-ScalaTest-running-WarcTest] INFO  Utils - Successfully started service 'SparkUI' on port 4044.
2018-04-26 18:36:30,517 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@24a2e565{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,517 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e36b7a0{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,518 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@60c1663c{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,518 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f5cf29b{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,519 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3c66b7d8{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,519 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@37e69c43{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,520 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5c7dfc05{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,520 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@345d053b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,521 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3d0cac1f{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,521 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e8b3b79{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,521 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d257579{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,522 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@518ddd3b{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,522 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@939ff41{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,522 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6e0e5dec{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,522 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@48a663e9{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,523 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@777d0bc3{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,523 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3178219a{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,523 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2d85fb64{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,524 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56476c16{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,524 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@497b560e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,525 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@39ffda4a{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,525 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3ba348ca{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,526 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@56e9a474{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,526 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2dbfcf7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,527 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@239f017e{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,527 [main-ScalaTest-running-WarcTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4044
2018-04-26 18:36:30,566 [main-ScalaTest-running-WarcTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,572 [main-ScalaTest-running-WarcTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40109.
2018-04-26 18:36:30,572 [main-ScalaTest-running-WarcTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:40109
2018-04-26 18:36:30,572 [main-ScalaTest-running-WarcTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,572 [main-ScalaTest-running-WarcTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40109, None)
2018-04-26 18:36:30,573 [dispatcher-event-loop-0] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:40109 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40109, None)
2018-04-26 18:36:30,573 [main-ScalaTest-running-WarcTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40109, None)
2018-04-26 18:36:30,573 [main-ScalaTest-running-WarcTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40109, None)
2018-04-26 18:36:30,575 [main-ScalaTest-running-WarcTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5b5ac798{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,579 [main-ScalaTest-running-WarcTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply$mcV$sp(RecordRDDTest.scala:44)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
io.archivesunleashed.RecordRDDTest$$anonfun$1.apply(RecordRDDTest.scala:39)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.RecordRDDTest.runTest(RecordRDDTest.scala:31)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply$mcV$sp(WarcTest.scala:40)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
	at io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.WarcTest.runTest(WarcTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.WarcTest.org$scalatest$BeforeAndAfter$$super$run(WarcTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.WarcTest.run(WarcTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,585 [main-ScalaTest-running-WarcTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,637 [main-ScalaTest-running-WarcTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,638 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:40109 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,639 [main-ScalaTest-running-WarcTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.17 sec <<< FAILURE!
io.archivesunleashed.WarcTest  Time elapsed: 0.001 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1162)
	at io.archivesunleashed.WarcTest$$anonfun$2.apply(WarcTest.scala:45)
	at io.archivesunleashed.WarcTest$$anonfun$2.apply(WarcTest.scala:45)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.WarcTest.org$scalatest$BeforeAndAfter$$super$runTest(WarcTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.WarcTest.runTest(WarcTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.WarcTest.org$scalatest$BeforeAndAfter$$super$run(WarcTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.WarcTest.run(WarcTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.app.ExtractGraphTest
2018-04-26 18:36:30,648 [main-ScalaTest-running-ExtractGraphTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.WarcTest$$anonfun$1.apply$mcV$sp(WarcTest.scala:40)
io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.WarcTest.runTest(WarcTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply$mcV$sp(ExtractGraphTest.scala:47)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.ExtractGraphTest.runTest(ExtractGraphTest.scala:34)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractGraphTest.org$scalatest$BeforeAndAfter$$super$run(ExtractGraphTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractGraphTest.run(ExtractGraphTest.scala:34)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,648 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,649 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,650 [main-ScalaTest-running-ExtractGraphTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,650 [main-ScalaTest-running-ExtractGraphTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,650 [main-ScalaTest-running-ExtractGraphTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,650 [main-ScalaTest-running-ExtractGraphTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,650 [main-ScalaTest-running-ExtractGraphTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,657 [main-ScalaTest-running-ExtractGraphTest] INFO  Utils - Successfully started service 'sparkDriver' on port 45353.
2018-04-26 18:36:30,663 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,664 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,664 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,664 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,665 [main-ScalaTest-running-ExtractGraphTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-ed4bda06-d0a0-4621-b610-76071d88556b
2018-04-26 18:36:30,666 [main-ScalaTest-running-ExtractGraphTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,668 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,674 [main-ScalaTest-running-ExtractGraphTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,678 [main-ScalaTest-running-ExtractGraphTest] INFO  Server - Started @4300ms
2018-04-26 18:36:30,678 [main-ScalaTest-running-ExtractGraphTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,678 [main-ScalaTest-running-ExtractGraphTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,678 [main-ScalaTest-running-ExtractGraphTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:30,679 [main-ScalaTest-running-ExtractGraphTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:30,679 [main-ScalaTest-running-ExtractGraphTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:30,679 [main-ScalaTest-running-ExtractGraphTest] INFO  AbstractConnector - Started ServerConnector@34d713a2{HTTP/1.1,[http/1.1]}{0.0.0.0:4045}
2018-04-26 18:36:30,680 [main-ScalaTest-running-ExtractGraphTest] INFO  Utils - Successfully started service 'SparkUI' on port 4045.
2018-04-26 18:36:30,681 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36aab105{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,682 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@889a8a8{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,684 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f29353f{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,684 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36f7d7b{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,684 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@60aec68a{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,684 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@25a7fedf{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,685 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6361b799{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,685 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1b9d9a2b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,685 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d919544{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,686 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@17dad32f{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,686 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@79696332{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,686 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@ed2f2f6{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,687 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@fe87ddd{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,687 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4eea94a4{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,687 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7c281eb8{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,687 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@65f40689{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,688 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@29be997f{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,688 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@33eb6758{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,688 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f8a6243{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,689 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a8ffd75{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,689 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1727e03a{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,689 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7f9e8421{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,690 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23da79eb{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,690 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e05586b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,690 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@35b17c06{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,690 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4045
2018-04-26 18:36:30,720 [main-ScalaTest-running-ExtractGraphTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,725 [main-ScalaTest-running-ExtractGraphTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34177.
2018-04-26 18:36:30,726 [main-ScalaTest-running-ExtractGraphTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:34177
2018-04-26 18:36:30,726 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,726 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34177, None)
2018-04-26 18:36:30,726 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:34177 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34177, None)
2018-04-26 18:36:30,727 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34177, None)
2018-04-26 18:36:30,727 [main-ScalaTest-running-ExtractGraphTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 34177, None)
2018-04-26 18:36:30,728 [main-ScalaTest-running-ExtractGraphTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@47f04e4d{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,731 [main-ScalaTest-running-ExtractGraphTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.WarcTest$$anonfun$1.apply$mcV$sp(WarcTest.scala:40)
io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
io.archivesunleashed.WarcTest$$anonfun$1.apply(WarcTest.scala:35)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.WarcTest.runTest(WarcTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply$mcV$sp(ExtractGraphTest.scala:47)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.ExtractGraphTest.runTest(ExtractGraphTest.scala:34)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractGraphTest.org$scalatest$BeforeAndAfter$$super$run(ExtractGraphTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractGraphTest.run(ExtractGraphTest.scala:34)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,736 [main-ScalaTest-running-ExtractGraphTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,778 [main-ScalaTest-running-ExtractGraphTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,779 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:34177 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,780 [main-ScalaTest-running-ExtractGraphTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.155 sec <<< FAILURE!
io.archivesunleashed.app.ExtractGraphTest  Time elapsed: 0.071 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.RDD$$anonfun$distinct$2.apply(RDD.scala:406)
	at org.apache.spark.rdd.RDD$$anonfun$distinct$2.apply(RDD.scala:406)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.distinct(RDD.scala:405)
	at io.archivesunleashed.app.ExtractGraph$.apply(ExtractGraph.scala:60)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$2.apply(ExtractGraphTest.scala:52)
	at io.archivesunleashed.app.ExtractGraphTest$$anonfun$2.apply(ExtractGraphTest.scala:50)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.app.ExtractGraphTest.org$scalatest$BeforeAndAfter$$super$runTest(ExtractGraphTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.app.ExtractGraphTest.runTest(ExtractGraphTest.scala:34)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractGraphTest.org$scalatest$BeforeAndAfter$$super$run(ExtractGraphTest.scala:34)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractGraphTest.run(ExtractGraphTest.scala:34)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.app.ExtractPopularImagesTest
2018-04-26 18:36:30,805 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply$mcV$sp(ExtractGraphTest.scala:47)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.app.ExtractGraphTest.runTest(ExtractGraphTest.scala:34)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply$mcV$sp(ExtractPopularImagesTest.scala:40)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.ExtractPopularImagesTest.runTest(ExtractPopularImagesTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractPopularImagesTest.org$scalatest$BeforeAndAfter$$super$run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractPopularImagesTest.run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,806 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,806 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,808 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,808 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,808 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,808 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,808 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,816 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Utils - Successfully started service 'sparkDriver' on port 41459.
2018-04-26 18:36:30,821 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,822 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,822 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,822 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,823 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-5bd64ac7-5169-40b3-b812-2d5ae2fa6d68
2018-04-26 18:36:30,824 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,826 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,830 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,833 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Server - Started @4456ms
2018-04-26 18:36:30,834 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,834 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,834 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:30,835 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:30,835 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:30,835 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2018-04-26 18:36:30,836 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  AbstractConnector - Started ServerConnector@77429040{HTTP/1.1,[http/1.1]}{0.0.0.0:4046}
2018-04-26 18:36:30,837 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Utils - Successfully started service 'SparkUI' on port 4046.
2018-04-26 18:36:30,839 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2d2b6960{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,839 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@38291795{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,839 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@234c5e41{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,839 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@40ef0af8{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,840 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@36790bec{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,840 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@461c3709{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,840 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7e3d7dd{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,840 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3f63a513{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,841 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@413bef78{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,841 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@66383c29{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,841 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7f7c420c{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,842 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5d152bcd{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,842 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43cb5f38{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,842 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6435fa1c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,842 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7944b8b4{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,843 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@d7bbf12{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,843 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1450131a{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,843 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5f7eee96{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,843 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3a36cd5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,844 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@53f0d09c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,844 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@47acd13b{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,845 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6f8e9d06{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,845 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@77d381e6{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,845 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3f6f3cc{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,845 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@180b3819{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,846 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4046
2018-04-26 18:36:30,879 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:30,885 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42381.
2018-04-26 18:36:30,885 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:42381
2018-04-26 18:36:30,885 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:30,885 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 42381, None)
2018-04-26 18:36:30,886 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:42381 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 42381, None)
2018-04-26 18:36:30,886 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 42381, None)
2018-04-26 18:36:30,886 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 42381, None)
2018-04-26 18:36:30,887 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@52ea0269{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,890 [main-ScalaTest-running-ExtractPopularImagesTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply$mcV$sp(ExtractGraphTest.scala:47)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
io.archivesunleashed.app.ExtractGraphTest$$anonfun$1.apply(ExtractGraphTest.scala:42)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.app.ExtractGraphTest.runTest(ExtractGraphTest.scala:34)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply$mcV$sp(ExtractPopularImagesTest.scala:40)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.ExtractPopularImagesTest.runTest(ExtractPopularImagesTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractPopularImagesTest.org$scalatest$BeforeAndAfter$$super$run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractPopularImagesTest.run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,895 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 215.1 KB, free 8.2 GB)
2018-04-26 18:36:30,939 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.5 KB, free 8.2 GB)
2018-04-26 18:36:30,940 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:42381 (size: 20.5 KB, free: 8.2 GB)
2018-04-26 18:36:30,941 [main-ScalaTest-running-ExtractPopularImagesTest] INFO  SparkContext - Created broadcast 0 from newAPIHadoopFile at package.scala:47
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.156 sec <<< FAILURE!
io.archivesunleashed.app.ExtractPopularImagesTest  Time elapsed: 0.069 sec  <<< ERROR!
java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:379)
	at org.apache.spark.rdd.NewHadoopRDD.getPartitions(NewHadoopRDD.scala:127)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
	at org.apache.spark.Partitioner$$anonfun$4.apply(Partitioner.scala:75)
	at org.apache.spark.Partitioner$$anonfun$4.apply(Partitioner.scala:75)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)
	at scala.collection.immutable.List.map(List.scala:285)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:75)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:326)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:326)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:325)
	at io.archivesunleashed.app.ExtractPopularImages$.apply(ExtractPopularImages.scala:41)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$2.apply(ExtractPopularImagesTest.scala:46)
	at io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$2.apply(ExtractPopularImagesTest.scala:43)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:186)
	at org.scalatest.TestSuite$class.withFixture(TestSuite.scala:196)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:183)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:196)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:196)
	at io.archivesunleashed.app.ExtractPopularImagesTest.org$scalatest$BeforeAndAfter$$super$runTest(ExtractPopularImagesTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:203)
	at io.archivesunleashed.app.ExtractPopularImagesTest.runTest(ExtractPopularImagesTest.scala:27)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.ExtractPopularImagesTest.org$scalatest$BeforeAndAfter$$super$run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.ExtractPopularImagesTest.run(ExtractPopularImagesTest.scala:27)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

Running io.archivesunleashed.app.WriteGEXFTest
2018-04-26 18:36:30,963 [main-ScalaTest-running-WriteGEXFTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply$mcV$sp(ExtractPopularImagesTest.scala:40)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.app.ExtractPopularImagesTest.runTest(ExtractPopularImagesTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2534)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:84)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply$mcV$sp(WriteGEXFTest.scala:44)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply(WriteGEXFTest.scala:39)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply(WriteGEXFTest.scala:39)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.WriteGEXFTest.runTest(WriteGEXFTest.scala:30)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.WriteGEXFTest.org$scalatest$BeforeAndAfter$$super$run(WriteGEXFTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.WriteGEXFTest.run(WriteGEXFTest.scala:30)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:30,964 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:30,964 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:30,965 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:30,965 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:30,965 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:30,965 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:30,965 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:30,973 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'sparkDriver' on port 36433.
2018-04-26 18:36:30,977 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:30,978 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:30,978 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:30,978 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:30,979 [main-ScalaTest-running-WriteGEXFTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-20e1743a-1f42-4c2d-82b4-00b979580bb1
2018-04-26 18:36:30,980 [main-ScalaTest-running-WriteGEXFTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:30,982 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:30,985 [main-ScalaTest-running-WriteGEXFTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:30,989 [main-ScalaTest-running-WriteGEXFTest] INFO  Server - Started @4611ms
2018-04-26 18:36:30,989 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:30,989 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:30,989 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:30,990 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:30,990 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:30,990 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2018-04-26 18:36:30,990 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
2018-04-26 18:36:30,991 [main-ScalaTest-running-WriteGEXFTest] INFO  AbstractConnector - Started ServerConnector@78b7f805{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:30,992 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'SparkUI' on port 4047.
2018-04-26 18:36:30,994 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@58f2466c{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,998 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5809fa26{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,999 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64763e49{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:30,999 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@23468512{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,000 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@69cd7630{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,001 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7e8279e5{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,002 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2b53840a{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,002 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3caafa67{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,003 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e546734{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,003 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@53747c4a{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,003 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@64b0d1fa{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,004 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@f2276c9{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,004 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@12d2ddde{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,005 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@62b475e2{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,005 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@e9474f{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,005 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1c61eda5{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,006 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1859ffda{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,006 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@59838256{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,006 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@131a7516{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,007 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ae15{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,008 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@577536e0{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,008 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@12219f6a{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,009 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@52d3fafd{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,009 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1376883{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,010 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1f736d00{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,010 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:31,050 [main-ScalaTest-running-WriteGEXFTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:31,057 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40575.
2018-04-26 18:36:31,058 [main-ScalaTest-running-WriteGEXFTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:40575
2018-04-26 18:36:31,058 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:31,058 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40575, None)
2018-04-26 18:36:31,058 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:40575 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40575, None)
2018-04-26 18:36:31,059 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40575, None)
2018-04-26 18:36:31,059 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40575, None)
2018-04-26 18:36:31,061 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6c8fe7a4{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:31,065 [main-ScalaTest-running-WriteGEXFTest] WARN  SparkContext - Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:75)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply$mcV$sp(ExtractPopularImagesTest.scala:40)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
io.archivesunleashed.app.ExtractPopularImagesTest$$anonfun$1.apply(ExtractPopularImagesTest.scala:35)
org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
io.archivesunleashed.app.ExtractPopularImagesTest.runTest(ExtractPopularImagesTest.scala:27)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
scala.collection.immutable.List.foreach(List.scala:381)
org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
org.scalatest.Suite$class.run(Suite.scala:1147)
org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2449)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$2.apply(SparkContext.scala:2445)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2445)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2547)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2401)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply$mcV$sp(WriteGEXFTest.scala:44)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply(WriteGEXFTest.scala:39)
	at io.archivesunleashed.app.WriteGEXFTest$$anonfun$1.apply(WriteGEXFTest.scala:39)
	at org.scalatest.BeforeAndAfter$class.runTest(BeforeAndAfter.scala:200)
	at io.archivesunleashed.app.WriteGEXFTest.runTest(WriteGEXFTest.scala:30)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:229)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:396)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:384)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:384)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:379)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:461)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:229)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1560)
	at org.scalatest.Suite$class.run(Suite.scala:1147)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1560)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:233)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:521)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:233)
	at io.archivesunleashed.app.WriteGEXFTest.org$scalatest$BeforeAndAfter$$super$run(WriteGEXFTest.scala:30)
	at org.scalatest.BeforeAndAfter$class.run(BeforeAndAfter.scala:258)
	at io.archivesunleashed.app.WriteGEXFTest.run(WriteGEXFTest.scala:30)
	at org.scalatest.junit.JUnitRunner.run(JUnitRunner.scala:99)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
2018-04-26 18:36:31,141 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Starting job: collect at WriteGEXF.scala:56
2018-04-26 18:36:31,159 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 0 (collect at WriteGEXF.scala:56) with 4 output partitions
2018-04-26 18:36:31,160 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 0 (collect at WriteGEXF.scala:56)
2018-04-26 18:36:31,160 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List()
2018-04-26 18:36:31,162 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List()
2018-04-26 18:36:31,168 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at map at WriteGEXF.scala:50), which has no missing parents
2018-04-26 18:36:31,193 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 1864.0 B, free 8.2 GB)
2018-04-26 18:36:31,198 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1216.0 B, free 8.2 GB)
2018-04-26 18:36:31,199 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:40575 (size: 1216.0 B, free: 8.2 GB)
2018-04-26 18:36:31,200 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:31,231 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at WriteGEXF.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:31,233 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 0.0 with 4 tasks
2018-04-26 18:36:31,305 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7851 bytes)
2018-04-26 18:36:31,309 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:31,309 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:31,310 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:31,322 [Executor task launch worker for task 0] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
2018-04-26 18:36:31,322 [Executor task launch worker for task 1] INFO  Executor - Running task 1.0 in stage 0.0 (TID 1)
2018-04-26 18:36:31,322 [Executor task launch worker for task 3] INFO  Executor - Running task 3.0 in stage 0.0 (TID 3)
2018-04-26 18:36:31,322 [Executor task launch worker for task 2] INFO  Executor - Running task 2.0 in stage 0.0 (TID 2)
2018-04-26 18:36:31,411 [Executor task launch worker for task 3] INFO  Executor - Finished task 3.0 in stage 0.0 (TID 3). 899 bytes result sent to driver
2018-04-26 18:36:31,411 [Executor task launch worker for task 0] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 708 bytes result sent to driver
2018-04-26 18:36:31,411 [Executor task launch worker for task 1] INFO  Executor - Finished task 1.0 in stage 0.0 (TID 1). 897 bytes result sent to driver
2018-04-26 18:36:31,411 [Executor task launch worker for task 2] INFO  Executor - Finished task 2.0 in stage 0.0 (TID 2). 897 bytes result sent to driver
2018-04-26 18:36:31,421 [task-result-getter-0] INFO  TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 111 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:31,424 [task-result-getter-1] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 146 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:31,426 [task-result-getter-2] INFO  TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 119 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:31,427 [task-result-getter-3] INFO  TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 118 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:31,428 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-04-26 18:36:31,434 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 0 (collect at WriteGEXF.scala:56) finished in 0.243 s
2018-04-26 18:36:31,440 [main-ScalaTest-running-WriteGEXFTest] INFO  DAGScheduler - Job 0 finished: collect at WriteGEXF.scala:56, took 0.299162 s
2018-04-26 18:36:31,481 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Starting job: collect at WriteGEXF.scala:62
2018-04-26 18:36:31,680 [dag-scheduler-event-loop] INFO  DAGScheduler - Registering RDD 3 (distinct at WriteGEXF.scala:62)
2018-04-26 18:36:31,681 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 1 (collect at WriteGEXF.scala:62) with 4 output partitions
2018-04-26 18:36:31,681 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 2 (collect at WriteGEXF.scala:62)
2018-04-26 18:36:31,682 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2018-04-26 18:36:31,683 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2018-04-26 18:36:31,684 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGEXF.scala:62), which has no missing parents
2018-04-26 18:36:31,695 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 8.2 GB)
2018-04-26 18:36:31,700 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2033.0 B, free 8.2 GB)
2018-04-26 18:36:31,701 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on spirals-vortex.lille.inria.fr:40575 (size: 2033.0 B, free: 8.2 GB)
2018-04-26 18:36:31,701 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:31,705 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGEXF.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:31,705 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 1.0 with 4 tasks
2018-04-26 18:36:31,709 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7840 bytes)
2018-04-26 18:36:31,709 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:31,710 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:31,710 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:31,711 [Executor task launch worker for task 6] INFO  Executor - Running task 2.0 in stage 1.0 (TID 6)
2018-04-26 18:36:31,711 [Executor task launch worker for task 7] INFO  Executor - Running task 3.0 in stage 1.0 (TID 7)
2018-04-26 18:36:31,711 [Executor task launch worker for task 4] INFO  Executor - Running task 0.0 in stage 1.0 (TID 4)
2018-04-26 18:36:31,711 [Executor task launch worker for task 5] INFO  Executor - Running task 1.0 in stage 1.0 (TID 5)
2018-04-26 18:36:31,786 [Executor task launch worker for task 4] INFO  Executor - Finished task 0.0 in stage 1.0 (TID 4). 1001 bytes result sent to driver
2018-04-26 18:36:31,786 [Executor task launch worker for task 7] INFO  Executor - Finished task 3.0 in stage 1.0 (TID 7). 1044 bytes result sent to driver
2018-04-26 18:36:31,787 [Executor task launch worker for task 6] INFO  Executor - Finished task 2.0 in stage 1.0 (TID 6). 1044 bytes result sent to driver
2018-04-26 18:36:31,787 [Executor task launch worker for task 5] INFO  Executor - Finished task 1.0 in stage 1.0 (TID 5). 1087 bytes result sent to driver
2018-04-26 18:36:31,789 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 1.0 (TID 7) in 79 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:31,789 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 1.0 (TID 4) in 82 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:31,789 [task-result-getter-2] INFO  TaskSetManager - Finished task 2.0 in stage 1.0 (TID 6) in 79 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:31,789 [task-result-getter-3] INFO  TaskSetManager - Finished task 1.0 in stage 1.0 (TID 5) in 80 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:31,789 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-04-26 18:36:31,794 [dag-scheduler-event-loop] INFO  DAGScheduler - ShuffleMapStage 1 (distinct at WriteGEXF.scala:62) finished in 0.106 s
2018-04-26 18:36:31,794 [dag-scheduler-event-loop] INFO  DAGScheduler - looking for newly runnable stages
2018-04-26 18:36:31,795 [dag-scheduler-event-loop] INFO  DAGScheduler - running: Set()
2018-04-26 18:36:31,795 [dag-scheduler-event-loop] INFO  DAGScheduler - waiting: Set(ResultStage 2)
2018-04-26 18:36:31,795 [dag-scheduler-event-loop] INFO  DAGScheduler - failed: Set()
2018-04-26 18:36:31,798 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGEXF.scala:62), which has no missing parents
2018-04-26 18:36:31,804 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 8.2 GB)
2018-04-26 18:36:31,807 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 8.2 GB)
2018-04-26 18:36:31,808 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on spirals-vortex.lille.inria.fr:40575 (size: 2.2 KB, free: 8.2 GB)
2018-04-26 18:36:31,809 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:31,810 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGEXF.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:31,810 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 2.0 with 4 tasks
2018-04-26 18:36:31,815 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2018-04-26 18:36:31,815 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
2018-04-26 18:36:31,815 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7649 bytes)
2018-04-26 18:36:31,816 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7649 bytes)
2018-04-26 18:36:31,816 [Executor task launch worker for task 9] INFO  Executor - Running task 1.0 in stage 2.0 (TID 9)
2018-04-26 18:36:31,816 [Executor task launch worker for task 8] INFO  Executor - Running task 0.0 in stage 2.0 (TID 8)
2018-04-26 18:36:31,816 [Executor task launch worker for task 10] INFO  Executor - Running task 2.0 in stage 2.0 (TID 10)
2018-04-26 18:36:31,816 [Executor task launch worker for task 11] INFO  Executor - Running task 3.0 in stage 2.0 (TID 11)
2018-04-26 18:36:31,830 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:31,830 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 4 blocks
2018-04-26 18:36:31,830 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:31,830 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 4 blocks
2018-04-26 18:36:31,832 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2018-04-26 18:36:31,832 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2018-04-26 18:36:31,832 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2018-04-26 18:36:31,832 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 5 ms
2018-04-26 18:36:31,862 [Executor task launch worker for task 8] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 8). 1138 bytes result sent to driver
2018-04-26 18:36:31,863 [Executor task launch worker for task 9] INFO  Executor - Finished task 1.0 in stage 2.0 (TID 9). 1138 bytes result sent to driver
2018-04-26 18:36:31,864 [task-result-getter-1] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 50 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:31,864 [task-result-getter-0] INFO  TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 49 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:31,870 [Executor task launch worker for task 11] INFO  Executor - Finished task 3.0 in stage 2.0 (TID 11). 1349 bytes result sent to driver
2018-04-26 18:36:31,870 [Executor task launch worker for task 10] INFO  Executor - Finished task 2.0 in stage 2.0 (TID 10). 1341 bytes result sent to driver
2018-04-26 18:36:31,871 [task-result-getter-2] INFO  TaskSetManager - Finished task 3.0 in stage 2.0 (TID 11) in 55 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:31,871 [task-result-getter-3] INFO  TaskSetManager - Finished task 2.0 in stage 2.0 (TID 10) in 56 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:31,871 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-04-26 18:36:31,872 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 2 (collect at WriteGEXF.scala:62) finished in 0.069 s
2018-04-26 18:36:31,873 [main-ScalaTest-running-WriteGEXFTest] INFO  DAGScheduler - Job 1 finished: collect at WriteGEXF.scala:62, took 0.390621 s
List(<?xml version="1.0" encoding="UTF-8"?>, <gexf xmlns="http://www.gexf.net/1.3draft",   xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance",   xsi:schemaLocation="http://www.gexf.net/1.3draft,                        http://www.gexf.net/1.3draft/gexf.xsd",   version="1.3">, <graph mode="static" defaultedgetype="directed">, <attributes class="edge">,   <attribute id="0" title="crawlDate" type="string" />, </attributes>, <nodes>, <node id="8e626f9f919e77ae8f868e7ae8be122d" label="Source1" />, <node id="f61def1ec71cd27401b8c821f04b7c27" label="Destination1" />, <node id="19351d3ec23dbb659284bd717ca0939a" label="Source3" />, <node id="0b6f39226c4defd9b414c287252171fd" label="Source2" />, <node id="8d3ab53ec817a1e5bf9ffd6e749b3983" label="Destination2" />, <node id="2723b8c86b76db0aee27f9c2e268aacf" label="Destination3" />, </nodes>, <edges>, <edge source="8e626f9f919e77ae8f868e7ae8be122d" target="f61def1ec71cd27401b8c821f04b7c27" weight="3" type="directed">, <attvalues>, <attvalue for="0" value="Date1" />, </attvalues>, </edge>, <edge source="0b6f39226c4defd9b414c287252171fd" target="8d3ab53ec817a1e5bf9ffd6e749b3983" weight="4" type="directed">, <attvalues>, <attvalue for="0" value="Date2" />, </attvalues>, </edge>, <edge source="19351d3ec23dbb659284bd717ca0939a" target="2723b8c86b76db0aee27f9c2e268aacf" weight="100" type="directed">, <attvalues>, <attvalue for="0" value="Date3" />, </attvalues>, </edge>, </edges>, </graph>, </gexf>)
2018-04-26 18:36:31,904 [main-ScalaTest-running-WriteGEXFTest] INFO  AbstractConnector - Stopped Spark@78b7f805{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:31,907 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:31,919 [dispatcher-event-loop-1] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:31,932 [main-ScalaTest-running-WriteGEXFTest] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:31,932 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:31,963 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:31,975 [dispatcher-event-loop-1] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:31,977 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,978 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,978 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,978 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,977 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,977 [Spark Context Cleaner] ERROR ContextCleaner - Error cleaning broadcast 0
java.lang.NullPointerException
	at org.apache.spark.storage.BlockManagerMaster.removeBroadcast(BlockManagerMaster.scala:148)
	at org.apache.spark.broadcast.TorrentBroadcast$.unpersist(TorrentBroadcast.scala:321)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.unbroadcast(TorrentBroadcastFactory.scala:45)
	at org.apache.spark.broadcast.BroadcastManager.unbroadcast(BroadcastManager.scala:66)
	at org.apache.spark.ContextCleaner.doCleanupBroadcast(ContextCleaner.scala:238)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:185)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:185)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1319)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:178)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:73)
2018-04-26 18:36:31,989 [block-manager-slave-async-thread-pool-0] INFO  BlockManager - Removing RDD 6
2018-04-26 18:36:31,990 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:31,991 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:31,992 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:31,993 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:31,993 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:31,993 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:31,993 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:31,993 [main-ScalaTest-running-WriteGEXFTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:31,998 [Spark Context Cleaner] INFO  ContextCleaner - Cleaned RDD 6
2018-04-26 18:36:32,003 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'sparkDriver' on port 44174.
2018-04-26 18:36:32,007 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:32,008 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:32,008 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:32,008 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:32,009 [main-ScalaTest-running-WriteGEXFTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-e3285698-73db-4f2f-82b4-c605c9786ae7
2018-04-26 18:36:32,010 [main-ScalaTest-running-WriteGEXFTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:32,012 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:32,015 [main-ScalaTest-running-WriteGEXFTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:32,018 [main-ScalaTest-running-WriteGEXFTest] INFO  Server - Started @5641ms
2018-04-26 18:36:32,019 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:32,019 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:32,019 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:32,020 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:32,020 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:32,020 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2018-04-26 18:36:32,020 [main-ScalaTest-running-WriteGEXFTest] WARN  Utils - Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
2018-04-26 18:36:32,023 [main-ScalaTest-running-WriteGEXFTest] INFO  AbstractConnector - Started ServerConnector@592ca48c{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,023 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'SparkUI' on port 4047.
2018-04-26 18:36:32,023 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5fed9976{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,024 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3fdcde7a{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,024 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4f363abd{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,025 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7302ff13{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,025 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4017fe2c{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,025 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1961d75a{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,025 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@677ce519{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,026 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3e26482{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,026 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7cfb0c4c{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,026 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b37df8e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,027 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6b63abdc{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,027 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7b351446{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,027 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5f08fe00{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,028 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@a1691c0{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,028 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7c5df615{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,028 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2f995afc{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,029 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@377949f1{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,029 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@9df564f{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,030 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a21f43f{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,030 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7f0a133d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,031 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@241fbec{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,031 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@715fa8c5{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,032 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@644a3add{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,032 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4665428b{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,032 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a70d302{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,032 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,064 [main-ScalaTest-running-WriteGEXFTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:32,069 [main-ScalaTest-running-WriteGEXFTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40137.
2018-04-26 18:36:32,069 [main-ScalaTest-running-WriteGEXFTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:40137
2018-04-26 18:36:32,069 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:32,069 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40137, None)
2018-04-26 18:36:32,070 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:40137 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40137, None)
2018-04-26 18:36:32,070 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40137, None)
2018-04-26 18:36:32,070 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 40137, None)
2018-04-26 18:36:32,071 [main-ScalaTest-running-WriteGEXFTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1c046c92{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,085 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Starting job: collect at WriteGEXF.scala:56
2018-04-26 18:36:32,086 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 0 (collect at WriteGEXF.scala:56) with 4 output partitions
2018-04-26 18:36:32,086 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 0 (collect at WriteGEXF.scala:56)
2018-04-26 18:36:32,086 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List()
2018-04-26 18:36:32,087 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List()
2018-04-26 18:36:32,087 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at map at WriteGEXF.scala:50), which has no missing parents
2018-04-26 18:36:32,098 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 1864.0 B, free 8.2 GB)
2018-04-26 18:36:32,100 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1216.0 B, free 8.2 GB)
2018-04-26 18:36:32,101 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:40137 (size: 1216.0 B, free: 8.2 GB)
2018-04-26 18:36:32,102 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,103 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at WriteGEXF.scala:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,103 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 0.0 with 4 tasks
2018-04-26 18:36:32,105 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7851 bytes)
2018-04-26 18:36:32,105 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,108 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,109 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,110 [Executor task launch worker for task 0] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
2018-04-26 18:36:32,111 [Executor task launch worker for task 1] INFO  Executor - Running task 1.0 in stage 0.0 (TID 1)
2018-04-26 18:36:32,112 [Executor task launch worker for task 2] INFO  Executor - Running task 2.0 in stage 0.0 (TID 2)
2018-04-26 18:36:32,113 [Executor task launch worker for task 3] INFO  Executor - Running task 3.0 in stage 0.0 (TID 3)
2018-04-26 18:36:32,117 [Executor task launch worker for task 0] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 708 bytes result sent to driver
2018-04-26 18:36:32,118 [Executor task launch worker for task 1] INFO  Executor - Finished task 1.0 in stage 0.0 (TID 1). 897 bytes result sent to driver
2018-04-26 18:36:32,120 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 16 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,120 [Executor task launch worker for task 3] INFO  Executor - Finished task 3.0 in stage 0.0 (TID 3). 899 bytes result sent to driver
2018-04-26 18:36:32,120 [task-result-getter-1] INFO  TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 15 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,121 [task-result-getter-2] INFO  TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 13 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,122 [Executor task launch worker for task 2] INFO  Executor - Finished task 2.0 in stage 0.0 (TID 2). 897 bytes result sent to driver
2018-04-26 18:36:32,124 [task-result-getter-3] INFO  TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 19 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,124 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,125 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 0 (collect at WriteGEXF.scala:56) finished in 0.032 s
2018-04-26 18:36:32,126 [main-ScalaTest-running-WriteGEXFTest] INFO  DAGScheduler - Job 0 finished: collect at WriteGEXF.scala:56, took 0.040235 s
2018-04-26 18:36:32,152 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Starting job: collect at WriteGEXF.scala:62
2018-04-26 18:36:32,165 [dag-scheduler-event-loop] INFO  DAGScheduler - Registering RDD 3 (distinct at WriteGEXF.scala:62)
2018-04-26 18:36:32,166 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 1 (collect at WriteGEXF.scala:62) with 4 output partitions
2018-04-26 18:36:32,166 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 2 (collect at WriteGEXF.scala:62)
2018-04-26 18:36:32,166 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2018-04-26 18:36:32,166 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2018-04-26 18:36:32,167 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGEXF.scala:62), which has no missing parents
2018-04-26 18:36:32,169 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 8.2 GB)
2018-04-26 18:36:32,171 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2033.0 B, free 8.2 GB)
2018-04-26 18:36:32,172 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on spirals-vortex.lille.inria.fr:40137 (size: 2033.0 B, free: 8.2 GB)
2018-04-26 18:36:32,172 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,173 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGEXF.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,173 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 1.0 with 4 tasks
2018-04-26 18:36:32,174 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7840 bytes)
2018-04-26 18:36:32,175 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,175 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,176 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,176 [Executor task launch worker for task 4] INFO  Executor - Running task 0.0 in stage 1.0 (TID 4)
2018-04-26 18:36:32,176 [Executor task launch worker for task 6] INFO  Executor - Running task 2.0 in stage 1.0 (TID 6)
2018-04-26 18:36:32,176 [Executor task launch worker for task 7] INFO  Executor - Running task 3.0 in stage 1.0 (TID 7)
2018-04-26 18:36:32,176 [Executor task launch worker for task 5] INFO  Executor - Running task 1.0 in stage 1.0 (TID 5)
2018-04-26 18:36:32,208 [Executor task launch worker for task 4] INFO  Executor - Finished task 0.0 in stage 1.0 (TID 4). 958 bytes result sent to driver
2018-04-26 18:36:32,208 [Executor task launch worker for task 6] INFO  Executor - Finished task 2.0 in stage 1.0 (TID 6). 1044 bytes result sent to driver
2018-04-26 18:36:32,209 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 1.0 (TID 4) in 35 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,210 [task-result-getter-1] INFO  TaskSetManager - Finished task 2.0 in stage 1.0 (TID 6) in 35 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,212 [Executor task launch worker for task 5] INFO  Executor - Finished task 1.0 in stage 1.0 (TID 5). 1044 bytes result sent to driver
2018-04-26 18:36:32,213 [task-result-getter-2] INFO  TaskSetManager - Finished task 1.0 in stage 1.0 (TID 5) in 39 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,214 [Executor task launch worker for task 7] INFO  Executor - Finished task 3.0 in stage 1.0 (TID 7). 1044 bytes result sent to driver
2018-04-26 18:36:32,218 [task-result-getter-3] INFO  TaskSetManager - Finished task 3.0 in stage 1.0 (TID 7) in 43 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,218 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,218 [dag-scheduler-event-loop] INFO  DAGScheduler - ShuffleMapStage 1 (distinct at WriteGEXF.scala:62) finished in 0.050 s
2018-04-26 18:36:32,218 [dag-scheduler-event-loop] INFO  DAGScheduler - looking for newly runnable stages
2018-04-26 18:36:32,218 [dag-scheduler-event-loop] INFO  DAGScheduler - running: Set()
2018-04-26 18:36:32,218 [dag-scheduler-event-loop] INFO  DAGScheduler - waiting: Set(ResultStage 2)
2018-04-26 18:36:32,219 [dag-scheduler-event-loop] INFO  DAGScheduler - failed: Set()
2018-04-26 18:36:32,219 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGEXF.scala:62), which has no missing parents
2018-04-26 18:36:32,221 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 8.2 GB)
2018-04-26 18:36:32,223 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 8.2 GB)
2018-04-26 18:36:32,224 [dispatcher-event-loop-1] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on spirals-vortex.lille.inria.fr:40137 (size: 2.2 KB, free: 8.2 GB)
2018-04-26 18:36:32,224 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,225 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGEXF.scala:62) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,225 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 2.0 with 4 tasks
2018-04-26 18:36:32,226 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7649 bytes)
2018-04-26 18:36:32,226 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 7649 bytes)
2018-04-26 18:36:32,227 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7649 bytes)
2018-04-26 18:36:32,227 [dispatcher-event-loop-2] INFO  TaskSetManager - Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7649 bytes)
2018-04-26 18:36:32,227 [Executor task launch worker for task 8] INFO  Executor - Running task 0.0 in stage 2.0 (TID 8)
2018-04-26 18:36:32,227 [Executor task launch worker for task 9] INFO  Executor - Running task 1.0 in stage 2.0 (TID 9)
2018-04-26 18:36:32,227 [Executor task launch worker for task 11] INFO  Executor - Running task 3.0 in stage 2.0 (TID 11)
2018-04-26 18:36:32,227 [Executor task launch worker for task 10] INFO  Executor - Running task 2.0 in stage 2.0 (TID 10)
2018-04-26 18:36:32,231 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,231 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,231 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,231 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,231 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,231 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,231 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,232 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2018-04-26 18:36:32,242 [Executor task launch worker for task 8] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 8). 1138 bytes result sent to driver
2018-04-26 18:36:32,243 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 17 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,247 [Executor task launch worker for task 10] INFO  Executor - Finished task 2.0 in stage 2.0 (TID 10). 1341 bytes result sent to driver
2018-04-26 18:36:32,247 [task-result-getter-1] INFO  TaskSetManager - Finished task 2.0 in stage 2.0 (TID 10) in 21 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,248 [Executor task launch worker for task 9] INFO  Executor - Finished task 1.0 in stage 2.0 (TID 9). 1138 bytes result sent to driver
2018-04-26 18:36:32,249 [task-result-getter-2] INFO  TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 23 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,253 [Executor task launch worker for task 11] INFO  Executor - Finished task 3.0 in stage 2.0 (TID 11). 1349 bytes result sent to driver
2018-04-26 18:36:32,253 [task-result-getter-3] INFO  TaskSetManager - Finished task 3.0 in stage 2.0 (TID 11) in 26 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,254 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,254 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 2 (collect at WriteGEXF.scala:62) finished in 0.034 s
2018-04-26 18:36:32,255 [main-ScalaTest-running-WriteGEXFTest] INFO  DAGScheduler - Job 1 finished: collect at WriteGEXF.scala:62, took 0.102203 s
true
2018-04-26 18:36:32,258 [main-ScalaTest-running-WriteGEXFTest] INFO  AbstractConnector - Stopped Spark@592ca48c{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,258 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,261 [dispatcher-event-loop-1] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:32,267 [main-ScalaTest-running-WriteGEXFTest] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:32,267 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:32,267 [main-ScalaTest-running-WriteGEXFTest] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:32,268 [dispatcher-event-loop-2] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:32,273 [main-ScalaTest-running-WriteGEXFTest] INFO  SparkContext - Successfully stopped SparkContext
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.313 sec
Running io.archivesunleashed.app.WriteGraphMLTest
2018-04-26 18:36:32,279 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:32,280 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:32,281 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:32,281 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:32,281 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:32,281 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:32,281 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:32,287 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'sparkDriver' on port 43094.
2018-04-26 18:36:32,290 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:32,291 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:32,292 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:32,292 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:32,293 [main-ScalaTest-running-WriteGraphMLTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-19672a07-731f-45e0-845e-2836fc361cc0
2018-04-26 18:36:32,293 [main-ScalaTest-running-WriteGraphMLTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:32,297 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:32,301 [main-ScalaTest-running-WriteGraphMLTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:32,303 [main-ScalaTest-running-WriteGraphMLTest] INFO  Server - Started @5926ms
2018-04-26 18:36:32,304 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:32,304 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:32,304 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:32,304 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:32,304 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:32,305 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2018-04-26 18:36:32,305 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
2018-04-26 18:36:32,305 [main-ScalaTest-running-WriteGraphMLTest] INFO  AbstractConnector - Started ServerConnector@14fc9bd{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,307 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'SparkUI' on port 4047.
2018-04-26 18:36:32,307 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7ed49a7f{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,307 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1cd6b1bd{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,308 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@443cdaa4{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,308 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b41e1bf{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,308 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@619c93ca{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,308 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@486e9d1d{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,309 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6aa5974e{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,309 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5e5ddfbc{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,309 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5bda157e{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,309 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@67e0fd6d{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,309 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@21390938{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,310 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1129829c{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,310 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1a531422{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,310 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a388990{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,311 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@13213f26{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,311 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4e4162bc{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,311 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4c319d52{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,311 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@72fbf94d{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,312 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6839203b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,312 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2d28fb02{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,312 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6db328f8{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,313 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@402f8592{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,313 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@61b65d54{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,313 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7f2c57fe{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,314 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@43935e9c{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,314 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,342 [main-ScalaTest-running-WriteGraphMLTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:32,347 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44451.
2018-04-26 18:36:32,347 [main-ScalaTest-running-WriteGraphMLTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:44451
2018-04-26 18:36:32,347 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:32,347 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 44451, None)
2018-04-26 18:36:32,347 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:44451 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 44451, None)
2018-04-26 18:36:32,348 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 44451, None)
2018-04-26 18:36:32,348 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 44451, None)
2018-04-26 18:36:32,349 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@49671897{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,360 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Starting job: collect at WriteGraphML.scala:53
2018-04-26 18:36:32,360 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 0 (collect at WriteGraphML.scala:53) with 4 output partitions
2018-04-26 18:36:32,360 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 0 (collect at WriteGraphML.scala:53)
2018-04-26 18:36:32,360 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List()
2018-04-26 18:36:32,361 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List()
2018-04-26 18:36:32,361 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at map at WriteGraphML.scala:49), which has no missing parents
2018-04-26 18:36:32,364 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 1872.0 B, free 8.2 GB)
2018-04-26 18:36:32,366 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1219.0 B, free 8.2 GB)
2018-04-26 18:36:32,367 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:44451 (size: 1219.0 B, free: 8.2 GB)
2018-04-26 18:36:32,369 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,369 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at WriteGraphML.scala:49) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,369 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 0.0 with 4 tasks
2018-04-26 18:36:32,371 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7851 bytes)
2018-04-26 18:36:32,371 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,371 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,372 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,382 [Executor task launch worker for task 0] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
2018-04-26 18:36:32,384 [Executor task launch worker for task 1] INFO  Executor - Running task 1.0 in stage 0.0 (TID 1)
2018-04-26 18:36:32,385 [Executor task launch worker for task 2] INFO  Executor - Running task 2.0 in stage 0.0 (TID 2)
2018-04-26 18:36:32,386 [Executor task launch worker for task 3] INFO  Executor - Running task 3.0 in stage 0.0 (TID 3)
2018-04-26 18:36:32,389 [Executor task launch worker for task 0] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 708 bytes result sent to driver
2018-04-26 18:36:32,390 [Executor task launch worker for task 3] INFO  Executor - Finished task 3.0 in stage 0.0 (TID 3). 892 bytes result sent to driver
2018-04-26 18:36:32,390 [Executor task launch worker for task 2] INFO  Executor - Finished task 2.0 in stage 0.0 (TID 2). 890 bytes result sent to driver
2018-04-26 18:36:32,390 [Executor task launch worker for task 1] INFO  Executor - Finished task 1.0 in stage 0.0 (TID 1). 890 bytes result sent to driver
2018-04-26 18:36:32,391 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 20 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,392 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 21 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,392 [task-result-getter-2] INFO  TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 21 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,393 [task-result-getter-3] INFO  TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 22 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,393 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,393 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 0 (collect at WriteGraphML.scala:53) finished in 0.031 s
2018-04-26 18:36:32,394 [main-ScalaTest-running-WriteGraphMLTest] INFO  DAGScheduler - Job 0 finished: collect at WriteGraphML.scala:53, took 0.033715 s
2018-04-26 18:36:32,407 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Starting job: collect at WriteGraphML.scala:57
2018-04-26 18:36:32,416 [dag-scheduler-event-loop] INFO  DAGScheduler - Registering RDD 3 (distinct at WriteGraphML.scala:57)
2018-04-26 18:36:32,417 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 1 (collect at WriteGraphML.scala:57) with 4 output partitions
2018-04-26 18:36:32,417 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 2 (collect at WriteGraphML.scala:57)
2018-04-26 18:36:32,417 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2018-04-26 18:36:32,417 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2018-04-26 18:36:32,417 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGraphML.scala:57), which has no missing parents
2018-04-26 18:36:32,419 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 8.2 GB)
2018-04-26 18:36:32,422 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2036.0 B, free 8.2 GB)
2018-04-26 18:36:32,422 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on spirals-vortex.lille.inria.fr:44451 (size: 2036.0 B, free: 8.2 GB)
2018-04-26 18:36:32,423 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,423 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGraphML.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,423 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 1.0 with 4 tasks
2018-04-26 18:36:32,424 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7840 bytes)
2018-04-26 18:36:32,425 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,425 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,425 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,425 [Executor task launch worker for task 4] INFO  Executor - Running task 0.0 in stage 1.0 (TID 4)
2018-04-26 18:36:32,425 [Executor task launch worker for task 7] INFO  Executor - Running task 3.0 in stage 1.0 (TID 7)
2018-04-26 18:36:32,425 [Executor task launch worker for task 5] INFO  Executor - Running task 1.0 in stage 1.0 (TID 5)
2018-04-26 18:36:32,425 [Executor task launch worker for task 6] INFO  Executor - Running task 2.0 in stage 1.0 (TID 6)
2018-04-26 18:36:32,441 [Executor task launch worker for task 4] INFO  Executor - Finished task 0.0 in stage 1.0 (TID 4). 958 bytes result sent to driver
2018-04-26 18:36:32,444 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 1.0 (TID 4) in 20 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,447 [Executor task launch worker for task 7] INFO  Executor - Finished task 3.0 in stage 1.0 (TID 7). 1044 bytes result sent to driver
2018-04-26 18:36:32,448 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 1.0 (TID 7) in 23 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,450 [Executor task launch worker for task 5] INFO  Executor - Finished task 1.0 in stage 1.0 (TID 5). 1044 bytes result sent to driver
2018-04-26 18:36:32,450 [task-result-getter-2] INFO  TaskSetManager - Finished task 1.0 in stage 1.0 (TID 5) in 26 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,451 [Executor task launch worker for task 6] INFO  Executor - Finished task 2.0 in stage 1.0 (TID 6). 1044 bytes result sent to driver
2018-04-26 18:36:32,451 [task-result-getter-3] INFO  TaskSetManager - Finished task 2.0 in stage 1.0 (TID 6) in 26 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,451 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,451 [dag-scheduler-event-loop] INFO  DAGScheduler - ShuffleMapStage 1 (distinct at WriteGraphML.scala:57) finished in 0.033 s
2018-04-26 18:36:32,452 [dag-scheduler-event-loop] INFO  DAGScheduler - looking for newly runnable stages
2018-04-26 18:36:32,452 [dag-scheduler-event-loop] INFO  DAGScheduler - running: Set()
2018-04-26 18:36:32,452 [dag-scheduler-event-loop] INFO  DAGScheduler - waiting: Set(ResultStage 2)
2018-04-26 18:36:32,452 [dag-scheduler-event-loop] INFO  DAGScheduler - failed: Set()
2018-04-26 18:36:32,452 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGraphML.scala:57), which has no missing parents
2018-04-26 18:36:32,454 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 8.2 GB)
2018-04-26 18:36:32,455 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 8.2 GB)
2018-04-26 18:36:32,456 [dispatcher-event-loop-2] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on spirals-vortex.lille.inria.fr:44451 (size: 2.2 KB, free: 8.2 GB)
2018-04-26 18:36:32,456 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,457 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGraphML.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,457 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 2.0 with 4 tasks
2018-04-26 18:36:32,458 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7649 bytes)
2018-04-26 18:36:32,458 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7649 bytes)
2018-04-26 18:36:32,458 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7649 bytes)
2018-04-26 18:36:32,459 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7649 bytes)
2018-04-26 18:36:32,459 [Executor task launch worker for task 8] INFO  Executor - Running task 0.0 in stage 2.0 (TID 8)
2018-04-26 18:36:32,459 [Executor task launch worker for task 9] INFO  Executor - Running task 1.0 in stage 2.0 (TID 9)
2018-04-26 18:36:32,459 [Executor task launch worker for task 11] INFO  Executor - Running task 3.0 in stage 2.0 (TID 11)
2018-04-26 18:36:32,459 [Executor task launch worker for task 10] INFO  Executor - Running task 2.0 in stage 2.0 (TID 10)
2018-04-26 18:36:32,462 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,462 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,462 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2018-04-26 18:36:32,462 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,462 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,462 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,462 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,462 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,471 [Executor task launch worker for task 11] INFO  Executor - Finished task 3.0 in stage 2.0 (TID 11). 1184 bytes result sent to driver
2018-04-26 18:36:32,472 [task-result-getter-0] INFO  TaskSetManager - Finished task 3.0 in stage 2.0 (TID 11) in 14 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,474 [Executor task launch worker for task 8] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 8). 1273 bytes result sent to driver
2018-04-26 18:36:32,474 [task-result-getter-1] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 16 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,476 [Executor task launch worker for task 10] INFO  Executor - Finished task 2.0 in stage 2.0 (TID 10). 1189 bytes result sent to driver
2018-04-26 18:36:32,476 [task-result-getter-2] INFO  TaskSetManager - Finished task 2.0 in stage 2.0 (TID 10) in 18 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,479 [Executor task launch worker for task 9] INFO  Executor - Finished task 1.0 in stage 2.0 (TID 9). 1283 bytes result sent to driver
2018-04-26 18:36:32,479 [task-result-getter-3] INFO  TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 21 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,479 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,480 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 2 (collect at WriteGraphML.scala:57) finished in 0.027 s
2018-04-26 18:36:32,480 [main-ScalaTest-running-WriteGraphMLTest] INFO  DAGScheduler - Job 1 finished: collect at WriteGraphML.scala:57, took 0.073221 s
2018-04-26 18:36:32,483 [main-ScalaTest-running-WriteGraphMLTest] INFO  AbstractConnector - Stopped Spark@14fc9bd{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,484 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,488 [dispatcher-event-loop-2] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:32,492 [main-ScalaTest-running-WriteGraphMLTest] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:32,492 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:32,492 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:32,493 [dispatcher-event-loop-3] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:32,497 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:32,498 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Running Spark version 2.3.0
2018-04-26 18:36:32,499 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Submitted application: example-spark
2018-04-26 18:36:32,500 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing view acls to: root
2018-04-26 18:36:32,500 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing modify acls to: root
2018-04-26 18:36:32,500 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing view acls groups to: 
2018-04-26 18:36:32,500 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - Changing modify acls groups to: 
2018-04-26 18:36:32,500 [main-ScalaTest-running-WriteGraphMLTest] INFO  SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-04-26 18:36:32,505 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'sparkDriver' on port 45349.
2018-04-26 18:36:32,507 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering MapOutputTracker
2018-04-26 18:36:32,508 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering BlockManagerMaster
2018-04-26 18:36:32,508 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-04-26 18:36:32,508 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2018-04-26 18:36:32,508 [main-ScalaTest-running-WriteGraphMLTest] INFO  DiskBlockManager - Created local directory at /tmp/blockmgr-5256b1cb-fc09-431d-a58b-c17a727836cc
2018-04-26 18:36:32,508 [main-ScalaTest-running-WriteGraphMLTest] INFO  MemoryStore - MemoryStore started with capacity 8.2 GB
2018-04-26 18:36:32,510 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkEnv - Registering OutputCommitCoordinator
2018-04-26 18:36:32,512 [main-ScalaTest-running-WriteGraphMLTest] INFO  Server - jetty-9.3.z-SNAPSHOT
2018-04-26 18:36:32,514 [main-ScalaTest-running-WriteGraphMLTest] INFO  Server - Started @6137ms
2018-04-26 18:36:32,515 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2018-04-26 18:36:32,515 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
2018-04-26 18:36:32,515 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
2018-04-26 18:36:32,515 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
2018-04-26 18:36:32,516 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
2018-04-26 18:36:32,516 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
2018-04-26 18:36:32,516 [main-ScalaTest-running-WriteGraphMLTest] WARN  Utils - Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
2018-04-26 18:36:32,517 [main-ScalaTest-running-WriteGraphMLTest] INFO  AbstractConnector - Started ServerConnector@40df6090{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,519 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'SparkUI' on port 4047.
2018-04-26 18:36:32,520 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@8c0a23f{/jobs,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,520 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@44d7e24{/jobs/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,520 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@26c8b296{/jobs/job,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,520 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1d289d3f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,521 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@10f405ff{/stages,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,521 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7f27f59b{/stages/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,521 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1c98b4eb{/stages/stage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,521 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@45801322{/stages/stage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,521 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@756b2d90{/stages/pool,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,522 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3520958b{/stages/pool/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,522 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6cc64028{/storage,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,522 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@291a4791{/storage/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,522 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5b1e88f{/storage/rdd,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,523 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@340cb97f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,523 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@6a1568d6{/environment,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,523 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@11c88cca{/environment/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,524 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@1b37fbec{/executors,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,524 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@4a216eb4{/executors/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,524 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@bb3ecfe{/executors/threadDump,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,524 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@5ec88f9e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,525 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@7a04f730{/static,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,525 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@3b11620a{/,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,525 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@2fd1ad8a{/api,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,525 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@689faf79{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,526 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@582e9152{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,526 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkUI - Bound SparkUI to 0.0.0.0, and started at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,551 [main-ScalaTest-running-WriteGraphMLTest] INFO  Executor - Starting executor ID driver on host localhost
2018-04-26 18:36:32,559 [main-ScalaTest-running-WriteGraphMLTest] INFO  Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38784.
2018-04-26 18:36:32,559 [main-ScalaTest-running-WriteGraphMLTest] INFO  NettyBlockTransferService - Server created on spirals-vortex.lille.inria.fr:38784
2018-04-26 18:36:32,559 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-04-26 18:36:32,559 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - Registering BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 38784, None)
2018-04-26 18:36:32,560 [dispatcher-event-loop-2] INFO  BlockManagerMasterEndpoint - Registering block manager spirals-vortex.lille.inria.fr:38784 with 8.2 GB RAM, BlockManagerId(driver, spirals-vortex.lille.inria.fr, 38784, None)
2018-04-26 18:36:32,561 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - Registered BlockManager BlockManagerId(driver, spirals-vortex.lille.inria.fr, 38784, None)
2018-04-26 18:36:32,561 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - Initialized BlockManager: BlockManagerId(driver, spirals-vortex.lille.inria.fr, 38784, None)
2018-04-26 18:36:32,562 [main-ScalaTest-running-WriteGraphMLTest] INFO  ContextHandler - Started o.s.j.s.ServletContextHandler@370c9018{/metrics/json,null,AVAILABLE,@Spark}
2018-04-26 18:36:32,570 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Starting job: collect at WriteGraphML.scala:53
2018-04-26 18:36:32,571 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 0 (collect at WriteGraphML.scala:53) with 4 output partitions
2018-04-26 18:36:32,571 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 0 (collect at WriteGraphML.scala:53)
2018-04-26 18:36:32,571 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List()
2018-04-26 18:36:32,571 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List()
2018-04-26 18:36:32,571 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at map at WriteGraphML.scala:49), which has no missing parents
2018-04-26 18:36:32,575 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0 stored as values in memory (estimated size 1872.0 B, free 8.2 GB)
2018-04-26 18:36:32,576 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1219.0 B, free 8.2 GB)
2018-04-26 18:36:32,577 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_0_piece0 in memory on spirals-vortex.lille.inria.fr:38784 (size: 1219.0 B, free: 8.2 GB)
2018-04-26 18:36:32,579 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,579 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at WriteGraphML.scala:49) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,579 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 0.0 with 4 tasks
2018-04-26 18:36:32,581 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7851 bytes)
2018-04-26 18:36:32,581 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,582 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,582 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2018-04-26 18:36:32,583 [Executor task launch worker for task 0] INFO  Executor - Running task 0.0 in stage 0.0 (TID 0)
2018-04-26 18:36:32,584 [Executor task launch worker for task 1] INFO  Executor - Running task 1.0 in stage 0.0 (TID 1)
2018-04-26 18:36:32,585 [Executor task launch worker for task 2] INFO  Executor - Running task 2.0 in stage 0.0 (TID 2)
2018-04-26 18:36:32,586 [Executor task launch worker for task 3] INFO  Executor - Running task 3.0 in stage 0.0 (TID 3)
2018-04-26 18:36:32,588 [Executor task launch worker for task 0] INFO  Executor - Finished task 0.0 in stage 0.0 (TID 0). 665 bytes result sent to driver
2018-04-26 18:36:32,589 [Executor task launch worker for task 3] INFO  Executor - Finished task 3.0 in stage 0.0 (TID 3). 892 bytes result sent to driver
2018-04-26 18:36:32,589 [Executor task launch worker for task 2] INFO  Executor - Finished task 2.0 in stage 0.0 (TID 2). 890 bytes result sent to driver
2018-04-26 18:36:32,589 [Executor task launch worker for task 1] INFO  Executor - Finished task 1.0 in stage 0.0 (TID 1). 890 bytes result sent to driver
2018-04-26 18:36:32,592 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 11 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,593 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 11 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,594 [task-result-getter-2] INFO  TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 13 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,594 [task-result-getter-3] INFO  TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 13 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,595 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,595 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 0 (collect at WriteGraphML.scala:53) finished in 0.023 s
2018-04-26 18:36:32,595 [main-ScalaTest-running-WriteGraphMLTest] INFO  DAGScheduler - Job 0 finished: collect at WriteGraphML.scala:53, took 0.025107 s
2018-04-26 18:36:32,609 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Starting job: collect at WriteGraphML.scala:57
2018-04-26 18:36:32,616 [dag-scheduler-event-loop] INFO  DAGScheduler - Registering RDD 3 (distinct at WriteGraphML.scala:57)
2018-04-26 18:36:32,616 [dag-scheduler-event-loop] INFO  DAGScheduler - Got job 1 (collect at WriteGraphML.scala:57) with 4 output partitions
2018-04-26 18:36:32,616 [dag-scheduler-event-loop] INFO  DAGScheduler - Final stage: ResultStage 2 (collect at WriteGraphML.scala:57)
2018-04-26 18:36:32,616 [dag-scheduler-event-loop] INFO  DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2018-04-26 18:36:32,616 [dag-scheduler-event-loop] INFO  DAGScheduler - Missing parents: List(ShuffleMapStage 1)
2018-04-26 18:36:32,617 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGraphML.scala:57), which has no missing parents
2018-04-26 18:36:32,619 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 8.2 GB)
2018-04-26 18:36:32,620 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2036.0 B, free 8.2 GB)
2018-04-26 18:36:32,620 [dispatcher-event-loop-0] INFO  BlockManagerInfo - Added broadcast_1_piece0 in memory on spirals-vortex.lille.inria.fr:38784 (size: 2036.0 B, free: 8.2 GB)
2018-04-26 18:36:32,621 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,621 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at distinct at WriteGraphML.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,621 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 1.0 with 4 tasks
2018-04-26 18:36:32,622 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7840 bytes)
2018-04-26 18:36:32,622 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,622 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,623 [dispatcher-event-loop-1] INFO  TaskSetManager - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7991 bytes)
2018-04-26 18:36:32,623 [Executor task launch worker for task 4] INFO  Executor - Running task 0.0 in stage 1.0 (TID 4)
2018-04-26 18:36:32,623 [Executor task launch worker for task 5] INFO  Executor - Running task 1.0 in stage 1.0 (TID 5)
2018-04-26 18:36:32,623 [Executor task launch worker for task 6] INFO  Executor - Running task 2.0 in stage 1.0 (TID 6)
2018-04-26 18:36:32,623 [Executor task launch worker for task 7] INFO  Executor - Running task 3.0 in stage 1.0 (TID 7)
2018-04-26 18:36:32,638 [Executor task launch worker for task 4] INFO  Executor - Finished task 0.0 in stage 1.0 (TID 4). 958 bytes result sent to driver
2018-04-26 18:36:32,642 [Executor task launch worker for task 7] INFO  Executor - Finished task 3.0 in stage 1.0 (TID 7). 1001 bytes result sent to driver
2018-04-26 18:36:32,645 [task-result-getter-0] INFO  TaskSetManager - Finished task 0.0 in stage 1.0 (TID 4) in 23 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,646 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 1.0 (TID 7) in 23 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,647 [Executor task launch worker for task 5] INFO  Executor - Finished task 1.0 in stage 1.0 (TID 5). 1001 bytes result sent to driver
2018-04-26 18:36:32,648 [task-result-getter-2] INFO  TaskSetManager - Finished task 1.0 in stage 1.0 (TID 5) in 26 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,649 [Executor task launch worker for task 6] INFO  Executor - Finished task 2.0 in stage 1.0 (TID 6). 1044 bytes result sent to driver
2018-04-26 18:36:32,650 [task-result-getter-3] INFO  TaskSetManager - Finished task 2.0 in stage 1.0 (TID 6) in 28 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,650 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,650 [dag-scheduler-event-loop] INFO  DAGScheduler - ShuffleMapStage 1 (distinct at WriteGraphML.scala:57) finished in 0.033 s
2018-04-26 18:36:32,650 [dag-scheduler-event-loop] INFO  DAGScheduler - looking for newly runnable stages
2018-04-26 18:36:32,650 [dag-scheduler-event-loop] INFO  DAGScheduler - running: Set()
2018-04-26 18:36:32,650 [dag-scheduler-event-loop] INFO  DAGScheduler - waiting: Set(ResultStage 2)
2018-04-26 18:36:32,651 [dag-scheduler-event-loop] INFO  DAGScheduler - failed: Set()
2018-04-26 18:36:32,651 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGraphML.scala:57), which has no missing parents
2018-04-26 18:36:32,653 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2 stored as values in memory (estimated size 3.9 KB, free 8.2 GB)
2018-04-26 18:36:32,655 [dag-scheduler-event-loop] INFO  MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 8.2 GB)
2018-04-26 18:36:32,656 [dispatcher-event-loop-2] INFO  BlockManagerInfo - Added broadcast_2_piece0 in memory on spirals-vortex.lille.inria.fr:38784 (size: 2.2 KB, free: 8.2 GB)
2018-04-26 18:36:32,656 [dag-scheduler-event-loop] INFO  SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-04-26 18:36:32,657 [dag-scheduler-event-loop] INFO  DAGScheduler - Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at distinct at WriteGraphML.scala:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2018-04-26 18:36:32,657 [dag-scheduler-event-loop] INFO  TaskSchedulerImpl - Adding task set 2.0 with 4 tasks
2018-04-26 18:36:32,658 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7649 bytes)
2018-04-26 18:36:32,658 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7649 bytes)
2018-04-26 18:36:32,658 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7649 bytes)
2018-04-26 18:36:32,659 [dispatcher-event-loop-3] INFO  TaskSetManager - Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7649 bytes)
2018-04-26 18:36:32,659 [Executor task launch worker for task 9] INFO  Executor - Running task 1.0 in stage 2.0 (TID 9)
2018-04-26 18:36:32,659 [Executor task launch worker for task 11] INFO  Executor - Running task 3.0 in stage 2.0 (TID 11)
2018-04-26 18:36:32,659 [Executor task launch worker for task 10] INFO  Executor - Running task 2.0 in stage 2.0 (TID 10)
2018-04-26 18:36:32,659 [Executor task launch worker for task 8] INFO  Executor - Running task 0.0 in stage 2.0 (TID 8)
2018-04-26 18:36:32,661 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,661 [Executor task launch worker for task 11] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,661 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,661 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,661 [Executor task launch worker for task 8] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,661 [Executor task launch worker for task 10] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,661 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Getting 2 non-empty blocks out of 4 blocks
2018-04-26 18:36:32,661 [Executor task launch worker for task 9] INFO  ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2018-04-26 18:36:32,671 [Executor task launch worker for task 9] INFO  Executor - Finished task 1.0 in stage 2.0 (TID 9). 1326 bytes result sent to driver
2018-04-26 18:36:32,672 [task-result-getter-0] INFO  TaskSetManager - Finished task 1.0 in stage 2.0 (TID 9) in 14 ms on localhost (executor driver) (1/4)
2018-04-26 18:36:32,674 [Executor task launch worker for task 11] INFO  Executor - Finished task 3.0 in stage 2.0 (TID 11). 1227 bytes result sent to driver
2018-04-26 18:36:32,674 [task-result-getter-1] INFO  TaskSetManager - Finished task 3.0 in stage 2.0 (TID 11) in 16 ms on localhost (executor driver) (2/4)
2018-04-26 18:36:32,678 [Executor task launch worker for task 10] INFO  Executor - Finished task 2.0 in stage 2.0 (TID 10). 1232 bytes result sent to driver
2018-04-26 18:36:32,678 [task-result-getter-2] INFO  TaskSetManager - Finished task 2.0 in stage 2.0 (TID 10) in 20 ms on localhost (executor driver) (3/4)
2018-04-26 18:36:32,680 [Executor task launch worker for task 8] INFO  Executor - Finished task 0.0 in stage 2.0 (TID 8). 1273 bytes result sent to driver
2018-04-26 18:36:32,681 [task-result-getter-3] INFO  TaskSetManager - Finished task 0.0 in stage 2.0 (TID 8) in 24 ms on localhost (executor driver) (4/4)
2018-04-26 18:36:32,681 [task-result-getter-3] INFO  TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-04-26 18:36:32,681 [dag-scheduler-event-loop] INFO  DAGScheduler - ResultStage 2 (collect at WriteGraphML.scala:57) finished in 0.029 s
2018-04-26 18:36:32,681 [main-ScalaTest-running-WriteGraphMLTest] INFO  DAGScheduler - Job 1 finished: collect at WriteGraphML.scala:57, took 0.072440 s
true
2018-04-26 18:36:32,684 [main-ScalaTest-running-WriteGraphMLTest] INFO  AbstractConnector - Stopped Spark@40df6090{HTTP/1.1,[http/1.1]}{0.0.0.0:4047}
2018-04-26 18:36:32,684 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4047
2018-04-26 18:36:32,687 [dispatcher-event-loop-2] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:32,692 [main-ScalaTest-running-WriteGraphMLTest] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:32,692 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:32,692 [main-ScalaTest-running-WriteGraphMLTest] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:32,693 [dispatcher-event-loop-0] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:32,697 [main-ScalaTest-running-WriteGraphMLTest] INFO  SparkContext - Successfully stopped SparkContext
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.422 sec
Running io.archivesunleashed.matchbox.ComputeImageSizeTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.04 sec
Running io.archivesunleashed.matchbox.ExtractAtMentionsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running io.archivesunleashed.matchbox.ExtractBoilerpipeTextTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.074 sec
Running io.archivesunleashed.matchbox.ExtractDateTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running io.archivesunleashed.matchbox.ExtractDomainTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec
Running io.archivesunleashed.matchbox.ExtractHashtagTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running io.archivesunleashed.matchbox.ExtractImageLinksTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.106 sec
Running io.archivesunleashed.matchbox.ExtractLinksTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 sec
Running io.archivesunleashed.matchbox.ExtractTextFromPDFsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 sec
Running io.archivesunleashed.matchbox.ExtractUrlsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 sec
Running io.archivesunleashed.matchbox.JsonUtilsTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.061 sec
Running io.archivesunleashed.matchbox.RemoveHTMLTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 sec
Running io.archivesunleashed.matchbox.RemoveHttpHeaderTest
java.lang.NullPointerException
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 sec
Running io.archivesunleashed.matchbox.StringUtilsTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 sec
Running io.archivesunleashed.matchbox.TupleFormatterTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.047 sec
Running io.archivesunleashed.util.TweetUtilsTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.046 sec
Running io.archivesunleashed.data.ArchiveRecordWritableTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.553 sec
Running io.archivesunleashed.data.ArcLoaderTest
2018-04-26 18:36:33,838 [main] INFO  ArcLoaderTest - 300 records read!
2018-04-26 18:36:34,012 [main] INFO  ArcLoaderTest - 300 records read!
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.287 sec
Running io.archivesunleashed.data.WarcLoaderTest
2018-04-26 18:36:34,385 [main] INFO  WarcLoaderTest - 822 records read!
2018-04-26 18:36:34,690 [main] INFO  WarcLoaderTest - 822 records read!
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.678 sec
Running io.archivesunleashed.data.ArchiveRecordInputFormatTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.304 sec
2018-04-26 18:36:35,001 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,003 [Thread-2] INFO  AbstractConnector - Stopped Spark@1556f2dd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-04-26 18:36:35,004 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4040
2018-04-26 18:36:35,005 [dispatcher-event-loop-3] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,009 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,009 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,009 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,009 [dispatcher-event-loop-0] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,012 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,012 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,013 [Thread-2] INFO  AbstractConnector - Stopped Spark@77a074b4{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2018-04-26 18:36:35,014 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4041
2018-04-26 18:36:35,015 [dispatcher-event-loop-3] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,017 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,017 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,017 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,017 [dispatcher-event-loop-0] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,020 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,020 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,022 [Thread-2] INFO  AbstractConnector - Stopped Spark@4d6ccc97{HTTP/1.1,[http/1.1]}{0.0.0.0:4043}
2018-04-26 18:36:35,022 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4043
2018-04-26 18:36:35,023 [dispatcher-event-loop-2] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,026 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,026 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,026 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,026 [dispatcher-event-loop-2] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,029 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,029 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,030 [Thread-2] INFO  AbstractConnector - Stopped Spark@49e4c2d5{HTTP/1.1,[http/1.1]}{0.0.0.0:4044}
2018-04-26 18:36:35,031 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4044
2018-04-26 18:36:35,034 [dispatcher-event-loop-0] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,037 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,037 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,037 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,037 [dispatcher-event-loop-1] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,040 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,040 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,041 [Thread-2] INFO  AbstractConnector - Stopped Spark@17461db{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2018-04-26 18:36:35,041 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4042
2018-04-26 18:36:35,042 [dispatcher-event-loop-3] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,044 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,044 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,045 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,045 [dispatcher-event-loop-0] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,047 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,047 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,048 [Thread-2] INFO  AbstractConnector - Stopped Spark@77429040{HTTP/1.1,[http/1.1]}{0.0.0.0:4046}
2018-04-26 18:36:35,048 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4046
2018-04-26 18:36:35,051 [dispatcher-event-loop-3] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,054 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,054 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,054 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,054 [dispatcher-event-loop-0] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,057 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,057 [Thread-2] INFO  SparkContext - Invoking stop() from shutdown hook
2018-04-26 18:36:35,058 [Thread-2] INFO  AbstractConnector - Stopped Spark@34d713a2{HTTP/1.1,[http/1.1]}{0.0.0.0:4045}
2018-04-26 18:36:35,058 [Thread-2] INFO  SparkUI - Stopped Spark web UI at http://spirals-vortex.lille.inria.fr:4045
2018-04-26 18:36:35,061 [dispatcher-event-loop-0] INFO  MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2018-04-26 18:36:35,064 [Thread-2] INFO  MemoryStore - MemoryStore cleared
2018-04-26 18:36:35,064 [Thread-2] INFO  BlockManager - BlockManager stopped
2018-04-26 18:36:35,064 [Thread-2] INFO  BlockManagerMaster - BlockManagerMaster stopped
2018-04-26 18:36:35,065 [dispatcher-event-loop-2] INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2018-04-26 18:36:35,067 [Thread-2] INFO  SparkContext - Successfully stopped SparkContext
2018-04-26 18:36:35,068 [Thread-2] INFO  ShutdownHookManager - Shutdown hook called
2018-04-26 18:36:35,069 [Thread-2] INFO  ShutdownHookManager - Deleting directory /tmp/spark-7a6799e1-25e6-4516-83d5-a2e8e8816722

Results :

Tests in error: 
  io.archivesunleashed.ArcTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.ArchiveRecordTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.CountableRDDTest: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:(..)
  io.archivesunleashed.RecordLoaderTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.RecordRDDTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.WarcTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.app.ExtractGraphTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  io.archivesunleashed.app.ExtractPopularImagesTest: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.mapreduce.lib.input.FileInputFormat

Tests run: 50, Failures: 0, Errors: 8, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 20.565 s
[INFO] Finished at: 2018-04-26T18:36:35+02:00
[INFO] Final Memory: 80M/1460M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.12.4:test (default-test) on project aut: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/archivesunleashed/aut/371645613/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
