[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Singularity
[INFO] SingularityBase
[INFO] SingularityUI
[INFO] SingularityMesosClient
[INFO] SingularitySwagger
[INFO] SingularityService
[INFO] SingularityRunnerBase
[INFO] SingularityS3Base
[INFO] SingularityClient
[INFO] SingularityExecutor
[INFO] SingularityExecutorCleanup
[INFO] SingularityS3Uploader
[INFO] SingularityS3Downloader
[INFO] EmbedSingularityExample
[INFO] SingularityServiceIntegrationTests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Singularity 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ Singularity ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ Singularity ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ Singularity ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ Singularity ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ Singularity ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ Singularity ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ Singularity ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/target/jacoco.exec
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/RequestCleanupType.java:12:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/SlaveMatchState.java:18:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/TaskCleanupType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/RequestType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/HealthcheckProtocol.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/RequestState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/java/com/hubspot/singularity/DeployState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/SingularityBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityUI 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityUI ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityUI ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityUI ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityUI ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityUI ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityUI ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityUI ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/SingularityUI/target/jacoco.exec
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:install-node-and-npm (install node and npm) @ SingularityUI ---
[INFO] Node v6.2.1 is already installed.
[INFO] Found NPM version 3.9.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm install) @ SingularityUI ---
[INFO] Running 'npm install --color=false' in /root/workspace/HubSpot/Singularity/312436596/SingularityUI
[ERROR] npm WARN optional Skipping failed optional dependency /chokidar/fsevents:
[ERROR] npm WARN notsup Not compatible with your operating system or architecture: fsevents@1.1.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm test) @ SingularityUI ---
[INFO] Running 'npm test --color=false' in /root/workspace/HubSpot/Singularity/312436596/SingularityUI
[INFO] 
[INFO] > SingularityUI@0.3.0 test /root/workspace/HubSpot/Singularity/312436596/SingularityUI
[INFO] > mocha --compilers js:babel-core/register test/index.test
[INFO] 
[ERROR] Warning: Accessing PropTypes via the main React package is deprecated, and will be removed in  React v16.0. Use the latest available v15.* prop-types package from npm instead. For info on usage, compatibility, migration and more, see https://fb.me/prop-types-docs
[INFO] 
[INFO] 
[INFO]   Utils
[INFO]     getTaskDataFromTaskId()
[INFO]       âœ“ should grab all fields from a valid task id
[INFO] 
[INFO]   Reducers
[INFO]     tailerView
[INFO]       âœ“ should be properly initialized
[INFO]       âœ“ should populate the tailerId field
[INFO]       âœ“ should auto-populate the requestIds, taskIds, and paths fields
[INFO]       âœ“ should add tailer groups
[INFO]       âœ“ should remove tailer groups
[INFO]       âœ“ should pick an individual tailer group
[INFO] 
[INFO] 
[INFO]   7 passing (47ms)
[INFO] 
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:gulp (gulp build) @ SingularityUI ---
[INFO] Running 'gulp build --no-color' in /root/workspace/HubSpot/Singularity/312436596/SingularityUI
[INFO] [15:19:03] Using gulpfile ~/workspace/HubSpot/Singularity/312436596/SingularityUI/gulpfile.js
[INFO] [15:19:03] Starting 'clean'...
[INFO] [15:19:03] Finished 'clean' after 49 ms
[INFO] [15:19:03] Starting 'static'...
[INFO] [15:19:03] Finished 'static' after 54 ms
[INFO] [15:19:03] Starting 'html'...
[INFO] [15:19:03] Finished 'html' after 27 ms
[INFO] [15:19:03] Starting 'build'...
[INFO] [15:21:35] Version: webpack [1m1.13.1[22m
[INFO] Time: [1m151575[22mms
[INFO]                                [1mAsset[22m     [1mSize[22m  [1mChunks[22m  [1m[22m           [1mChunk Names[22m
[INFO] [1m[32m89889688147bd7575d6327160d64e760.svg[39m[22m   109 kB        [1m[22m  [1m[32m[emitted][39m[22m  
[INFO]                  [1m[32mjs/vendor.bundle.js[39m[22m   618 kB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                     [1m[32mjs/app.bundle.js[39m[22m   2.2 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                          [1m[32mcss/app.css[39m[22m   350 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]              [1m[32mjs/vendor.bundle.js.map[39m[22m  4.62 MB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                 [1m[32mjs/app.bundle.js.map[39m[22m  10.5 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                      [1m[32mcss/app.css.map[39m[22m   419 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] [15:21:35] Finished 'build' after 2.53 min
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-index.html-template) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-ui) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 17 resources
[INFO] 
[INFO] --- build-helper-maven-plugin:1.10:add-resource (add-generated-resources) @ SingularityUI ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityUI/src/main/resources
[INFO] Copying 18 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityUI/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityUI ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityMesosClient 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityMesosClient ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityMesosClient ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:29:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:31:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:33:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:35:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:37:3: Redundant 'public' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityMesosClient ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityMesosClient ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityMesosClient ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularityMesosClient/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityMesosClient ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityMesosClient ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularitySwagger 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularitySwagger ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularitySwagger ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularitySwagger ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularitySwagger ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/SingularitySwagger/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularitySwagger/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularitySwagger ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312436596/SingularitySwagger/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularitySwagger ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularitySwagger ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityService 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityService ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityService ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityService ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityService ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/hooks/LoadBalancerClientImpl.java:114:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:18:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:20:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:22:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:24:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:26:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:175:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:224:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:249:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:289:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:315:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/config/UIConfiguration.java:22:10: Redundant 'static' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorManager.java:64:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityCmdLineArgsMigration.java:57:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:84:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:139:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/history/SingularityHistoryModule.java:126:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorAsyncManager.java:46:5: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312436596/SingularityService/src/main/java/com/hubspot/singularity/smtp/SmtpMailer.java:366:5: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityService ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityService ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityService ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312436596/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312436596/SingularityService/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- swagger-maven-plugin:2.3.2:generate (build-embedded-documentation) @ SingularityService ---
[INFO] Reflections took 84 ms to scan 1 urls, producing 12 keys and 79 values 
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UsageResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskTrackerResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DisastersResource
[INFO] Detect Resource:com.hubspot.singularity.resources.SandboxResource
[INFO] Detect Resource:com.hubspot.singularity.resources.StateResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UserResource
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
[INFO] Detect Resource:com.hubspot.singularity.resources.HistoryResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.PriorityResource
[INFO] Detect Resource:com.hubspot.singularity.resources.InactiveSlaveResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.S3LogResource
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DeployResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.SlaveResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RackResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.WebhookResource
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestGroupResource
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TestResource
[INFO] Writing doc to /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/index.html...
[INFO] Done!
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/service.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_requests.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_usage.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_track.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_disasters.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_sandbox.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_state.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_users.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_history.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_priority.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_inactive.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_logs.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_deploys.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_slaves.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_racks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_webhooks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_groups.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_tasks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/classes/assets/api-docs/api_test.json
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityService ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom (4 KB at 5.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom (3 KB at 108.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar (75 KB at 1027.9 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
Running com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.data.InactiveSlaveManagerTest
Running com.hubspot.singularity.scheduler.SingularityDeploysTest
Running com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
Running com.hubspot.singularity.scheduler.SingularityUsageTest
Running com.hubspot.singularity.JavaUtilsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.21 sec - in com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.data.BlendedHistoryTest
15:22:17.103 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 2112440746)
15:22:17.236 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:17.229 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 821734783)
15:22:17.363 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:18.279 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 449082772)
15:22:18.411 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:18.407 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 574925565)
15:22:18.545 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:18.898 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 85086282)
15:22:19.071 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:19.000 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 201192450)
15:22:19.110 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.158 sec - in com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
15:22:21.593 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1625421984)
15:22:21.723 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:24.849 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:24.884 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13790ms
15:22:25.074 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:25.092 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1e0b10ab
15:22:25.110 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13972ms
15:22:25.233 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@399b690a{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@95e2186,MANAGED}
15:22:25.250 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@54709765
15:22:25.251 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2aa0c509{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@4ff8fa50,MANAGED}
15:22:25.260 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@308ec6a4
15:22:25.356 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@5cc74767{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@38871f7e,MANAGED}
15:22:25.373 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3604c744
15:22:25.389 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@156084ab{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@54ee6229,MANAGED}
15:22:25.526 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@4ff8fa50 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:25.554 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@4ff8fa50 added {[/tasks/*]=>tasks,POJO}
15:22:25.579 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@54ee6229 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:25.603 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@54ee6229 added {[/tasks/*]=>tasks,POJO}
15:22:26.258 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:26.301 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15195ms
15:22:26.492 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@2edd4f66
15:22:26.623 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@15d8b7c4{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@48c96e4f,MANAGED}
15:22:26.653 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@2de6d333
15:22:26.653 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@1f1b09d3{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@52095cd4,MANAGED}
15:22:26.661 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:26.689 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:26.709 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15638ms
15:22:26.733 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15650ms
15:22:26.857 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@43c3092c
15:22:26.884 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@850751a
15:22:26.935 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7f146e49{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@663b6647,MANAGED}
15:22:26.940 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@52095cd4 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:26.953 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@760a5e48
15:22:26.953 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@49b3d43c{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@495e506f,MANAGED}
15:22:26.972 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@52095cd4 added {[/tasks/*]=>tasks,POJO}
15:22:27.014 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:27.029 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@288168c2{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@1a31f3a3,MANAGED}
15:22:27.039 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15955ms
15:22:27.054 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@68718379
15:22:27.069 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@356e9509{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5004ae58,MANAGED}
15:22:27.103 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@495e506f added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:27.128 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@495e506f added {[/tasks/*]=>tasks,POJO}
15:22:27.139 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@4505c2c
15:22:27.246 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@72745de5{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@52ffb63f,MANAGED}
15:22:27.260 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@142c6250
15:22:27.261 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7ce454cd{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@1644efc0,MANAGED}
15:22:27.266 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5004ae58 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:27.287 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5004ae58 added {[/tasks/*]=>tasks,POJO}
15:22:27.420 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1644efc0 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:27.450 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1644efc0 added {[/tasks/*]=>tasks,POJO}
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.83 sec - in com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.helpers.RFC5545ScheduleTest
15:22:28.132 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:28.160 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @17090ms
15:22:28.326 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1d1a2113
15:22:28.434 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3d63f037{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2da440dd,MANAGED}
15:22:28.437 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@30cb7544
15:22:28.441 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@4ca7803c{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7363de25,MANAGED}
15:22:28.591 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7363de25 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:28.611 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7363de25 added {[/tasks/*]=>tasks,POJO}
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.108 sec - in com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
15:22:37.006 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 844384237)
15:22:37.039 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:22:37.284 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:22:37.291 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @26206ms
15:22:37.318 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@e26e716
15:22:37.369 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@612ffb4d{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5c6db049,MANAGED}
15:22:37.376 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@792faee2
15:22:37.378 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2321b536{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7fa0fde9,MANAGED}
15:22:37.489 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7fa0fde9 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:22:37.518 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@7fa0fde9 added {[/tasks/*]=>tasks,POJO}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 30.453 sec <<< FAILURE! - in com.hubspot.singularity.data.BlendedHistoryTest
testBlendedRequestHistory(com.hubspot.singularity.data.BlendedHistoryTest)  Time elapsed: 30.205 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.mesos.SingularityStartupTest
15:22:48.364 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:22:48.514 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:22:48.528 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40014] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6bc7e90000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:22:49.448 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:22:49.770 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:50.145 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:22:50.493 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:51.225 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:51.644 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:51.675 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573771056-1-host1-rack1'}), timestamp=Optional.of(1.512573771E9)}), taskId=test-request-firstDeployId-1512573771056-1-host1-rack1, serverTimestamp=1512573771995, serverId='b6d41fd9-aacf-4f87-935c-3331aee73365', slaveId=Optional.absent()}
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 38.741 sec <<< FAILURE! - in com.hubspot.singularity.data.InactiveSlaveManagerTest
itShouldNotContainHostAfterActivatingHost(com.hubspot.singularity.data.InactiveSlaveManagerTest)  Time elapsed: 30.065 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.SingularityMachineStatesTest
15:22:52.818 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:52.943 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573771056-1-host1-rack1
15:22:52.952 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573771056-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573771056-1-host1-rack1, serverTimestamp=1512573772925, serverId='b6d41fd9-aacf-4f87-935c-3331aee73365', slaveId=Optional.absent()}
15:22:53.028 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:53.029 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:53.697 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573771853-1-host1-rack1'}), timestamp=Optional.of(1.512573771E9)}), taskId=test-request-firstDeployId-1512573771853-1-host1-rack1, serverTimestamp=1512573773661, serverId='38d48b39-0c52-4aca-b226-53e11f8d4033', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573772121-1-host1-rack1'}), timestamp=Optional.of(1.512573772E9)}), taskId=test-request-firstDeployId-1512573772121-1-host1-rack1, serverTimestamp=1512573773800, serverId='0f0d7400-bf6d-4250-bdbc-f7820f5e6502', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573774646-1-host1-rack1'}), timestamp=Optional.of(1.512573774E9)}), taskId=test-request-firstDeployId-1512573774646-1-host1-rack1, serverTimestamp=1512573774735, serverId='38d48b39-0c52-4aca-b226-53e11f8d4033', slaveId=Optional.absent()}
15:22:54.771 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:54.876 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573772121-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573772121-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573772121-1-host1-rack1, serverTimestamp=1512573774838, serverId='0f0d7400-bf6d-4250-bdbc-f7820f5e6502', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573773542-1-host1-rack1'}), timestamp=Optional.of(1.512573773E9)}), taskId=test-request-firstDeployId-1512573773542-1-host1-rack1, serverTimestamp=1512573774581, serverId='cb8d8d71-72e3-4c58-9bd5-23f3d800cf88', slaveId=Optional.absent()}
15:22:55.709 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 41.083 sec <<< FAILURE! - in com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
testTaskShellCommandPersistence(com.hubspot.singularity.mesos.SingularityTaskShellCommandTest)  Time elapsed: 30.057 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.SingularityHistoryTest
15:22:56.428 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:50983] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c12750000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:22:56.879 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r1-d1-23-3-BOUNCE-1, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:22:56.920 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r2-d3-231-1-UNPAUSED-23, cmdLineArgsList=Optional.of([cmd line args]), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573776088-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573776088-2-host1-DEFAULT, serverTimestamp=1512573776916, serverId='fc27be47-e9f9-4194-b957-33f819d49607', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573776771-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573776771-1-host2-DEFAULT, serverTimestamp=1512573776958, serverId='fc27be47-e9f9-4194-b957-33f819d49607', slaveId=Optional.absent()}
15:22:56.996 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:57.042 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r2-de, already correct
15:22:57.045 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r1-d1, already correct
15:22:57.046 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 0 requests in 00:00.048
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573777087-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573777087-2-host2-DEFAULT, serverTimestamp=1512573777172, serverId='fc27be47-e9f9-4194-b957-33f819d49607', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573776088-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573776088-2-host1-DEFAULT, serverTimestamp=1512573777230, serverId='fc27be47-e9f9-4194-b957-33f819d49607', slaveId=Optional.absent()}
15:22:57.682 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:58.039 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:58.253 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573778019-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573778019-1-host1-rack1'}), timestamp=Optional.of(1.512573778E9)}), taskId=test-request-firstDeployId-1512573778019-1-host1-rack1, serverTimestamp=1512573778191, serverId='1b67d3ee-46ea-4b55-aef8-a65eef2ae559', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573778370-1-host1-rack1'}), timestamp=Optional.of(1.512573778E9)}), taskId=test-request-firstDeployId-1512573778370-1-host1-rack1, serverTimestamp=1512573778448, serverId='1b67d3ee-46ea-4b55-aef8-a65eef2ae559', slaveId=Optional.absent()}
15:22:58.714 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:58.727 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1470)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1500)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:742)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:734)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.findProtectedNodeInForeground(CreateBuilderImpl.java:731)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$1100(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$10.callPerformBackgroundOperation(CreateBuilderImpl.java:633)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:22:59.279 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573779409-1-host1-rack1'}), timestamp=Optional.of(1.512573779E9)}), taskId=test-request-firstDeployId-1512573779409-1-host1-rack1, serverTimestamp=1512573779531, serverId='e2eded45-d465-4c04-93e3-5904effd3fed', slaveId=Optional.absent()}
[immediateRequest-immediateDeploy, oneOffRequest-oneOffDeploy1512573779883, newDeployRequest-newDeploy]
15:22:59.974 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:22:59.978 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Rewriting path immediateRequest-immediateDeploy to immediateRequest-immediateDeploy1512573779883
15:22:59.998 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path oneOffRequest-oneOffDeploy1512573779883, already correct
15:23:00.000 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path newDeployRequest-newDeploy, already correct
15:23:00.001 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 1 requests in 00:00.027
15:23:00.006 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
[immediateRequest-immediateDeploy1512573779883, oneOffRequest-oneOffDeploy1512573779883, newDeployRequest-newDeploy]
15:23:00.165 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

15:23:00.224 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:00.254 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573780133-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573780133-1-host1-DEFAULT, serverTimestamp=1512573780263, serverId='e2eded45-d465-4c04-93e3-5904effd3fed', slaveId=Optional.absent()}
15:23:00.333 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

15:23:00.381 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573779409-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573779409-1-host1-rack1, serverTimestamp=1512573780362, serverId='e2eded45-d465-4c04-93e3-5904effd3fed', slaveId=Optional.absent()}
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 40.498 sec <<< FAILURE! - in com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
testMigrationRunner(com.hubspot.singularity.data.zkmigrations.ZkMigrationTest)  Time elapsed: 30.046 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.data.zkmigrations.ZkMigrationTest.testMigrationRunner(ZkMigrationTest.java:56)

Running com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573780522-1-host1-rack1'}), timestamp=Optional.of(1.51257378E9)}), taskId=test-request-firstDeployId-1512573780522-1-host1-rack1, serverTimestamp=1512573780645, serverId='ab8b8fcc-1e42-4454-80c3-93c8c735452b', slaveId=Optional.absent()}
15:23:00.920 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573781029-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573781029-1-host2-DEFAULT, serverTimestamp=1512573781233, serverId='ab8b8fcc-1e42-4454-80c3-93c8c735452b', slaveId=Optional.absent()}
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.053 sec - in com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
Running com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.257 sec - in com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
Running com.hubspot.singularity.scheduler.SingularityHealthchecksTest
15:23:02.449 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:02.985 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:03.194 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:03.316 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:03.755 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:03.996 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:04.375 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573784400-1-host1-rack1'}), timestamp=Optional.of(1.512573784E9)}), taskId=test-request-firstDeployId-1512573784400-1-host1-rack1, serverTimestamp=1512573784450, serverId='08a03956-dc67-4093-b17a-92a87d97a080', slaveId=Optional.absent()}
15:23:04.662 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='timeout_test', timestamp=1512570184441, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512570184441}), updatedRequest=Optional.absent()} is overdue (duration: 01:00:00.221), allowed: 00:01:00.000
15:23:05.013 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:05.486 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:05.642 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512573784944-1-host1-rack1'}), timestamp=Optional.of(1.512573784E9)}), taskId=test-request-retry_test-1512573784944-1-host1-rack1, serverTimestamp=1512573786115, serverId='6e6dd8ca-6e87-4085-b9af-1c2b8bfa89e7', slaveId=Optional.absent()}
15:23:06.314 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:06.476 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:51762] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c4fb80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:23:06.531 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573786806-1-host1-rack1'}), timestamp=Optional.of(1.512573786E9)}), taskId=test-request-firstDeployId-1512573786806-1-host1-rack1, serverTimestamp=1512573786925, serverId='a37950b0-efa5-45ad-894a-0d36b00fae84', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573787026-2-host1-rack1'}), timestamp=Optional.of(1.512573787E9)}), taskId=test-request-firstDeployId-1512573787026-2-host1-rack1, serverTimestamp=1512573787113, serverId='a37950b0-efa5-45ad-894a-0d36b00fae84', slaveId=Optional.absent()}
15:23:07.137 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:07.545 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:07.546 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573787357-1-host1-rack1'}), timestamp=Optional.of(1.512573787E9)}), taskId=test-request-firstDeployId-1512573787357-1-host1-rack1, serverTimestamp=1512573787519, serverId='488163ea-086c-40bd-ba82-2930fa0eacc1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573787456-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573787456-1-host2-DEFAULT, serverTimestamp=1512573787685, serverId='a37950b0-efa5-45ad-894a-0d36b00fae84', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573787625-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573787625-2-host2-DEFAULT, serverTimestamp=1512573787732, serverId='a37950b0-efa5-45ad-894a-0d36b00fae84', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573787686-2-host1-rack1'}), timestamp=Optional.of(1.512573787E9)}), taskId=test-request-firstDeployId-1512573787686-2-host1-rack1, serverTimestamp=1512573787755, serverId='488163ea-086c-40bd-ba82-2930fa0eacc1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573787783-3-host1-rack1'}), timestamp=Optional.of(1.512573787E9)}), taskId=test-request-firstDeployId-1512573787783-3-host1-rack1, serverTimestamp=1512573787812, serverId='488163ea-086c-40bd-ba82-2930fa0eacc1', slaveId=Optional.absent()}
15:23:08.013 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:08.231 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512573784944-1-IMMEDIATE-1512573784944, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer517'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512573784944-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.821 sec - in com.hubspot.singularity.mesos.SingularityStartupTest
Running com.hubspot.singularity.scheduler.HistoryPersisterTest
15:23:08.250 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512573784944-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:08.269 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512573784944-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573787357-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573787357-1-host1-rack1, serverTimestamp=1512573788399, serverId='488163ea-086c-40bd-ba82-2930fa0eacc1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573788187-3-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573788187-3-host1-DEFAULT, serverTimestamp=1512573788443, serverId='488163ea-086c-40bd-ba82-2930fa0eacc1', slaveId=Optional.absent()}
15:23:08.524 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60999] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c55e40000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:23:08.541 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:08.906 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512573788832, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512573789054, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512573789170, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512573789337, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:09.386 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:09.424 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512573789418, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573789130-1-host1-rack1'}), timestamp=Optional.of(1.512573789E9)}), taskId=test-request-firstDeployId-1512573789130-1-host1-rack1, serverTimestamp=1512573789296, serverId='53b15ce3-20da-4b7d-8b50-a006d1c46633', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512573789506, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512573789605, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:09.634 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512573789622, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:09.745 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-2-firstDeployId-15000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512573789695, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:09.814 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-2-firstDeployId-35000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512573789790, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:09.969 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-2-firstDeployId-25000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573789841-1-host1-rack1'}), timestamp=Optional.of(1.512573789E9)}), taskId=test-request-firstDeployId-1512573789841-1-host1-rack1, serverTimestamp=1512573789910, serverId='53b15ce3-20da-4b7d-8b50-a006d1c46633', slaveId=Optional.absent()}
15:23:09.988 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512573789915, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:10.251 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573789130-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573789130-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573789130-1-host1-rack1, serverTimestamp=1512573790207, serverId='53b15ce3-20da-4b7d-8b50-a006d1c46633', slaveId=Optional.absent()}
15:23:10.323 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:10.445 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512573790433, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:10.489 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512573790477, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
15:23:10.571 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-2-firstDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512573790533, serverId='24974563-e5b3-48ec-bd0b-4032f77e289e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990162-1-host1-rack1'}), timestamp=Optional.of(1.51257379E9)}), taskId=test-request-firstDeployId-1512562990162-1-host1-rack1, serverTimestamp=1512573790341, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:10.672 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562990162-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990162-1-host1-rack1'}), timestamp=Optional.of(1.51256659E9)}), taskId=test-request-firstDeployId-1512562990162-1-host1-rack1, serverTimestamp=1512573790626, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:10.850 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:38270] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c5b9e0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990789-1-host1-rack1'}), timestamp=Optional.of(1.51257379E9)}), taskId=test-request-firstDeployId-1512562990789-1-host1-rack1, serverTimestamp=1512573790867, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:10.943 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562990789-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990789-1-host1-rack1'}), timestamp=Optional.of(1.51256659E9)}), taskId=test-request-firstDeployId-1512562990789-1-host1-rack1, serverTimestamp=1512573790916, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:10.994 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52527] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c5efc0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990986-1-host1-rack1'}), timestamp=Optional.of(1.51257379E9)}), taskId=test-request-firstDeployId-1512562990986-1-host1-rack1, serverTimestamp=1512573791036, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.091 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562990986-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562990986-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562990986-1-host1-rack1, serverTimestamp=1512573791068, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573790782-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573790782-1-host1-DEFAULT, serverTimestamp=1512573791099, serverId='11ba6222-19a7-4a99-a99f-31c8470ee692', slaveId=Optional.absent()}
15:23:11.175 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991131-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991131-1-host1-rack1, serverTimestamp=1512573791164, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.217 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991131-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991131-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991131-1-host1-rack1, serverTimestamp=1512573791194, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991259-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991259-1-host1-rack1, serverTimestamp=1512573791304, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.329 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991259-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991259-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991259-1-host1-rack1, serverTimestamp=1512573791318, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991383-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991383-1-host1-rack1, serverTimestamp=1512573791429, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.457 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991383-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991383-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991383-1-host1-rack1, serverTimestamp=1512573791448, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791372-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512573791372-1-host1-rack1, serverTimestamp=1512573791468, serverId='e4e404a4-eb97-4ef4-a74c-9f5ef36a2ae6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991508-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991508-1-host1-rack1, serverTimestamp=1512573791537, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.593 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991508-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791530-2-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512573791530-2-host1-rack1, serverTimestamp=1512573791587, serverId='e4e404a4-eb97-4ef4-a74c-9f5ef36a2ae6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991508-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991508-1-host1-rack1, serverTimestamp=1512573791567, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.635 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791605-3-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512573791605-3-host1-rack1, serverTimestamp=1512573791638, serverId='e4e404a4-eb97-4ef4-a74c-9f5ef36a2ae6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991632-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991632-1-host1-rack1, serverTimestamp=1512573791708, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.739 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991632-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991632-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991632-1-host1-rack1, serverTimestamp=1512573791728, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991791-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991791-1-host1-rack1, serverTimestamp=1512573791853, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.873 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991791-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791816-4-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512573791816-4-host1-rack1, serverTimestamp=1512573791892, serverId='e4e404a4-eb97-4ef4-a74c-9f5ef36a2ae6', slaveId=Optional.absent()}
15:23:11.923 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573789841-1-IMMEDIATE-1512573789841, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer401'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573789841-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:23:11.924 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573789841-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:11.926 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573789841-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5d076f26 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@53c09af6[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991791-1-host1-rack1'}), timestamp=Optional.of(1.512566591E9)}), taskId=test-request-firstDeployId-1512562991791-1-host1-rack1, serverTimestamp=1512573791865, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:11.989 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991964-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512562991964-1-host1-rack1, serverTimestamp=1512573791996, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
15:23:12.027 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562991964-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562991964-1-host1-rack1'}), timestamp=Optional.of(1.512566592E9)}), taskId=test-request-firstDeployId-1512562991964-1-host1-rack1, serverTimestamp=1512573792016, serverId='e1da9158-adaa-4d8e-a6df-34c55c1be548', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791861-1-host1-rack1'}), timestamp=Optional.of(1.512573791E9)}), taskId=test-request-firstDeployId-1512573791861-1-host1-rack1, serverTimestamp=1512573792056, serverId='f33c0c23-43e2-4ab8-a780-3c56a622482d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573791605-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573791605-3-host1-rack1, serverTimestamp=1512573792153, serverId='e4e404a4-eb97-4ef4-a74c-9f5ef36a2ae6', slaveId=Optional.absent()}
15:23:12.452 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55025] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c607c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:23:12.606 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573792492-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573792492-1-host1-DEFAULT, serverTimestamp=1512573792579, serverId='f33c0c23-43e2-4ab8-a780-3c56a622482d', slaveId=Optional.absent()}
15:23:12.645 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:12.813 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 59.491 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
testExpiringSkipHealthchecks(com.hubspot.singularity.scheduler.SingularityExpiringActionsTest)  Time elapsed: 30.049 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.ValidatorTest
15:23:13.397 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:43043] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c6c520000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 58.406 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityUsageTest
testUsagePollerComplex(com.hubspot.singularity.scheduler.SingularityUsageTest)  Time elapsed: 30.12 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.SandboxManagerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573793182-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573793182-1-host2-DEFAULT, serverTimestamp=1512573793558, serverId='fafacdf7-8886-42bc-a05e-8b46bf8ec754', slaveId=Optional.absent()}
15:23:13.860 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:13.938 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:13.984 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:14.164 [Time-limited test] WARN com.hubspot.singularity.data.history.SingularityRequestHistoryPersister - Failed to persist SingularityRequestHistory{createdAt=1512562994131, user=Optional.absent(), eventType=CREATED, request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, message=Optional.absent()} into History
java.lang.UnsupportedOperationException: NoopHistoryManager can not save
	at com.hubspot.singularity.data.history.NoopHistoryManager.saveRequestHistoryUpdate(NoopHistoryManager.java:26)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:144)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:26)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurgeAndShouldDelete(SingularityHistoryPersister.java:63)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurge(SingularityHistoryPersister.java:52)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.runActionOnPoll(SingularityRequestHistoryPersister.java:122)
	at com.hubspot.singularity.scheduler.HistoryPersisterTest.testPurgingDoesntApplyIfDatabasePresent(HistoryPersisterTest.java:211)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573794102-1-host1-rack1'}), timestamp=Optional.of(1.512573794E9)}), taskId=test-request-firstDeployId-1512573794102-1-host1-rack1, serverTimestamp=1512573794206, serverId='8f360672-3152-49d4-8c1c-0ebc4116e6fa', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573794529-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573794529-1-host2-DEFAULT, serverTimestamp=1512573794742, serverId='8f360672-3152-49d4-8c1c-0ebc4116e6fa', slaveId=Optional.absent()}
15:23:15.236 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:15.294 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:15.482 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:15.525 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:15.807 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512573795939, serverId='74899d76-9306-4290-8938-7635a3bd1378', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512573796102, serverId='74899d76-9306-4290-8938-7635a3bd1378', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512573796192, serverId='74899d76-9306-4290-8938-7635a3bd1378', slaveId=Optional.absent()}
15:23:16.903 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797182-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797182-2-host1-rack1, serverTimestamp=1512573797481, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
15:23:17.531 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797303-1-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797303-1-host2-rack1, serverTimestamp=1512573797534, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
15:23:17.816 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797832-2-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797832-2-host4-rack2, serverTimestamp=1512573797974, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797907-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797907-3-host3-rack2, serverTimestamp=1512573797996, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797182-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797182-2-host1-rack1, serverTimestamp=1512573798042, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
15:23:18.089 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:18.199 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
15:23:18.214 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573798208-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573798208-3-host1-rack1, serverTimestamp=1512573798327, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573798268-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573798268-2-host2-rack1, serverTimestamp=1512573798354, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797907-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797907-3-host3-rack2, serverTimestamp=1512573798448, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573797832-2-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573797832-2-host4-rack2, serverTimestamp=1512573798477, serverId='17b4cab0-c43f-4a61-9ae2-10507679e451', slaveId=Optional.absent()}
15:23:18.654 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573798790-1-host1-rack1'}), timestamp=Optional.of(1.512573618E9)}), taskId=test-request-firstDeployId-1512573798790-1-host1-rack1, serverTimestamp=1512573798888, serverId='b123a54e-e09d-4cbf-b204-5feb9f2d47ef', slaveId=Optional.absent()}
15:23:19.035 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573798790-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573798790-1-host1-rack1'}), timestamp=Optional.of(1.512573679E9)}), taskId=test-request-firstDeployId-1512573798790-1-host1-rack1, serverTimestamp=1512573799023, serverId='b123a54e-e09d-4cbf-b204-5feb9f2d47ef', slaveId=Optional.absent()}
15:23:19.165 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41707] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c83ab0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:23:19.244 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:19.438 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:19.481 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562999534-1-host1-rack1'}), timestamp=Optional.of(1.512573799E9)}), taskId=test-request-firstDeployId-1512562999534-1-host1-rack1, serverTimestamp=1512573799607, serverId='f8e47618-796b-4aa4-96da-73bb30a2fdc5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562999683-2-host1-rack1'}), timestamp=Optional.of(1.512573799E9)}), taskId=test-request-firstDeployId-1512562999683-2-host1-rack1, serverTimestamp=1512573799741, serverId='f8e47618-796b-4aa4-96da-73bb30a2fdc5', slaveId=Optional.absent()}
15:23:19.799 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512562999534-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512562999534-1-host1-rack1'}), timestamp=Optional.of(1.512566599E9)}), taskId=test-request-firstDeployId-1512562999534-1-host1-rack1, serverTimestamp=1512573799786, serverId='f8e47618-796b-4aa4-96da-73bb30a2fdc5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573794102-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573794102-1-host1-rack1, serverTimestamp=1512573799778, serverId='8f360672-3152-49d4-8c1c-0ebc4116e6fa', slaveId=Optional.absent()}
15:23:19.860 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:20.457 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:20.607 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:20.753 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512562999683-2-IMMEDIATE-1512562999683, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer41'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512562999683-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:20.763 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512562999683-2-IMMEDIATE-1512562999683, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer41'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512562999683-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@65aa93e4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1f43dfd1[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d3-1512573800806-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d3-1512573800806-1-host1-DEFAULT, serverTimestamp=1512573800898, serverId='b18073a6-cea1-4759-b942-06d5af9f8113', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d4-1512573801029-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d4-1512573801029-1-host1-DEFAULT, serverTimestamp=1512573801081, serverId='b18073a6-cea1-4759-b942-06d5af9f8113', slaveId=Optional.absent()}
15:23:21.187 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:21.572 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:21.768 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:21.805 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573801696-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573801696-2-host1-DEFAULT, serverTimestamp=1512573801796, serverId='c829f1b2-6d10-4941-8f0f-c70dc773df26', slaveId=Optional.absent()}
15:23:21.981 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:22.307 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.252 sec - in com.hubspot.singularity.scheduler.HistoryPersisterTest
Running com.hubspot.singularity.config.MergingSourceProviderTest
15:23:22.574 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573802431-1-host2-DEFAULT'}), timestamp=Optional.of(1.512573802E9)}), taskId=test-request-firstDeployId-1512573802431-1-host2-DEFAULT, serverTimestamp=1512573802555, serverId='2033a948-3eba-4d7f-88d0-74ddb4b82b6c', slaveId=Optional.absent()}
15:23:22.818 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573802743-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573802743-1-host1-rack1'}), timestamp=Optional.of(1.512573802E9)}), taskId=test-request-firstDeployId-1512573802743-1-host1-rack1, serverTimestamp=1512573802807, serverId='b0c8530a-69eb-47da-b340-ff2913362ab5', slaveId=Optional.absent()}
15:23:22.916 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573802846-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573802846-1-host1-rack1'}), timestamp=Optional.of(1.512573802E9)}), taskId=test-request-firstDeployId-1512573802846-1-host1-rack1, serverTimestamp=1512573802907, serverId='b0c8530a-69eb-47da-b340-ff2913362ab5', slaveId=Optional.absent()}
15:23:23.428 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:23.533 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:23.566 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:24.073 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:24.509 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:24.515 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573801696-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:24.516 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573801696-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5eac87f4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@19b7f4db[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:24.520 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.085 sec - in com.hubspot.singularity.data.SandboxManagerTest
Running com.hubspot.singularity.SingularityAuthorizationHelperTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573804627-1-host1-rack1'}), timestamp=Optional.of(1.512573804E9)}), taskId=test-request-firstDeployId-1512573804627-1-host1-rack1, serverTimestamp=1512573804709, serverId='834b901b-062c-4393-a372-818b99eb6d13', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573804780-2-host1-rack1'}), timestamp=Optional.of(1.512573804E9)}), taskId=test-request-firstDeployId-1512573804780-2-host1-rack1, serverTimestamp=1512573804837, serverId='834b901b-062c-4393-a372-818b99eb6d13', slaveId=Optional.absent()}
15:23:24.878 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:24.904 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:56562] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6c9c960000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573805061-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573805061-1-host2-DEFAULT, serverTimestamp=1512573805100, serverId='834b901b-062c-4393-a372-818b99eb6d13', slaveId=Optional.absent()}
15:23:25.187 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573804627-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573804627-1-host1-rack1, serverTimestamp=1512573805205, serverId='834b901b-062c-4393-a372-818b99eb6d13', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573805307-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573805307-2-host2-DEFAULT, serverTimestamp=1512573805364, serverId='834b901b-062c-4393-a372-818b99eb6d13', slaveId=Optional.absent()}
15:23:25.424 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:25.856 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.388 sec - in com.hubspot.singularity.SingularityAuthorizationHelperTest
Running com.hubspot.singularity.scheduler.SingularitySchedulerTest
15:23:26.139 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:26.232 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:26.244 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573806337-1-host1-rack1'}), timestamp=Optional.of(1.512573806E9)}), taskId=test-request-firstDeployId-1512573806337-1-host1-rack1, serverTimestamp=1512573806432, serverId='ae8ca32e-fdcd-4305-bee7-c3147c11e93f', slaveId=Optional.absent()}
15:23:26.536 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:26.919 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573801478-2-UPDATED_REQUEST-1512573801360, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer687'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573801696-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1512573801696-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:26.923 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573801478-2-UPDATED_REQUEST-1512573801360, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer687'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573801696-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1512573801696-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6d8555da rejected from java.util.concurrent.ScheduledThreadPoolExecutor@55792591[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:23:27.268 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:27.374 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.883 sec - in com.hubspot.singularity.config.MergingSourceProviderTest
Running com.hubspot.singularity.data.StateManagerTest
15:23:27.755 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:27.790 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:27.838 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512573807989, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573807972-1-host1-rack1'}), timestamp=Optional.of(1.512573807E9)}), taskId=test-request-firstDeployId-1512573807972-1-host1-rack1, serverTimestamp=1512573808038, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512573808086, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573808077-2-host1-rack1'}), timestamp=Optional.of(1.512573808E9)}), taskId=test-request-firstDeployId-1512573808077-2-host1-rack1, serverTimestamp=1512573808128, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512573808145, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573808138-3-host1-rack1'}), timestamp=Optional.of(1.512573808E9)}), taskId=test-request-firstDeployId-1512573808138-3-host1-rack1, serverTimestamp=1512573808189, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
15:23:28.251 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512573808275, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512573808329, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
15:23:28.344 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512573808379, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512573808444, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573808371-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573808371-1-host2-DEFAULT, serverTimestamp=1512573808441, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
15:23:28.478 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(20.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512573808469, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573807972-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573807972-1-host1-rack1, serverTimestamp=1512573808484, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
15:23:28.548 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-2-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(21.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512573808539, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
15:23:28.574 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-6-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(22.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512573808567, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
15:23:28.594 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-4-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(23.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512573808587, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
15:23:28.650 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-3-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(24.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512573808631, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573808574-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573808574-2-host2-DEFAULT, serverTimestamp=1512573808678, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
15:23:28.713 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-5-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(25.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512573808691, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
15:23:28.741 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-7-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(26.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512573808732, serverId='8d49d788-f449-4a49-9d43-8c91fee3ebec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573808077-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573808077-2-host1-rack1, serverTimestamp=1512573808755, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573808851-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573808851-3-host2-DEFAULT, serverTimestamp=1512573808910, serverId='6e5cef84-8b18-4149-be56-4bc7468b7ee6', slaveId=Optional.absent()}
15:23:28.935 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:29.083 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:29.143 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:23:29.518 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573806337-1-IMMEDIATE-1512573806337, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer189'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573806337-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573809571-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573809571-1-host2-DEFAULT, serverTimestamp=1512573809684, serverId='a1062f89-c869-4421-92fb-7e4fc1228708', slaveId=Optional.absent()}SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573809563-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573809563-1-host1-DEFAULT, serverTimestamp=1512573809692, serverId='94731eaa-5fc2-4a56-bbd1-60a0f88f4ea0', slaveId=Optional.absent()}

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573809794-4-host1-rack1'}), timestamp=Optional.of(1.512573809E9)}), taskId=test-request-firstDeployId-1512573809794-4-host1-rack1, serverTimestamp=1512573809829, serverId='a1062f89-c869-4421-92fb-7e4fc1228708', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512573809841-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512573809841-1-host1-DEFAULT, serverTimestamp=1512573809889, serverId='94731eaa-5fc2-4a56-bbd1-60a0f88f4ea0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573809856-5-host1-rack1'}), timestamp=Optional.of(1.512573809E9)}), taskId=test-request-firstDeployId-1512573809856-5-host1-rack1, serverTimestamp=1512573809926, serverId='a1062f89-c869-4421-92fb-7e4fc1228708', slaveId=Optional.absent()}
15:23:30.025 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:30.160 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:23:44.810 [SyncThread:0] WARN org.apache.zookeeper.server.persistence.FileTxnLog - fsync-ing the write ahead log in SyncThread:0 took 1265ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 48.509 sec <<< FAILURE! - in com.hubspot.singularity.data.StateManagerTest
itDoesntCountCleaningTasks(com.hubspot.singularity.data.StateManagerTest)  Time elapsed: 48.504 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

15:24:27.754 [SyncThread:0] WARN org.apache.zookeeper.server.persistence.FileTxnLog - fsync-ing the write ahead log in SyncThread:0 took 1163ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
Tests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 97.664 sec <<< FAILURE! - in com.hubspot.singularity.SingularityHistoryTest
testTaskSearchQueryBlended(com.hubspot.singularity.SingularityHistoryTest)  Time elapsed: 64.721 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.SingularityHistoryTest.testTaskSearchQueryBlended(SingularityHistoryTest.java:384)

Tests run: 16, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 100.778 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityMachineStatesTest
testFrozenSlaveTransitions(com.hubspot.singularity.scheduler.SingularityMachineStatesTest)  Time elapsed: 64.455 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Tests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 84.918 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
testSlavePlacementSpread(com.hubspot.singularity.scheduler.SingularitySlavePlacementTest)  Time elapsed: 57.883 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.scheduler.SingularitySlavePlacementTest.testSlavePlacementSpread(SingularitySlavePlacementTest.java:79)

15:24:33.698 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosScheduler - Scheduler threw an uncaught exception - exiting
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.CuratorManager.create(CuratorManager.java:176)
	at com.hubspot.singularity.data.CuratorManager.create(CuratorManager.java:165)
	at com.hubspot.singularity.data.TaskManager.saveTaskHistoryUpdate(TaskManager.java:589)
	at com.hubspot.singularity.data.TaskManager.saveTaskHistoryUpdate(TaskManager.java:561)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:242)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:268)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:277)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTestBase.statusUpdate(SingularitySchedulerTestBase.java:362)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTestBase.launchTask(SingularitySchedulerTestBase.java:347)
	at com.hubspot.singularity.SingularityHistoryTest.testTaskSearchQueryBlended(SingularityHistoryTest.java:384)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:325)
	at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:267)
	at com.hubspot.singularity.data.CuratorManager.privateCreate(CuratorManager.java:188)
	at com.hubspot.singularity.data.CuratorManager.create(CuratorManager.java:170)
	... 23 common frames omitted
15:24:38.461 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:45757] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6cb21b0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:38.493 [SyncThread:0] WARN org.apache.zookeeper.server.persistence.FileTxnLog - fsync-ing the write ahead log in SyncThread:0 took 1738ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
15:24:38.495 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-firstDeployId-20000-2-IMMEDIATE-20000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:38.533 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-firstDeployId-20000-2-IMMEDIATE-20000, but not active
15:24:38.553 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-firstDeployId-20000-2-host2-rack1, but not active
15:24:38.555 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-firstDeployId-30000-3-IMMEDIATE-30000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:38.557 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-firstDeployId-30000-3-IMMEDIATE-30000, but not active
15:24:38.721 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-firstDeployId-30000-3-host3-rack1, but not active
15:24:39.075 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-secondDeployId-40000-4-IMMEDIATE-40000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:39.126 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573806337-1-host1-rack1
15:24:39.127 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-secondDeployId-40000-4-IMMEDIATE-40000, but not active
15:24:39.169 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:39.197 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-secondDeployId-40000-4-host4-rack1, but not active
15:24:39.200 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-secondDeployId-50000-5-IMMEDIATE-50000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.of(test-run-id-5), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:39.239 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-secondDeployId-50000-5-IMMEDIATE-50000, but not active
Max healthcheck time cannot be greater than 100, (was startup timeout: 50, interval: 5, attempts: 10)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573806337-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573806337-1-host1-rack1, serverTimestamp=1512573879063, serverId='ae8ca32e-fdcd-4305-bee7-c3147c11e93f', slaveId=Optional.absent()}
15:24:39.287 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hosts/localhost
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:117)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:113)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hosts/localhost
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1045)
	at org.apache.curator.framework.imps.ExistsBuilderImpl$2.call(ExistsBuilderImpl.java:172)
	at org.apache.curator.framework.imps.ExistsBuilderImpl$2.call(ExistsBuilderImpl.java:161)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:158)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:148)
	at org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:36)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	... 3 common frames omitted
15:24:39.294 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57980] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6ca0510000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:39.296 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:39.315 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-secondDeployId-50000-5-host5-rack1, but not active
15:24:39.317 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-secondDeployId-60000-6-IMMEDIATE-60000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:39.328 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-secondDeployId-60000-6-IMMEDIATE-60000, but not active
15:24:39.407 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-secondDeployId-60000-6-host6-rack1, but not active
15:24:39.409 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=test-request-secondDeployId-70000-7-IMMEDIATE-70000, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
15:24:39.419 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - deletePendingTask test-request-secondDeployId-70000-7-IMMEDIATE-70000, but not active
15:24:39.491 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - putActiveTask test-request-secondDeployId-70000-7-host7-rack1, but not active
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573879532-1-host1-rack1'}), timestamp=Optional.of(1.512573879E9)}), taskId=test-request-firstDeployId-1512573879532-1-host1-rack1, serverTimestamp=1512573879602, serverId='b8b36ced-7e24-4ad2-b16f-b387de3bf6f8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573879645-2-host1-rack1'}), timestamp=Optional.of(1.512573879E9)}), taskId=test-request-firstDeployId-1512573879645-2-host1-rack1, serverTimestamp=1512573879695, serverId='b8b36ced-7e24-4ad2-b16f-b387de3bf6f8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573879592-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573879592-1-host1-DEFAULT, serverTimestamp=1512573879807, serverId='db7783ae-35d3-40ee-8196-ef7cb6c36154', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573879877-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573879877-1-host2-DEFAULT, serverTimestamp=1512573879917, serverId='b8b36ced-7e24-4ad2-b16f-b387de3bf6f8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573879532-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573879532-1-host1-rack1, serverTimestamp=1512573880031, serverId='b8b36ced-7e24-4ad2-b16f-b387de3bf6f8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573880149-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573880149-2-host2-DEFAULT, serverTimestamp=1512573880179, serverId='b8b36ced-7e24-4ad2-b16f-b387de3bf6f8', slaveId=Optional.absent()}
15:24:40.505 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:40.591 [Time-limited test-EventThread] WARN org.apache.curator.ConnectionState - Session expired event received
15:24:40.616 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
15:24:40.684 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.705 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.795 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573879645-2-IMMEDIATE-1512573879645, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer236'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573879645-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:40.799 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573879645-2-IMMEDIATE-1512573879645, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer236'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573879645-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@8717840 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@14d83a42[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:41.563 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:41.906 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:42.663 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573882443-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573882443-1-host1-DEFAULT, serverTimestamp=1512573882861, serverId='111c9acd-1b1e-45ee-b01e-759b359630cc', slaveId=Optional.absent()}
15:24:43.174 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573883835-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573883835-1-host1-DEFAULT, serverTimestamp=1512573883980, serverId='76401945-6ec8-4ed3-b91d-3c0b0fcf9237', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573883835-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573883835-1-host1-DEFAULT, serverTimestamp=1512573884080, serverId='76401945-6ec8-4ed3-b91d-3c0b0fcf9237', slaveId=Optional.absent()}
15:24:44.601 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
15:24:45.050 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573882443-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:45.054 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573882443-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@67b3b539 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@72d61b4b[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:45.252 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:45.475 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573885459-1-host1-rack1'}), timestamp=Optional.of(1.512573885E9)}), taskId=test-request-firstDeployId-1512573885459-1-host1-rack1, serverTimestamp=1512573885858, serverId='ce89773f-82b5-4bd8-ad59-97c66263fb0c', slaveId=Optional.absent()}
15:24:45.928 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:45.934 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573885905-2-host1-rack1'}), timestamp=Optional.of(1.512573885E9)}), taskId=test-request-firstDeployId-1512573885905-2-host1-rack1, serverTimestamp=1512573885957, serverId='ce89773f-82b5-4bd8-ad59-97c66263fb0c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573886007-3-host1-rack1'}), timestamp=Optional.of(1.512573886E9)}), taskId=test-request-firstDeployId-1512573886007-3-host1-rack1, serverTimestamp=1512573886143, serverId='ce89773f-82b5-4bd8-ad59-97c66263fb0c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573885925-1-host1-rack1'}), timestamp=Optional.of(1.512573885E9)}), taskId=test-request-secondDeployId-1512573885925-1-host1-rack1, serverTimestamp=1512573886168, serverId='7eab05fc-0992-47fc-b636-8d28e36b4ee5', slaveId=Optional.absent()}
15:24:46.357 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:24:46.466 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573885905-2-host1-rack1
15:24:46.513 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573885905-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573885905-2-host1-rack1, serverTimestamp=1512573886431, serverId='ce89773f-82b5-4bd8-ad59-97c66263fb0c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512573886823-1-host1-rack1'}), timestamp=Optional.of(1.512573886E9)}), taskId=test-request-new_task_healthcheck-1512573886823-1-host1-rack1, serverTimestamp=1512573886953, serverId='1e2e5e63-7b81-46b3-92d0-a2802419b6e1', slaveId=Optional.absent()}
15:24:47.792 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:47.871 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573882213-1-UPDATED_REQUEST-1512573882135, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer269'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573882443-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=0.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1512573882443-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:47.875 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573882213-1-UPDATED_REQUEST-1512573882135, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer269'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573882443-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=0.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1512573882443-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5289a4e4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@56b62a6d[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:48.150 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-deploy_test-1512573887983-1-host1-rack1'}), timestamp=Optional.of(1.512573887E9)}), taskId=test-request-deploy_test-1512573887983-1-host1-rack1, serverTimestamp=1512573888170, serverId='197dcbc2-cd3a-48c4-8853-8ca9558f06ed', slaveId=Optional.absent()}
15:24:48.985 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:48.993 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='new_task_healthcheck', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.absent(), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-new_task_healthcheck-1512573886823-1-IMMEDIATE-1512573886823, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer774'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512573886823-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:48.994 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-new_task_healthcheck-1512573886823-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:48.995 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-new_task_healthcheck-1512573886823-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:49.268 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:53185] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6de5020000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:49.418 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 18, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 96.097 sec <<< FAILURE! - in com.hubspot.singularity.data.ValidatorTest
itForbidsHealthCheckGreaterThanMaxTotalHealthCheck(com.hubspot.singularity.data.ValidatorTest)  Time elapsed: 51.292 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

15:24:49.534 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573889777-1-host1-rack1'}), timestamp=Optional.of(1.512573889E9)}), taskId=test-request-firstDeployId-1512573889777-1-host1-rack1, serverTimestamp=1512573889892, serverId='45adc076-9c0d-42e6-89c1-ab2a915031ee', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573889955-2-host1-rack1'}), timestamp=Optional.of(1.512573889E9)}), taskId=test-request-firstDeployId-1512573889955-2-host1-rack1, serverTimestamp=1512573889999, serverId='45adc076-9c0d-42e6-89c1-ab2a915031ee', slaveId=Optional.absent()}
15:24:50.334 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573890417-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573890417-1-host2-DEFAULT, serverTimestamp=1512573890586, serverId='45adc076-9c0d-42e6-89c1-ab2a915031ee', slaveId=Optional.absent()}
15:24:50.705 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573889777-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573889777-1-host1-rack1, serverTimestamp=1512573890779, serverId='45adc076-9c0d-42e6-89c1-ab2a915031ee', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-hc_test-1512573890679-1-host1-rack1'}), timestamp=Optional.of(1.51257389E9)}), taskId=test-request-hc_test-1512573890679-1-host1-rack1, serverTimestamp=1512573890974, serverId='47027cb5-b6d9-49eb-8808-018d7c81e617', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573891291-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573891291-2-host2-DEFAULT, serverTimestamp=1512573891550, serverId='45adc076-9c0d-42e6-89c1-ab2a915031ee', slaveId=Optional.absent()}
15:24:52.984 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='hc_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-hc_test-1512573890679-1-IMMEDIATE-1512573890679, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer762'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-hc_test-1512573890679-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:52.985 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-hc_test-1512573890679-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:52.987 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-hc_test-1512573890679-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:53.220 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573893330-1-host1-rack1'}), timestamp=Optional.of(1.512573893E9)}), taskId=test-request-firstDeployId-1512573893330-1-host1-rack1, serverTimestamp=1512573893447, serverId='fc2c628c-e635-4660-9ce4-5383c0a6226f', slaveId=Optional.absent()}
15:24:53.493 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573893330-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573893330-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573893330-1-host1-rack1, serverTimestamp=1512573893487, serverId='fc2c628c-e635-4660-9ce4-5383c0a6226f', slaveId=Optional.absent()}
15:24:53.867 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:54.179 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573894061-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573894061-2-host1-DEFAULT, serverTimestamp=1512573894209, serverId='fc2c628c-e635-4660-9ce4-5383c0a6226f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-timeout_test-1512570294059-1-host1-rack1'}), timestamp=Optional.of(1.512570294E9)}), taskId=test-request-timeout_test-1512570294059-1-host1-rack1, serverTimestamp=1512573894651, serverId='d96254f4-9c3b-4b2f-be55-8f813b923585', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573894567-1-host1-rack1'}), timestamp=Optional.of(1.512573894E9)}), taskId=test-request-firstDeployId-1512573894567-1-host1-rack1, serverTimestamp=1512573894773, serverId='ca46f248-24cc-4f5f-b432-3721e5a91e9f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573894956-1-host1-rack1'}), timestamp=Optional.of(1.512573894E9)}), taskId=test-request-secondDeployId-1512573894956-1-host1-rack1, serverTimestamp=1512573895052, serverId='ca46f248-24cc-4f5f-b432-3721e5a91e9f', slaveId=Optional.absent()}
15:24:55.201 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-secondDeployId-1512573894956-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573894956-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573894956-1-host1-rack1, serverTimestamp=1512573895157, serverId='ca46f248-24cc-4f5f-b432-3721e5a91e9f', slaveId=Optional.absent()}
15:24:55.270 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573894567-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573894567-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573894567-1-host1-rack1, serverTimestamp=1512573895264, serverId='ca46f248-24cc-4f5f-b432-3721e5a91e9f', slaveId=Optional.absent()}
15:24:55.631 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573895746-1-host1-rack1'}), timestamp=Optional.of(1.512573895E9)}), taskId=test-request-firstDeployId-1512573895746-1-host1-rack1, serverTimestamp=1512573895900, serverId='4613417d-1984-4e5e-8100-71134f300044', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573896326-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573896326-1-host1-DEFAULT, serverTimestamp=1512573896531, serverId='4613417d-1984-4e5e-8100-71134f300044', slaveId=Optional.absent()}
15:24:56.639 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:56.663 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='timeout_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.of(86400000), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-timeout_test-1512570294059-1-IMMEDIATE-1512570294059, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer116'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-timeout_test-1512570294059-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:56.664 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-timeout_test-1512570294059-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:56.665 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-timeout_test-1512570294059-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573895746-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573895746-1-host1-rack1, serverTimestamp=1512573896695, serverId='4613417d-1984-4e5e-8100-71134f300044', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573896985-1-host1-rack1'}), timestamp=Optional.of(1.512573896E9)}), taskId=test-request-firstDeployId-1512573896985-1-host1-rack1, serverTimestamp=1512573897195, serverId='23b3446a-9659-4eac-8ae1-f57d7250deca', slaveId=Optional.absent()}
15:24:57.348 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573897272-2-host1-rack1'}), timestamp=Optional.of(1.512573897E9)}), taskId=test-request-firstDeployId-1512573897272-2-host1-rack1, serverTimestamp=1512573897389, serverId='23b3446a-9659-4eac-8ae1-f57d7250deca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512573897659-1-host1-rack1'}), timestamp=Optional.of(1.512573897E9)}), taskId=test-request-retry_test-1512573897659-1-host1-rack1, serverTimestamp=1512573897816, serverId='8960e6f5-1206-4af9-9863-63dc504aefd4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573897799-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573897799-1-host1-DEFAULT, serverTimestamp=1512573898025, serverId='23b3446a-9659-4eac-8ae1-f57d7250deca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573897953-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573897953-2-host1-DEFAULT, serverTimestamp=1512573898064, serverId='23b3446a-9659-4eac-8ae1-f57d7250deca', slaveId=Optional.absent()}
15:24:58.998 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573899237-1-host1-rack1'}), timestamp=Optional.of(1.512573899E9)}), taskId=test-request-firstDeployId-1512573899237-1-host1-rack1, serverTimestamp=1512573899383, serverId='68344bce-1ad0-433b-938a-89e7c1d657f4', slaveId=Optional.absent()}
15:24:59.697 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573899237-1-host1-rack1
15:24:59.699 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573899237-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573899237-1-host1-rack1, serverTimestamp=1512573899680, serverId='68344bce-1ad0-433b-938a-89e7c1d657f4', slaveId=Optional.absent()}
15:24:59.828 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(3), failureStatusCodes=Optional.of([404])}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512573897659-1-IMMEDIATE-1512573897659, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer903'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512573897659-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:59.829 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512573897659-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:59.830 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512573897659-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:00.008 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:49007] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e0c6f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:00.594 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:00.754 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512573900768-1-host1-rack1'}), timestamp=Optional.of(1.5125739E9)}), taskId=test-request-retry_test-1512573900768-1-host1-rack1, serverTimestamp=1512573901149, serverId='82c0d460-c853-4a98-af37-500ffb851310', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901118-1-host1-rack1'}), timestamp=Optional.of(1.512573901E9)}), taskId=test-request-firstDeployId-1512573901118-1-host1-rack1, serverTimestamp=1512573901220, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
15:25:01.395 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901281-2-host1-rack1'}), timestamp=Optional.of(1.512573901E9)}), taskId=test-request-firstDeployId-1512573901281-2-host1-rack1, serverTimestamp=1512573901417, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901450-3-host1-rack1'}), timestamp=Optional.of(1.512573901E9)}), taskId=test-request-firstDeployId-1512573901450-3-host1-rack1, serverTimestamp=1512573901605, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
15:25:01.730 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573780522-1-IMMEDIATE-1512573780522, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer811'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573780522-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:01.732 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573780522-1-IMMEDIATE-1512573780522, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer811'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573780522-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@338723a7 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3d40cba7[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901686-4-host1-rack1'}), timestamp=Optional.of(1.512573901E9)}), taskId=test-request-firstDeployId-1512573901686-4-host1-rack1, serverTimestamp=1512573901735, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901692-1-host1-rack1'}), timestamp=Optional.of(1.512573901E9)}), taskId=test-request-firstDeployId-1512573901692-1-host1-rack1, serverTimestamp=1512573901835, serverId='13c56b2a-eaaa-466d-a86c-78d4feed5dae', slaveId=Optional.absent()}
15:25:02.077 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:02.136 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573901692-1-host1-rack1
15:25:02.140 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901692-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573901692-1-host1-rack1, serverTimestamp=1512573902130, serverId='13c56b2a-eaaa-466d-a86c-78d4feed5dae', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573902143-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573902143-2-host2-DEFAULT, serverTimestamp=1512573902432, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573902308-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573902308-1-host2-DEFAULT, serverTimestamp=1512573902442, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901118-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573901118-1-host1-rack1, serverTimestamp=1512573902524, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573901281-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573901281-2-host1-rack1, serverTimestamp=1512573902571, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573902795-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573902795-4-host2-DEFAULT, serverTimestamp=1512573902979, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573902615-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573902615-3-host2-DEFAULT, serverTimestamp=1512573903037, serverId='4fcef7c5-d8ff-415c-8296-ad9ffb77edfe', slaveId=Optional.absent()}
15:25:03.161 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512573900768-1-IMMEDIATE-1512573900768, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer294'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512573900768-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:03.162 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512573900768-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:03.164 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512573900768-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:03.690 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:03.953 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573903880-1-host1-rack1'}), timestamp=Optional.of(1.512573903E9)}), taskId=test-request-firstDeployId-1512573903880-1-host1-rack1, serverTimestamp=1512573904045, serverId='effbd7ef-791f-4670-898e-8edd6ae4dc59', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573904341-1-host1-rack1'}), timestamp=Optional.of(1.512573904E9)}), taskId=test-request-secondDeployId-1512573904341-1-host1-rack1, serverTimestamp=1512573904395, serverId='effbd7ef-791f-4670-898e-8edd6ae4dc59', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-startup_timeout_test-1512570304059-1-host1-rack1'}), timestamp=Optional.of(1.512570304E9)}), taskId=test-request-startup_timeout_test-1512570304059-1-host1-rack1, serverTimestamp=1512573904599, serverId='d92cd098-dd4d-40d9-ac82-1485e9dc44ee', slaveId=Optional.absent()}
15:25:05.541 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:05.946 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='secondDeployId', timestamp=1512573905759, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=0, stepComplete=false, autoAdvanceDeploySteps=false, failedDeployTasks=[], timestamp=1512573905759}), updatedRequest=Optional.absent()} request was PAUSED, removing deploy
Tests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 124.039 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityHealthchecksTest
testSkipHealthchecksEdgeCases(com.hubspot.singularity.scheduler.SingularityHealthchecksTest)  Time elapsed: 74.139 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.scheduler.SingularityHealthchecksTest.testSkipHealthchecksEdgeCases(SingularityHealthchecksTest.java:60)

15:25:07.064 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:07.302 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573908301-1-host1-rack1'}), timestamp=Optional.of(1.512573909E9)}), taskId=test-request-firstDeployId-1512573908301-1-host1-rack1, serverTimestamp=1512573907653, serverId='d96c130d-368e-459b-bfae-7053cb769c9b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573907651-1-host1-rack1'}), timestamp=Optional.of(1.512573907E9)}), taskId=test-request-firstDeployId-1512573907651-1-host1-rack1, serverTimestamp=1512573907752, serverId='723a1a7a-a860-4fd7-92c5-9fa7302a0b17', slaveId=Optional.absent()}
15:25:08.011 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573786806-1-IMMEDIATE-1512573786806, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer602'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573786806-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:08.012 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573786806-1-IMMEDIATE-1512573786806, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer602'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573786806-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@60e0de67 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6e272c0b[Shutting down, pool size = 2, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573907870-2-host1-rack1'}), timestamp=Optional.of(1.512573907E9)}), taskId=test-request-firstDeployId-1512573907870-2-host1-rack1, serverTimestamp=1512573908057, serverId='723a1a7a-a860-4fd7-92c5-9fa7302a0b17', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911301-2-host1-rack1'}), timestamp=Optional.of(1.512573912E9)}), taskId=test-request-firstDeployId-1512573911301-2-host1-rack1, serverTimestamp=1512573908034, serverId='d96c130d-368e-459b-bfae-7053cb769c9b', slaveId=Optional.absent()}
15:25:08.122 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573787026-2-IMMEDIATE-1512573787026, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer883'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573787026-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:08.124 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573787026-2-IMMEDIATE-1512573787026, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer883'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573787026-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3580e6f rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6e272c0b[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911301-3-host1-rack1'}), timestamp=Optional.of(1.512573912E9)}), taskId=test-request-firstDeployId-1512573911301-3-host1-rack1, serverTimestamp=1512573908328, serverId='d96c130d-368e-459b-bfae-7053cb769c9b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573908465-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573908465-1-host1-DEFAULT, serverTimestamp=1512573908614, serverId='723a1a7a-a860-4fd7-92c5-9fa7302a0b17', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573907651-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573907651-1-host1-rack1, serverTimestamp=1512573908726, serverId='723a1a7a-a860-4fd7-92c5-9fa7302a0b17', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573908938-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573908938-1-host2-DEFAULT, serverTimestamp=1512573909037, serverId='723a1a7a-a860-4fd7-92c5-9fa7302a0b17', slaveId=Optional.absent()}
15:25:09.129 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:33278] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e2c590000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:09.786 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573908301-1-IMMEDIATE-1512573908301, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer824'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573908301-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:09.787 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573908301-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:09.790 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573908301-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@28f5792a rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1d4e99a5[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:10.040 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573911301-2-IMMEDIATE-1512573911301, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer521'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573911301-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:10.042 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573911301-2-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:10.044 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573911301-2-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@71380c80 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1d4e99a5[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:10.333 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573911301-3-IMMEDIATE-1512573911301, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer779'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573911301-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:10.334 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573911301-3-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:10.337 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573911301-3-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@47cb326b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1d4e99a5[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:11.380 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:11.649 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911772-1-host1-rack1'}), timestamp=Optional.of(1.512573911E9)}), taskId=test-request-firstDeployId-1512573911772-1-host1-rack1, serverTimestamp=1512573912010, serverId='8a6a05be-c79a-41ca-a3fe-38e752bdb6b1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911765-1-host1-rack1'}), timestamp=Optional.of(1.512573911E9)}), taskId=test-request-firstDeployId-1512573911765-1-host1-rack1, serverTimestamp=1512573911994, serverId='b6568004-4139-42ca-aec3-d485c468bfe1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573912049-2-host1-rack1'}), timestamp=Optional.of(1.512573912E9)}), taskId=test-request-firstDeployId-1512573912049-2-host1-rack1, serverTimestamp=1512573912168, serverId='8a6a05be-c79a-41ca-a3fe-38e752bdb6b1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512573912700-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512573912700-1-host1-DEFAULT, serverTimestamp=1512573912802, serverId='8a6a05be-c79a-41ca-a3fe-38e752bdb6b1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911765-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573911765-1-host1-rack1, serverTimestamp=1512573912765, serverId='b6568004-4139-42ca-aec3-d485c468bfe1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573911772-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573911772-1-host1-rack1, serverTimestamp=1512573912923, serverId='8a6a05be-c79a-41ca-a3fe-38e752bdb6b1', slaveId=Optional.absent()}
15:25:13.123 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573791861-1-IMMEDIATE-1512573791861, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer759'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573791861-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:13.125 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573791861-1-IMMEDIATE-1512573791861, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer759'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573791861-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@46052483 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@48c2d233[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573913201-1-host1-rack1'}), timestamp=Optional.of(1.512573913E9)}), taskId=test-request-firstDeployId-1512573913201-1-host1-rack1, serverTimestamp=1512573913371, serverId='8a6a05be-c79a-41ca-a3fe-38e752bdb6b1', slaveId=Optional.absent()}
15:25:14.074 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 25, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 180.471 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityDeploysTest
testUsesNewRequestDataFromPendingDeploy(com.hubspot.singularity.scheduler.SingularityDeploysTest)  Time elapsed: 30.156 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

testLbUpdatesAfterEachDeployStep(com.hubspot.singularity.scheduler.SingularityDeploysTest)  Time elapsed: 56.555 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

15:25:15.863 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573916230-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573916230-1-host1-DEFAULT, serverTimestamp=1512573916315, serverId='4e624be6-7359-44c2-9bbd-c56f399ce707', slaveId=Optional.absent()}
15:25:17.676 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573917769-1-host1-rack1'}), timestamp=Optional.of(1.512573917E9)}), taskId=test-request-firstDeployId-1512573917769-1-host1-rack1, serverTimestamp=1512573917825, serverId='2ef49331-0042-40c6-b6da-5754bf178894', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573917863-2-host1-rack1'}), timestamp=Optional.of(1.512573917E9)}), taskId=test-request-firstDeployId-1512573917863-2-host1-rack1, serverTimestamp=1512573917892, serverId='2ef49331-0042-40c6-b6da-5754bf178894', slaveId=Optional.absent()}
15:25:17.950 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:17.961 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:17.983 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573917863-2-host1-rack1
15:25:17.986 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573917863-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573917863-2-host1-rack1, serverTimestamp=1512573917977, serverId='2ef49331-0042-40c6-b6da-5754bf178894', slaveId=Optional.absent()}
15:25:18.018 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573917769-1-host1-rack1
15:25:18.024 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573917769-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573917769-1-host1-rack1, serverTimestamp=1512573917997, serverId='2ef49331-0042-40c6-b6da-5754bf178894', slaveId=Optional.absent()}
15:25:18.117 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:38401] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e556d0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:19.268 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:21.836 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573921945-1-host1-rack1'}), timestamp=Optional.of(1.512573921E9)}), taskId=test-request-firstDeployId-1512573921945-1-host1-rack1, serverTimestamp=1512573922007, serverId='824a04b5-4edb-4325-841b-72af8798d0af', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573922040-2-host1-rack1'}), timestamp=Optional.of(1.512573922E9)}), taskId=test-request-firstDeployId-1512573922040-2-host1-rack1, serverTimestamp=1512573922064, serverId='824a04b5-4edb-4325-841b-72af8798d0af', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573922074-3-host1-rack1'}), timestamp=Optional.of(1.512573922E9)}), taskId=test-request-firstDeployId-1512573922074-3-host1-rack1, serverTimestamp=1512573922100, serverId='824a04b5-4edb-4325-841b-72af8798d0af', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573922191-5-host1-rack1'}), timestamp=Optional.of(1.512573922E9)}), taskId=test-request-firstDeployId-1512573922191-5-host1-rack1, serverTimestamp=1512573922224, serverId='824a04b5-4edb-4325-841b-72af8798d0af', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573922191-5-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573922191-5-host1-rack1, serverTimestamp=1512573922236, serverId='824a04b5-4edb-4325-841b-72af8798d0af', slaveId=Optional.absent()}
15:25:22.281 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42131] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e65be0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:24.706 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:24.955 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='firstDeployId', timestamp=1512573924711, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512573924711}), updatedRequest=Optional.absent()} request was MISSING, removing deploy
15:25:26.176 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573926245-1-host1-rack1'}), timestamp=Optional.of(1.512573926E9)}), taskId=test-request-firstDeployId-1512573926245-1-host1-rack1, serverTimestamp=1512573926289, serverId='1746183f-7ee5-493d-bfec-0dbd6b1b74d6', slaveId=Optional.absent()}
15:25:26.370 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573926245-1-host1-rack1
15:25:26.374 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573926245-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573926245-1-host1-rack1, serverTimestamp=1512573926352, serverId='1746183f-7ee5-493d-bfec-0dbd6b1b74d6', slaveId=Optional.absent()}
15:25:27.531 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:27.788 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:51139] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e7c060000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:28.933 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573929180-1-host1-rack1'}), timestamp=Optional.of(1.512573929E9)}), taskId=test-request-firstDeployId-1512573929180-1-host1-rack1, serverTimestamp=1512573929225, serverId='6729e29b-afe2-4d0c-9b13-337a58e938a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573929252-2-host1-rack1'}), timestamp=Optional.of(1.512573929E9)}), taskId=test-request-firstDeployId-1512573929252-2-host1-rack1, serverTimestamp=1512573929276, serverId='6729e29b-afe2-4d0c-9b13-337a58e938a9', slaveId=Optional.absent()}
15:25:31.772 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:33.099 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933155-1-host1-rack1'}), timestamp=Optional.of(1.512573933E9)}), taskId=test-request-firstDeployId-1512573933155-1-host1-rack1, serverTimestamp=1512573933205, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933231-1-host1-rack1'}), timestamp=Optional.of(1.512573933E9)}), taskId=test-request-firstDeployId-1512573933231-1-host1-rack1, serverTimestamp=1512573933256, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
15:25:33.270 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573933155-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933155-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573933155-1-host1-rack1, serverTimestamp=1512573933265, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
15:25:33.285 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573933231-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933231-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573933231-1-host1-rack1, serverTimestamp=1512573933280, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933320-1-host1-rack1'}), timestamp=Optional.of(1.512573933E9)}), taskId=test-request-firstDeployId-1512573933320-1-host1-rack1, serverTimestamp=1512573933348, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
15:25:33.363 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573933320-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573933320-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573933320-1-host1-rack1, serverTimestamp=1512573933358, serverId='90f9e711-2fa3-43fa-bea0-b9d492fe9eb5', slaveId=Optional.absent()}
15:25:33.400 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:59682] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e91ce0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:34.545 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:35.814 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:36.073 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44837] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6e9c610000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:37.199 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:38.607 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:39.835 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573939899-1-host1-rack1'}), timestamp=Optional.of(1.512573939E9)}), taskId=test-request-firstDeployId-1512573939899-1-host1-rack1, serverTimestamp=1512573939945, serverId='6c2fa15f-8216-432d-8263-ad9906183741', slaveId=Optional.absent()}
15:25:40.004 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:40.034 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573939899-1-host1-rack1
15:25:40.041 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573939899-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573939899-1-host1-rack1, serverTimestamp=1512573940028, serverId='6c2fa15f-8216-432d-8263-ad9906183741', slaveId=Optional.absent()}
15:25:40.121 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:54399] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6eac120000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:41.286 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573941352-1-host1-rack1'}), timestamp=Optional.of(1.512573941E9)}), taskId=test-request-firstDeployId-1512573941352-1-host1-rack1, serverTimestamp=1512573941421, serverId='07972e8b-6062-4335-bd55-dc3fcf843d4e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573941521-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573941521-1-host2-DEFAULT, serverTimestamp=1512573941546, serverId='07972e8b-6062-4335-bd55-dc3fcf843d4e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573941352-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573941352-1-host1-rack1, serverTimestamp=1512573941564, serverId='07972e8b-6062-4335-bd55-dc3fcf843d4e', slaveId=Optional.absent()}
15:25:43.771 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:45.137 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:45.351 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40743] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6ec0ce0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:46.504 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:47.898 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:49.364 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:50.703 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573950920-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573950920-2-host2-DEFAULT, serverTimestamp=1512573950997, serverId='25b5ed94-c43e-475b-92e7-47be7d3525bb', slaveId=Optional.absent()}
[test-request-firstDeployId-1512573951005-2-TASK_DONE-1512573951005]
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573950967-5-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573950967-5-host2-DEFAULT, serverTimestamp=1512573951079, serverId='25b5ed94-c43e-475b-92e7-47be7d3525bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573950939-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573950939-4-host2-DEFAULT, serverTimestamp=1512573951113, serverId='25b5ed94-c43e-475b-92e7-47be7d3525bb', slaveId=Optional.absent()}
15:25:52.305 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573952369-1-host1-rack1'}), timestamp=Optional.of(1.512573952E9)}), taskId=test-request-firstDeployId-1512573952369-1-host1-rack1, serverTimestamp=1512573952429, serverId='2f2370da-cfc6-413d-b2ca-8616f81c0ff1', slaveId=Optional.absent()}
15:25:54.621 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954684-1-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954684-1-host1-rack1, serverTimestamp=1512573954728, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954753-2-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954753-2-host1-rack1, serverTimestamp=1512573954780, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954789-3-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954789-3-host1-rack1, serverTimestamp=1512573954812, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954821-4-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954821-4-host1-rack1, serverTimestamp=1512573954844, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:54.858 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954684-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954684-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954684-1-host1-rack1, serverTimestamp=1512573954853, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:54.890 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954753-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954753-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954753-2-host1-rack1, serverTimestamp=1512573954872, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:54.914 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954789-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954789-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954789-3-host1-rack1, serverTimestamp=1512573954909, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954950-1-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954950-1-host1-rack1, serverTimestamp=1512573954976, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954984-2-host1-rack1'}), timestamp=Optional.of(1.512573954E9)}), taskId=test-request-firstDeployId-1512573954984-2-host1-rack1, serverTimestamp=1512573955008, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573955016-3-host1-rack1'}), timestamp=Optional.of(1.512573955E9)}), taskId=test-request-firstDeployId-1512573955016-3-host1-rack1, serverTimestamp=1512573955040, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:55.054 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954950-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954950-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954950-1-host1-rack1, serverTimestamp=1512573955050, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:55.091 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954984-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954984-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954984-2-host1-rack1, serverTimestamp=1512573955086, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:55.112 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573955016-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573955016-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573955016-3-host1-rack1, serverTimestamp=1512573955107, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:55.158 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573954821-4-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573954821-4-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573954821-4-host1-rack1, serverTimestamp=1512573955154, serverId='27c966d1-0363-494f-ad4b-cd8e4134cfe0', slaveId=Optional.absent()}
15:25:56.349 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:56.441 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB delete request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512573956438, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-1512573956432-DELETE-1} (test-request-1512573956432-DELETE-1) got unexpected response FAILED
15:25:57.597 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573957655-1-host1-rack1'}), timestamp=Optional.of(1.512573957E9)}), taskId=test-request-firstDeployId-1512573957655-1-host1-rack1, serverTimestamp=1512573957701, serverId='896fe9da-e506-4bc4-990d-5a5bb997273a', slaveId=Optional.absent()}
15:25:59.997 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:01.500 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573961563-1-host1-rack1'}), timestamp=Optional.of(1.512573961E9)}), taskId=test-request-firstDeployId-1512573961563-1-host1-rack1, serverTimestamp=1512573961609, serverId='22994d39-7587-42d0-a039-cb3e2e675d9c', slaveId=Optional.absent()}
15:26:01.662 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573961563-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573961563-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573961563-1-host1-rack1, serverTimestamp=1512573961658, serverId='22994d39-7587-42d0-a039-cb3e2e675d9c', slaveId=Optional.absent()}
15:26:02.855 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573962911-1-host1-rack1'}), timestamp=Optional.of(1.512573962E9)}), taskId=test-request-firstDeployId-1512573962911-1-host1-rack1, serverTimestamp=1512573962956, serverId='ec4a6414-365d-4690-8b3b-789987c749fc', slaveId=Optional.absent()}
15:26:02.989 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573962911-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573962911-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573962911-1-host1-rack1, serverTimestamp=1512573962985, serverId='ec4a6414-365d-4690-8b3b-789987c749fc', slaveId=Optional.absent()}
15:26:03.028 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB removal request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512573963022, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-firstDeployId-1512573962911-1-host1-rack1-REMOVE-1} (test-request-firstDeployId-1512573962911-1-host1-rack1-REMOVE-1) got unexpected response FAILED
15:26:03.046 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42998] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f05f20000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:04.182 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:05.425 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:06.733 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573966835-1-host1-rack1'}), timestamp=Optional.of(1.512573966E9)}), taskId=test-request-firstDeployId-1512573966835-1-host1-rack1, serverTimestamp=1512573966883, serverId='6e98f98d-588f-464f-976e-1f787445f97a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573966835-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573966835-1-host1-rack1, serverTimestamp=1512573966965, serverId='6e98f98d-588f-464f-976e-1f787445f97a', slaveId=Optional.absent()}
15:26:08.168 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573968325-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573968325-1-host2-DEFAULT, serverTimestamp=1512573968355, serverId='7f1ca8c0-5055-468e-8a2a-9f2c0e92d57c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573968394-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573968394-1-host2-DEFAULT, serverTimestamp=1512573968409, serverId='7f1ca8c0-5055-468e-8a2a-9f2c0e92d57c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512573968447-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512573968447-1-host2-DEFAULT, serverTimestamp=1512573968468, serverId='7f1ca8c0-5055-468e-8a2a-9f2c0e92d57c', slaveId=Optional.absent()}
15:26:09.627 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573969687-1-host1-rack1'}), timestamp=Optional.of(1.512573969E9)}), taskId=test-request-firstDeployId-1512573969687-1-host1-rack1, serverTimestamp=1512573969733, serverId='8d8bce1c-544a-45de-a71d-ded898e6a496', slaveId=Optional.absent()}
15:26:09.769 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573969687-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573969687-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573969687-1-host1-rack1, serverTimestamp=1512573969764, serverId='8d8bce1c-544a-45de-a71d-ded898e6a496', slaveId=Optional.absent()}
15:26:11.071 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:11.196 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:58898] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f262a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:12.337 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:13.473 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:14.744 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573974865-1-host1-rack1'}), timestamp=Optional.of(1.512573974E9)}), taskId=test-request-firstDeployId-1512573974865-1-host1-rack1, serverTimestamp=1512573974914, serverId='40f3c5e7-21aa-4df0-bd3d-8098f472ed49', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573974950-2-host2-rack1'}), timestamp=Optional.of(1.512573974E9)}), taskId=test-request-firstDeployId-1512573974950-2-host2-rack1, serverTimestamp=1512573974971, serverId='40f3c5e7-21aa-4df0-bd3d-8098f472ed49', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573975067-1-host3-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512573975067-1-host3-DEFAULT, serverTimestamp=1512573975088, serverId='40f3c5e7-21aa-4df0-bd3d-8098f472ed49', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573974865-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573974865-1-host1-rack1, serverTimestamp=1512573975142, serverId='40f3c5e7-21aa-4df0-bd3d-8098f472ed49', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573975185-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512573975185-2-host1-DEFAULT, serverTimestamp=1512573975201, serverId='40f3c5e7-21aa-4df0-bd3d-8098f472ed49', slaveId=Optional.absent()}
15:26:16.974 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573974950-2-IMMEDIATE-1512573974950, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host2', id=SingularityMesosIdObject{value='offer396'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573974950-2-host2-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:26:16.974 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573974950-2-host2-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:16.976 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573974950-2-host2-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@213ee581 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2ff90fd6[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:17.092 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573975046-1-BOUNCE-1512573974987, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host3', id=SingularityMesosIdObject{value='offer267'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573975067-1-host3-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host3}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1512573975067-1-host3-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
15:26:17.094 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573975067-1-host3-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:17.096 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573975067-1-host3-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2bc68ef1 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2ff90fd6[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:17.204 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573975153-2-TASK_DONE-1512573975150, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer950'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573975185-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(disk), ranges=Optional.absent(), allOtherFields={scalar={value=1024.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1512573975185-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
15:26:17.205 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512573975185-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:17.206 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512573975185-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@24530d87 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2ff90fd6[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:18.355 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:19.654 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573979711-1-host1-rack1'}), timestamp=Optional.of(1.512573979E9)}), taskId=test-request-firstDeployId-1512573979711-1-host1-rack1, serverTimestamp=1512573979752, serverId='dc92ac26-fdf9-4553-8c4a-97cf34ecd129', slaveId=Optional.absent()}
15:26:19.864 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:37814] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f47ab0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:22.003 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:22.009 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Unexpected taskId task 
com.hubspot.singularity.data.transcoders.SingularityTranscoderException: java.lang.reflect.InvocationTargetException
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:44)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.getTaskId(SingularityMesosStatusUpdateHandler.java:137)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:185)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:268)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:277)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testTaskOddities(SingularitySchedulerTest.java:1493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException: null
	at sun.reflect.GeneratedMethodAccessor269.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:42)
	... 19 common frames omitted
Caused by: com.hubspot.singularity.InvalidSingularityTaskIdException: TaskId task was invalid (There must be at least 5 instances of - (there were 0))
	at com.hubspot.singularity.SingularityTaskId.valueOf(SingularityTaskId.java:114)
	... 23 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573982063-1-host1-rack1'}), timestamp=Optional.of(1.512573982E9)}), taskId=test-request-firstDeployId-1512573982063-1-host1-rack1, serverTimestamp=1512573982109, serverId='f91a5db0-bc3c-4192-8a4b-9c26fdf90751', slaveId=Optional.absent()}
15:26:22.148 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Task test-request-firstDeployId-1512573982063-1-host1-rack1 is active but is missing task data
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573982063-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573982063-1-host1-rack1, serverTimestamp=1512573982146, serverId='f91a5db0-bc3c-4192-8a4b-9c26fdf90751', slaveId=Optional.absent()}
15:26:22.165 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573982063-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573982063-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573982063-1-host1-rack1, serverTimestamp=1512573982161, serverId='f91a5db0-bc3c-4192-8a4b-9c26fdf90751', slaveId=Optional.absent()}
[SingularityTaskHistoryUpdate[timestamp=1512573982146, taskState=TASK_RUNNING, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]], SingularityTaskHistoryUpdate[timestamp=1512573982161, taskState=TASK_FAILED, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]]]
15:26:22.204 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:59939] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f50cd0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:23.371 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:23.914 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47997] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f560c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:25.031 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985103-1-host1-rack1'}), timestamp=Optional.of(1.512573985E9)}), taskId=test-request-firstDeployId-1512573985103-1-host1-rack1, serverTimestamp=1512573985148, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985173-2-host1-rack1'}), timestamp=Optional.of(1.512573985E9)}), taskId=test-request-firstDeployId-1512573985173-2-host1-rack1, serverTimestamp=1512573985195, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985204-3-host1-rack1'}), timestamp=Optional.of(1.512573985E9)}), taskId=test-request-firstDeployId-1512573985204-3-host1-rack1, serverTimestamp=1512573985228, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985406-1-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512573985406-1-host1-DEFAULT, serverTimestamp=1512573985450, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985377-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512573985377-2-host1-DEFAULT, serverTimestamp=1512573985468, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573985428-3-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512573985428-3-host1-DEFAULT, serverTimestamp=1512573985477, serverId='7173fa8f-f067-46d7-a4c9-815e983b09bb', slaveId=Optional.absent()}
15:26:27.661 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:28.841 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:28.965 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:39119] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6f6b860000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:30.099 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512563190161-1-host1-rack1'}), timestamp=Optional.of(1.51257399E9)}), taskId=test-request-firstDeployId-1512563190161-1-host1-rack1, serverTimestamp=1512573990209, serverId='e3e6aea2-3f30-47d0-9286-0c126453c95b', slaveId=Optional.absent()}
15:26:30.283 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512563190161-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512563190161-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512563190161-1-host1-rack1, serverTimestamp=1512573990278, serverId='e3e6aea2-3f30-47d0-9286-0c126453c95b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573989661-1-host1-rack1'}), timestamp=Optional.of(1.51257399E9)}), taskId=test-request-firstDeployId-1512573989661-1-host1-rack1, serverTimestamp=1512573990325, serverId='e3e6aea2-3f30-47d0-9286-0c126453c95b', slaveId=Optional.absent()}
15:26:30.338 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573989661-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573989661-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573989661-1-host1-rack1, serverTimestamp=1512573990333, serverId='e3e6aea2-3f30-47d0-9286-0c126453c95b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573989659-1-host1-rack1'}), timestamp=Optional.of(1.51257399E9)}), taskId=test-request-firstDeployId-1512573989659-1-host1-rack1, serverTimestamp=1512573990399, serverId='e3e6aea2-3f30-47d0-9286-0c126453c95b', slaveId=Optional.absent()}
15:26:32.564 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:34.039 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573994095-1-host1-rack1'}), timestamp=Optional.of(1.512573994E9)}), taskId=test-request-firstDeployId-1512573994095-1-host1-rack1, serverTimestamp=1512573994141, serverId='e928d26e-56e2-4aab-a6d5-9bcdbba3e79e', slaveId=Optional.absent()}
15:26:34.199 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:26:34.223 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573994095-1-host1-rack1
15:26:34.248 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573994095-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573994095-1-host1-rack1, serverTimestamp=1512573994218, serverId='e928d26e-56e2-4aab-a6d5-9bcdbba3e79e', slaveId=Optional.absent()}
15:26:35.446 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:36.681 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573996739-1-host1-rack1'}), timestamp=Optional.of(1.512573996E9)}), taskId=test-request-firstDeployId-1512573996739-1-host1-rack1, serverTimestamp=1512573996784, serverId='8842183e-b171-4247-9d4c-dec0bfaf9b41', slaveId=Optional.absent()}
15:26:36.814 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573996739-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573996739-1-host1-rack1'}), timestamp=Optional.of(1.512555996E9)}), taskId=test-request-firstDeployId-1512573996739-1-host1-rack1, serverTimestamp=1512573996809, serverId='8842183e-b171-4247-9d4c-dec0bfaf9b41', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573996824-1-host1-rack1'}), timestamp=Optional.of(1.512573996E9)}), taskId=test-request-firstDeployId-1512573996824-1-host1-rack1, serverTimestamp=1512573996853, serverId='8842183e-b171-4247-9d4c-dec0bfaf9b41', slaveId=Optional.absent()}
15:26:36.865 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512573996824-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512573996824-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512573996824-1-host1-rack1, serverTimestamp=1512573996860, serverId='8842183e-b171-4247-9d4c-dec0bfaf9b41', slaveId=Optional.absent()}
15:26:38.029 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512573998210-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512573998210-1-host1-DEFAULT, serverTimestamp=1512573998242, serverId='3016e364-d1f9-471a-932d-4576f684d5de', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512573998299-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512573998299-1-host1-DEFAULT, serverTimestamp=1512573998321, serverId='3016e364-d1f9-471a-932d-4576f684d5de', slaveId=Optional.absent()}
15:26:39.496 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.of(1.512573999E9)}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512573999651, serverId='93a8a500-b956-4fa0-9fb5-62343f518a78', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1'}), timestamp=Optional.of(1.512573999E9)}), taskId=mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1, serverTimestamp=1512573999703, serverId='93a8a500-b956-4fa0-9fb5-62343f518a78', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='highPriorityRequest-highPriorityDeploy-10-1-host1-rack1'}), timestamp=Optional.of(1.512573999E9)}), taskId=highPriorityRequest-highPriorityDeploy-10-1-host1-rack1, serverTimestamp=1512573999739, serverId='93a8a500-b956-4fa0-9fb5-62343f518a78', slaveId=Optional.absent()}
15:26:39.806 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512573999794, serverId='93a8a500-b956-4fa0-9fb5-62343f518a78', slaveId=Optional.absent()}
15:26:42.050 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:43.460 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512574003540-1-host1-rack1'}), timestamp=Optional.of(1.512574003E9)}), taskId=test-request-firstDeployId-1512574003540-1-host1-rack1, serverTimestamp=1512574003585, serverId='f6658bc4-bc4e-4f5e-b0a7-0240342a639c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512574003608-2-host1-rack1'}), timestamp=Optional.of(1.512574003E9)}), taskId=test-request-firstDeployId-1512574003608-2-host1-rack1, serverTimestamp=1512574003632, serverId='f6658bc4-bc4e-4f5e-b0a7-0240342a639c', slaveId=Optional.absent()}
15:26:43.659 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512574003540-1-host1-rack1
15:26:43.661 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512574003540-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512574003540-1-host1-rack1, serverTimestamp=1512574003654, serverId='f6658bc4-bc4e-4f5e-b0a7-0240342a639c', slaveId=Optional.absent()}
15:26:43.690 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:26:43.705 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512574003608-2-host1-rack1
15:26:43.708 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512574003608-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512574003608-2-host1-rack1, serverTimestamp=1512574003700, serverId='f6658bc4-bc4e-4f5e-b0a7-0240342a639c', slaveId=Optional.absent()}
15:26:44.960 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:46.522 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:46.748 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:48781] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1602c6fb0750000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:46.897 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573885459-1-IMMEDIATE-1512573885459, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer888'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573885459-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:46.899 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573885459-1-IMMEDIATE-1512573885459, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer888'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573885459-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4392c940 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6d673c0[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:47.147 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573886007-3-IMMEDIATE-1512573886007, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer236'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573886007-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:47.148 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512573886007-3-IMMEDIATE-1512573886007, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer236'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512573886007-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@44180910 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6d673c0[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:47.876 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512574007934-1-host1-rack1'}), timestamp=Optional.of(1.512574007E9)}), taskId=test-request-firstDeployId-1512574007934-1-host1-rack1, serverTimestamp=1512574007976, serverId='8a791a61-0d4f-4a0c-8627-c1473128391e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512574008018-1-host1-rack1'}), timestamp=Optional.of(1.512574008E9)}), taskId=test-request-secondDeployId-1512574008018-1-host1-rack1, serverTimestamp=1512574008050, serverId='8a791a61-0d4f-4a0c-8627-c1473128391e', slaveId=Optional.absent()}
15:26:48.996 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512574007934-1-IMMEDIATE-1512574007934, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer728'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512574007934-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:49.000 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512574007934-1-IMMEDIATE-1512574007934, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer728'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=disk, type=SCALAR, scalar={value=2048.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512574007934-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7f51245a rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7196d5c0[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:50.123 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:51.498 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:52.804 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 75, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 207.25 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularitySchedulerTest
testDecommissionDoesntKillPendingDeploy(com.hubspot.singularity.scheduler.SingularitySchedulerTest)  Time elapsed: 42.013 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds


Results :

Tests in error: 
  SingularityHistoryTest.testTaskSearchQueryBlended:384->SingularitySchedulerTestBase.launchTask:347->SingularitySchedulerTestBase.statusUpdate:362 Â» TestTimedOut
  BlendedHistoryTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut t...
  InactiveSlaveManagerTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  StateManagerTest>SingularityCuratorTestBase.curatorTeardown:55 Â» TestTimedOut ...
  ValidatorTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut test t...
  ZkMigrationTest.testMigrationRunner:56->Object.wait:502->Object.wait:-2 Â» TestTimedOut
  SingularityTaskShellCommandTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityDeploysTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityDeploysTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityExpiringActionsTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityHealthchecksTest.testSkipHealthchecksEdgeCases:60->SingularitySchedulerTestBase.finishNewTaskChecks:418 Â» TestTimedOut
  SingularityMachineStatesTest>SingularitySchedulerTestBase.setupDriver:207 Â» TestTimedOut
  SingularitySchedulerTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularitySlavePlacementTest.testSlavePlacementSpread:79 Â» TestTimedOut test ...
  SingularityUsageTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut

Tests run: 254, Failures: 0, Errors: 15, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Singularity ........................................ SUCCESS [  4.321 s]
[INFO] SingularityBase .................................... SUCCESS [  5.291 s]
[INFO] SingularityUI ...................................... SUCCESS [02:55 min]
[INFO] SingularityMesosClient ............................. SUCCESS [  3.080 s]
[INFO] SingularitySwagger ................................. SUCCESS [  1.627 s]
[INFO] SingularityService ................................. FAILURE [05:12 min]
[INFO] SingularityRunnerBase .............................. SKIPPED
[INFO] SingularityS3Base .................................. SKIPPED
[INFO] SingularityClient .................................. SKIPPED
[INFO] SingularityExecutor ................................ SKIPPED
[INFO] SingularityExecutorCleanup ......................... SKIPPED
[INFO] SingularityS3Uploader .............................. SKIPPED
[INFO] SingularityS3Downloader ............................ SKIPPED
[INFO] EmbedSingularityExample ............................ SKIPPED
[INFO] SingularityServiceIntegrationTests ................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 08:22 min
[INFO] Finished at: 2017-12-06T16:26:53+01:00
[INFO] Final Memory: 153M/2204M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project SingularityService: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/HubSpot/Singularity/312436596/SingularityService/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :SingularityService
