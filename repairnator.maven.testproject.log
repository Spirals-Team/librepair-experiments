[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Singularity
[INFO] SingularityBase
[INFO] SingularityUI
[INFO] SingularityServiceBase
[INFO] SingularityMesosClient
[INFO] SingularitySwagger
[INFO] SingularityService
[INFO] SingularityRunnerBase
[INFO] SingularityS3Base
[INFO] SingularityClient
[INFO] SingularityExecutor
[INFO] SingularityExecutorCleanup
[INFO] SingularityS3Uploader
[INFO] SingularityS3Downloader
[INFO] EmbedSingularityExample
[INFO] SingularityServiceIntegrationTests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Singularity 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ Singularity ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ Singularity ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ Singularity ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ Singularity ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ Singularity ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ Singularity ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ Singularity ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/target/jacoco.exec
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/RequestCleanupType.java:12:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/SlaveMatchState.java:18:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/TaskCleanupType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/RequestType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/HealthcheckProtocol.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/RequestState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/java/com/hubspot/singularity/DeployState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularityBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityUI 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityUI ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityUI ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityUI ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityUI ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityUI ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityUI ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityUI ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularityUI/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-index.html-template) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-ui) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 12 resources
[INFO] 
[INFO] --- build-helper-maven-plugin:1.10:add-resource (add-generated-resources) @ SingularityUI ---
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:install-node-and-npm (install node and npm) @ SingularityUI ---
[INFO] Node v6.2.1 is already installed.
[INFO] Found NPM version 3.9.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm install) @ SingularityUI ---
[INFO] Running 'npm install --color=false' in /root/workspace/HubSpot/Singularity/309611571/SingularityUI
[ERROR] npm WARN optional Skipping failed optional dependency /chokidar/fsevents:
[ERROR] npm WARN notsup Not compatible with your operating system or architecture: fsevents@1.1.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm test) @ SingularityUI ---
[INFO] Running 'npm test --color=false' in /root/workspace/HubSpot/Singularity/309611571/SingularityUI
[INFO] 
[INFO] > SingularityUI@0.3.0 test /root/workspace/HubSpot/Singularity/309611571/SingularityUI
[INFO] > mocha --compilers js:babel-core/register test/index.test
[INFO] 
[ERROR] Warning: Accessing PropTypes via the main React package is deprecated, and will be removed in  React v16.0. Use the latest available v15.* prop-types package from npm instead. For info on usage, compatibility, migration and more, see https://fb.me/prop-types-docs
[INFO] 
[INFO] 
[INFO]   Utils
[INFO]     getTaskDataFromTaskId()
[INFO]       âœ“ should grab all fields from a valid task id
[INFO] 
[INFO]   Reducers
[INFO]     tailerView
[INFO]       âœ“ should be properly initialized
[INFO]       âœ“ should populate the tailerId field
[INFO]       âœ“ should auto-populate the requestIds, taskIds, and paths fields
[INFO]       âœ“ should add tailer groups
[INFO]       âœ“ should remove tailer groups
[INFO]       âœ“ should pick an individual tailer group
[INFO] 
[INFO] 
[INFO]   7 passing (42ms)
[INFO] 
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:gulp (gulp build) @ SingularityUI ---
[INFO] Running 'gulp build --no-color' in /root/workspace/HubSpot/Singularity/309611571/SingularityUI
[INFO] [18:18:19] Using gulpfile ~/workspace/HubSpot/Singularity/309611571/SingularityUI/gulpfile.js
[INFO] [18:18:19] Starting 'clean'...
[INFO] [18:18:19] Finished 'clean' after 46 ms
[INFO] [18:18:19] Starting 'static'...
[INFO] [18:18:19] Finished 'static' after 48 ms
[INFO] [18:18:19] Starting 'html'...
[INFO] [18:18:19] Finished 'html' after 28 ms
[INFO] [18:18:19] Starting 'build'...
[INFO] [18:20:54] Version: webpack [1m1.13.1[22m
[INFO] Time: [1m154579[22mms
[INFO]                                [1mAsset[22m     [1mSize[22m  [1mChunks[22m  [1m[22m           [1mChunk Names[22m
[INFO] [1m[32m89889688147bd7575d6327160d64e760.svg[39m[22m   109 kB        [1m[22m  [1m[32m[emitted][39m[22m  
[INFO]                  [1m[32mjs/vendor.bundle.js[39m[22m   618 kB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                     [1m[32mjs/app.bundle.js[39m[22m  2.18 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                          [1m[32mcss/app.css[39m[22m   338 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]              [1m[32mjs/vendor.bundle.js.map[39m[22m  4.62 MB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                 [1m[32mjs/app.bundle.js.map[39m[22m  10.4 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                      [1m[32mcss/app.css.map[39m[22m   415 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] [18:20:54] Finished 'build' after 2.58 min
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityUI/src/main/resources
[INFO] Copying 13 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityUI/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityUI ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityServiceBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityServiceBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityServiceBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityServiceBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityServiceBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityServiceBase/src/main/java/com/hubspot/singularity/config/UIConfiguration.java:22:10: Redundant 'static' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityServiceBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityServiceBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityServiceBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularityServiceBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityServiceBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityServiceBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityServiceBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityServiceBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityServiceBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityServiceBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityServiceBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityMesosClient 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityMesosClient ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityMesosClient ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:29:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:31:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:33:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:35:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:37:3: Redundant 'public' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityMesosClient ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityMesosClient ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityMesosClient ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularityMesosClient/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityMesosClient ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityMesosClient ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularitySwagger 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularitySwagger ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularitySwagger ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularitySwagger ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularitySwagger ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularitySwagger/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularitySwagger/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularitySwagger ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/309611571/SingularitySwagger/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularitySwagger ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularitySwagger ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityService 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityService ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityService ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityService ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityService ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/hooks/LoadBalancerClientImpl.java:114:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:18:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:20:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:22:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:24:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:26:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:175:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:224:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:249:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:289:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:315:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorManager.java:64:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityCmdLineArgsMigration.java:58:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:84:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:139:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/history/SingularityHistoryModule.java:126:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorAsyncManager.java:46:5: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/309611571/SingularityService/src/main/java/com/hubspot/singularity/smtp/SmtpMailer.java:366:5: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityService ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityService ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityService ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/309611571/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/309611571/SingularityService/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- swagger-maven-plugin:2.3.2:generate (build-embedded-documentation) @ SingularityService ---
[INFO] Reflections took 83 ms to scan 2 urls, producing 13 keys and 78 values 
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskTrackerResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.WebhookResource
[INFO] Detect Resource:com.hubspot.singularity.resources.InactiveSlaveResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.S3LogResource
[INFO] Detect Resource:com.hubspot.singularity.resources.StateResource
[INFO] Detect Resource:com.hubspot.singularity.resources.SandboxResource
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DisastersResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UsageResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.SlaveResource
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RackResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TestResource
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
[INFO] Detect Resource:com.hubspot.singularity.resources.HistoryResource
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestGroupResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.PriorityResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UserResource
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DeployResource
[INFO] Writing doc to /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/index.html...
[INFO] Done!
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/service.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_track.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_webhooks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_inactive.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_logs.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_state.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_sandbox.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_tasks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_disasters.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_usage.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_slaves.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_requests.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_racks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_test.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_history.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_groups.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_priority.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_users.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/classes/assets/api-docs/api_deploys.json
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityService ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom (4 KB at 9.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom (3 KB at 113.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar (75 KB at 1138.6 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hubspot.singularity.scheduler.HistoryPersisterTest
Running com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
Running com.hubspot.singularity.scheduler.SingularityMachineStatesTest
Running com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
Running com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.scheduler.SingularityDeploysTest
Running com.hubspot.singularity.SingularityHistoryTest
Running com.hubspot.singularity.scheduler.MesosUtilsTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.137 sec - in com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.mesos.SingularityStartupTest
18:21:41.795 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1631135932)
18:21:41.919 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:42.664 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 2085264529)
18:21:42.772 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:43.118 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1728179948)
18:21:43.274 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:43.677 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1288461846)
18:21:43.842 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:43.911 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1170160639)
18:21:44.070 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:44.167 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 93253413)
18:21:44.252 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:44.767 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1561961064)
18:21:44.883 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.945 sec - in com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.scheduler.SingularitySchedulerTest
18:21:49.083 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1986242917)
18:21:49.178 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
18:21:49.365 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:49.414 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14646ms
18:21:49.547 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6c127fac
18:21:49.650 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3face0b2{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@34218887,MANAGED}
18:21:49.653 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@2172efcd
18:21:49.653 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7ba68b3{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5e75cfb6,MANAGED}
18:21:49.865 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5e75cfb6 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:49.906 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5e75cfb6 added {[/tasks/*]=>tasks,POJO}
18:21:50.407 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:50.433 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15639ms
18:21:50.601 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:50.636 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@75a9d540
18:21:50.650 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15863ms
18:21:50.781 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7fd0d3f1{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@55b331a,MANAGED}
18:21:50.786 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@20de88d6
18:21:50.787 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@5908ad53{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@6f3d0b13,MANAGED}
18:21:50.863 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7d164623
18:21:51.016 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@627ad86e{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@221a8b4,MANAGED}
18:21:51.019 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6fb09651
18:21:51.032 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3691d5e7{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@1e70dd54,MANAGED}
18:21:51.140 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@6f3d0b13 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:51.184 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@6f3d0b13 added {[/tasks/*]=>tasks,POJO}
18:21:51.278 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1e70dd54 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:51.328 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@1e70dd54 added {[/tasks/*]=>tasks,POJO}
18:21:51.700 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:51.748 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @16969ms
18:21:51.781 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:51.807 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:51.832 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @17055ms
18:21:51.835 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @17056ms
18:21:51.914 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@52e8412f
18:21:51.965 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3e354d34
18:21:52.019 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@15cbbac6
18:21:52.022 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@13ca6062{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@492f4578,MANAGED}
18:21:52.041 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6f80b1ad
18:21:52.041 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@136e9ada{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@b987d6a,MANAGED}
18:21:52.114 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3006816c{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@57f10da4,MANAGED}
18:21:52.129 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@70a20562
18:21:52.144 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@740d04e6{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@41c6a4a9,MANAGED}
18:21:52.161 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@4f0a2010{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@328c268d,MANAGED}
18:21:52.196 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@b8f3149
18:21:52.197 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3ba4d592{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@29e3caa8,MANAGED}
18:21:52.268 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@b987d6a added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:52.278 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:52.307 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@b987d6a added {[/tasks/*]=>tasks,POJO}
18:21:52.315 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @17547ms
18:21:52.342 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@41c6a4a9 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:52.393 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@41c6a4a9 added {[/tasks/*]=>tasks,POJO}
18:21:52.493 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@29e3caa8 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:52.516 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3f843ffd
18:21:52.545 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@29e3caa8 added {[/tasks/*]=>tasks,POJO}
18:21:52.570 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@38389fb9{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@12bef825,MANAGED}
18:21:52.622 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6e1eee86
18:21:52.623 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@312dfcae{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@72ec6b8b,MANAGED}
18:21:52.888 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@72ec6b8b added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:52.912 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@72ec6b8b added {[/tasks/*]=>tasks,POJO}
18:21:55.570 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
18:21:55.594 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @20812ms
18:21:55.641 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1c7fabd0
18:21:55.678 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3cfc8191{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@6dddc9e5,MANAGED}
18:21:55.684 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@36add92b
18:21:55.685 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@580220cb{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@27b23db7,MANAGED}
18:21:55.825 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@27b23db7 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
18:21:55.833 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@27b23db7 added {[/tasks/*]=>tasks,POJO}
18:22:14.343 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:15.353 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:15.756 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:15.815 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:16.027 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:16.127 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:16.614 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:16.491 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:16.771 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:17.246 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:17.298 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:17.357 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:17.603 [Time-limited test] WARN com.hubspot.singularity.data.history.SingularityRequestHistoryPersister - Failed to persist SingularityRequestHistory{createdAt=1512055336746, user=Optional.absent(), eventType=CREATED, request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, message=Optional.absent()} into History
java.lang.UnsupportedOperationException: NoopHistoryManager can not save
	at com.hubspot.singularity.data.history.NoopHistoryManager.saveRequestHistoryUpdate(NoopHistoryManager.java:26)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:141)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:25)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurgeAndShouldDelete(SingularityHistoryPersister.java:63)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurge(SingularityHistoryPersister.java:52)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.runActionOnPoll(SingularityRequestHistoryPersister.java:119)
	at com.hubspot.singularity.scheduler.HistoryPersisterTest.testPurgingDoesntApplyIfDatabasePresent(HistoryPersisterTest.java:211)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
18:22:18.080 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:18.175 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

18:22:18.478 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

18:22:18.543 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055336600-1-host1-rack1'}), timestamp=Optional.of(1.512066136E9)}), taskId=test-request-firstDeployId-1512055336600-1-host1-rack1, serverTimestamp=1512066138567, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:19.096 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055336600-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055336600-1-host1-rack1'}), timestamp=Optional.of(1.512058939E9)}), taskId=test-request-firstDeployId-1512055336600-1-host1-rack1, serverTimestamp=1512066139068, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339192-1-host1-rack1'}), timestamp=Optional.of(1.512066139E9)}), taskId=test-request-firstDeployId-1512055339192-1-host1-rack1, serverTimestamp=1512066139266, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:19.334 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055339192-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339192-1-host1-rack1'}), timestamp=Optional.of(1.512058939E9)}), taskId=test-request-firstDeployId-1512055339192-1-host1-rack1, serverTimestamp=1512066139309, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339430-1-host1-rack1'}), timestamp=Optional.of(1.512066139E9)}), taskId=test-request-firstDeployId-1512055339430-1-host1-rack1, serverTimestamp=1512066139501, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:19.605 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055339430-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339430-1-host1-rack1'}), timestamp=Optional.of(1.512058939E9)}), taskId=test-request-firstDeployId-1512055339430-1-host1-rack1, serverTimestamp=1512066139565, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339713-1-host1-rack1'}), timestamp=Optional.of(1.512066139E9)}), taskId=test-request-firstDeployId-1512055339713-1-host1-rack1, serverTimestamp=1512066139777, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:19.857 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055339713-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339713-1-host1-rack1'}), timestamp=Optional.of(1.512058939E9)}), taskId=test-request-firstDeployId-1512055339713-1-host1-rack1, serverTimestamp=1512066139799, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339922-1-host1-rack1'}), timestamp=Optional.of(1.512066139E9)}), taskId=test-request-firstDeployId-1512055339922-1-host1-rack1, serverTimestamp=1512066140009, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:20.095 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055339922-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066138641-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066138641-2-host1-DEFAULT, serverTimestamp=1512066140004, serverId='8d8896f8-0783-4a20-b742-cc52ef405097', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055339922-1-host1-rack1'}), timestamp=Optional.of(1.51205894E9)}), taskId=test-request-firstDeployId-1512055339922-1-host1-rack1, serverTimestamp=1512066140077, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340165-1-host1-rack1'}), timestamp=Optional.of(1.51206614E9)}), taskId=test-request-firstDeployId-1512055340165-1-host1-rack1, serverTimestamp=1512066140260, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:20.320 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055340165-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066139585-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066139585-1-host2-DEFAULT, serverTimestamp=1512066140215, serverId='8d8896f8-0783-4a20-b742-cc52ef405097', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340165-1-host1-rack1'}), timestamp=Optional.of(1.51205894E9)}), taskId=test-request-firstDeployId-1512055340165-1-host1-rack1, serverTimestamp=1512066140303, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340467-1-host1-rack1'}), timestamp=Optional.of(1.51206614E9)}), taskId=test-request-firstDeployId-1512055340467-1-host1-rack1, serverTimestamp=1512066140527, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:20.578 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:20.583 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055340467-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340467-1-host1-rack1'}), timestamp=Optional.of(1.51205894E9)}), taskId=test-request-firstDeployId-1512055340467-1-host1-rack1, serverTimestamp=1512066140565, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:20.746 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340669-1-host1-rack1'}), timestamp=Optional.of(1.51206614E9)}), taskId=test-request-firstDeployId-1512055340669-1-host1-rack1, serverTimestamp=1512066140766, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066138353-1-host1-rack1'}), timestamp=Optional.of(1.512066138E9)}), taskId=test-request-firstDeployId-1512066138353-1-host1-rack1, serverTimestamp=1512066139817, serverId='75682583-e8a9-4c92-aabb-17d93009801b', slaveId=Optional.absent()}
18:22:20.842 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055340669-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340669-1-host1-rack1'}), timestamp=Optional.of(1.51205894E9)}), taskId=test-request-firstDeployId-1512055340669-1-host1-rack1, serverTimestamp=1512066140807, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066140639-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066140639-2-host2-DEFAULT, serverTimestamp=1512066140851, serverId='8d8896f8-0783-4a20-b742-cc52ef405097', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340882-1-host1-rack1'}), timestamp=Optional.of(1.51206614E9)}), taskId=test-request-firstDeployId-1512055340882-1-host1-rack1, serverTimestamp=1512066140951, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:21.018 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055340882-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055340882-1-host1-rack1'}), timestamp=Optional.of(1.51205894E9)}), taskId=test-request-firstDeployId-1512055340882-1-host1-rack1, serverTimestamp=1512066140981, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055341050-1-host1-rack1'}), timestamp=Optional.of(1.512066141E9)}), taskId=test-request-firstDeployId-1512055341050-1-host1-rack1, serverTimestamp=1512066141096, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:21.126 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055341050-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066138641-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066138641-2-host1-DEFAULT, serverTimestamp=1512066141036, serverId='8d8896f8-0783-4a20-b742-cc52ef405097', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055341050-1-host1-rack1'}), timestamp=Optional.of(1.512058941E9)}), taskId=test-request-firstDeployId-1512055341050-1-host1-rack1, serverTimestamp=1512066141114, serverId='595f8ba2-4513-4ce0-b676-5ea74684202a', slaveId=Optional.absent()}
18:22:21.193 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066138433-1-host1-rack1'}), timestamp=Optional.of(1.512066138E9)}), taskId=test-request-firstDeployId-1512066138433-1-host1-rack1, serverTimestamp=1512066140182, serverId='f963598b-12af-4d4f-9c76-1ff89d1db3e7', slaveId=Optional.absent()}
18:22:21.419 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066138353-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066138353-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066138353-1-host1-rack1, serverTimestamp=1512066141373, serverId='75682583-e8a9-4c92-aabb-17d93009801b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066141922-1-host1-rack1'}), timestamp=Optional.of(1.512066141E9)}), taskId=test-request-firstDeployId-1512066141922-1-host1-rack1, serverTimestamp=1512066142093, serverId='f963598b-12af-4d4f-9c76-1ff89d1db3e7', slaveId=Optional.absent()}
18:22:22.287 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:23.098 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 44.467 sec <<< FAILURE! - in com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
testTaskShellCommandPersistence(com.hubspot.singularity.mesos.SingularityTaskShellCommandTest)  Time elapsed: 30.065 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.StateManagerTest
18:22:23.409 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:23.907 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:23.967 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066143159-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066143159-1-host2-DEFAULT, serverTimestamp=1512066143768, serverId='e544bcc7-cd38-4f5f-8cca-b3b1d1a0236a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512066144236-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512066144236-1-host1-DEFAULT, serverTimestamp=1512066144341, serverId='e544bcc7-cd38-4f5f-8cca-b3b1d1a0236a', slaveId=Optional.absent()}
18:22:24.451 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:24.984 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066144608-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066144608-1-host1-rack1'}), timestamp=Optional.of(1.512066144E9)}), taskId=test-request-firstDeployId-1512066144608-1-host1-rack1, serverTimestamp=1512066144897, serverId='a4dfc9b4-24a0-4bcc-b7fb-00b00891c8b4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066145093-1-host1-rack1'}), timestamp=Optional.of(1.512066145E9)}), taskId=test-request-firstDeployId-1512066145093-1-host1-rack1, serverTimestamp=1512066145150, serverId='a4dfc9b4-24a0-4bcc-b7fb-00b00891c8b4', slaveId=Optional.absent()}
18:22:25.334 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:26.049 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:26.253 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066145783-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066145783-2-host1-DEFAULT, serverTimestamp=1512066146362, serverId='3fd923c4-7a3a-4984-8ff8-feca8d5de829', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055346227-1-host1-rack1'}), timestamp=Optional.of(1.512066146E9)}), taskId=test-request-firstDeployId-1512055346227-1-host1-rack1, serverTimestamp=1512066146361, serverId='63e1dda2-7e27-4cf3-8de7-ad34591fc6dd', slaveId=Optional.absent()}
18:22:26.633 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055346557-2-host1-rack1'}), timestamp=Optional.of(1.512066146E9)}), taskId=test-request-firstDeployId-1512055346557-2-host1-rack1, serverTimestamp=1512066146631, serverId='63e1dda2-7e27-4cf3-8de7-ad34591fc6dd', slaveId=Optional.absent()}
18:22:26.731 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055346227-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055346227-1-host1-rack1'}), timestamp=Optional.of(1.512058946E9)}), taskId=test-request-firstDeployId-1512055346227-1-host1-rack1, serverTimestamp=1512066146719, serverId='63e1dda2-7e27-4cf3-8de7-ad34591fc6dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066146633-4-host1-rack1'}), timestamp=Optional.of(1.512066146E9)}), taskId=test-request-firstDeployId-1512066146633-4-host1-rack1, serverTimestamp=1512066146738, serverId='3fd923c4-7a3a-4984-8ff8-feca8d5de829', slaveId=Optional.absent()}
18:22:26.863 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066146822-5-host1-rack1'}), timestamp=Optional.of(1.512066146E9)}), taskId=test-request-firstDeployId-1512066146822-5-host1-rack1, serverTimestamp=1512066146884, serverId='3fd923c4-7a3a-4984-8ff8-feca8d5de829', slaveId=Optional.absent()}
18:22:27.185 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:27.279 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066147030-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066147030-1-host1-DEFAULT, serverTimestamp=1512066147406, serverId='fb3e9326-fc7d-4d9f-8c77-a4955b0b9e09', slaveId=Optional.absent()}
18:22:27.510 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57914] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2a59300000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:22:27.656 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512055346557-2-IMMEDIATE-1512055346557, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer975'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512055346557-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066147418-1-host1-rack1'}), timestamp=Optional.of(1.512066147E9)}), taskId=test-request-firstDeployId-1512066147418-1-host1-rack1, serverTimestamp=1512066147531, serverId='ffb7d9e6-dec7-4937-b75d-c29b837c726f', slaveId=Optional.absent()}
18:22:27.678 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512055346557-2-IMMEDIATE-1512055346557, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer975'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512055346557-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@22763128 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@56e2fd04[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.616 sec - in com.hubspot.singularity.data.StateManagerTest
Running com.hubspot.singularity.data.ValidatorTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066147936-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066147936-1-host1-DEFAULT, serverTimestamp=1512066148130, serverId='ffb7d9e6-dec7-4937-b75d-c29b837c726f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512066148057, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512066148338, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512066148404, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512066148533, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512066148603, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512066148700, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512066148761, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:28.806 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512066148778, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:28.912 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-2-firstDeployId-15000-1-host1-rack1
18:22:28.936 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512066148892, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:28.959 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:29.426 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-2-firstDeployId-35000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512066148942, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:29.527 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-2-firstDeployId-25000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512066149508, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:29.566 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:29.610 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:29.908 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 52.374 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.HistoryPersisterTest
testTaskCountPurging(com.hubspot.singularity.scheduler.HistoryPersisterTest)  Time elapsed: 30.095 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.BlendedHistoryTest
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 48.435 sec <<< FAILURE! - in com.hubspot.singularity.mesos.SingularityStartupTest
testScheduledTasksDontGetRescheduledDuringRun(com.hubspot.singularity.mesos.SingularityStartupTest)  Time elapsed: 30.054 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.SingularityHealthchecksTest
18:22:30.298 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512066150260, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:30.353 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512066150341, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:30.421 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-2-firstDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512066150392, serverId='bac7a95e-b6e1-4042-990e-fc6fa5fe8702', slaveId=Optional.absent()}
18:22:30.816 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:31.077 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='timeout_test', timestamp=1512062550885, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512062550885}), updatedRequest=Optional.absent()} is overdue (duration: 01:00:00.192), allowed: 00:01:00.000
18:22:31.587 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:31.589 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.891 sec - in com.hubspot.singularity.data.BlendedHistoryTest
Running com.hubspot.singularity.data.InactiveSlaveManagerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512066151806-1-host1-rack1'}), timestamp=Optional.of(1.512066151E9)}), taskId=test-request-retry_test-1512066151806-1-host1-rack1, serverTimestamp=1512066151926, serverId='38e61347-8b96-46b1-afc8-441f2340775b', slaveId=Optional.absent()}
18:22:31.964 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:32.397 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:32.579 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:32.804 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066152786-1-host1-rack1'}), timestamp=Optional.of(1.512066152E9)}), taskId=test-request-firstDeployId-1512066152786-1-host1-rack1, serverTimestamp=1512066152890, serverId='02e97ed4-111c-4a13-98e7-7a31b2c5f361', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153095-2-host1-rack1'}), timestamp=Optional.of(1.512066153E9)}), taskId=test-request-firstDeployId-1512066153095-2-host1-rack1, serverTimestamp=1512066153148, serverId='02e97ed4-111c-4a13-98e7-7a31b2c5f361', slaveId=Optional.absent()}
18:22:33.336 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:33.539 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066153513-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066153513-1-host1-DEFAULT, serverTimestamp=1512066153564, serverId='02e97ed4-111c-4a13-98e7-7a31b2c5f361', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153141-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066153141-1-host1-DEFAULT, serverTimestamp=1512066153519, serverId='3478162b-3fb6-40db-951e-2f94a7b2ea51', slaveId=Optional.absent()}18:22:33.629 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066153438-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066153438-2-host1-DEFAULT, serverTimestamp=1512066153624, serverId='02e97ed4-111c-4a13-98e7-7a31b2c5f361', slaveId=Optional.absent()}
18:22:33.659 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153531-1-host1-rack1'}), timestamp=Optional.of(1.512066153E9)}), taskId=test-request-firstDeployId-1512066153531-1-host1-rack1, serverTimestamp=1512066153714, serverId='7236cd9f-4adf-4db6-a540-f5750163c743', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153847-2-host1-rack1'}), timestamp=Optional.of(1.512066153E9)}), taskId=test-request-firstDeployId-1512066153847-2-host1-rack1, serverTimestamp=1512066153877, serverId='7236cd9f-4adf-4db6-a540-f5750163c743', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153902-3-host1-rack1'}), timestamp=Optional.of(1.512066153E9)}), taskId=test-request-firstDeployId-1512066153902-3-host1-rack1, serverTimestamp=1512066153923, serverId='7236cd9f-4adf-4db6-a540-f5750163c743', slaveId=Optional.absent()}
18:22:33.961 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512066151806-1-IMMEDIATE-1512066151806, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer660'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512066151806-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:33.963 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512066151806-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:33.965 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512066151806-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:33.969 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:22:33.995 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066153847-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066153847-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066153847-2-host1-rack1, serverTimestamp=1512066153984, serverId='7236cd9f-4adf-4db6-a540-f5750163c743', slaveId=Optional.absent()}
18:22:34.519 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066154664-1-host1-rack1'}), timestamp=Optional.of(1.512066154E9)}), taskId=test-request-firstDeployId-1512066154664-1-host1-rack1, serverTimestamp=1512066154758, serverId='3fd23bbc-5f94-4186-a10f-261e197c24ca', slaveId=Optional.absent()}
18:22:35.025 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
18:22:35.096 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066155044-1-host1-rack1'}), timestamp=Optional.of(1.512066155E9)}), taskId=test-request-firstDeployId-1512066155044-1-host1-rack1, serverTimestamp=1512066155087, serverId='3fd23bbc-5f94-4186-a10f-261e197c24ca', slaveId=Optional.absent()}
18:22:35.332 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:35.342 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:35.358 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066154664-1-host1-rack1
18:22:35.380 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066154664-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066154664-1-host1-rack1, serverTimestamp=1512066155345, serverId='3fd23bbc-5f94-4186-a10f-261e197c24ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512066155698, serverId='7a07f822-6a43-4926-b592-4fcfae1ff845', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512066155826, serverId='7a07f822-6a43-4926-b592-4fcfae1ff845', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512066155873, serverId='7a07f822-6a43-4926-b592-4fcfae1ff845', slaveId=Optional.absent()}
18:22:36.110 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066156202-1-host1-rack1'}), timestamp=Optional.of(1.512066156E9)}), taskId=test-request-firstDeployId-1512066156202-1-host1-rack1, serverTimestamp=1512066156280, serverId='29803180-177e-48cd-8096-9ba6d7c587fb', slaveId=Optional.absent()}
18:22:36.563 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066156599-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066156599-1-host2-DEFAULT, serverTimestamp=1512066156658, serverId='29803180-177e-48cd-8096-9ba6d7c587fb', slaveId=Optional.absent()}
18:22:36.939 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:36.957 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:37.048 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:37.105 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066155044-1-IMMEDIATE-1512066155044, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer69'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066155044-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:37.106 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066155044-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:37.112 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066155044-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@28b68844 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@26716322[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.324 sec - in com.hubspot.singularity.data.InactiveSlaveManagerTest
Running com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
18:22:37.429 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:37.439 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157273-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157273-1-host1-rack1, serverTimestamp=1512066157546, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157397-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157397-2-host2-rack1, serverTimestamp=1512066157566, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157682-1-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157682-1-host4-rack2, serverTimestamp=1512066157767, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157734-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157734-3-host3-rack2, serverTimestamp=1512066157781, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157273-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157273-1-host1-rack1, serverTimestamp=1512066157813, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157963-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157963-1-host1-rack1, serverTimestamp=1512066158059, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066158035-3-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066158035-3-host2-rack1, serverTimestamp=1512066158122, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157734-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157734-3-host3-rack2, serverTimestamp=1512066158165, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
18:22:38.216 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066157682-1-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066157682-1-host4-rack2, serverTimestamp=1512066158202, serverId='78a663a9-109e-4aae-bcdb-5fd880c912ba', slaveId=Optional.absent()}
18:22:38.462 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:38.847 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:38.859 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
18:22:38.878 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:38.945 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066158993-1-host1-rack1'}), timestamp=Optional.of(1.512066158E9)}), taskId=test-request-firstDeployId-1512066158993-1-host1-rack1, serverTimestamp=1512066159104, serverId='d98b448e-0d91-4ca5-a187-7a1a00d22d00', slaveId=Optional.absent()}
18:22:39.284 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:39.417 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:39.474 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55007] WARN org.apache.zookeeper.server.NIOServerCnxn - Exception causing close of session 0x1600e2a8bd00000 due to java.nio.channels.AsynchronousCloseException
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066159453-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066159453-1-host2-DEFAULT, serverTimestamp=1512066159562, serverId='d98b448e-0d91-4ca5-a187-7a1a00d22d00', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066159591-1-host1-rack1'}), timestamp=Optional.of(1.512065979E9)}), taskId=test-request-firstDeployId-1512066159591-1-host1-rack1, serverTimestamp=1512066159739, serverId='388522a4-fe5c-4145-b359-a779285d1815', slaveId=Optional.absent()}
18:22:39.860 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066159591-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066159591-1-host1-rack1'}), timestamp=Optional.of(1.512066039E9)}), taskId=test-request-firstDeployId-1512066159591-1-host1-rack1, serverTimestamp=1512066159833, serverId='388522a4-fe5c-4145-b359-a779285d1815', slaveId=Optional.absent()}
18:22:40.095 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:40.120 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:40.206 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066160242-1-host1-rack1'}), timestamp=Optional.of(1.51206616E9)}), taskId=test-request-firstDeployId-1512066160242-1-host1-rack1, serverTimestamp=1512066160310, serverId='25e9dcc8-89bf-44a9-bdf2-71ce8ea77cc4', slaveId=Optional.absent()}
18:22:40.408 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066160242-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066160242-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066160242-1-host1-rack1, serverTimestamp=1512066160399, serverId='25e9dcc8-89bf-44a9-bdf2-71ce8ea77cc4', slaveId=Optional.absent()}
18:22:40.615 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066160505-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066160505-1-host2-DEFAULT, serverTimestamp=1512066160641, serverId='25e9dcc8-89bf-44a9-bdf2-71ce8ea77cc4', slaveId=Optional.absent()}
18:22:40.772 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:41.142 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40523] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2a93950000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:22:41.283 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:41.640 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r1-d1-23-3-BOUNCE-1, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}, but not active
18:22:41.644 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:41.649 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r2-d3-231-1-UNPAUSED-23, cmdLineArgsList=Optional.of([cmd line args]), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}, but not active
18:22:41.690 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:41.704 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r2-de, already correct
18:22:41.706 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r1-d1, already correct
18:22:41.706 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 0 requests in 00:00.015
18:22:42.318 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:42.348 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:42.516 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55319] WARN org.apache.zookeeper.server.NIOServerCnxnFactory - Ignoring unexpected runtime exception
java.nio.channels.CancelledKeyException: null
	at sun.nio.ch.SelectionKeyImpl.ensureValid(SelectionKeyImpl.java:73)
	at sun.nio.ch.SelectionKeyImpl.readyOps(SelectionKeyImpl.java:87)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:187)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066162446-1-host1-rack1'}), timestamp=Optional.of(1.512066162E9)}), taskId=test-request-firstDeployId-1512066162446-1-host1-rack1, serverTimestamp=1512066162563, serverId='f321517a-782b-43e2-b52f-a726fc7fd7bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066162881-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066162881-1-host2-DEFAULT, serverTimestamp=1512066162938, serverId='f321517a-782b-43e2-b52f-a726fc7fd7bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066162446-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066162446-1-host1-rack1, serverTimestamp=1512066163053, serverId='f321517a-782b-43e2-b52f-a726fc7fd7bb', slaveId=Optional.absent()}
[oneOffRequest-oneOffDeploy1512066163201, immediateRequest-immediateDeploy, newDeployRequest-newDeploy]
18:22:43.233 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:43.235 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path oneOffRequest-oneOffDeploy1512066163201, already correct
18:22:43.237 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Rewriting path immediateRequest-immediateDeploy to immediateRequest-immediateDeploy1512066163201
18:22:43.241 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path newDeployRequest-newDeploy, already correct
18:22:43.242 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 1 requests in 00:00.008
[oneOffRequest-oneOffDeploy1512066163201, immediateRequest-immediateDeploy1512066163201, newDeployRequest-newDeploy]
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.265 sec - in com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
Running com.hubspot.singularity.data.SandboxManagerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066163349-1-host2-DEFAULT'}), timestamp=Optional.of(1.512066163E9)}), taskId=test-request-firstDeployId-1512066163349-1-host2-DEFAULT, serverTimestamp=1512066163447, serverId='3de973af-7374-4fb2-85a8-fde7c6adf2fb', slaveId=Optional.absent()}
18:22:43.542 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:43.757 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:44.098 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d3-1512066164131-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d3-1512066164131-1-host1-DEFAULT, serverTimestamp=1512066164233, serverId='6e2a9a88-ffda-41cb-b6f3-37d3007393b3', slaveId=Optional.absent()}
18:22:44.478 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:44.491 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44253] WARN org.apache.zookeeper.server.NIOServerCnxn - Exception causing close of session 0x1600e2a9a150000 due to java.nio.channels.ClosedChannelException
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d4-1512066164493-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d4-1512066164493-1-host1-DEFAULT, serverTimestamp=1512066164541, serverId='6e2a9a88-ffda-41cb-b6f3-37d3007393b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066158993-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066158993-1-host1-rack1, serverTimestamp=1512066164602, serverId='d98b448e-0d91-4ca5-a187-7a1a00d22d00', slaveId=Optional.absent()}
18:22:44.963 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:45.383 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:45.533 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066165487-1-host1-rack1'}), timestamp=Optional.of(1.512066165E9)}), taskId=test-request-firstDeployId-1512066165487-1-host1-rack1, serverTimestamp=1512066165549, serverId='64504c0b-4acf-48ed-bc41-a69bc78cad3c', slaveId=Optional.absent()}
18:22:45.721 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066165487-1-host1-rack1
18:22:45.724 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066165487-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066165487-1-host1-rack1, serverTimestamp=1512066165712, serverId='64504c0b-4acf-48ed-bc41-a69bc78cad3c', slaveId=Optional.absent()}
18:22:46.133 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Max healthcheck time cannot be greater than 100, (was startup timeout: 50, interval: 5, attempts: 10)
18:22:46.206 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:46.367 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:46.671 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:46.709 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066166549-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066166549-1-host1-rack1'}), timestamp=Optional.of(1.512066166E9)}), taskId=test-request-firstDeployId-1512066166549-1-host1-rack1, serverTimestamp=1512066166647, serverId='0ac426ab-5e87-48e6-b4bd-cd833d7763e1', slaveId=Optional.absent()}
18:22:46.876 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066166753-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066166785-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066166785-2-host1-DEFAULT, serverTimestamp=1512066166869, serverId='915d2a25-c6c5-4fc0-a5ce-8ce3645a7a41', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066166753-1-host1-rack1'}), timestamp=Optional.of(1.512066166E9)}), taskId=test-request-firstDeployId-1512066166753-1-host1-rack1, serverTimestamp=1512066166846, serverId='0ac426ab-5e87-48e6-b4bd-cd833d7763e1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066166734-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066166734-2-host2-DEFAULT, serverTimestamp=1512066166876, serverId='96ea76d7-39e0-4878-a684-a215eee90fdc', slaveId=Optional.absent()}
18:22:46.982 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:47.035 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57749] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2aa7450000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 12, Failures: 1, Errors: 1, Skipped: 0, Time elapsed: 68.529 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
testReservedSlaveWithMatchinRequestAttribute(com.hubspot.singularity.scheduler.SingularitySlavePlacementTest)  Time elapsed: 30.086 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

testEvenRackPlacement(com.hubspot.singularity.scheduler.SingularitySlavePlacementTest)  Time elapsed: 9.728 sec  <<< FAILURE!
java.lang.AssertionError: expected:<4> but was:<7>
	at com.hubspot.singularity.scheduler.SingularitySlavePlacementTest.testEvenRackPlacement(SingularitySlavePlacementTest.java:272)

Running com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
18:22:47.352 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066167460-1-host1-rack1'}), timestamp=Optional.of(1.512066167E9)}), taskId=test-request-firstDeployId-1512066167460-1-host1-rack1, serverTimestamp=1512066167523, serverId='fb94a726-2889-4d50-a847-84c7c92dc056', slaveId=Optional.absent()}
18:22:47.651 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:22:47.693 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066167460-1-host1-rack1
18:22:47.699 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066167460-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066167460-1-host1-rack1, serverTimestamp=1512066167684, serverId='fb94a726-2889-4d50-a847-84c7c92dc056', slaveId=Optional.absent()}
18:22:47.757 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:47.804 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:48.028 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:48.267 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066168365-1-host1-rack1'}), timestamp=Optional.of(1.512066168E9)}), taskId=test-request-firstDeployId-1512066168365-1-host1-rack1, serverTimestamp=1512066168430, serverId='9f8171f7-8823-4a7e-a918-9aeaac3ad3ea', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066168495-2-host1-rack1'}), timestamp=Optional.of(1.512066168E9)}), taskId=test-request-firstDeployId-1512066168495-2-host1-rack1, serverTimestamp=1512066168528, serverId='9f8171f7-8823-4a7e-a918-9aeaac3ad3ea', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066168685-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066168685-1-host2-DEFAULT, serverTimestamp=1512066168723, serverId='9f8171f7-8823-4a7e-a918-9aeaac3ad3ea', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066168365-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066168365-1-host1-rack1, serverTimestamp=1512066168800, serverId='9f8171f7-8823-4a7e-a918-9aeaac3ad3ea', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066168866-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066168866-2-host2-DEFAULT, serverTimestamp=1512066168920, serverId='9f8171f7-8823-4a7e-a918-9aeaac3ad3ea', slaveId=Optional.absent()}
18:22:49.100 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:49.128 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066166785-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:49.129 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066166785-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@175d5ca5 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@199aa03e[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:49.293 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:49.312 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
18:22:49.516 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:49.668 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 16, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 71.127 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityMachineStatesTest
testFrozenSlaveCanBeDecommissioned(com.hubspot.singularity.scheduler.SingularityMachineStatesTest)  Time elapsed: 30.115 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.SingularityAuthorizationHelperTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512066169866, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512066169998, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512066170050, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.099 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512066170160, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512066170207, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512066170280, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512066170360, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.397 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1-1-host1-rack1
18:22:50.402 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:50.406 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066170269-1-host1-rack1'}), timestamp=Optional.of(1.51206617E9)}), taskId=test-request-firstDeployId-1512066170269-1-host1-rack1, serverTimestamp=1512066170345, serverId='87f5078a-5651-4ffb-95d0-8097113de2c3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(20.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512066170387, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.466 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-2-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(21.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512066170455, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.530 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-6-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066170502-1-host1-rack1'}), timestamp=Optional.of(1.51206617E9)}), taskId=test-request-secondDeployId-1512066170502-1-host1-rack1, serverTimestamp=1512066170525, serverId='87f5078a-5651-4ffb-95d0-8097113de2c3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(22.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512066170516, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.594 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-4-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(23.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512066170578, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.621 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-3-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(24.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512066170609, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.667 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-5-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(25.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512066170658, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
18:22:50.691 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-7-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(26.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512066170682, serverId='9aa2f874-1dfd-4c0f-94df-d205d30f115c', slaveId=Optional.absent()}
Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.996 sec - in com.hubspot.singularity.SingularityAuthorizationHelperTest
Running com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
18:22:50.882 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:50.903 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.348 sec - in com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
Running com.hubspot.singularity.config.MergingSourceProviderTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171052-1-host1-rack1'}), timestamp=Optional.of(1.512066171E9)}), taskId=test-request-firstDeployId-1512066171052-1-host1-rack1, serverTimestamp=1512066171151, serverId='a3d25695-621a-431a-80f2-64dab776df5c', slaveId=Optional.absent()}
18:22:51.305 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171391-1-host1-rack1'}), timestamp=Optional.of(1.512066171E9)}), taskId=test-request-firstDeployId-1512066171391-1-host1-rack1, serverTimestamp=1512066171444, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171489-2-host1-rack1'}), timestamp=Optional.of(1.512066171E9)}), taskId=test-request-firstDeployId-1512066171489-2-host1-rack1, serverTimestamp=1512066171515, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171524-3-host1-rack1'}), timestamp=Optional.of(1.512066171E9)}), taskId=test-request-firstDeployId-1512066171524-3-host1-rack1, serverTimestamp=1512066171551, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
18:22:51.714 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066171757-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066171757-1-host2-DEFAULT, serverTimestamp=1512066171807, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171391-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066171391-1-host1-rack1, serverTimestamp=1512066171833, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
18:22:51.907 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066166579-2-UPDATED_REQUEST-1512066166490, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer935'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066166785-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066166785-2-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:51.909 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066166579-2-UPDATED_REQUEST-1512066166490, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer935'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066166785-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066166785-2-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@38154cc1 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@464dd9ee[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066171943-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066171943-2-host1-DEFAULT, serverTimestamp=1512066172034, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
18:22:52.093 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:52.159 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171489-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066171489-2-host1-rack1, serverTimestamp=1512066172109, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066172244-3-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066172244-3-host1-DEFAULT, serverTimestamp=1512066172283, serverId='1177bd26-0aca-4e4d-9015-e488d24bed33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512066172408, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512066172529, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512066172594, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1512066172688, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1512066172737, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1512066172792, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1512066172843, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:52.864 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(80.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512066172855, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:52.912 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
18:22:52.926 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(90.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512066172885, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:52.957 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-60000-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(100.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1512066172948, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:53.001 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-40000-4-host4-rack1
18:22:53.007 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(110.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1512066172976, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:53.184 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(120.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512066173173, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:53.233 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-50000-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(130.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1512066173214, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
18:22:53.244 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066171052-1-IMMEDIATE-1512066171052, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer862'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066171052-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:53.269 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(140.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1512066173256, serverId='91ee0856-3c37-4c4c-afc1-a50326a56c3f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066174141-1-host1-rack1'}), timestamp=Optional.of(1.512066175E9)}), taskId=test-request-firstDeployId-1512066174141-1-host1-rack1, serverTimestamp=1512066173265, serverId='16538142-77d7-4b8b-bb87-07749afbc4dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066177141-2-host1-rack1'}), timestamp=Optional.of(1.512066178E9)}), taskId=test-request-firstDeployId-1512066177141-2-host1-rack1, serverTimestamp=1512066173437, serverId='16538142-77d7-4b8b-bb87-07749afbc4dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066177141-3-host1-rack1'}), timestamp=Optional.of(1.512066178E9)}), taskId=test-request-firstDeployId-1512066177141-3-host1-rack1, serverTimestamp=1512066173536, serverId='16538142-77d7-4b8b-bb87-07749afbc4dd', slaveId=Optional.absent()}
Tests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 73.951 sec <<< FAILURE! - in com.hubspot.singularity.SingularityHistoryTest
historyPurgerTest(com.hubspot.singularity.SingularityHistoryTest)  Time elapsed: 30.076 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.SingularityUsageTest
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.155 sec - in com.hubspot.singularity.data.SandboxManagerTest
Running com.hubspot.singularity.helpers.RFC5545ScheduleTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.234 sec - in com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.JavaUtilsTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.225 sec - in com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
18:22:54.170 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:54.183 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
18:22:54.345 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066171052-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066171052-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066171052-1-host1-rack1, serverTimestamp=1512066174336, serverId='a3d25695-621a-431a-80f2-64dab776df5c', slaveId=Optional.absent()}
18:22:54.378 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42940] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2ab9790000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:22:54.585 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066174667-1-host1-rack1'}), timestamp=Optional.of(1.512066174E9)}), taskId=test-request-firstDeployId-1512066174667-1-host1-rack1, serverTimestamp=1512066174738, serverId='40fced57-4a99-40db-9418-33dbc23b382d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066174809-2-host1-rack1'}), timestamp=Optional.of(1.512066174E9)}), taskId=test-request-firstDeployId-1512066174809-2-host1-rack1, serverTimestamp=1512066174870, serverId='40fced57-4a99-40db-9418-33dbc23b382d', slaveId=Optional.absent()}
18:22:54.899 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:54.963 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066175038-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066175038-1-host1-DEFAULT, serverTimestamp=1512066175083, serverId='40fced57-4a99-40db-9418-33dbc23b382d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066174667-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066174667-1-host1-rack1, serverTimestamp=1512066175199, serverId='40fced57-4a99-40db-9418-33dbc23b382d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066175275-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066175275-2-host1-DEFAULT, serverTimestamp=1512066175322, serverId='40fced57-4a99-40db-9418-33dbc23b382d', slaveId=Optional.absent()}
18:22:55.364 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066174141-1-IMMEDIATE-1512066174141, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer920'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066174141-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:55.367 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066174141-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.372 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066174141-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2c1c3921 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@77033f52[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.438 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:55.442 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066177141-2-IMMEDIATE-1512066177141, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer542'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066177141-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:55.444 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066177141-2-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.446 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066177141-2-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2d7a2fc2 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@77033f52[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.542 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066177141-3-IMMEDIATE-1512066177141, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer827'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066177141-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:22:55.543 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066177141-3-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.545 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066177141-3-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@48066826 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@77033f52[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.556 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
18:22:55.590 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.581 sec - in com.hubspot.singularity.data.ValidatorTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.559 sec - in com.hubspot.singularity.config.MergingSourceProviderTest
18:22:55.876 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066174809-2-IMMEDIATE-1512066174809, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer487'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066174809-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.880 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066174809-2-IMMEDIATE-1512066174809, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer487'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066174809-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7180c736 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@37ee636b[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:55.928 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066175679-1-host1-rack1'}), timestamp=Optional.of(1.512066175E9)}), taskId=test-request-firstDeployId-1512066175679-1-host1-rack1, serverTimestamp=1512066175831, serverId='af51e608-088a-4f40-a151-4a26ad2c4094', slaveId=Optional.absent()}
18:22:56.160 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066175679-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066175679-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066175679-1-host1-rack1, serverTimestamp=1512066176146, serverId='af51e608-088a-4f40-a151-4a26ad2c4094', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066176198-1-host1-rack1'}), timestamp=Optional.of(1.512066176E9)}), taskId=test-request-firstDeployId-1512066176198-1-host1-rack1, serverTimestamp=1512066176218, serverId='af51e608-088a-4f40-a151-4a26ad2c4094', slaveId=Optional.absent()}
18:22:56.261 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066176198-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066176198-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066176198-1-host1-rack1, serverTimestamp=1512066176238, serverId='af51e608-088a-4f40-a151-4a26ad2c4094', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066176318-1-host1-rack1'}), timestamp=Optional.of(1.512066176E9)}), taskId=test-request-firstDeployId-1512066176318-1-host1-rack1, serverTimestamp=1512066176365, serverId='af51e608-088a-4f40-a151-4a26ad2c4094', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066176292-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066176292-1-host1-DEFAULT, serverTimestamp=1512066176368, serverId='d3504bb9-b4e9-4bd6-b75e-2b6f82b1b666', slaveId=Optional.absent()}
18:22:56.975 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:57.242 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066177115-1-host1-rack1'}), timestamp=Optional.of(1.512066177E9)}), taskId=test-request-firstDeployId-1512066177115-1-host1-rack1, serverTimestamp=1512066177188, serverId='721f1fb7-633c-4f76-a087-05c674d17e75', slaveId=Optional.absent()}
18:22:57.269 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.236 sec - in com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066177115-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066177115-1-host1-rack1, serverTimestamp=1512066177606, serverId='721f1fb7-633c-4f76-a087-05c674d17e75', slaveId=Optional.absent()}
18:22:58.420 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066176292-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:58.423 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066176292-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@663b6105 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1f0bf771[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:22:58.583 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066178666-1-host1-rack1'}), timestamp=Optional.of(1.512066178E9)}), taskId=test-request-firstDeployId-1512066178666-1-host1-rack1, serverTimestamp=1512066178786, serverId='f34089d1-fbbc-47be-8769-022db2a81262', slaveId=Optional.absent()}
18:22:58.896 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:22:59.010 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066178666-1-host1-rack1
18:22:59.014 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066178666-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066178666-1-host1-rack1, serverTimestamp=1512066178995, serverId='f34089d1-fbbc-47be-8769-022db2a81262', slaveId=Optional.absent()}
18:22:59.215 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066179257-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066179257-1-host1-DEFAULT, serverTimestamp=1512066179351, serverId='cf7a1827-b95b-4b75-b759-18c17b7091d5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066179257-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066179257-1-host1-DEFAULT, serverTimestamp=1512066179376, serverId='cf7a1827-b95b-4b75-b759-18c17b7091d5', slaveId=Optional.absent()}
18:22:59.704 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512066179781-1-host1-rack1'}), timestamp=Optional.of(1.512066179E9)}), taskId=test-request-new_task_healthcheck-1512066179781-1-host1-rack1, serverTimestamp=1512066179841, serverId='d4d20cd2-4b67-4e51-b86f-39e6945363a0', slaveId=Optional.absent()}
18:23:00.009 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:00.585 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:00.650 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:00.903 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066180796-1-host1-rack1'}), timestamp=Optional.of(1.51206618E9)}), taskId=test-request-secondDeployId-1512066180796-1-host1-rack1, serverTimestamp=1512066180858, serverId='8e75f4be-abb2-44fe-a9d6-63fed40183b5', slaveId=Optional.absent()}
18:23:01.410 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:01.410 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066176195-1-UPDATED_REQUEST-1512066176160, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer295'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066176292-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), allOtherFields={ranges={range=[{begin=80, end=82}]}, type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066176292-1-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=PORT, value=80}, {name=PORT0, value=80}, {name=PORT1, value=81}, {name=PORT2, value=82}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:01.420 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066176195-1-UPDATED_REQUEST-1512066176160, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer295'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066176292-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), allOtherFields={ranges={range=[{begin=80, end=82}]}, type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066176292-1-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=PORT, value=80}, {name=PORT0, value=80}, {name=PORT1, value=81}, {name=PORT2, value=82}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@33f32cb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@700a674[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066181607-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066181607-1-host2-DEFAULT, serverTimestamp=1512066181646, serverId='9279db5e-24e9-4c46-a1b3-c721f84c444e', slaveId=Optional.absent()}
18:23:01.885 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='new_task_healthcheck', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.absent(), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-new_task_healthcheck-1512066179781-1-IMMEDIATE-1512066179781, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer25'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512066179781-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:23:01.885 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-new_task_healthcheck-1512066179781-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:01.887 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-new_task_healthcheck-1512066179781-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:02.174 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:02.341 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-deploy_test-1512066182301-1-host1-rack1'}), timestamp=Optional.of(1.512066182E9)}), taskId=test-request-deploy_test-1512066182301-1-host1-rack1, serverTimestamp=1512066182389, serverId='03405c6f-5fbb-4461-a686-260befb0752b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066182465-1-host1-rack1'}), timestamp=Optional.of(1.512066182E9)}), taskId=test-request-firstDeployId-1512066182465-1-host1-rack1, serverTimestamp=1512066182546, serverId='28ffb18d-1ed1-45bf-95d1-afc62fd48fb6', slaveId=Optional.absent()}
18:23:02.658 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066182804-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066182804-1-host1-DEFAULT, serverTimestamp=1512066182845, serverId='28ffb18d-1ed1-45bf-95d1-afc62fd48fb6', slaveId=Optional.absent()}
18:23:02.896 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066182465-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066182465-1-host1-rack1, serverTimestamp=1512066182889, serverId='28ffb18d-1ed1-45bf-95d1-afc62fd48fb6', slaveId=Optional.absent()}
18:23:03.085 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183025-1-host1-rack1'}), timestamp=Optional.of(1.512066183E9)}), taskId=test-request-firstDeployId-1512066183025-1-host1-rack1, serverTimestamp=1512066183101, serverId='d6e46140-206e-4d09-8645-e58ba213597d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183142-2-host1-rack1'}), timestamp=Optional.of(1.512066183E9)}), taskId=test-request-firstDeployId-1512066183142-2-host1-rack1, serverTimestamp=1512066183171, serverId='d6e46140-206e-4d09-8645-e58ba213597d', slaveId=Optional.absent()}
18:23:03.272 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:23:03.285 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:23:03.302 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066183025-1-host1-rack1
18:23:03.305 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183025-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066183025-1-host1-rack1, serverTimestamp=1512066183295, serverId='d6e46140-206e-4d09-8645-e58ba213597d', slaveId=Optional.absent()}
18:23:03.341 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066183142-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-hc_test-1512066183253-1-host1-rack1'}), timestamp=Optional.of(1.512066183E9)}), taskId=test-request-hc_test-1512066183253-1-host1-rack1, serverTimestamp=1512066183321, serverId='b8c7bdf0-d864-4def-8791-6f7c1f5a077d', slaveId=Optional.absent()}
18:23:03.358 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183142-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066183142-2-host1-rack1, serverTimestamp=1512066183319, serverId='d6e46140-206e-4d09-8645-e58ba213597d', slaveId=Optional.absent()}
18:23:03.456 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:35440] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2aeb0f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:03.468 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47447] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2aea550000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:03.641 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183719-1-host1-rack1'}), timestamp=Optional.of(1.512066183E9)}), taskId=test-request-firstDeployId-1512066183719-1-host1-rack1, serverTimestamp=1512066183768, serverId='ab0456bc-463e-48f3-b464-ee62ae030b04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183812-2-host1-rack1'}), timestamp=Optional.of(1.512066183E9)}), taskId=test-request-firstDeployId-1512066183812-2-host1-rack1, serverTimestamp=1512066183839, serverId='ab0456bc-463e-48f3-b464-ee62ae030b04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066183977-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066183977-1-host2-DEFAULT, serverTimestamp=1512066184015, serverId='ab0456bc-463e-48f3-b464-ee62ae030b04', slaveId=Optional.absent()}
18:23:04.032 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066183719-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066183719-1-host1-rack1, serverTimestamp=1512066184061, serverId='ab0456bc-463e-48f3-b464-ee62ae030b04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066184134-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066184134-2-host1-DEFAULT, serverTimestamp=1512066184183, serverId='ab0456bc-463e-48f3-b464-ee62ae030b04', slaveId=Optional.absent()}
18:23:04.278 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57851] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2aed5c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:04.653 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:05.126 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:05.337 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='hc_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-hc_test-1512066183253-1-IMMEDIATE-1512066183253, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer888'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-hc_test-1512066183253-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:23:05.337 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-hc_test-1512066183253-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:05.340 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-hc_test-1512066183253-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:05.621 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:05.693 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066185893-1-host1-rack1'}), timestamp=Optional.of(1.512066185E9)}), taskId=test-request-firstDeployId-1512066185893-1-host1-rack1, serverTimestamp=1512066185938, serverId='7ec896f3-aeaf-4742-9ab3-29ffde134e64', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-timeout_test-1512062585740-1-host1-rack1'}), timestamp=Optional.of(1.512062585E9)}), taskId=test-request-timeout_test-1512062585740-1-host1-rack1, serverTimestamp=1512066185958, serverId='cb3ff03c-fb6e-4292-9467-b7cc1f6aed0f', slaveId=Optional.absent()}
18:23:06.286 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066186379-1-host1-rack1'}), timestamp=Optional.of(1.512066186E9)}), taskId=test-request-firstDeployId-1512066186379-1-host1-rack1, serverTimestamp=1512066186441, serverId='e7fe95d4-b0d9-4baa-b733-50f67ba907ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066186487-2-host1-rack1'}), timestamp=Optional.of(1.512066186E9)}), taskId=test-request-firstDeployId-1512066186487-2-host1-rack1, serverTimestamp=1512066186515, serverId='e7fe95d4-b0d9-4baa-b733-50f67ba907ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066186526-3-host1-rack1'}), timestamp=Optional.of(1.512066186E9)}), taskId=test-request-firstDeployId-1512066186526-3-host1-rack1, serverTimestamp=1512066186556, serverId='e7fe95d4-b0d9-4baa-b733-50f67ba907ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066186657-5-host1-rack1'}), timestamp=Optional.of(1.512066186E9)}), taskId=test-request-firstDeployId-1512066186657-5-host1-rack1, serverTimestamp=1512066186689, serverId='e7fe95d4-b0d9-4baa-b733-50f67ba907ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066186657-5-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066186657-5-host1-rack1, serverTimestamp=1512066186703, serverId='e7fe95d4-b0d9-4baa-b733-50f67ba907ca', slaveId=Optional.absent()}
18:23:06.751 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44002] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2af7ac0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:07.236 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:07.522 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066187469-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066187469-2-host1-DEFAULT, serverTimestamp=1512066187623, serverId='0b40b6c4-b10d-441d-b249-3c4348040abf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066187624-1-host1-rack1'}), timestamp=Optional.of(1.512066187E9)}), taskId=test-request-firstDeployId-1512066187624-1-host1-rack1, serverTimestamp=1512066187688, serverId='45ee8c27-3ac5-494b-a759-d119589e32dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066187778-1-host1-rack1'}), timestamp=Optional.of(1.512066187E9)}), taskId=test-request-secondDeployId-1512066187778-1-host1-rack1, serverTimestamp=1512066187810, serverId='45ee8c27-3ac5-494b-a759-d119589e32dd', slaveId=Optional.absent()}
18:23:07.864 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-secondDeployId-1512066187778-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066187778-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066187778-1-host1-rack1, serverTimestamp=1512066187857, serverId='45ee8c27-3ac5-494b-a759-d119589e32dd', slaveId=Optional.absent()}
18:23:07.891 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066187624-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066187624-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066187624-1-host1-rack1, serverTimestamp=1512066187885, serverId='45ee8c27-3ac5-494b-a759-d119589e32dd', slaveId=Optional.absent()}
18:23:07.975 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='timeout_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.of(86400000), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-timeout_test-1512062585740-1-IMMEDIATE-1512062585740, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer646'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-timeout_test-1512062585740-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:23:07.976 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-timeout_test-1512062585740-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:07.981 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-timeout_test-1512062585740-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:08.282 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066188406-1-host1-rack1'}), timestamp=Optional.of(1.512066188E9)}), taskId=test-request-firstDeployId-1512066188406-1-host1-rack1, serverTimestamp=1512066188475, serverId='053d4823-e88b-4bcf-9437-87d3d0684100', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066188534-2-host1-rack1'}), timestamp=Optional.of(1.512066188E9)}), taskId=test-request-firstDeployId-1512066188534-2-host1-rack1, serverTimestamp=1512066188564, serverId='053d4823-e88b-4bcf-9437-87d3d0684100', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066188575-3-host1-rack1'}), timestamp=Optional.of(1.512066188E9)}), taskId=test-request-firstDeployId-1512066188575-3-host1-rack1, serverTimestamp=1512066188608, serverId='053d4823-e88b-4bcf-9437-87d3d0684100', slaveId=Optional.absent()}
18:23:08.967 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:09.012 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066188830-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066188830-3-host2-DEFAULT, serverTimestamp=1512066189036, serverId='053d4823-e88b-4bcf-9437-87d3d0684100', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066188534-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066188534-2-host1-rack1, serverTimestamp=1512066189077, serverId='053d4823-e88b-4bcf-9437-87d3d0684100', slaveId=Optional.absent()}
18:23:09.201 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='firstDeployId', timestamp=1512066189033, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512066189033}), updatedRequest=Optional.absent()} request was MISSING, removing deploy
18:23:09.298 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:09.378 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.878 sec - in com.hubspot.singularity.scheduler.SingularityUsageTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066189418-1-host1-rack1'}), timestamp=Optional.of(1.512066189E9)}), taskId=test-request-firstDeployId-1512066189418-1-host1-rack1, serverTimestamp=1512066189510, serverId='e8574cea-d01e-464a-a306-4388a61bd63c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066189558-2-host1-rack1'}), timestamp=Optional.of(1.512066189E9)}), taskId=test-request-firstDeployId-1512066189558-2-host1-rack1, serverTimestamp=1512066189597, serverId='e8574cea-d01e-464a-a306-4388a61bd63c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512066189560-1-host1-rack1'}), timestamp=Optional.of(1.512066189E9)}), taskId=test-request-retry_test-1512066189560-1-host1-rack1, serverTimestamp=1512066189675, serverId='87628455-f0a3-4f0c-8b3b-85d197921b9a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066189822-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066189822-2-host1-DEFAULT, serverTimestamp=1512066189891, serverId='e8574cea-d01e-464a-a306-4388a61bd63c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066189864-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066189864-1-host1-DEFAULT, serverTimestamp=1512066189914, serverId='e8574cea-d01e-464a-a306-4388a61bd63c', slaveId=Optional.absent()}
18:23:10.417 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066190492-1-host1-rack1'}), timestamp=Optional.of(1.51206619E9)}), taskId=test-request-firstDeployId-1512066190492-1-host1-rack1, serverTimestamp=1512066190544, serverId='0d4038f5-3fb7-4594-8361-b882db0dd3cf', slaveId=Optional.absent()}
18:23:10.649 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066190492-1-host1-rack1
18:23:10.652 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066190492-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066190492-1-host1-rack1, serverTimestamp=1512066190628, serverId='0d4038f5-3fb7-4594-8361-b882db0dd3cf', slaveId=Optional.absent()}
18:23:11.313 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066191401-1-host1-rack1'}), timestamp=Optional.of(1.512066191E9)}), taskId=test-request-firstDeployId-1512066191401-1-host1-rack1, serverTimestamp=1512066191465, serverId='7a7617c3-c03c-4593-9907-738c65560b6c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066191509-2-host1-rack1'}), timestamp=Optional.of(1.512066191E9)}), taskId=test-request-firstDeployId-1512066191509-2-host1-rack1, serverTimestamp=1512066191539, serverId='7a7617c3-c03c-4593-9907-738c65560b6c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066191549-3-host1-rack1'}), timestamp=Optional.of(1.512066191E9)}), taskId=test-request-firstDeployId-1512066191549-3-host1-rack1, serverTimestamp=1512066191579, serverId='7a7617c3-c03c-4593-9907-738c65560b6c', slaveId=Optional.absent()}
18:23:11.701 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(3), failureStatusCodes=Optional.of([404])}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512066189560-1-IMMEDIATE-1512066189560, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer112'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512066189560-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:23:11.702 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512066189560-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:11.705 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512066189560-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066191690-4-host1-rack1'}), timestamp=Optional.of(1.512066191E9)}), taskId=test-request-firstDeployId-1512066191690-4-host1-rack1, serverTimestamp=1512066191729, serverId='7a7617c3-c03c-4593-9907-738c65560b6c', slaveId=Optional.absent()}
18:23:11.856 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066191509-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066191509-2-host1-rack1, serverTimestamp=1512066191886, serverId='7a7617c3-c03c-4593-9907-738c65560b6c', slaveId=Optional.absent()}
18:23:12.151 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:12.321 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512066192332-1-host1-rack1'}), timestamp=Optional.of(1.512066192E9)}), taskId=test-request-retry_test-1512066192332-1-host1-rack1, serverTimestamp=1512066192407, serverId='4426bd9f-ba26-48fa-b5ca-a1a7fdd4e3a0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192429-1-host1-rack1'}), timestamp=Optional.of(1.512066192E9)}), taskId=test-request-firstDeployId-1512066192429-1-host1-rack1, serverTimestamp=1512066192494, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192542-2-host1-rack1'}), timestamp=Optional.of(1.512066192E9)}), taskId=test-request-firstDeployId-1512066192542-2-host1-rack1, serverTimestamp=1512066192575, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192587-3-host1-rack1'}), timestamp=Optional.of(1.512066192E9)}), taskId=test-request-firstDeployId-1512066192587-3-host1-rack1, serverTimestamp=1512066192619, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192631-4-host1-rack1'}), timestamp=Optional.of(1.512066192E9)}), taskId=test-request-firstDeployId-1512066192631-4-host1-rack1, serverTimestamp=1512066192659, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066192809-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066192809-1-host2-DEFAULT, serverTimestamp=1512066192876, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066192843-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066192843-2-host2-DEFAULT, serverTimestamp=1512066192901, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 18.874 sec - in com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192429-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066192429-1-host1-rack1, serverTimestamp=1512066192965, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066192542-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066192542-2-host1-rack1, serverTimestamp=1512066193011, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066193079-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066193079-3-host2-DEFAULT, serverTimestamp=1512066193152, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066193110-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066193110-4-host2-DEFAULT, serverTimestamp=1512066193164, serverId='e9a640c9-6a2f-4466-8bf7-13ce2d952acb', slaveId=Optional.absent()}
18:23:13.481 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066193727-1-host1-rack1'}), timestamp=Optional.of(1.512066193E9)}), taskId=test-request-firstDeployId-1512066193727-1-host1-rack1, serverTimestamp=1512066193790, serverId='352a859d-4acf-496f-be5c-00f075b4c836', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066193840-2-host1-rack1'}), timestamp=Optional.of(1.512066193E9)}), taskId=test-request-firstDeployId-1512066193840-2-host1-rack1, serverTimestamp=1512066193872, serverId='352a859d-4acf-496f-be5c-00f075b4c836', slaveId=Optional.absent()}
18:23:14.427 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512066192332-1-IMMEDIATE-1512066192332, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer506'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512066192332-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:23:14.427 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512066192332-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:14.429 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512066192332-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:23:14.783 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-startup_timeout_test-1512062594816-1-host1-rack1'}), timestamp=Optional.of(1.512062594E9)}), taskId=test-request-startup_timeout_test-1512062594816-1-host1-rack1, serverTimestamp=1512066194958, serverId='757a52ce-1723-4eb9-a882-548807e8cfd3', slaveId=Optional.absent()}
18:23:15.483 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:15.645 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='secondDeployId', timestamp=1512066195565, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=0, stepComplete=false, autoAdvanceDeploySteps=false, failedDeployTasks=[], timestamp=1512066195565}), updatedRequest=Optional.absent()} request was PAUSED, removing deploy
18:23:15.677 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41113] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b1b970000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 46.056 sec - in com.hubspot.singularity.scheduler.SingularityHealthchecksTest
18:23:16.388 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:16.873 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066196970-1-host1-rack1'}), timestamp=Optional.of(1.512066196E9)}), taskId=test-request-firstDeployId-1512066196970-1-host1-rack1, serverTimestamp=1512066197025, serverId='9a04477e-c56f-4052-87f6-0fbb07bb19de', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197066-2-host1-rack1'}), timestamp=Optional.of(1.512066197E9)}), taskId=test-request-firstDeployId-1512066197066-2-host1-rack1, serverTimestamp=1512066197096, serverId='9a04477e-c56f-4052-87f6-0fbb07bb19de', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066197248-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066197248-1-host2-DEFAULT, serverTimestamp=1512066197289, serverId='9a04477e-c56f-4052-87f6-0fbb07bb19de', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066196970-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066196970-1-host1-rack1, serverTimestamp=1512066197355, serverId='9a04477e-c56f-4052-87f6-0fbb07bb19de', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197459-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066197459-1-host2-DEFAULT, serverTimestamp=1512066197498, serverId='9a04477e-c56f-4052-87f6-0fbb07bb19de', slaveId=Optional.absent()}
18:23:17.757 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197845-1-host1-rack1'}), timestamp=Optional.of(1.512066197E9)}), taskId=test-request-firstDeployId-1512066197845-1-host1-rack1, serverTimestamp=1512066197894, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197942-1-host1-rack1'}), timestamp=Optional.of(1.512066197E9)}), taskId=test-request-firstDeployId-1512066197942-1-host1-rack1, serverTimestamp=1512066197964, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
18:23:18.012 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066197845-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197845-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066197845-1-host1-rack1, serverTimestamp=1512066198006, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
18:23:18.033 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066197942-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066197942-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066197942-1-host1-rack1, serverTimestamp=1512066198026, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066198074-1-host1-rack1'}), timestamp=Optional.of(1.512066198E9)}), taskId=test-request-firstDeployId-1512066198074-1-host1-rack1, serverTimestamp=1512066198094, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
18:23:18.126 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066198074-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066198074-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066198074-1-host1-rack1, serverTimestamp=1512066198120, serverId='9be71126-91f2-446c-8199-fe43d7655e7c', slaveId=Optional.absent()}
18:23:19.337 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:19.694 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066199771-1-host1-rack1'}), timestamp=Optional.of(1.512066199E9)}), taskId=test-request-firstDeployId-1512066199771-1-host1-rack1, serverTimestamp=1512066199821, serverId='0191c351-ddb3-4ff1-a02b-563bf188d289', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066199858-2-host1-rack1'}), timestamp=Optional.of(1.512066199E9)}), taskId=test-request-firstDeployId-1512066199858-2-host1-rack1, serverTimestamp=1512066199887, serverId='0191c351-ddb3-4ff1-a02b-563bf188d289', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066200017-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512066200017-1-host1-DEFAULT, serverTimestamp=1512066200051, serverId='0191c351-ddb3-4ff1-a02b-563bf188d289', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066199771-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066199771-1-host1-rack1, serverTimestamp=1512066200098, serverId='0191c351-ddb3-4ff1-a02b-563bf188d289', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066200213-1-host1-rack1'}), timestamp=Optional.of(1.5120662E9)}), taskId=test-request-firstDeployId-1512066200213-1-host1-rack1, serverTimestamp=1512066200235, serverId='0191c351-ddb3-4ff1-a02b-563bf188d289', slaveId=Optional.absent()}
18:23:20.632 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 25, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 101.654 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityDeploysTest
testUsesNewRequestDataFromPendingDeploy(com.hubspot.singularity.scheduler.SingularityDeploysTest)  Time elapsed: 30.082 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

18:23:22.146 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:23.641 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:24.887 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066204955-1-host1-rack1'}), timestamp=Optional.of(1.512066204E9)}), taskId=test-request-firstDeployId-1512066204955-1-host1-rack1, serverTimestamp=1512066205004, serverId='81fdc0ff-4e50-4865-8faa-171e61792fbe', slaveId=Optional.absent()}
18:23:25.066 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:23:25.096 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066204955-1-host1-rack1
18:23:25.107 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066204955-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066204955-1-host1-rack1, serverTimestamp=1512066205089, serverId='81fdc0ff-4e50-4865-8faa-171e61792fbe', slaveId=Optional.absent()}
18:23:25.186 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:50979] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b40690000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:26.350 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066206419-1-host1-rack1'}), timestamp=Optional.of(1.512066206E9)}), taskId=test-request-firstDeployId-1512066206419-1-host1-rack1, serverTimestamp=1512066206467, serverId='7ed99ffa-ca25-464f-a54c-6467825c5151', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066206595-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066206595-1-host2-DEFAULT, serverTimestamp=1512066206613, serverId='7ed99ffa-ca25-464f-a54c-6467825c5151', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066206419-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066206419-1-host1-rack1, serverTimestamp=1512066206646, serverId='7ed99ffa-ca25-464f-a54c-6467825c5151', slaveId=Optional.absent()}
18:23:28.871 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:30.275 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:30.489 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:51739] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b55640000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:31.639 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:33.045 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:33.354 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:54406] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b605a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:34.490 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:34.708 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:35658] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b65f90000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:35.874 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066216171-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066216171-2-host2-DEFAULT, serverTimestamp=1512066216203, serverId='8984dd59-3692-407d-a41f-adff3271d7a9', slaveId=Optional.absent()}
[test-request-firstDeployId-1512066216219-2-TASK_DONE-1512066216219]
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066216103-5-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066216103-5-host2-DEFAULT, serverTimestamp=1512066216295, serverId='8984dd59-3692-407d-a41f-adff3271d7a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066216123-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066216123-4-host2-DEFAULT, serverTimestamp=1512066216327, serverId='8984dd59-3692-407d-a41f-adff3271d7a9', slaveId=Optional.absent()}
18:23:37.566 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066217635-1-host1-rack1'}), timestamp=Optional.of(1.512066217E9)}), taskId=test-request-firstDeployId-1512066217635-1-host1-rack1, serverTimestamp=1512066217669, serverId='c406960c-c958-4b5d-8d1d-5c1495fedd8c', slaveId=Optional.absent()}
18:23:39.916 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066219988-1-host1-rack1'}), timestamp=Optional.of(1.512066219E9)}), taskId=test-request-firstDeployId-1512066219988-1-host1-rack1, serverTimestamp=1512066220036, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220073-2-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220073-2-host1-rack1, serverTimestamp=1512066220099, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220108-3-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220108-3-host1-rack1, serverTimestamp=1512066220131, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220140-4-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220140-4-host1-rack1, serverTimestamp=1512066220171, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.186 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066219988-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066219988-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066219988-1-host1-rack1, serverTimestamp=1512066220181, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.205 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220073-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220073-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220073-2-host1-rack1, serverTimestamp=1512066220200, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.243 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220108-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220108-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220108-3-host1-rack1, serverTimestamp=1512066220238, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220276-1-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220276-1-host1-rack1, serverTimestamp=1512066220293, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220314-2-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220314-2-host1-rack1, serverTimestamp=1512066220330, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220350-3-host1-rack1'}), timestamp=Optional.of(1.51206622E9)}), taskId=test-request-firstDeployId-1512066220350-3-host1-rack1, serverTimestamp=1512066220370, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.395 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220276-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220276-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220276-1-host1-rack1, serverTimestamp=1512066220387, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.416 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220314-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220314-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220314-2-host1-rack1, serverTimestamp=1512066220411, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.450 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220350-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220350-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220350-3-host1-rack1, serverTimestamp=1512066220445, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.493 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066220140-4-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066220140-4-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066220140-4-host1-rack1, serverTimestamp=1512066220487, serverId='cf324564-991d-493c-99d2-7e37ee9f7939', slaveId=Optional.absent()}
18:23:40.543 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52976] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b7b170000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:41.699 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:41.803 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB delete request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512066221800, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-1512066221788-DELETE-1} (test-request-1512066221788-DELETE-1) got unexpected response FAILED
18:23:41.819 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57741] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b820f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:43.011 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066223091-1-host1-rack1'}), timestamp=Optional.of(1.512066223E9)}), taskId=test-request-firstDeployId-1512066223091-1-host1-rack1, serverTimestamp=1512066223128, serverId='bfbae2bd-ca6d-4eb9-b992-906ca3804bfd', slaveId=Optional.absent()}
18:23:43.272 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60708] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2b87080000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:45.438 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:46.926 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066226990-1-host1-rack1'}), timestamp=Optional.of(1.512066226E9)}), taskId=test-request-firstDeployId-1512066226990-1-host1-rack1, serverTimestamp=1512066227026, serverId='9da8e744-b7fc-4852-8d02-180dd7ff5442', slaveId=Optional.absent()}
18:23:47.103 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066226990-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066226990-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066226990-1-host1-rack1, serverTimestamp=1512066227096, serverId='9da8e744-b7fc-4852-8d02-180dd7ff5442', slaveId=Optional.absent()}
18:23:48.302 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066228371-1-host1-rack1'}), timestamp=Optional.of(1.512066228E9)}), taskId=test-request-firstDeployId-1512066228371-1-host1-rack1, serverTimestamp=1512066228412, serverId='456c2347-d066-4a53-bb2f-9d44e41758ec', slaveId=Optional.absent()}
18:23:48.459 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066228371-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066228371-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066228371-1-host1-rack1, serverTimestamp=1512066228454, serverId='456c2347-d066-4a53-bb2f-9d44e41758ec', slaveId=Optional.absent()}
18:23:48.494 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB removal request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512066228485, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-firstDeployId-1512066228371-1-host1-rack1-REMOVE-1} (test-request-firstDeployId-1512066228371-1-host1-rack1-REMOVE-1) got unexpected response FAILED
18:23:49.647 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:50.913 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:52.249 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066232367-1-host1-rack1'}), timestamp=Optional.of(1.512066232E9)}), taskId=test-request-firstDeployId-1512066232367-1-host1-rack1, serverTimestamp=1512066232418, serverId='accbb301-9642-4877-a492-6bfa60a4ff91', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066232367-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066232367-1-host1-rack1, serverTimestamp=1512066232509, serverId='accbb301-9642-4877-a492-6bfa60a4ff91', slaveId=Optional.absent()}
18:23:53.748 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066233940-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066233940-1-host2-DEFAULT, serverTimestamp=1512066233974, serverId='24ed71c7-6e91-49d7-8bc9-0759d85a5ca6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066234015-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066234015-1-host1-DEFAULT, serverTimestamp=1512066234029, serverId='24ed71c7-6e91-49d7-8bc9-0759d85a5ca6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512066234069-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512066234069-1-host1-DEFAULT, serverTimestamp=1512066234084, serverId='24ed71c7-6e91-49d7-8bc9-0759d85a5ca6', slaveId=Optional.absent()}
18:23:54.130 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:35585] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2bb0f80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:23:55.273 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066235339-1-host1-rack1'}), timestamp=Optional.of(1.512066235E9)}), taskId=test-request-firstDeployId-1512066235339-1-host1-rack1, serverTimestamp=1512066235380, serverId='542d0ee4-e559-4215-ab7b-b0b143b805bf', slaveId=Optional.absent()}
18:23:55.429 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066235339-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066235339-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066235339-1-host1-rack1, serverTimestamp=1512066235423, serverId='542d0ee4-e559-4215-ab7b-b0b143b805bf', slaveId=Optional.absent()}
18:23:56.763 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:58.043 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:23:59.585 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:00.872 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066240997-1-host1-rack1'}), timestamp=Optional.of(1.51206624E9)}), taskId=test-request-firstDeployId-1512066240997-1-host1-rack1, serverTimestamp=1512066241055, serverId='3d29bf61-2bf8-41cc-b7f2-ada883dd6b21', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066241085-2-host2-rack1'}), timestamp=Optional.of(1.512066241E9)}), taskId=test-request-firstDeployId-1512066241085-2-host2-rack1, serverTimestamp=1512066241118, serverId='3d29bf61-2bf8-41cc-b7f2-ada883dd6b21', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066241220-1-host3-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512066241220-1-host3-DEFAULT, serverTimestamp=1512066241238, serverId='3d29bf61-2bf8-41cc-b7f2-ada883dd6b21', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066240997-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066240997-1-host1-rack1, serverTimestamp=1512066241298, serverId='3d29bf61-2bf8-41cc-b7f2-ada883dd6b21', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066241337-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512066241337-2-host1-DEFAULT, serverTimestamp=1512066241352, serverId='3d29bf61-2bf8-41cc-b7f2-ada883dd6b21', slaveId=Optional.absent()}
18:24:03.121 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066241085-2-IMMEDIATE-1512066241085, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host2', id=SingularityMesosIdObject{value='offer622'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066241085-2-host2-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
18:24:03.122 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066241085-2-host2-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:03.123 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066241085-2-host2-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@298687cb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@27416c8b[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:03.243 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066241196-1-BOUNCE-1512066241128, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host3', id=SingularityMesosIdObject{value='offer757'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066241220-1-host3-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, resources=[MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host3}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066241220-1-host3-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
18:24:03.245 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066241220-1-host3-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:03.247 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066241220-1-host3-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@237eecbb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@27416c8b[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:03.356 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066241308-2-TASK_DONE-1512066241306, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer893'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066241337-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512066241337-2-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
18:24:03.357 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512066241337-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:03.358 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512066241337-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@1b360784 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@27416c8b[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:05.510 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:06.879 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066246938-1-host1-rack1'}), timestamp=Optional.of(1.512066246E9)}), taskId=test-request-firstDeployId-1512066246938-1-host1-rack1, serverTimestamp=1512066246984, serverId='7b4e8ae4-c300-4ed4-b924-ce804ca34678', slaveId=Optional.absent()}
18:24:09.245 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:09.253 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Unexpected taskId task 
com.hubspot.singularity.data.transcoders.SingularityTranscoderException: java.lang.reflect.InvocationTargetException
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:44)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.getTaskId(SingularityMesosStatusUpdateHandler.java:137)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:179)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:262)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:277)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testTaskOddities(SingularitySchedulerTest.java:1489)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException: null
	at sun.reflect.GeneratedMethodAccessor231.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:42)
	... 19 common frames omitted
Caused by: com.hubspot.singularity.InvalidSingularityTaskIdException: TaskId task was invalid (There must be at least 5 instances of - (there were 0))
	at com.hubspot.singularity.SingularityTaskId.valueOf(SingularityTaskId.java:114)
	... 23 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066249315-1-host1-rack1'}), timestamp=Optional.of(1.512066249E9)}), taskId=test-request-firstDeployId-1512066249315-1-host1-rack1, serverTimestamp=1512066249358, serverId='6fa8f71c-1461-42d2-85b0-b3b6cc0c086c', slaveId=Optional.absent()}
18:24:09.414 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Task test-request-firstDeployId-1512066249315-1-host1-rack1 is active but is missing task data
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066249315-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066249315-1-host1-rack1, serverTimestamp=1512066249413, serverId='6fa8f71c-1461-42d2-85b0-b3b6cc0c086c', slaveId=Optional.absent()}
18:24:09.433 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066249315-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066249315-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066249315-1-host1-rack1, serverTimestamp=1512066249428, serverId='6fa8f71c-1461-42d2-85b0-b3b6cc0c086c', slaveId=Optional.absent()}
[SingularityTaskHistoryUpdate[timestamp=1512066249413, taskState=TASK_RUNNING, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]], SingularityTaskHistoryUpdate[timestamp=1512066249427, taskState=TASK_FAILED, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]]]
18:24:10.643 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:11.193 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:58039] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2bf30f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:24:12.335 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252405-1-host1-rack1'}), timestamp=Optional.of(1.512066252E9)}), taskId=test-request-firstDeployId-1512066252405-1-host1-rack1, serverTimestamp=1512066252448, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252482-2-host1-rack1'}), timestamp=Optional.of(1.512066252E9)}), taskId=test-request-firstDeployId-1512066252482-2-host1-rack1, serverTimestamp=1512066252507, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252515-3-host1-rack1'}), timestamp=Optional.of(1.512066252E9)}), taskId=test-request-firstDeployId-1512066252515-3-host1-rack1, serverTimestamp=1512066252543, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252691-1-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512066252691-1-host2-DEFAULT, serverTimestamp=1512066252767, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252734-3-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512066252734-3-host2-DEFAULT, serverTimestamp=1512066252775, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066252715-2-host2-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512066252715-2-host2-DEFAULT, serverTimestamp=1512066252791, serverId='8a71c40b-b0a3-48b3-9f17-3ec096cd60fb', slaveId=Optional.absent()}
18:24:14.978 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:16.160 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:17.422 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055457483-1-host1-rack1'}), timestamp=Optional.of(1.512066257E9)}), taskId=test-request-firstDeployId-1512055457483-1-host1-rack1, serverTimestamp=1512066257532, serverId='99d3498a-9ec1-404d-8ada-333f4d031b08', slaveId=Optional.absent()}
18:24:17.591 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512055457483-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512055457483-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512055457483-1-host1-rack1, serverTimestamp=1512066257586, serverId='99d3498a-9ec1-404d-8ada-333f4d031b08', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066256983-1-host1-rack1'}), timestamp=Optional.of(1.512066257E9)}), taskId=test-request-firstDeployId-1512066256983-1-host1-rack1, serverTimestamp=1512066257638, serverId='99d3498a-9ec1-404d-8ada-333f4d031b08', slaveId=Optional.absent()}
18:24:17.655 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066256983-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066256983-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066256983-1-host1-rack1, serverTimestamp=1512066257649, serverId='99d3498a-9ec1-404d-8ada-333f4d031b08', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066256981-1-host1-rack1'}), timestamp=Optional.of(1.512066257E9)}), taskId=test-request-firstDeployId-1512066256981-1-host1-rack1, serverTimestamp=1512066257715, serverId='99d3498a-9ec1-404d-8ada-333f4d031b08', slaveId=Optional.absent()}
18:24:19.887 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:21.374 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066261442-1-host1-rack1'}), timestamp=Optional.of(1.512066261E9)}), taskId=test-request-firstDeployId-1512066261442-1-host1-rack1, serverTimestamp=1512066261487, serverId='3949fbb2-7eca-4d12-97eb-6e8f9ec61feb', slaveId=Optional.absent()}
18:24:21.540 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:24:21.563 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066261442-1-host1-rack1
18:24:21.570 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066261442-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066261442-1-host1-rack1, serverTimestamp=1512066261556, serverId='3949fbb2-7eca-4d12-97eb-6e8f9ec61feb', slaveId=Optional.absent()}
18:24:22.791 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:25.042 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066265102-1-host1-rack1'}), timestamp=Optional.of(1.512066265E9)}), taskId=test-request-firstDeployId-1512066265102-1-host1-rack1, serverTimestamp=1512066265139, serverId='a404ed47-7bc4-4bac-aae1-3767adad5d9e', slaveId=Optional.absent()}
18:24:25.189 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066265102-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066265102-1-host1-rack1'}), timestamp=Optional.of(1.512048265E9)}), taskId=test-request-firstDeployId-1512066265102-1-host1-rack1, serverTimestamp=1512066265183, serverId='a404ed47-7bc4-4bac-aae1-3767adad5d9e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066265201-1-host1-rack1'}), timestamp=Optional.of(1.512066265E9)}), taskId=test-request-firstDeployId-1512066265201-1-host1-rack1, serverTimestamp=1512066265232, serverId='a404ed47-7bc4-4bac-aae1-3767adad5d9e', slaveId=Optional.absent()}
18:24:25.247 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066265201-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066265201-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066265201-1-host1-rack1, serverTimestamp=1512066265242, serverId='a404ed47-7bc4-4bac-aae1-3767adad5d9e', slaveId=Optional.absent()}
18:24:25.292 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47072] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2c27880000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:24:26.426 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512066266597-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512066266597-1-host2-DEFAULT, serverTimestamp=1512066266627, serverId='ba9b8fcd-c30f-4c7e-8dfb-adbacc5747a0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512066266684-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512066266684-1-host2-DEFAULT, serverTimestamp=1512066266698, serverId='ba9b8fcd-c30f-4c7e-8dfb-adbacc5747a0', slaveId=Optional.absent()}
18:24:27.883 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.of(1.512066268E9)}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512066268071, serverId='8faccd4a-fd08-45e1-9323-bbd8e9ac56df', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1'}), timestamp=Optional.of(1.512066268E9)}), taskId=mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1, serverTimestamp=1512066268119, serverId='8faccd4a-fd08-45e1-9323-bbd8e9ac56df', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='highPriorityRequest-highPriorityDeploy-10-1-host1-rack1'}), timestamp=Optional.of(1.512066268E9)}), taskId=highPriorityRequest-highPriorityDeploy-10-1-host1-rack1, serverTimestamp=1512066268158, serverId='8faccd4a-fd08-45e1-9323-bbd8e9ac56df', slaveId=Optional.absent()}
18:24:28.212 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512066268207, serverId='8faccd4a-fd08-45e1-9323-bbd8e9ac56df', slaveId=Optional.absent()}
18:24:30.490 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:31.870 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066271945-1-host1-rack1'}), timestamp=Optional.of(1.512066271E9)}), taskId=test-request-firstDeployId-1512066271945-1-host1-rack1, serverTimestamp=1512066272003, serverId='898dc63a-6b5a-4445-a27a-719bbc613ff3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066272028-2-host1-rack1'}), timestamp=Optional.of(1.512066272E9)}), taskId=test-request-firstDeployId-1512066272028-2-host1-rack1, serverTimestamp=1512066272051, serverId='898dc63a-6b5a-4445-a27a-719bbc613ff3', slaveId=Optional.absent()}
18:24:32.083 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066271945-1-host1-rack1
18:24:32.086 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066271945-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066271945-1-host1-rack1, serverTimestamp=1512066272078, serverId='898dc63a-6b5a-4445-a27a-719bbc613ff3', slaveId=Optional.absent()}
18:24:32.124 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
18:24:32.144 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512066272028-2-host1-rack1
18:24:32.148 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066272028-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512066272028-2-host1-rack1, serverTimestamp=1512066272135, serverId='898dc63a-6b5a-4445-a27a-719bbc613ff3', slaveId=Optional.absent()}
18:24:33.348 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:34.775 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:34.828 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066153531-1-IMMEDIATE-1512066153531, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer71'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066153531-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:34.829 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066153531-1-IMMEDIATE-1512066153531, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer71'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066153531-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@326987c1 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@5276cf14[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:34.930 [check-new-task-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066153902-3-IMMEDIATE-1512066153902, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer443'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066153902-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:34.931 [check-new-task-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066153902-3-IMMEDIATE-1512066153902, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer443'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066153902-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@1edf8edf rejected from java.util.concurrent.ScheduledThreadPoolExecutor@5276cf14[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:36.120 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512066276180-1-host1-rack1'}), timestamp=Optional.of(1.512066276E9)}), taskId=test-request-firstDeployId-1512066276180-1-host1-rack1, serverTimestamp=1512066276214, serverId='52fdaaa2-ef1f-49d8-a135-a25987ca5fc5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512066276269-1-host1-rack1'}), timestamp=Optional.of(1.512066276E9)}), taskId=test-request-secondDeployId-1512066276269-1-host1-rack1, serverTimestamp=1512066276298, serverId='52fdaaa2-ef1f-49d8-a135-a25987ca5fc5', slaveId=Optional.absent()}
18:24:37.238 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066276180-1-IMMEDIATE-1512066276180, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer670'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066276180-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:37.240 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512066276180-1-IMMEDIATE-1512066276180, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer670'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512066276180-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@483b187f rejected from java.util.concurrent.ScheduledThreadPoolExecutor@46fcff08[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
18:24:38.365 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:38.630 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:46356] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1600e2c5f850000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
18:24:39.808 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
18:24:41.158 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 75, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 174.527 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularitySchedulerTest
testNotAcceptOfferWithRoleForRequestWithoutRole(com.hubspot.singularity.scheduler.SingularitySchedulerTest)  Time elapsed: 30.077 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testNotAcceptOfferWithRoleForRequestWithoutRole(SingularitySchedulerTest.java:2367)


Results :

Failed tests: 
  SingularitySlavePlacementTest.testEvenRackPlacement:272 expected:<4> but was:<7>
Tests in error: 
  SingularityHistoryTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityStartupTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityTaskShellCommandTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  HistoryPersisterTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityDeploysTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityMachineStatesTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularitySchedulerTest.testNotAcceptOfferWithRoleForRequestWithoutRole:2367 Â» TestTimedOut
  SingularitySlavePlacementTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut

Tests run: 254, Failures: 1, Errors: 8, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Singularity ........................................ SUCCESS [  2.988 s]
[INFO] SingularityBase .................................... SUCCESS [  4.635 s]
[INFO] SingularityUI ...................................... SUCCESS [02:58 min]
[INFO] SingularityServiceBase ............................. SUCCESS [  6.678 s]
[INFO] SingularityMesosClient ............................. SUCCESS [  2.483 s]
[INFO] SingularitySwagger ................................. SUCCESS [  1.512 s]
[INFO] SingularityService ................................. FAILURE [03:35 min]
[INFO] SingularityRunnerBase .............................. SKIPPED
[INFO] SingularityS3Base .................................. SKIPPED
[INFO] SingularityClient .................................. SKIPPED
[INFO] SingularityExecutor ................................ SKIPPED
[INFO] SingularityExecutorCleanup ......................... SKIPPED
[INFO] SingularityS3Uploader .............................. SKIPPED
[INFO] SingularityS3Downloader ............................ SKIPPED
[INFO] EmbedSingularityExample ............................ SKIPPED
[INFO] SingularityServiceIntegrationTests ................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 06:53 min
[INFO] Finished at: 2017-11-30T19:24:41+01:00
[INFO] Final Memory: 167M/2298M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project SingularityService: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/HubSpot/Singularity/309611571/SingularityService/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :SingularityService
