[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Singularity
[INFO] SingularityBase
[INFO] SingularityUI
[INFO] SingularityMesosClient
[INFO] SingularitySwagger
[INFO] SingularityService
[INFO] SingularityRunnerBase
[INFO] SingularityS3Base
[INFO] SingularityClient
[INFO] SingularityExecutor
[INFO] SingularityExecutorCleanup
[INFO] SingularityS3Uploader
[INFO] SingularityS3Downloader
[INFO] EmbedSingularityExample
[INFO] SingularityServiceIntegrationTests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Singularity 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ Singularity ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ Singularity ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ Singularity ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ Singularity ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ Singularity ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ Singularity ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ Singularity ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/target/jacoco.exec
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/RequestCleanupType.java:12:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/SlaveMatchState.java:18:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/TaskCleanupType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/RequestType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/HealthcheckProtocol.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/RequestState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/java/com/hubspot/singularity/DeployState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/SingularityBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityUI 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityUI ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityUI ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityUI ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityUI ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityUI ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityUI ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityUI ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/SingularityUI/target/jacoco.exec
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:install-node-and-npm (install node and npm) @ SingularityUI ---
[INFO] Node v6.2.1 is already installed.
[INFO] Found NPM version 3.9.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm install) @ SingularityUI ---
[INFO] Running 'npm install --color=false' in /root/workspace/HubSpot/Singularity/312989843/SingularityUI
[ERROR] npm WARN optional Skipping failed optional dependency /chokidar/fsevents:
[ERROR] npm WARN notsup Not compatible with your operating system or architecture: fsevents@1.1.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm test) @ SingularityUI ---
[INFO] Running 'npm test --color=false' in /root/workspace/HubSpot/Singularity/312989843/SingularityUI
[INFO] 
[INFO] > SingularityUI@0.3.0 test /root/workspace/HubSpot/Singularity/312989843/SingularityUI
[INFO] > mocha --compilers js:babel-core/register test/index.test
[INFO] 
[ERROR] Warning: Accessing PropTypes via the main React package is deprecated, and will be removed in  React v16.0. Use the latest available v15.* prop-types package from npm instead. For info on usage, compatibility, migration and more, see https://fb.me/prop-types-docs
[INFO] 
[INFO] 
[INFO]   Utils
[INFO]     getTaskDataFromTaskId()
[INFO]       âœ“ should grab all fields from a valid task id
[INFO] 
[INFO]   Reducers
[INFO]     tailerView
[INFO]       âœ“ should be properly initialized
[INFO]       âœ“ should populate the tailerId field
[INFO]       âœ“ should auto-populate the requestIds, taskIds, and paths fields
[INFO]       âœ“ should add tailer groups
[INFO]       âœ“ should remove tailer groups
[INFO]       âœ“ should pick an individual tailer group
[INFO] 
[INFO] 
[INFO]   7 passing (45ms)
[INFO] 
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:gulp (gulp build) @ SingularityUI ---
[INFO] Running 'gulp build --no-color' in /root/workspace/HubSpot/Singularity/312989843/SingularityUI
[INFO] [15:20:39] Using gulpfile ~/workspace/HubSpot/Singularity/312989843/SingularityUI/gulpfile.js
[INFO] [15:20:39] Starting 'clean'...
[INFO] [15:20:39] Finished 'clean' after 47 ms
[INFO] [15:20:39] Starting 'static'...
[INFO] [15:20:39] Finished 'static' after 47 ms
[INFO] [15:20:39] Starting 'html'...
[INFO] [15:20:39] Finished 'html' after 27 ms
[INFO] [15:20:39] Starting 'build'...
[INFO] [15:23:24] Version: webpack [1m1.13.1[22m
[INFO] Time: [1m165030[22mms
[INFO]                                [1mAsset[22m     [1mSize[22m  [1mChunks[22m  [1m[22m           [1mChunk Names[22m
[INFO] [1m[32m89889688147bd7575d6327160d64e760.svg[39m[22m   109 kB        [1m[22m  [1m[32m[emitted][39m[22m  
[INFO]                  [1m[32mjs/vendor.bundle.js[39m[22m   618 kB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                     [1m[32mjs/app.bundle.js[39m[22m  2.18 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                          [1m[32mcss/app.css[39m[22m   338 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]              [1m[32mjs/vendor.bundle.js.map[39m[22m  4.62 MB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                 [1m[32mjs/app.bundle.js.map[39m[22m  10.4 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                      [1m[32mcss/app.css.map[39m[22m   415 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] [15:23:24] Finished 'build' after 2.75 min
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-index.html-template) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-ui) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 12 resources
[INFO] 
[INFO] --- build-helper-maven-plugin:1.10:add-resource (add-generated-resources) @ SingularityUI ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityUI/src/main/resources
[INFO] Copying 13 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityUI/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityUI ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityMesosClient 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityMesosClient ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityMesosClient ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:29:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:31:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:33:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:35:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:37:3: Redundant 'public' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityMesosClient ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityMesosClient ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityMesosClient ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularityMesosClient/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityMesosClient ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityMesosClient ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularitySwagger 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularitySwagger ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularitySwagger ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularitySwagger ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularitySwagger ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/SingularitySwagger/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularitySwagger/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularitySwagger ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/312989843/SingularitySwagger/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularitySwagger ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularitySwagger ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityService 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityService ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityService ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityService ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityService ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/hooks/LoadBalancerClientImpl.java:114:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:18:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:20:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:22:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:24:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:26:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:175:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:224:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:249:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:289:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:315:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/config/UIConfiguration.java:22:10: Redundant 'static' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorManager.java:64:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityCmdLineArgsMigration.java:58:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:84:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:139:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/history/SingularityHistoryModule.java:126:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorAsyncManager.java:46:5: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/312989843/SingularityService/src/main/java/com/hubspot/singularity/smtp/SmtpMailer.java:366:5: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityService ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityService ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityService ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/312989843/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/312989843/SingularityService/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- swagger-maven-plugin:2.3.2:generate (build-embedded-documentation) @ SingularityService ---
[INFO] Reflections took 85 ms to scan 1 urls, producing 13 keys and 79 values 
[INFO] Detect Resource:com.hubspot.singularity.resources.SandboxResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UsageResource
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.WebhookResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskTrackerResource
[INFO] Detect Resource:com.hubspot.singularity.resources.StateResource
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DeployResource
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
[INFO] Detect Resource:com.hubspot.singularity.resources.HistoryResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UserResource
[INFO] Detect Resource:com.hubspot.singularity.resources.InactiveSlaveResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TestResource
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestGroupResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.S3LogResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RackResource
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.PriorityResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DisastersResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.SlaveResource
[INFO] Writing doc to /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/index.html...
[INFO] Done!
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/service.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_sandbox.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_usage.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_tasks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_webhooks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_track.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_state.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_deploys.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_history.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_users.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_inactive.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_test.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_groups.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_logs.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_racks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_requests.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_priority.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_disasters.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/classes/assets/api-docs/api_slaves.json
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityService ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom (4 KB at 10.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom (3 KB at 108.7 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar (75 KB at 1233.5 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hubspot.singularity.scheduler.HistoryPersisterTest
Running com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
Running com.hubspot.singularity.data.ValidatorTest
Running com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
Running com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.scheduler.SingularityUsageTest
Running com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.SingularityS3Test
15:24:06.299 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1381694864)
15:24:06.419 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.215 sec - in com.hubspot.singularity.SingularityS3Test
Running com.hubspot.singularity.mesos.SingularityStartupTest
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.044 sec - in com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.scheduler.SingularityDeploysTest
15:24:07.192 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 361535167)
15:24:07.363 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:08.069 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 190573260)
15:24:08.267 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:08.473 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 375207408)
15:24:08.592 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:08.621 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 24418869)
15:24:08.753 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:08.898 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 911697084)
15:24:09.003 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:09.683 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1441132899)
15:24:09.766 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.514 sec - in com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
15:24:13.658 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:13.709 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13241ms
15:24:13.918 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7138da6
15:24:14.013 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2152403b{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@394a839d,MANAGED}
15:24:14.023 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@346ae125
15:24:14.023 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7f54af01{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@ca5810,MANAGED}
15:24:14.227 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@ca5810 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:14.279 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@ca5810 added {[/tasks/*]=>tasks,POJO}
15:24:14.648 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:14.679 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14237ms
15:24:14.856 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7776cb76
15:24:14.963 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7cdd0d23{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@ec854af,MANAGED}
15:24:14.973 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6b38318c
15:24:14.982 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2b3fff19{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5df7d090,MANAGED}
15:24:15.141 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5df7d090 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:15.179 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@5df7d090 added {[/tasks/*]=>tasks,POJO}
15:24:15.526 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:15.542 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15086ms
15:24:15.696 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7d120613
15:24:15.741 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:15.787 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15331ms
15:24:15.796 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@54f2f038{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7156fc6f,MANAGED}
15:24:15.814 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7e8bf405
15:24:15.814 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2c7fb0ba{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@46f12c7b,MANAGED}
15:24:15.979 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@7bc7223d
15:24:15.993 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@46f12c7b added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:16.028 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@46f12c7b added {[/tasks/*]=>tasks,POJO}
15:24:16.047 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:16.104 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15660ms
15:24:16.123 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@507c54e5{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@1f4aef4e,MANAGED}
15:24:16.149 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@532d9eaa
15:24:16.150 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@23e5f77{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@74b00794,MANAGED}
15:24:16.254 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3eaceeb
15:24:16.365 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@445bf146{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@4600f13e,MANAGED}
15:24:16.383 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@97366c4
15:24:16.383 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@f3a5d42{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@26546258,MANAGED}
15:24:16.427 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@74b00794 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:16.460 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@74b00794 added {[/tasks/*]=>tasks,POJO}
15:24:16.516 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@26546258 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:16.548 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@26546258 added {[/tasks/*]=>tasks,POJO}
15:24:16.852 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:16.865 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:16.874 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @16422ms
15:24:16.880 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @16435ms
15:24:16.947 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@273f058e
15:24:17.002 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@132c37d2
15:24:17.045 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2b97ab5b{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2005111d,MANAGED}
15:24:17.081 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@29c19b9d
15:24:17.082 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@542c2c14{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@c027ba6,MANAGED}
15:24:17.083 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7c3d8e23{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@50965aea,MANAGED}
15:24:17.088 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@86e4976
15:24:17.089 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3c566a44{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@78e8fc76,MANAGED}
15:24:17.278 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@78e8fc76 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:17.295 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@c027ba6 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:17.307 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@78e8fc76 added {[/tasks/*]=>tasks,POJO}
15:24:17.334 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@c027ba6 added {[/tasks/*]=>tasks,POJO}
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 14.853 sec - in com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
Running com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
15:24:31.111 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1911531748)
15:24:31.176 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
15:24:32.114 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
15:24:32.126 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @31669ms
15:24:32.176 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@73209619
15:24:32.231 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@782b14ed{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2ef7bb6e,MANAGED}
15:24:32.263 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3d083adf
15:24:32.266 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@47107ae2{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@37481c91,MANAGED}
15:24:32.409 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@37481c91 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
15:24:32.423 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@37481c91 added {[/tasks/*]=>tasks,POJO}
15:24:36.665 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:37.567 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:38.384 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
15:24:38.501 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:39.412 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:39.756 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.022 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.146 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.560 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:40.781 [Time-limited test] WARN com.hubspot.singularity.data.history.SingularityRequestHistoryPersister - Failed to persist SingularityRequestHistory{createdAt=1512649480603, user=Optional.absent(), eventType=CREATED, request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, message=Optional.absent()} into History
java.lang.UnsupportedOperationException: NoopHistoryManager can not save
	at com.hubspot.singularity.data.history.NoopHistoryManager.saveRequestHistoryUpdate(NoopHistoryManager.java:26)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:141)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:25)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurgeAndShouldDelete(SingularityHistoryPersister.java:63)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurge(SingularityHistoryPersister.java:52)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.runActionOnPoll(SingularityRequestHistoryPersister.java:119)
	at com.hubspot.singularity.scheduler.HistoryPersisterTest.testPurgingDoesntApplyIfDatabasePresent(HistoryPersisterTest.java:211)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
15:24:40.793 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:40.981 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:41.965 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660280638-1-host1-rack1'}), timestamp=Optional.of(1.51266028E9)}), taskId=test-request-firstDeployId-1512660280638-1-host1-rack1, serverTimestamp=1512660281721, serverId='0e934260-e3c6-4609-aafa-14bef8c0e2ee', slaveId=Optional.absent()}
15:24:42.366 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r1-d1-23-3-BOUNCE-1, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}, but not active
15:24:42.428 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:42.443 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r2-d3-231-1-UNPAUSED-23, cmdLineArgsList=Optional.of([cmd line args]), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}, but not active
15:24:42.447 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
15:24:42.565 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:42.600 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r2-de, already correct
15:24:42.604 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r1-d1, already correct
15:24:42.604 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 0 requests in 00:00.038
15:24:42.710 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660280638-1-host1-rack1
15:24:42.750 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660280638-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660280638-1-host1-rack1, serverTimestamp=1512660282661, serverId='0e934260-e3c6-4609-aafa-14bef8c0e2ee', slaveId=Optional.absent()}
15:24:43.053 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660281153-1-host1-rack1'}), timestamp=Optional.of(1.512660281E9)}), taskId=test-request-firstDeployId-1512660281153-1-host1-rack1, serverTimestamp=1512660282556, serverId='192d8a65-f51a-4a12-8fc7-77d12d395305', slaveId=Optional.absent()}
15:24:43.516 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660281153-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660281153-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660281153-1-host1-rack1, serverTimestamp=1512660283487, serverId='192d8a65-f51a-4a12-8fc7-77d12d395305', slaveId=Optional.absent()}
15:24:44.063 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
[oneOffRequest-oneOffDeploy1512660284132, immediateRequest-immediateDeploy, newDeployRequest-newDeploy]
15:24:44.202 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:44.205 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path oneOffRequest-oneOffDeploy1512660284132, already correct
15:24:44.207 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Rewriting path immediateRequest-immediateDeploy to immediateRequest-immediateDeploy1512660284132
15:24:44.217 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path newDeployRequest-newDeploy, already correct
15:24:44.218 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 1 requests in 00:00.016
[oneOffRequest-oneOffDeploy1512660284132, immediateRequest-immediateDeploy1512660284132, newDeployRequest-newDeploy]
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 40.832 sec <<< FAILURE! - in com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
testMigrationRunner(com.hubspot.singularity.data.zkmigrations.ZkMigrationTest)  Time elapsed: 30.047 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.SingularityHealthchecksTest
15:24:45.060 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:45.219 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:45.348 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:45.411 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:45.877 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:46.362 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660286076-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660286076-1-host1-rack1'}), timestamp=Optional.of(1.512660286E9)}), taskId=test-request-firstDeployId-1512660286076-1-host1-rack1, serverTimestamp=1512660286334, serverId='3868a121-dbc0-414d-81f8-32d1038cee54', slaveId=Optional.absent()}
15:24:46.419 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:46.506 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:46.506 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660286446-1-host1-rack1'}), timestamp=Optional.of(1.512660286E9)}), taskId=test-request-firstDeployId-1512660286446-1-host1-rack1, serverTimestamp=1512660286503, serverId='3868a121-dbc0-414d-81f8-32d1038cee54', slaveId=Optional.absent()}
15:24:47.510 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
15:24:47.799 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:47.908 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512660287299-1-host1-rack1'}), timestamp=Optional.of(1.512660287E9)}), taskId=test-request-retry_test-1512660287299-1-host1-rack1, serverTimestamp=1512660287982, serverId='f13c4d0d-3952-4879-ab0b-d76cf7146277', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660288109-1-host1-rack1'}), timestamp=Optional.of(1.512660288E9)}), taskId=test-request-firstDeployId-1512660288109-1-host1-rack1, serverTimestamp=1512660288262, serverId='a7e95480-9ada-4cd5-8a01-f72b9f7e824b', slaveId=Optional.absent()}
15:24:48.805 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660288715-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660288715-1-host1-DEFAULT, serverTimestamp=1512660288810, serverId='a7e95480-9ada-4cd5-8a01-f72b9f7e824b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660288109-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660288109-1-host1-rack1, serverTimestamp=1512660288905, serverId='a7e95480-9ada-4cd5-8a01-f72b9f7e824b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512649487960-1-host1-rack1'}), timestamp=Optional.of(1.512660287E9)}), taskId=test-request-firstDeployId-1512649487960-1-host1-rack1, serverTimestamp=1512660288821, serverId='635da0e3-ff74-40d0-b89d-5ef4ce5e24ca', slaveId=Optional.absent()}
15:24:49.082 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:49.094 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512649489029-2-host1-rack1'}), timestamp=Optional.of(1.512660289E9)}), taskId=test-request-firstDeployId-1512649489029-2-host1-rack1, serverTimestamp=1512660289074, serverId='635da0e3-ff74-40d0-b89d-5ef4ce5e24ca', slaveId=Optional.absent()}
15:24:49.147 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:49.180 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512649487960-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512649487960-1-host1-rack1'}), timestamp=Optional.of(1.512653089E9)}), taskId=test-request-firstDeployId-1512649487960-1-host1-rack1, serverTimestamp=1512660289157, serverId='635da0e3-ff74-40d0-b89d-5ef4ce5e24ca', slaveId=Optional.absent()}
15:24:49.353 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660289501-1-host1-rack1'}), timestamp=Optional.of(1.512660289E9)}), taskId=test-request-firstDeployId-1512660289501-1-host1-rack1, serverTimestamp=1512660289606, serverId='890e0acf-143a-468a-b2a6-6a05d09f04da', slaveId=Optional.absent()}
15:24:50.079 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512660287299-1-IMMEDIATE-1512660287299, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer182'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512660287299-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:50.082 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512660287299-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660289938-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660289938-1-host1-DEFAULT, serverTimestamp=1512660290071, serverId='890e0acf-143a-468a-b2a6-6a05d09f04da', slaveId=Optional.absent()}
15:24:50.087 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512660287299-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:50.087 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512649489029-2-IMMEDIATE-1512649489029, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer703'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512649489029-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:50.098 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512649489029-2-IMMEDIATE-1512649489029, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer703'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512649489029-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2c7b89db rejected from java.util.concurrent.ScheduledThreadPoolExecutor@327626ca[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:50.355 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
15:24:50.357 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:50.706 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:50.805 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660290963-1-host1-rack1'}), timestamp=Optional.of(1.51266029E9)}), taskId=test-request-firstDeployId-1512660290963-1-host1-rack1, serverTimestamp=1512660291097, serverId='51769075-48dd-4b77-8bfc-16c89aec2fb4', slaveId=Optional.absent()}
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 44.654 sec <<< FAILURE! - in com.hubspot.singularity.mesos.SingularityStartupTest
testScheduledTasksDontGetRescheduledDuringRun(com.hubspot.singularity.mesos.SingularityStartupTest)  Time elapsed: 30.046 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.SingularitySchedulerTest
15:24:51.399 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:51.595 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660291490-1-host1-rack1'}), timestamp=Optional.of(1.512660291E9)}), taskId=test-request-firstDeployId-1512660291490-1-host1-rack1, serverTimestamp=1512660291564, serverId='51769075-48dd-4b77-8bfc-16c89aec2fb4', slaveId=Optional.absent()}
15:24:51.693 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:51.770 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:51.779 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
15:24:51.810 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660290963-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660290963-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660290963-1-host1-rack1, serverTimestamp=1512660291780, serverId='51769075-48dd-4b77-8bfc-16c89aec2fb4', slaveId=Optional.absent()}
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 48.343 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.HistoryPersisterTest
testTaskCountPurging(com.hubspot.singularity.scheduler.HistoryPersisterTest)  Time elapsed: 30.1 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.JavaUtilsTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.675 sec - in com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
Running com.hubspot.singularity.data.SandboxManagerTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.222 sec - in com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
15:24:52.598 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660292666-1-host1-rack1'}), timestamp=Optional.of(1.512660292E9)}), taskId=test-request-firstDeployId-1512660292666-1-host1-rack1, serverTimestamp=1512660292719, serverId='3b33c75c-a26e-47cf-958f-91689e58cc07', slaveId=Optional.absent()}
15:24:52.755 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:52.868 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='timeout_test', timestamp=1512656692656, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512656692656}), updatedRequest=Optional.absent()} is overdue (duration: 01:00:00.212), allowed: 00:01:00.000
15:24:52.926 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52223] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x16031944ec70000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:53.162 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:53.215 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:53.582 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660291490-1-IMMEDIATE-1512660291490, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer932'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660291490-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:24:53.583 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660291490-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:53.588 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660291490-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@630bcf6a rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6dcc3d7b[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:53.643 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:54.273 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660294442-1-host1-rack1'}), timestamp=Optional.of(1.512660294E9)}), taskId=test-request-firstDeployId-1512660294442-1-host1-rack1, serverTimestamp=1512660294588, serverId='0e0f8ce7-6d9d-4dbd-97a0-7e408fce39f1', slaveId=Optional.absent()}
15:24:54.718 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660294683-2-host1-rack1'}), timestamp=Optional.of(1.512660294E9)}), taskId=test-request-firstDeployId-1512660294683-2-host1-rack1, serverTimestamp=1512660294731, serverId='0e0f8ce7-6d9d-4dbd-97a0-7e408fce39f1', slaveId=Optional.absent()}
Max healthcheck time cannot be greater than 100, (was startup timeout: 50, interval: 5, attempts: 10)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660295108-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660295108-2-host1-DEFAULT, serverTimestamp=1512660295183, serverId='0e0f8ce7-6d9d-4dbd-97a0-7e408fce39f1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660295045-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660295045-1-host1-DEFAULT, serverTimestamp=1512660295236, serverId='0e0f8ce7-6d9d-4dbd-97a0-7e408fce39f1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660295230-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660295230-1-host2-DEFAULT, serverTimestamp=1512660295486, serverId='cde286a4-d408-43b5-8c2f-b03965244cf9', slaveId=Optional.absent()}
15:24:55.633 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:55.657 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:55.672 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512660295889-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512660295889-1-host2-DEFAULT, serverTimestamp=1512660295972, serverId='cde286a4-d408-43b5-8c2f-b03965244cf9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660295891-1-host1-rack1'}), timestamp=Optional.of(1.512660295E9)}), taskId=test-request-firstDeployId-1512660295891-1-host1-rack1, serverTimestamp=1512660296103, serverId='b0e29765-ae02-4a31-b1a3-d076ca6bd51f', slaveId=Optional.absent()}
15:24:56.256 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660295983-1-host1-rack1'}), timestamp=Optional.of(1.512660295E9)}), taskId=test-request-firstDeployId-1512660295983-1-host1-rack1, serverTimestamp=1512660296173, serverId='4f35851f-8101-41b9-97d0-30a89efe537b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660296372-2-host1-rack1'}), timestamp=Optional.of(1.512660296E9)}), taskId=test-request-firstDeployId-1512660296372-2-host1-rack1, serverTimestamp=1512660296404, serverId='4f35851f-8101-41b9-97d0-30a89efe537b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660296426-3-host1-rack1'}), timestamp=Optional.of(1.512660296E9)}), taskId=test-request-firstDeployId-1512660296426-3-host1-rack1, serverTimestamp=1512660296473, serverId='4f35851f-8101-41b9-97d0-30a89efe537b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660296574-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660296574-1-host1-DEFAULT, serverTimestamp=1512660296790, serverId='b0e29765-ae02-4a31-b1a3-d076ca6bd51f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660296372-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660296372-2-host1-rack1, serverTimestamp=1512660296934, serverId='4f35851f-8101-41b9-97d0-30a89efe537b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660296426-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660296426-3-host1-rack1, serverTimestamp=1512660296967, serverId='4f35851f-8101-41b9-97d0-30a89efe537b', slaveId=Optional.absent()}
15:24:57.418 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:57.427 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:57.467 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:53563] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x16031945b470000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:57.550 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:57.893 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660297934-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660297934-1-host2-DEFAULT, serverTimestamp=1512660298127, serverId='fdba945d-1ee0-4b14-8cbb-17262a39223b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660298269-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660298269-2-host1-DEFAULT, serverTimestamp=1512660298428, serverId='1d04b1e8-8367-4f9e-8b72-bacdbd4f1972', slaveId=Optional.absent()}
15:24:58.874 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:58.890 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660299008-1-host1-rack1'}), timestamp=Optional.of(1.512660299E9)}), taskId=test-request-firstDeployId-1512660299008-1-host1-rack1, serverTimestamp=1512660299090, serverId='0de4d3c8-1128-4e52-ae4e-2d412cbc56dc', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660299383-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660299383-1-host1-DEFAULT, serverTimestamp=1512660299456, serverId='0de4d3c8-1128-4e52-ae4e-2d412cbc56dc', slaveId=Optional.absent()}
15:24:59.616 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:24:59.830 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:24:59.837 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:24:59.857 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44190] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319467160000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:24:59.879 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660299807-1-host1-rack1'}), timestamp=Optional.of(1.512660299E9)}), taskId=test-request-firstDeployId-1512660299807-1-host1-rack1, serverTimestamp=1512660299921, serverId='532b7f96-6a1a-45ca-ae66-ed74bf2b710e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660300030-2-host1-rack1'}), timestamp=Optional.of(1.5126603E9)}), taskId=test-request-firstDeployId-1512660300030-2-host1-rack1, serverTimestamp=1512660300065, serverId='532b7f96-6a1a-45ca-ae66-ed74bf2b710e', slaveId=Optional.absent()}
15:25:00.085 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660300079-3-host1-rack1'}), timestamp=Optional.of(1.5126603E9)}), taskId=test-request-firstDeployId-1512660300079-3-host1-rack1, serverTimestamp=1512660300113, serverId='532b7f96-6a1a-45ca-ae66-ed74bf2b710e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660300298-4-host1-rack1'}), timestamp=Optional.of(1.5126603E9)}), taskId=test-request-firstDeployId-1512660300298-4-host1-rack1, serverTimestamp=1512660300344, serverId='532b7f96-6a1a-45ca-ae66-ed74bf2b710e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660300079-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660300079-3-host1-rack1, serverTimestamp=1512660300582, serverId='532b7f96-6a1a-45ca-ae66-ed74bf2b710e', slaveId=Optional.absent()}
Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 56.486 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityUsageTest
testUsagePollerComplex(com.hubspot.singularity.scheduler.SingularityUsageTest)  Time elapsed: 30.087 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.BlendedHistoryTest
15:25:01.099 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:25:01.239 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 57.713 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
testExpiringSkipHealthchecks(com.hubspot.singularity.scheduler.SingularityExpiringActionsTest)  Time elapsed: 30.093 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.InactiveSlaveManagerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660295891-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660295891-1-host1-rack1, serverTimestamp=1512660301822, serverId='b0e29765-ae02-4a31-b1a3-d076ca6bd51f', slaveId=Optional.absent()}
15:25:02.109 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:02.286 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:25:02.305 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.786 sec - in com.hubspot.singularity.data.BlendedHistoryTest
Running com.hubspot.singularity.config.MergingSourceProviderTest
15:25:02.683 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:25:02.703 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47914] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319475670000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:02.928 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:03.074 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:03.266 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660303041-1-host1-rack1'}), timestamp=Optional.of(1.512660303E9)}), taskId=test-request-firstDeployId-1512660303041-1-host1-rack1, serverTimestamp=1512660303116, serverId='0340513d-68a8-4ce8-9f9d-e7cbea44f1d9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660303279-2-host1-rack1'}), timestamp=Optional.of(1.512660303E9)}), taskId=test-request-firstDeployId-1512660303279-2-host1-rack1, serverTimestamp=1512660303322, serverId='0340513d-68a8-4ce8-9f9d-e7cbea44f1d9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660303351-3-host1-rack1'}), timestamp=Optional.of(1.512660303E9)}), taskId=test-request-firstDeployId-1512660303351-3-host1-rack1, serverTimestamp=1512660303373, serverId='0340513d-68a8-4ce8-9f9d-e7cbea44f1d9', slaveId=Optional.absent()}
15:25:03.448 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:03.453 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:03.494 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660303279-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660303279-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660303279-2-host1-rack1, serverTimestamp=1512660303470, serverId='0340513d-68a8-4ce8-9f9d-e7cbea44f1d9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660303756-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660303756-2-host1-DEFAULT, serverTimestamp=1512660303837, serverId='334e769b-d57a-49bb-8477-156a2b62b781', slaveId=Optional.absent()}
15:25:04.163 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:25:04.177 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.153 sec - in com.hubspot.singularity.data.SandboxManagerTest
Running com.hubspot.singularity.data.StateManagerTest
15:25:04.353 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:04.595 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:04.718 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:160)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
15:25:04.725 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:05.525 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:06.152 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660303756-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:06.153 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660303756-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3f8e1896 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1d24f1bb[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:06.323 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:06.325 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:06.451 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.858 sec - in com.hubspot.singularity.data.InactiveSlaveManagerTest
Running com.hubspot.singularity.SingularityHistoryTest
15:25:06.976 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660306542-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660306542-3-host2-DEFAULT, serverTimestamp=1512660307247, serverId='55c11836-26d6-4a3f-a968-4f59046d6a79', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d3-1512660307387-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d3-1512660307387-1-host1-DEFAULT, serverTimestamp=1512660307495, serverId='deb75dcd-3322-45a4-92e0-280d1c908287', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660307544-4-host1-rack1'}), timestamp=Optional.of(1.512660307E9)}), taskId=test-request-firstDeployId-1512660307544-4-host1-rack1, serverTimestamp=1512660307651, serverId='55c11836-26d6-4a3f-a968-4f59046d6a79', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d4-1512660307670-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d4-1512660307670-1-host1-DEFAULT, serverTimestamp=1512660307708, serverId='deb75dcd-3322-45a4-92e0-280d1c908287', slaveId=Optional.absent()}
15:25:07.812 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660307738-5-host1-rack1'}), timestamp=Optional.of(1.512660307E9)}), taskId=test-request-firstDeployId-1512660307738-5-host1-rack1, serverTimestamp=1512660307805, serverId='55c11836-26d6-4a3f-a968-4f59046d6a79', slaveId=Optional.absent()}
15:25:08.241 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.035 sec - in com.hubspot.singularity.config.MergingSourceProviderTest
Running com.hubspot.singularity.SingularityAuthorizationHelperTest
15:25:08.524 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:08.666 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660308523-1-host1-rack1'}), timestamp=Optional.of(1.512660308E9)}), taskId=test-request-firstDeployId-1512660308523-1-host1-rack1, serverTimestamp=1512660308640, serverId='073655ee-e937-41ef-8d5f-8a4cd5d91b6c', slaveId=Optional.absent()}
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.718 sec - in com.hubspot.singularity.data.StateManagerTest
Running com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
15:25:08.940 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303531-2-UPDATED_REQUEST-1512660303482, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer33'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303756-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660303756-2-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:08.950 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303531-2-UPDATED_REQUEST-1512660303482, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer33'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303756-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660303756-2-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@44e67b7a rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7f79f51[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:09.064 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:34733] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x16031948aba0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:09.362 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:09.408 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:09.708 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660309588-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660309588-1-host1-rack1'}), timestamp=Optional.of(1.512660309E9)}), taskId=test-request-firstDeployId-1512660309588-1-host1-rack1, serverTimestamp=1512660309676, serverId='78b31347-be08-450d-a0e9-5b4f4c816212', slaveId=Optional.absent()}
15:25:09.835 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660309750-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660309750-1-host1-rack1'}), timestamp=Optional.of(1.512660309E9)}), taskId=test-request-firstDeployId-1512660309750-1-host1-rack1, serverTimestamp=1512660309818, serverId='78b31347-be08-450d-a0e9-5b4f4c816212', slaveId=Optional.absent()}
Tests run: 14, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.562 sec <<< FAILURE! - in com.hubspot.singularity.SingularityAuthorizationHelperTest
itRestrictsReadWriteChangesForNonAdminsAndGroupOwners(com.hubspot.singularity.SingularityAuthorizationHelperTest)  Time elapsed: 0.001 sec  <<< FAILURE!
java.lang.AssertionError: Expected exception: javax.ws.rs.WebApplicationException

Running com.hubspot.singularity.scheduler.SingularityMachineStatesTest
15:25:10.349 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:10.510 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:10.511 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660310631-1-host1-rack1'}), timestamp=Optional.of(1.51266031E9)}), taskId=test-request-firstDeployId-1512660310631-1-host1-rack1, serverTimestamp=1512660310764, serverId='8ca993f6-7435-446c-8d34-a4a6b7febe33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660310480-1-host1-rack1'}), timestamp=Optional.of(1.51266031E9)}), taskId=test-request-firstDeployId-1512660310480-1-host1-rack1, serverTimestamp=1512660310603, serverId='75a29715-e669-40ae-b2e7-012d4a79308a', slaveId=Optional.absent()}
15:25:10.882 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660310631-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660310631-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660310631-1-host1-rack1, serverTimestamp=1512660310870, serverId='8ca993f6-7435-446c-8d34-a4a6b7febe33', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311133-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660311133-2-host2-DEFAULT, serverTimestamp=1512660311174, serverId='8ca993f6-7435-446c-8d34-a4a6b7febe33', slaveId=Optional.absent()}
15:25:11.262 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:11.370 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311410-1-host1-rack1'}), timestamp=Optional.of(1.512660311E9)}), taskId=test-request-firstDeployId-1512660311410-1-host1-rack1, serverTimestamp=1512660311489, serverId='37c5b414-2948-475f-8a3a-ddce43b72cc4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311540-2-host1-rack1'}), timestamp=Optional.of(1.512660311E9)}), taskId=test-request-firstDeployId-1512660311540-2-host1-rack1, serverTimestamp=1512660311564, serverId='37c5b414-2948-475f-8a3a-ddce43b72cc4', slaveId=Optional.absent()}
15:25:11.741 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660308523-1-IMMEDIATE-1512660308523, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer877'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660308523-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:11.757 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 18, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 67.916 sec <<< FAILURE! - in com.hubspot.singularity.data.ValidatorTest
whenRunNowItForbidsTooLongRunIds(com.hubspot.singularity.data.ValidatorTest)  Time elapsed: 30.081 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

15:25:11.861 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660308523-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660308523-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660308523-1-host1-rack1, serverTimestamp=1512660311850, serverId='073655ee-e937-41ef-8d5f-8a4cd5d91b6c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311721-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660311721-1-host1-DEFAULT, serverTimestamp=1512660311958, serverId='2a7c2bea-4120-4e86-94bb-50f1331b86d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660311869-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660311869-1-host1-DEFAULT, serverTimestamp=1512660311946, serverId='37c5b414-2948-475f-8a3a-ddce43b72cc4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311873-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660311873-2-host2-DEFAULT, serverTimestamp=1512660312020, serverId='2a7c2bea-4120-4e86-94bb-50f1331b86d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311410-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660311410-1-host1-rack1, serverTimestamp=1512660312098, serverId='37c5b414-2948-475f-8a3a-ddce43b72cc4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660312169-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660312169-1-host2-DEFAULT, serverTimestamp=1512660312214, serverId='2a7c2bea-4120-4e86-94bb-50f1331b86d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660312170-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660312170-2-host2-DEFAULT, serverTimestamp=1512660312222, serverId='37c5b414-2948-475f-8a3a-ddce43b72cc4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660311721-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660311721-1-host1-DEFAULT, serverTimestamp=1512660312327, serverId='2a7c2bea-4120-4e86-94bb-50f1331b86d1', slaveId=Optional.absent()}
15:25:12.418 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:12.558 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660312708-1-host1-rack1'}), timestamp=Optional.of(1.512660312E9)}), taskId=test-request-firstDeployId-1512660312708-1-host1-rack1, serverTimestamp=1512660312782, serverId='0f74527b-6923-4cc5-8ca7-42a17ef3c471', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660313072-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660313072-1-host1-DEFAULT, serverTimestamp=1512660313123, serverId='0f74527b-6923-4cc5-8ca7-42a17ef3c471', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660312708-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660312708-1-host1-rack1, serverTimestamp=1512660313217, serverId='0f74527b-6923-4cc5-8ca7-42a17ef3c471', slaveId=Optional.absent()}
15:25:13.298 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660313606-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660313606-1-host1-DEFAULT, serverTimestamp=1512660313720, serverId='fb4859fa-91a0-4670-92c7-4ea0511555b3', slaveId=Optional.absent()}
15:25:14.179 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:14.836 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:14.860 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:15.005 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660314974-1-host1-rack1'}), timestamp=Optional.of(1.512660314E9)}), taskId=test-request-firstDeployId-1512660314974-1-host1-rack1, serverTimestamp=1512660315057, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
15:25:15.145 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660315127-2-host1-rack1'}), timestamp=Optional.of(1.512660315E9)}), taskId=test-request-firstDeployId-1512660315127-2-host1-rack1, serverTimestamp=1512660315161, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
15:25:15.185 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660315178-3-host1-rack1'}), timestamp=Optional.of(1.512660315E9)}), taskId=test-request-firstDeployId-1512660315178-3-host1-rack1, serverTimestamp=1512660315221, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
15:25:15.315 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660315471-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660315471-1-host1-DEFAULT, serverTimestamp=1512660315511, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660314974-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660314974-1-host1-rack1, serverTimestamp=1512660315556, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660315479-1-host1-rack1'}), timestamp=Optional.of(1.512660315E9)}), taskId=test-request-firstDeployId-1512660315479-1-host1-rack1, serverTimestamp=1512660315608, serverId='2114c513-f796-47d1-a98c-651f4e28dee1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660315676-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660315676-2-host2-DEFAULT, serverTimestamp=1512660315737, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
15:25:15.788 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660313606-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:15.789 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660313606-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@1c5addec rejected from java.util.concurrent.ScheduledThreadPoolExecutor@df8ac3a[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660315127-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660315127-2-host1-rack1, serverTimestamp=1512660315847, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660315914-1-host1-rack1'}), timestamp=Optional.of(1.512660315E9)}), taskId=test-request-firstDeployId-1512660315914-1-host1-rack1, serverTimestamp=1512660315958, serverId='2114c513-f796-47d1-a98c-651f4e28dee1', slaveId=Optional.absent()}
15:25:16.097 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660315960-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660315960-3-host2-DEFAULT, serverTimestamp=1512660316092, serverId='1a408f8d-95ce-4081-92f6-969b81ff28bf', slaveId=Optional.absent()}
15:25:16.598 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:16.673 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660316713-1-host1-rack1'}), timestamp=Optional.of(1.512660316E9)}), taskId=test-request-firstDeployId-1512660316713-1-host1-rack1, serverTimestamp=1512660316774, serverId='81535cd7-fbf2-40f1-8924-d7657a59d495', slaveId=Optional.absent()}
15:25:16.934 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660316713-1-host1-rack1
15:25:16.938 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660316713-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660316713-1-host1-rack1, serverTimestamp=1512660316928, serverId='81535cd7-fbf2-40f1-8924-d7657a59d495', slaveId=Optional.absent()}
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 8.177 sec - in com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
15:25:17.239 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512660317332-1-host1-rack1'}), timestamp=Optional.of(1.512660317E9)}), taskId=test-request-new_task_healthcheck-1512660317332-1-host1-rack1, serverTimestamp=1512660317397, serverId='961080ee-47f3-40c7-ad67-4a1b0a38fee0', slaveId=Optional.absent()}
15:25:17.729 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:18.153 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318047-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660318047-2-host2-DEFAULT, serverTimestamp=1512660318139, serverId='5899d40c-5cfd-4b59-8631-e733ec710baf', slaveId=Optional.absent()}
15:25:18.253 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.049 sec - in com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
15:25:18.549 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:18.566 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512660318608, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512660318742, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:18.753 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660313511-1-UPDATED_REQUEST-1512660313476, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer946'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660313606-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660313606-1-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=PORT, value=80}, {name=PORT0, value=80}, {name=PORT1, value=81}, {name=PORT2, value=82}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:18.755 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660313511-1-UPDATED_REQUEST-1512660313476, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer946'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660313606-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660313606-1-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=PORT, value=80}, {name=PORT0, value=80}, {name=PORT1, value=81}, {name=PORT2, value=82}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@183ad809 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1c054fd6[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318702-1-host1-rack1'}), timestamp=Optional.of(1.512660318E9)}), taskId=test-request-firstDeployId-1512660318702-1-host1-rack1, serverTimestamp=1512660318786, serverId='7e94bce0-1f03-416f-9990-25dfbc44da1c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512660318827, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318840-2-host1-rack1'}), timestamp=Optional.of(1.512660318E9)}), taskId=test-request-firstDeployId-1512660318840-2-host1-rack1, serverTimestamp=1512660318880, serverId='7e94bce0-1f03-416f-9990-25dfbc44da1c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318697-1-host1-rack1'}), timestamp=Optional.of(1.512660318E9)}), taskId=test-request-firstDeployId-1512660318697-1-host1-rack1, serverTimestamp=1512660318828, serverId='280e738e-082d-4a55-98b9-91c52065c6f5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512660318972, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.020 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512660319016, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.067 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660318697-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512660319077, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.089 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318697-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660318697-1-host1-rack1, serverTimestamp=1512660319056, serverId='280e738e-082d-4a55-98b9-91c52065c6f5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512660319140, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.172 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512660319160, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660319170-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660319170-1-host1-DEFAULT, serverTimestamp=1512660319226, serverId='7e94bce0-1f03-416f-9990-25dfbc44da1c', slaveId=Optional.absent()}
15:25:19.235 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-2-firstDeployId-15000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1512660319223, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.268 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-2-firstDeployId-35000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1512660319259, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.305 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-2-firstDeployId-25000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1512660319285, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660318702-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660318702-1-host1-rack1, serverTimestamp=1512660319363, serverId='7e94bce0-1f03-416f-9990-25dfbc44da1c', slaveId=Optional.absent()}
15:25:19.455 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='new_task_healthcheck', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.absent(), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-new_task_healthcheck-1512660317332-1-IMMEDIATE-1512660317332, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer885'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-new_task_healthcheck-1512660317332-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:19.456 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-new_task_healthcheck-1512660317332-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:19.458 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-new_task_healthcheck-1512660317332-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660319446-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660319446-2-host2-DEFAULT, serverTimestamp=1512660319508, serverId='7e94bce0-1f03-416f-9990-25dfbc44da1c', slaveId=Optional.absent()}
15:25:19.525 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:19.584 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512660319510, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.628 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512660319617, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.689 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-2-firstDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1512660319682, serverId='dbbaa7c4-f75a-4b0a-bcc7-226a8978e23b', slaveId=Optional.absent()}
15:25:19.737 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:45637] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194b4250000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:19.890 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660318840-2-IMMEDIATE-1512660318840, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer358'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660318840-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:19.892 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660318840-2-IMMEDIATE-1512660318840, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer358'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660318840-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5f291072 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@7f76024d[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:20.421 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660320494-1-host1-rack1'}), timestamp=Optional.of(1.51266032E9)}), taskId=test-request-firstDeployId-1512660320494-1-host1-rack1, serverTimestamp=1512660320553, serverId='43d02452-f3ee-4e43-a230-350668abaa9e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660320671-1-host1-rack1'}), timestamp=Optional.of(1.51266032E9)}), taskId=test-request-secondDeployId-1512660320671-1-host1-rack1, serverTimestamp=1512660320699, serverId='43d02452-f3ee-4e43-a230-350668abaa9e', slaveId=Optional.absent()}
15:25:20.724 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:20.892 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-hc_test-1512660320897-1-host1-rack1'}), timestamp=Optional.of(1.51266032E9)}), taskId=test-request-hc_test-1512660320897-1-host1-rack1, serverTimestamp=1512660320962, serverId='bed59c90-c9b7-4d93-9db6-b54bbe7c3859', slaveId=Optional.absent()}
15:25:21.196 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:21.211 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660321551-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660321551-1-host2-DEFAULT, serverTimestamp=1512660321625, serverId='dc259d53-dfb6-46dc-a7de-debaf19c5c1e', slaveId=Optional.absent()}
15:25:22.607 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:22.760 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:22.984 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='hc_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-hc_test-1512660320897-1-IMMEDIATE-1512660320897, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer571'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-hc_test-1512660320897-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:22.986 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-hc_test-1512660320897-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:22.988 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-hc_test-1512660320897-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:23.078 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:23.084 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660323019-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660323019-1-host2-DEFAULT, serverTimestamp=1512660323081, serverId='ba68d71f-7251-49ed-973b-9445a8179e76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660323019-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660323019-1-host2-DEFAULT, serverTimestamp=1512660323104, serverId='ba68d71f-7251-49ed-973b-9445a8179e76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512660323320, serverId='170490dc-600d-416e-91c9-083010ba766e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660324211-1-host1-rack1'}), timestamp=Optional.of(1.512660325E9)}), taskId=test-request-firstDeployId-1512660324211-1-host1-rack1, serverTimestamp=1512660323354, serverId='f77d7295-28d4-410d-8dbf-ff7a900ecfba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512660323409, serverId='170490dc-600d-416e-91c9-083010ba766e', slaveId=Optional.absent()}
15:25:23.492 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512660323487, serverId='170490dc-600d-416e-91c9-083010ba766e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327211-2-host1-rack1'}), timestamp=Optional.of(1.512660328E9)}), taskId=test-request-firstDeployId-1512660327211-2-host1-rack1, serverTimestamp=1512660323501, serverId='f77d7295-28d4-410d-8dbf-ff7a900ecfba', slaveId=Optional.absent()}
15:25:23.543 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44329] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194c6390000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327211-3-host1-rack1'}), timestamp=Optional.of(1.512660328E9)}), taskId=test-request-firstDeployId-1512660327211-3-host1-rack1, serverTimestamp=1512660323564, serverId='f77d7295-28d4-410d-8dbf-ff7a900ecfba', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-timeout_test-1512656723545-1-host1-rack1'}), timestamp=Optional.of(1.512656723E9)}), taskId=test-request-timeout_test-1512656723545-1-host1-rack1, serverTimestamp=1512660323715, serverId='56a7b9b0-b99e-4676-8474-4334caab0f3b', slaveId=Optional.absent()}
15:25:23.934 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:23.986 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44747] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194c9dd0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:24.420 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660324526-1-host1-rack1'}), timestamp=Optional.of(1.512660324E9)}), taskId=test-request-secondDeployId-1512660324526-1-host1-rack1, serverTimestamp=1512660324593, serverId='a0886200-f632-4aae-ba88-70b6274335a9', slaveId=Optional.absent()}
15:25:24.688 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42719] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194cba80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.157 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:25.417 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660324211-1-IMMEDIATE-1512660324211, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer749'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660324211-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:25.418 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660324211-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.420 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660324211-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4860c740 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@13b7f13f[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.509 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660327211-2-IMMEDIATE-1512660327211, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer513'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660327211-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:25.510 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660327211-2-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.513 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660327211-2-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@143d5c1d rejected from java.util.concurrent.ScheduledThreadPoolExecutor@13b7f13f[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.571 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660327211-3-IMMEDIATE-1512660327211, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer531'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660327211-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:25.572 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660327211-3-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.573 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660327211-3-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7bf199db rejected from java.util.concurrent.ScheduledThreadPoolExecutor@13b7f13f[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.726 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='timeout_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.of(86400000), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-timeout_test-1512656723545-1-IMMEDIATE-1512656723545, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer808'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-timeout_test-1512656723545-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:25.727 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-timeout_test-1512656723545-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.729 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-timeout_test-1512656723545-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:25.810 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:25.869 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660325916-1-host1-rack1'}), timestamp=Optional.of(1.512660145E9)}), taskId=test-request-firstDeployId-1512660325916-1-host1-rack1, serverTimestamp=1512660326012, serverId='f53ea684-37cd-4022-9e3f-63c58881c337', slaveId=Optional.absent()}
15:25:26.112 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660325916-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-deploy_test-1512660326009-1-host1-rack1'}), timestamp=Optional.of(1.512660326E9)}), taskId=test-request-deploy_test-1512660326009-1-host1-rack1, serverTimestamp=1512660326099, serverId='e75f53d8-4a4d-4aed-918e-52f7df706ce9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660325916-1-host1-rack1'}), timestamp=Optional.of(1.512660206E9)}), taskId=test-request-firstDeployId-1512660325916-1-host1-rack1, serverTimestamp=1512660326104, serverId='f53ea684-37cd-4022-9e3f-63c58881c337', slaveId=Optional.absent()}
15:25:26.144 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512660326308-1-host1-rack1'}), timestamp=Optional.of(1.512660326E9)}), taskId=test-request-retry_test-1512660326308-1-host1-rack1, serverTimestamp=1512660326391, serverId='1dfc97d8-a424-4484-adec-4eff22359cd6', slaveId=Optional.absent()}
15:25:26.458 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:26.872 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660326668-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660326668-1-host1-rack1, serverTimestamp=1512660326922, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660326777-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660326777-2-host2-rack1, serverTimestamp=1512660326944, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660326978-1-host1-rack1'}), timestamp=Optional.of(1.512660326E9)}), taskId=test-request-firstDeployId-1512660326978-1-host1-rack1, serverTimestamp=1512660327045, serverId='9bf986b8-1ff6-4791-99b4-a04baf89032e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327083-1-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327083-1-host4-rack2, serverTimestamp=1512660327182, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327144-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327144-3-host3-rack2, serverTimestamp=1512660327211, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660326668-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660326668-1-host1-rack1, serverTimestamp=1512660327259, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660326978-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660326978-1-host1-rack1, serverTimestamp=1512660327402, serverId='9bf986b8-1ff6-4791-99b4-a04baf89032e', slaveId=Optional.absent()}
15:25:27.481 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327447-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327447-1-host1-rack1, serverTimestamp=1512660327526, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
15:25:27.573 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327500-3-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327500-3-host2-rack1, serverTimestamp=1512660327572, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327144-3-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327144-3-host3-rack2, serverTimestamp=1512660327606, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327083-1-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327083-1-host4-rack2, serverTimestamp=1512660327659, serverId='80af5608-a22d-4288-b70d-2f0b0aade8dd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327602-1-host1-rack1'}), timestamp=Optional.of(1.512660327E9)}), taskId=test-request-firstDeployId-1512660327602-1-host1-rack1, serverTimestamp=1512660327676, serverId='20d4657e-be77-4bd7-83dd-d8717df80aae', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327726-2-host1-rack1'}), timestamp=Optional.of(1.512660327E9)}), taskId=test-request-firstDeployId-1512660327726-2-host1-rack1, serverTimestamp=1512660327757, serverId='20d4657e-be77-4bd7-83dd-d8717df80aae', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660327922-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660327922-1-host1-DEFAULT, serverTimestamp=1512660327960, serverId='20d4657e-be77-4bd7-83dd-d8717df80aae', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660327602-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660327602-1-host1-rack1, serverTimestamp=1512660328023, serverId='20d4657e-be77-4bd7-83dd-d8717df80aae', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660328107-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660328107-2-host2-DEFAULT, serverTimestamp=1512660328150, serverId='20d4657e-be77-4bd7-83dd-d8717df80aae', slaveId=Optional.absent()}
15:25:28.408 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(3), failureStatusCodes=Optional.of([404])}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512660326308-1-IMMEDIATE-1512660326308, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer63'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512660326308-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:28.410 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512660326308-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:28.412 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512660326308-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660328517-1-host2-DEFAULT'}), timestamp=Optional.of(1.512660328E9)}), taskId=test-request-firstDeployId-1512660328517-1-host2-DEFAULT, serverTimestamp=1512660328574, serverId='c2a698c1-8aac-4869-9061-1ecdb90871bf', slaveId=Optional.absent()}
15:25:28.709 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:28.847 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1512660328985-1-host1-rack1'}), timestamp=Optional.of(1.512660328E9)}), taskId=test-request-retry_test-1512660328985-1-host1-rack1, serverTimestamp=1512660329057, serverId='e738ffe3-5c45-42da-8e40-15b978ee7f87', slaveId=Optional.absent()}
15:25:29.185 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:53356] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194dca30000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:29.840 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:29.902 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:30.152 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:30.423 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660330355-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660330355-1-host2-DEFAULT, serverTimestamp=1512660330408, serverId='065e93ab-d30e-42a8-bba1-052877c3e396', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660330538-1-host1-rack1'}), timestamp=Optional.of(1.51266033E9)}), taskId=test-request-firstDeployId-1512660330538-1-host1-rack1, serverTimestamp=1512660330584, serverId='145922cc-e603-4bad-a65e-eba2124fc410', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660330649-1-host1-rack1'}), timestamp=Optional.of(1.51266033E9)}), taskId=test-request-secondDeployId-1512660330649-1-host1-rack1, serverTimestamp=1512660330684, serverId='145922cc-e603-4bad-a65e-eba2124fc410', slaveId=Optional.absent()}
15:25:30.735 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-secondDeployId-1512660330649-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660330649-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660330649-1-host1-rack1, serverTimestamp=1512660330726, serverId='145922cc-e603-4bad-a65e-eba2124fc410', slaveId=Optional.absent()}
15:25:30.761 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660330538-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660330538-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660330538-1-host1-rack1, serverTimestamp=1512660330755, serverId='145922cc-e603-4bad-a65e-eba2124fc410', slaveId=Optional.absent()}
15:25:30.818 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:56996] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194e3160000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:31.068 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1512660328985-1-IMMEDIATE-1512660328985, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer180'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1512660328985-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:25:31.069 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1512660328985-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:31.071 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1512660328985-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:516)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:25:31.228 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:31.360 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:31.479 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:31.724 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-startup_timeout_test-1512656731519-1-host1-rack1'}), timestamp=Optional.of(1.512656731E9)}), taskId=test-request-startup_timeout_test-1512656731519-1-host1-rack1, serverTimestamp=1512660331734, serverId='7bc17656-9f86-4743-ad41-06ecf5092727', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660331842-1-host1-rack1'}), timestamp=Optional.of(1.512660331E9)}), taskId=test-request-firstDeployId-1512660331842-1-host1-rack1, serverTimestamp=1512660331902, serverId='a5a9f0c0-d0c8-43d4-b43b-40b3f1d6bc8b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660331942-2-host1-rack1'}), timestamp=Optional.of(1.512660331E9)}), taskId=test-request-firstDeployId-1512660331942-2-host1-rack1, serverTimestamp=1512660331976, serverId='a5a9f0c0-d0c8-43d4-b43b-40b3f1d6bc8b', slaveId=Optional.absent()}
15:25:32.045 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:32.049 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:32.057 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:32.075 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660331842-1-host1-rack1
15:25:32.078 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660331842-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660331842-1-host1-rack1, serverTimestamp=1512660332069, serverId='a5a9f0c0-d0c8-43d4-b43b-40b3f1d6bc8b', slaveId=Optional.absent()}
15:25:32.111 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660331942-2-host1-rack1
15:25:32.118 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660331942-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660331942-2-host1-rack1, serverTimestamp=1512660332090, serverId='a5a9f0c0-d0c8-43d4-b43b-40b3f1d6bc8b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660332161-1-host1-rack1'}), timestamp=Optional.of(1.512660332E9)}), taskId=test-request-firstDeployId-1512660332161-1-host1-rack1, serverTimestamp=1512660332216, serverId='27346d38-b1ec-40d9-9315-3379b752ac67', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660332253-2-host1-rack1'}), timestamp=Optional.of(1.512660332E9)}), taskId=test-request-firstDeployId-1512660332253-2-host1-rack1, serverTimestamp=1512660332289, serverId='27346d38-b1ec-40d9-9315-3379b752ac67', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660332463-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660332463-1-host2-DEFAULT, serverTimestamp=1512660332527, serverId='27346d38-b1ec-40d9-9315-3379b752ac67', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660332499-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660332499-2-host2-DEFAULT, serverTimestamp=1512660332563, serverId='27346d38-b1ec-40d9-9315-3379b752ac67', slaveId=Optional.absent()}
15:25:32.591 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:32.853 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 48.34 sec - in com.hubspot.singularity.scheduler.SingularityHealthchecksTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512660333017, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512660333091, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512660333132, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512660333216, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512660333252, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512660333280, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512660333319, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.344 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(20.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1512660333336, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.372 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-2-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(21.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1512660333364, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.394 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-6-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(22.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1512660333387, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.446 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-4-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(23.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1512660333422, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.466 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-3-3-host3-rack1
15:25:33.475 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(24.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1512660333459, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.500 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-5-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(25.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1512660333491, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.522 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-7-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(26.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1512660333516, serverId='c47dd7c4-2e08-4db4-9e8a-43d0e30c1734', slaveId=Optional.absent()}
15:25:33.895 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:33.999 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52986] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194eef70000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:34.786 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:34.949 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512660334954, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512660335063, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512660335118, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335063-1-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335063-1-host1-rack1, serverTimestamp=1512660335139, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335181-2-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335181-2-host1-rack1, serverTimestamp=1512660335212, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335222-3-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335222-3-host1-rack1, serverTimestamp=1512660335256, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1512660335263, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335266-4-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335266-4-host1-rack1, serverTimestamp=1512660335300, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
15:25:35.308 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1512660335316, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1512660335365, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1512660335424, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
15:25:35.452 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(80.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1512660335435, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
15:25:35.479 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(90.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1512660335468, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
15:25:35.536 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-60000-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(100.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1512660335524, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335456-1-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335456-1-host1-rack1, serverTimestamp=1512660335518, serverId='9c35f94c-1687-4bc8-9afb-91bea37591c7', slaveId=Optional.absent()}
15:25:35.561 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-40000-4-host4-rack1
15:25:35.566 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(110.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1512660335550, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660335506-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660335506-2-host2-DEFAULT, serverTimestamp=1512660335603, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335570-2-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335570-2-host1-rack1, serverTimestamp=1512660335632, serverId='9c35f94c-1687-4bc8-9afb-91bea37591c7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660335556-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660335556-1-host2-DEFAULT, serverTimestamp=1512660335641, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335643-3-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335643-3-host1-rack1, serverTimestamp=1512660335696, serverId='9c35f94c-1687-4bc8-9afb-91bea37591c7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335063-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660335063-1-host1-rack1, serverTimestamp=1512660335736, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
15:25:35.789 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335181-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660335181-2-host1-rack1, serverTimestamp=1512660335760, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(120.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1512660335774, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
15:25:35.854 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-50000-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(130.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1512660335819, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
15:25:35.902 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335864-5-host1-rack1'}), timestamp=Optional.of(1.512660335E9)}), taskId=test-request-firstDeployId-1512660335864-5-host1-rack1, serverTimestamp=1512660335903, serverId='9c35f94c-1687-4bc8-9afb-91bea37591c7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(140.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1512660335883, serverId='40629af9-38dd-4df6-88ed-052bcbd4a8b3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660335864-5-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660335864-5-host1-rack1, serverTimestamp=1512660335920, serverId='9c35f94c-1687-4bc8-9afb-91bea37591c7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660335879-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660335879-4-host2-DEFAULT, serverTimestamp=1512660335947, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660335845-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660335845-3-host2-DEFAULT, serverTimestamp=1512660335998, serverId='51b20225-2554-4409-8d0a-a109d34617a9', slaveId=Optional.absent()}
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 29.619 sec - in com.hubspot.singularity.SingularityHistoryTest
15:25:37.336 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:37.526 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57332] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603194fe250000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.463 sec - in com.hubspot.singularity.scheduler.SingularityMachineStatesTest
15:25:38.168 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:38.302 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:38.351 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='firstDeployId', timestamp=1512660338173, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1512660338173}), updatedRequest=Optional.absent()} request was MISSING, removing deploy
15:25:38.472 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='secondDeployId', timestamp=1512660338405, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=0, stepComplete=false, autoAdvanceDeploySteps=false, failedDeployTasks=[], timestamp=1512660338405}), updatedRequest=Optional.absent()} request was PAUSED, removing deploy
15:25:39.541 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660339618-1-host1-rack1'}), timestamp=Optional.of(1.512660339E9)}), taskId=test-request-firstDeployId-1512660339618-1-host1-rack1, serverTimestamp=1512660339678, serverId='27fae0db-46ae-4527-95c7-af8f69070356', slaveId=Optional.absent()}
15:25:39.719 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:39.765 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660339618-1-host1-rack1
15:25:39.769 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660339618-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660339618-1-host1-rack1, serverTimestamp=1512660339755, serverId='27fae0db-46ae-4527-95c7-af8f69070356', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660339817-1-host1-rack1'}), timestamp=Optional.of(1.512660339E9)}), taskId=test-request-firstDeployId-1512660339817-1-host1-rack1, serverTimestamp=1512660339870, serverId='1943a434-858f-4d34-b30c-01ea38ac52a2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660339903-2-host1-rack1'}), timestamp=Optional.of(1.512660339E9)}), taskId=test-request-firstDeployId-1512660339903-2-host1-rack1, serverTimestamp=1512660339928, serverId='1943a434-858f-4d34-b30c-01ea38ac52a2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660340052-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660340052-1-host2-DEFAULT, serverTimestamp=1512660340089, serverId='1943a434-858f-4d34-b30c-01ea38ac52a2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660339817-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660339817-1-host1-rack1, serverTimestamp=1512660340152, serverId='1943a434-858f-4d34-b30c-01ea38ac52a2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660340240-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660340240-1-host2-DEFAULT, serverTimestamp=1512660340276, serverId='1943a434-858f-4d34-b30c-01ea38ac52a2', slaveId=Optional.absent()}
15:25:40.302 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:54298] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319507560000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:41.005 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:42.499 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:42.508 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660342606-1-host1-rack1'}), timestamp=Optional.of(1.512660342E9)}), taskId=test-request-firstDeployId-1512660342606-1-host1-rack1, serverTimestamp=1512660342665, serverId='e78224fc-d5da-4d38-8005-350a4cfb1d6e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660342697-2-host1-rack1'}), timestamp=Optional.of(1.512660342E9)}), taskId=test-request-firstDeployId-1512660342697-2-host1-rack1, serverTimestamp=1512660342720, serverId='e78224fc-d5da-4d38-8005-350a4cfb1d6e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660342748-1-host1-rack1'}), timestamp=Optional.of(1.512660342E9)}), taskId=test-request-firstDeployId-1512660342748-1-host1-rack1, serverTimestamp=1512660342802, serverId='95743be0-346d-44dc-b006-13f4d3d7b670', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660342847-2-host1-rack1'}), timestamp=Optional.of(1.512660342E9)}), taskId=test-request-firstDeployId-1512660342847-2-host1-rack1, serverTimestamp=1512660342876, serverId='95743be0-346d-44dc-b006-13f4d3d7b670', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660342856-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1512660342856-1-host2-DEFAULT, serverTimestamp=1512660342903, serverId='e78224fc-d5da-4d38-8005-350a4cfb1d6e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660342606-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660342606-1-host1-rack1, serverTimestamp=1512660342960, serverId='e78224fc-d5da-4d38-8005-350a4cfb1d6e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660343084-1-host1-rack1'}), timestamp=Optional.of(1.512660343E9)}), taskId=test-request-firstDeployId-1512660343084-1-host1-rack1, serverTimestamp=1512660343112, serverId='e78224fc-d5da-4d38-8005-350a4cfb1d6e', slaveId=Optional.absent()}
Tests run: 25, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 96.863 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityDeploysTest
testUsesNewRequestDataFromPendingDeploy(com.hubspot.singularity.scheduler.SingularityDeploysTest)  Time elapsed: 30.057 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

15:25:45.384 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:46.711 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346784-1-host1-rack1'}), timestamp=Optional.of(1.512660346E9)}), taskId=test-request-firstDeployId-1512660346784-1-host1-rack1, serverTimestamp=1512660346832, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346879-1-host1-rack1'}), timestamp=Optional.of(1.512660346E9)}), taskId=test-request-firstDeployId-1512660346879-1-host1-rack1, serverTimestamp=1512660346896, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
15:25:46.921 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660346784-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346784-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660346784-1-host1-rack1, serverTimestamp=1512660346916, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
15:25:46.939 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660346879-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346879-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660346879-1-host1-rack1, serverTimestamp=1512660346934, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346970-1-host1-rack1'}), timestamp=Optional.of(1.512660346E9)}), taskId=test-request-firstDeployId-1512660346970-1-host1-rack1, serverTimestamp=1512660346987, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
15:25:47.015 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660346970-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660346970-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660346970-1-host1-rack1, serverTimestamp=1512660347008, serverId='3dafe6e8-8340-48d4-86cf-e121f04744d7', slaveId=Optional.absent()}
15:25:48.286 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:49.557 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:50.960 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:52.397 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:53.673 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660353740-1-host1-rack1'}), timestamp=Optional.of(1.512660353E9)}), taskId=test-request-firstDeployId-1512660353740-1-host1-rack1, serverTimestamp=1512660353801, serverId='40b18496-2001-4c90-af36-a74fa8f830af', slaveId=Optional.absent()}
15:25:53.877 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:25:53.905 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660353740-1-host1-rack1
15:25:53.914 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660353740-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660353740-1-host1-rack1, serverTimestamp=1512660353899, serverId='40b18496-2001-4c90-af36-a74fa8f830af', slaveId=Optional.absent()}
15:25:55.144 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660355208-1-host1-rack1'}), timestamp=Optional.of(1.512660355E9)}), taskId=test-request-firstDeployId-1512660355208-1-host1-rack1, serverTimestamp=1512660355252, serverId='9264f0b5-f797-4932-91ad-66237e25b167', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660355380-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660355380-1-host1-DEFAULT, serverTimestamp=1512660355398, serverId='9264f0b5-f797-4932-91ad-66237e25b167', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660355208-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660355208-1-host1-rack1, serverTimestamp=1512660355432, serverId='9264f0b5-f797-4932-91ad-66237e25b167', slaveId=Optional.absent()}
15:25:57.627 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:25:57.821 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:52509] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x16031954d820000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:25:59.218 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:00.576 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:02.042 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:02.339 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:33193] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x16031955ea80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:03.504 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:03.721 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:49039] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319564770000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:04.877 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660365041-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660365041-2-host1-DEFAULT, serverTimestamp=1512660365185, serverId='f66104ac-66fc-44d6-ae5d-ff9dd5608052', slaveId=Optional.absent()}
[test-request-firstDeployId-1512660365200-2-TASK_DONE-1512660365200]
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660365084-4-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660365084-4-host1-DEFAULT, serverTimestamp=1512660365277, serverId='f66104ac-66fc-44d6-ae5d-ff9dd5608052', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660365105-5-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660365105-5-host1-DEFAULT, serverTimestamp=1512660365308, serverId='f66104ac-66fc-44d6-ae5d-ff9dd5608052', slaveId=Optional.absent()}
15:26:05.366 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:44010] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319569d60000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:06.504 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660366564-1-host1-rack1'}), timestamp=Optional.of(1.512660366E9)}), taskId=test-request-firstDeployId-1512660366564-1-host1-rack1, serverTimestamp=1512660366605, serverId='cd56e654-a7bd-4ddf-98e6-80f1891ccf8f', slaveId=Optional.absent()}
15:26:08.860 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660368924-1-host1-rack1'}), timestamp=Optional.of(1.512660368E9)}), taskId=test-request-firstDeployId-1512660368924-1-host1-rack1, serverTimestamp=1512660368969, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660368996-2-host1-rack1'}), timestamp=Optional.of(1.512660368E9)}), taskId=test-request-firstDeployId-1512660368996-2-host1-rack1, serverTimestamp=1512660369020, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369029-3-host1-rack1'}), timestamp=Optional.of(1.512660369E9)}), taskId=test-request-firstDeployId-1512660369029-3-host1-rack1, serverTimestamp=1512660369052, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369061-4-host1-rack1'}), timestamp=Optional.of(1.512660369E9)}), taskId=test-request-firstDeployId-1512660369061-4-host1-rack1, serverTimestamp=1512660369084, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.100 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660368924-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660368924-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660368924-1-host1-rack1, serverTimestamp=1512660369095, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.119 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660368996-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660368996-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660368996-2-host1-rack1, serverTimestamp=1512660369114, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.157 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660369029-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369029-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660369029-3-host1-rack1, serverTimestamp=1512660369151, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369189-1-host1-rack1'}), timestamp=Optional.of(1.512660369E9)}), taskId=test-request-firstDeployId-1512660369189-1-host1-rack1, serverTimestamp=1512660369205, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369227-2-host1-rack1'}), timestamp=Optional.of(1.512660369E9)}), taskId=test-request-firstDeployId-1512660369227-2-host1-rack1, serverTimestamp=1512660369244, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369267-3-host1-rack1'}), timestamp=Optional.of(1.512660369E9)}), taskId=test-request-firstDeployId-1512660369267-3-host1-rack1, serverTimestamp=1512660369283, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.308 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660369189-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369189-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660369189-1-host1-rack1, serverTimestamp=1512660369300, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.332 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660369227-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369227-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660369227-2-host1-rack1, serverTimestamp=1512660369326, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.368 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660369267-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369267-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660369267-3-host1-rack1, serverTimestamp=1512660369362, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.411 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660369061-4-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660369061-4-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660369061-4-host1-rack1, serverTimestamp=1512660369405, serverId='1f0f86f1-2684-4174-9891-c0eba423fd7a', slaveId=Optional.absent()}
15:26:09.459 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:50728] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603195795a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:10.596 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:10.696 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB delete request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512660370693, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-1512660370684-DELETE-1} (test-request-1512660370684-DELETE-1) got unexpected response FAILED
15:26:10.713 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41046] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319580420000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:11.891 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660371956-1-host1-rack1'}), timestamp=Optional.of(1.512660371E9)}), taskId=test-request-firstDeployId-1512660371956-1-host1-rack1, serverTimestamp=1512660371995, serverId='71863c40-dd9b-47b0-8fa6-675cb47f6282', slaveId=Optional.absent()}
15:26:14.303 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:15.830 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660375903-1-host1-rack1'}), timestamp=Optional.of(1.512660375E9)}), taskId=test-request-firstDeployId-1512660375903-1-host1-rack1, serverTimestamp=1512660375941, serverId='eeb9581c-f0ab-4e30-8630-c862fc1df342', slaveId=Optional.absent()}
15:26:16.012 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660375903-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660375903-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660375903-1-host1-rack1, serverTimestamp=1512660376007, serverId='eeb9581c-f0ab-4e30-8630-c862fc1df342', slaveId=Optional.absent()}
15:26:17.204 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660377268-1-host1-rack1'}), timestamp=Optional.of(1.512660377E9)}), taskId=test-request-firstDeployId-1512660377268-1-host1-rack1, serverTimestamp=1512660377306, serverId='0f7f9d80-f848-434b-835e-278ccc3a00f2', slaveId=Optional.absent()}
15:26:17.358 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660377268-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660377268-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660377268-1-host1-rack1, serverTimestamp=1512660377352, serverId='0f7f9d80-f848-434b-835e-278ccc3a00f2', slaveId=Optional.absent()}
15:26:17.400 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB removal request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1512660377387, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-firstDeployId-1512660377268-1-host1-rack1-REMOVE-1} (test-request-firstDeployId-1512660377268-1-host1-rack1-REMOVE-1) got unexpected response FAILED
15:26:18.555 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:19.804 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:21.144 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660381252-1-host1-rack1'}), timestamp=Optional.of(1.512660381E9)}), taskId=test-request-firstDeployId-1512660381252-1-host1-rack1, serverTimestamp=1512660381300, serverId='0dc0ac23-d837-4d4a-8d63-91d6b5c21fdc', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660381252-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660381252-1-host1-rack1, serverTimestamp=1512660381384, serverId='0dc0ac23-d837-4d4a-8d63-91d6b5c21fdc', slaveId=Optional.absent()}
15:26:23.583 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660383765-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660383765-1-host1-DEFAULT, serverTimestamp=1512660383797, serverId='30e13617-9537-4f3a-874a-b721d048d1c1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660383838-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660383838-1-host2-DEFAULT, serverTimestamp=1512660383866, serverId='30e13617-9537-4f3a-874a-b721d048d1c1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1512660383909-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1512660383909-1-host1-DEFAULT, serverTimestamp=1512660383924, serverId='30e13617-9537-4f3a-874a-b721d048d1c1', slaveId=Optional.absent()}
15:26:25.108 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660385171-1-host1-rack1'}), timestamp=Optional.of(1.512660385E9)}), taskId=test-request-firstDeployId-1512660385171-1-host1-rack1, serverTimestamp=1512660385209, serverId='ef76abd9-25da-425c-8866-5dba3a088d75', slaveId=Optional.absent()}
15:26:25.261 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660385171-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660385171-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660385171-1-host1-rack1, serverTimestamp=1512660385256, serverId='ef76abd9-25da-425c-8866-5dba3a088d75', slaveId=Optional.absent()}
15:26:25.430 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:58571] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603195b8f20000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:26.573 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:27.851 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:29.384 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:30.652 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660390776-1-host1-rack1'}), timestamp=Optional.of(1.51266039E9)}), taskId=test-request-firstDeployId-1512660390776-1-host1-rack1, serverTimestamp=1512660390834, serverId='a0b18329-f48a-4c59-99f6-666a72cf05d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660390872-2-host2-rack1'}), timestamp=Optional.of(1.51266039E9)}), taskId=test-request-firstDeployId-1512660390872-2-host2-rack1, serverTimestamp=1512660390903, serverId='a0b18329-f48a-4c59-99f6-666a72cf05d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660390997-2-host3-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512660390997-2-host3-DEFAULT, serverTimestamp=1512660391014, serverId='a0b18329-f48a-4c59-99f6-666a72cf05d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660390776-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660390776-1-host1-rack1, serverTimestamp=1512660391070, serverId='a0b18329-f48a-4c59-99f6-666a72cf05d1', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660391107-1-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512660391107-1-host1-DEFAULT, serverTimestamp=1512660391123, serverId='a0b18329-f48a-4c59-99f6-666a72cf05d1', slaveId=Optional.absent()}
15:26:32.907 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660390872-2-IMMEDIATE-1512660390872, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host2', id=SingularityMesosIdObject{value='offer745'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660390872-2-host2-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
15:26:32.908 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660390872-2-host2-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:32.909 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660390872-2-host2-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7f094e7b rejected from java.util.concurrent.ScheduledThreadPoolExecutor@71cebfea[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:33.019 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660390977-2-BOUNCE-1512660390914, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host3', id=SingularityMesosIdObject{value='offer595'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660390997-2-host3-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=2}, {name=TASK_HOST, value=host3}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660390997-2-host3-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
15:26:33.020 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660390997-2-host3-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:33.021 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660390997-2-host3-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5ce93240 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@71cebfea[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:33.127 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660391078-1-TASK_DONE-1512660391077, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer958'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660391107-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=INSTANCE_NO, value=1}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=TASK_REQUEST_ID, value=test-request}, {name=TASK_DEPLOY_ID, value=firstDeployId}, {name=TASK_ID, value=test-request-firstDeployId-1512660391107-1-host1-DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
15:26:33.128 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1512660391107-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:327)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:316)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:33.130 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1512660391107-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@4e728509 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@71cebfea[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:26:34.258 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:35.593 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660395655-1-host1-rack1'}), timestamp=Optional.of(1.512660395E9)}), taskId=test-request-firstDeployId-1512660395655-1-host1-rack1, serverTimestamp=1512660395709, serverId='03fb79e9-d117-469a-9a57-1ae2510d4f4b', slaveId=Optional.absent()}
15:26:37.983 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:37.989 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Unexpected taskId task 
com.hubspot.singularity.data.transcoders.SingularityTranscoderException: java.lang.reflect.InvocationTargetException
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:44)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.getTaskId(SingularityMesosStatusUpdateHandler.java:137)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:179)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:262)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:277)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testTaskOddities(SingularitySchedulerTest.java:1489)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException: null
	at sun.reflect.GeneratedMethodAccessor240.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:42)
	... 19 common frames omitted
Caused by: com.hubspot.singularity.InvalidSingularityTaskIdException: TaskId task was invalid (There must be at least 5 instances of - (there were 0))
	at com.hubspot.singularity.SingularityTaskId.valueOf(SingularityTaskId.java:114)
	... 23 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660398044-1-host1-rack1'}), timestamp=Optional.of(1.512660398E9)}), taskId=test-request-firstDeployId-1512660398044-1-host1-rack1, serverTimestamp=1512660398082, serverId='8d6c450f-f932-4061-86a1-7a212fc7796b', slaveId=Optional.absent()}
15:26:38.139 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Task test-request-firstDeployId-1512660398044-1-host1-rack1 is active but is missing task data
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660398044-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660398044-1-host1-rack1, serverTimestamp=1512660398138, serverId='8d6c450f-f932-4061-86a1-7a212fc7796b', slaveId=Optional.absent()}
15:26:38.155 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660398044-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660398044-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660398044-1-host1-rack1, serverTimestamp=1512660398151, serverId='8d6c450f-f932-4061-86a1-7a212fc7796b', slaveId=Optional.absent()}
[SingularityTaskHistoryUpdate[timestamp=1512660398137, taskState=TASK_RUNNING, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]], SingularityTaskHistoryUpdate[timestamp=1512660398151, taskState=TASK_FAILED, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]]]
15:26:38.191 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:36480] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x1603195eb250000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:39.318 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:41.026 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401098-1-host1-rack1'}), timestamp=Optional.of(1.512660401E9)}), taskId=test-request-firstDeployId-1512660401098-1-host1-rack1, serverTimestamp=1512660401141, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401171-2-host1-rack1'}), timestamp=Optional.of(1.512660401E9)}), taskId=test-request-firstDeployId-1512660401171-2-host1-rack1, serverTimestamp=1512660401196, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401205-3-host1-rack1'}), timestamp=Optional.of(1.512660401E9)}), taskId=test-request-firstDeployId-1512660401205-3-host1-rack1, serverTimestamp=1512660401229, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401422-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512660401422-2-host1-DEFAULT, serverTimestamp=1512660401455, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401379-3-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512660401379-3-host1-DEFAULT, serverTimestamp=1512660401463, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660401404-1-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1512660401404-1-host1-DEFAULT, serverTimestamp=1512660401480, serverId='a3ad0da4-059d-4d02-8f2a-a135567fd84c', slaveId=Optional.absent()}
15:26:43.675 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:44.871 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:45.004 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:56845] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319606190000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:46.161 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512649606224-1-host1-rack1'}), timestamp=Optional.of(1.512660406E9)}), taskId=test-request-firstDeployId-1512649606224-1-host1-rack1, serverTimestamp=1512660406265, serverId='1f069599-df1f-42b7-b4b5-eda2a8fceb7b', slaveId=Optional.absent()}
15:26:46.322 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512649606224-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512649606224-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512649606224-1-host1-rack1, serverTimestamp=1512660406318, serverId='1f069599-df1f-42b7-b4b5-eda2a8fceb7b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660405724-1-host1-rack1'}), timestamp=Optional.of(1.512660406E9)}), taskId=test-request-firstDeployId-1512660405724-1-host1-rack1, serverTimestamp=1512660406362, serverId='1f069599-df1f-42b7-b4b5-eda2a8fceb7b', slaveId=Optional.absent()}
15:26:46.378 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660405724-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660405724-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660405724-1-host1-rack1, serverTimestamp=1512660406373, serverId='1f069599-df1f-42b7-b4b5-eda2a8fceb7b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660405722-1-host1-rack1'}), timestamp=Optional.of(1.512660406E9)}), taskId=test-request-firstDeployId-1512660405722-1-host1-rack1, serverTimestamp=1512660406436, serverId='1f069599-df1f-42b7-b4b5-eda2a8fceb7b', slaveId=Optional.absent()}
15:26:48.662 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:49.014 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:39450] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319614c70000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:26:50.150 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660410211-1-host1-rack1'}), timestamp=Optional.of(1.51266041E9)}), taskId=test-request-firstDeployId-1512660410211-1-host1-rack1, serverTimestamp=1512660410254, serverId='5c87aa6a-f927-4015-a650-609b0a531c14', slaveId=Optional.absent()}
15:26:50.317 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:26:50.344 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660410211-1-host1-rack1
15:26:50.351 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660410211-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660410211-1-host1-rack1, serverTimestamp=1512660410338, serverId='5c87aa6a-f927-4015-a650-609b0a531c14', slaveId=Optional.absent()}
15:26:51.569 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:52.831 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660412891-1-host1-rack1'}), timestamp=Optional.of(1.512660412E9)}), taskId=test-request-firstDeployId-1512660412891-1-host1-rack1, serverTimestamp=1512660412925, serverId='c3f42028-b4b1-458c-8b29-2155d05d47c3', slaveId=Optional.absent()}
15:26:52.968 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660412891-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660412891-1-host1-rack1'}), timestamp=Optional.of(1.512642412E9)}), taskId=test-request-firstDeployId-1512660412891-1-host1-rack1, serverTimestamp=1512660412964, serverId='c3f42028-b4b1-458c-8b29-2155d05d47c3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660412979-1-host1-rack1'}), timestamp=Optional.of(1.512660412E9)}), taskId=test-request-firstDeployId-1512660412979-1-host1-rack1, serverTimestamp=1512660413009, serverId='c3f42028-b4b1-458c-8b29-2155d05d47c3', slaveId=Optional.absent()}
15:26:53.022 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660412979-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660412979-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660412979-1-host1-rack1, serverTimestamp=1512660413017, serverId='c3f42028-b4b1-458c-8b29-2155d05d47c3', slaveId=Optional.absent()}
15:26:54.191 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512660414365-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512660414365-1-host2-DEFAULT, serverTimestamp=1512660414397, serverId='e6f8e3a1-43b1-41c1-abee-47678411eac9', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1512660414451-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1512660414451-1-host2-DEFAULT, serverTimestamp=1512660414465, serverId='e6f8e3a1-43b1-41c1-abee-47678411eac9', slaveId=Optional.absent()}
15:26:55.631 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.of(1.512660415E9)}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512660415799, serverId='72281ed0-507a-43bf-a2c2-9e0a6189804b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1'}), timestamp=Optional.of(1.512660415E9)}), taskId=mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1, serverTimestamp=1512660415859, serverId='72281ed0-507a-43bf-a2c2-9e0a6189804b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='highPriorityRequest-highPriorityDeploy-10-1-host1-rack1'}), timestamp=Optional.of(1.512660415E9)}), taskId=highPriorityRequest-highPriorityDeploy-10-1-host1-rack1, serverTimestamp=1512660415903, serverId='72281ed0-507a-43bf-a2c2-9e0a6189804b', slaveId=Optional.absent()}
15:26:55.957 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1512660415952, serverId='72281ed0-507a-43bf-a2c2-9e0a6189804b', slaveId=Optional.absent()}
15:26:58.190 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:26:59.593 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660419662-1-host1-rack1'}), timestamp=Optional.of(1.512660419E9)}), taskId=test-request-firstDeployId-1512660419662-1-host1-rack1, serverTimestamp=1512660419705, serverId='885131a8-18cc-49ec-98fd-f2d75b6bdc93', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660419732-2-host1-rack1'}), timestamp=Optional.of(1.512660419E9)}), taskId=test-request-firstDeployId-1512660419732-2-host1-rack1, serverTimestamp=1512660419756, serverId='885131a8-18cc-49ec-98fd-f2d75b6bdc93', slaveId=Optional.absent()}
15:26:59.786 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660419662-1-host1-rack1
15:26:59.789 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660419662-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660419662-1-host1-rack1, serverTimestamp=1512660419781, serverId='885131a8-18cc-49ec-98fd-f2d75b6bdc93', slaveId=Optional.absent()}
15:26:59.821 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
15:26:59.836 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1512660419732-2-host1-rack1
15:26:59.841 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660419732-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1512660419732-2-host1-rack1, serverTimestamp=1512660419832, serverId='885131a8-18cc-49ec-98fd-f2d75b6bdc93', slaveId=Optional.absent()}
15:27:01.048 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:27:02.485 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:27:03.898 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1512660423955-1-host1-rack1'}), timestamp=Optional.of(1.512660423E9)}), taskId=test-request-firstDeployId-1512660423955-1-host1-rack1, serverTimestamp=1512660423990, serverId='63f62e7c-21c6-466d-8a1a-b034a5d8f9e3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1512660424043-1-host1-rack1'}), timestamp=Optional.of(1.512660424E9)}), taskId=test-request-secondDeployId-1512660424043-1-host1-rack1, serverTimestamp=1512660424071, serverId='63f62e7c-21c6-466d-8a1a-b034a5d8f9e3', slaveId=Optional.absent()}
15:27:04.258 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303041-1-IMMEDIATE-1512660303041, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer935'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303041-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:04.259 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303041-1-IMMEDIATE-1512660303041, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer935'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303041-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@77df81ac rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4a696626[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:04.383 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303351-3-IMMEDIATE-1512660303351, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer239'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303351-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:04.384 [check-new-task-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660303351-3-IMMEDIATE-1512660303351, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer239'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660303351-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5a44fe9c rejected from java.util.concurrent.ScheduledThreadPoolExecutor@4a696626[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:05.009 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660423955-1-IMMEDIATE-1512660423955, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer154'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660423955-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:174)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:05.012 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1512660423955-1-IMMEDIATE-1512660423955, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer154'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1512660423955-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5c055c0f rejected from java.util.concurrent.ScheduledThreadPoolExecutor@52c2a9ff[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
15:27:06.186 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:27:06.469 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:48459] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319659420000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
15:27:07.604 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:27:08.924 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
15:27:09.204 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:57026] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160319664260000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 75, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 137.845 sec - in com.hubspot.singularity.scheduler.SingularitySchedulerTest

Results :

Failed tests: 
  SingularityAuthorizationHelperTest.itRestrictsReadWriteChangesForNonAdminsAndGroupOwners Expected exception: javax.ws.rs.WebApplicationException
Tests in error: 
  ValidatorTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut test t...
  ZkMigrationTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut test...
  SingularityStartupTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  HistoryPersisterTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut
  SingularityDeploysTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut
  SingularityExpiringActionsTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut
  SingularityUsageTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut

Tests run: 255, Failures: 1, Errors: 7, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Singularity ........................................ SUCCESS [  3.250 s]
[INFO] SingularityBase .................................... SUCCESS [  4.435 s]
[INFO] SingularityUI ...................................... SUCCESS [03:09 min]
[INFO] SingularityMesosClient ............................. SUCCESS [  2.933 s]
[INFO] SingularitySwagger ................................. SUCCESS [  1.730 s]
[INFO] SingularityService ................................. FAILURE [03:39 min]
[INFO] SingularityRunnerBase .............................. SKIPPED
[INFO] SingularityS3Base .................................. SKIPPED
[INFO] SingularityClient .................................. SKIPPED
[INFO] SingularityExecutor ................................ SKIPPED
[INFO] SingularityExecutorCleanup ......................... SKIPPED
[INFO] SingularityS3Uploader .............................. SKIPPED
[INFO] SingularityS3Downloader ............................ SKIPPED
[INFO] EmbedSingularityExample ............................ SKIPPED
[INFO] SingularityServiceIntegrationTests ................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 07:01 min
[INFO] Finished at: 2017-12-07T16:27:09+01:00
[INFO] Final Memory: 143M/1988M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project SingularityService: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/HubSpot/Singularity/312989843/SingularityService/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :SingularityService
