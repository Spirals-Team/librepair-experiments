[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Singularity
[INFO] SingularityBase
[INFO] SingularityUI
[INFO] SingularityMesosClient
[INFO] SingularitySwagger
[INFO] SingularityService
[INFO] SingularityRunnerBase
[INFO] SingularityS3Base
[INFO] SingularityClient
[INFO] SingularityExecutor
[INFO] SingularityExecutorCleanup
[INFO] SingularityS3Uploader
[INFO] SingularityS3Downloader
[INFO] EmbedSingularityExample
[INFO] SingularityServiceIntegrationTests
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Singularity 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ Singularity ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ Singularity ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ Singularity ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ Singularity ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ Singularity ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ Singularity ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ Singularity ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/target/jacoco.exec
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityBase 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityBase ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityBase ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityBase ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityBase ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/RequestCleanupType.java:12:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/SlaveMatchState.java:18:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/TaskCleanupType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/RequestType.java:13:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/HealthcheckProtocol.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/RequestState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/java/com/hubspot/singularity/DeployState.java:9:3: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityBase ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityBase ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityBase ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/SingularityBase/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityBase ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityBase ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityBase/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityBase ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityBase ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityUI 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityUI ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityUI ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityUI ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityUI ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityUI ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityUI ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityUI ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/SingularityUI/target/jacoco.exec
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:install-node-and-npm (install node and npm) @ SingularityUI ---
[INFO] Node v6.2.1 is already installed.
[INFO] Found NPM version 3.9.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm install) @ SingularityUI ---
[INFO] Running 'npm install --color=false' in /root/workspace/HubSpot/Singularity/319411833/SingularityUI
[ERROR] npm WARN optional Skipping failed optional dependency /chokidar/fsevents:
[ERROR] npm WARN notsup Not compatible with your operating system or architecture: fsevents@1.1.3
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:npm (npm test) @ SingularityUI ---
[INFO] Running 'npm test --color=false' in /root/workspace/HubSpot/Singularity/319411833/SingularityUI
[INFO] 
[INFO] > SingularityUI@0.3.0 test /root/workspace/HubSpot/Singularity/319411833/SingularityUI
[INFO] > mocha --compilers js:babel-core/register test/index.test
[INFO] 
[ERROR] Warning: Accessing PropTypes via the main React package is deprecated, and will be removed in  React v16.0. Use the latest available v15.* prop-types package from npm instead. For info on usage, compatibility, migration and more, see https://fb.me/prop-types-docs
[INFO] 
[INFO] 
[INFO]   Utils
[INFO]     getTaskDataFromTaskId()
[INFO]       âœ“ should grab all fields from a valid task id
[INFO] 
[INFO]   Reducers
[INFO]     tailerView
[INFO]       âœ“ should be properly initialized
[INFO]       âœ“ should populate the tailerId field
[INFO]       âœ“ should auto-populate the requestIds, taskIds, and paths fields
[INFO]       âœ“ should add tailer groups
[INFO]       âœ“ should remove tailer groups
[INFO]       âœ“ should pick an individual tailer group
[INFO] 
[INFO] 
[INFO]   7 passing (35ms)
[INFO] 
[INFO] 
[INFO] --- frontend-maven-plugin:0.0.23:gulp (gulp build) @ SingularityUI ---
[INFO] Running 'gulp build --no-color' in /root/workspace/HubSpot/Singularity/319411833/SingularityUI
[INFO] [23:19:53] Using gulpfile ~/workspace/HubSpot/Singularity/319411833/SingularityUI/gulpfile.js
[INFO] [23:19:53] Starting 'clean'...
[INFO] [23:19:53] Finished 'clean' after 49 ms
[INFO] [23:19:53] Starting 'static'...
[INFO] [23:19:53] Finished 'static' after 57 ms
[INFO] [23:19:53] Starting 'html'...
[INFO] [23:19:53] Finished 'html' after 29 ms
[INFO] [23:19:53] Starting 'build'...
[INFO] [23:22:24] Version: webpack [1m1.13.1[22m
[INFO] Time: [1m150552[22mms
[INFO]                                [1mAsset[22m     [1mSize[22m  [1mChunks[22m  [1m[22m           [1mChunk Names[22m
[INFO] [1m[32m89889688147bd7575d6327160d64e760.svg[39m[22m   109 kB        [1m[22m  [1m[32m[emitted][39m[22m  
[INFO]                  [1m[32mjs/vendor.bundle.js[39m[22m   622 kB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                     [1m[32mjs/app.bundle.js[39m[22m   2.2 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                          [1m[32mcss/app.css[39m[22m   350 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]              [1m[32mjs/vendor.bundle.js.map[39m[22m  4.64 MB       [1m0[22m  [1m[32m[emitted][39m[22m  js/vendor
[INFO]                 [1m[32mjs/app.bundle.js.map[39m[22m  10.5 MB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO]                      [1m[32mcss/app.css.map[39m[22m   419 kB       [1m1[22m  [1m[32m[emitted][39m[22m  js/app
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] Child [1mextract-text-webpack-plugin[22m:
[INFO]     
[INFO] [23:22:24] Finished 'build' after 2.52 min
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-index.html-template) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-resources-plugin:2.7:copy-resources (copy-ui) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 17 resources
[INFO] 
[INFO] --- build-helper-maven-plugin:1.10:add-resource (add-generated-resources) @ SingularityUI ---
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityUI/src/main/resources
[INFO] Copying 18 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityUI ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityUI/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityUI ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityUI ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityMesosClient 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityMesosClient ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityMesosClient ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:29:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:31:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:33:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:35:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/java/com/hubspot/mesos/client/MesosClient.java:37:3: Redundant 'public' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityMesosClient ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityMesosClient ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityMesosClient ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityMesosClient ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityMesosClient ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularityMesosClient/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityMesosClient ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityMesosClient ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularitySwagger 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularitySwagger ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularitySwagger ---
[INFO] Starting audit...
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularitySwagger ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularitySwagger ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularitySwagger ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/SingularitySwagger/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularitySwagger/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularitySwagger ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularitySwagger ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /root/workspace/HubSpot/Singularity/319411833/SingularitySwagger/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularitySwagger ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularitySwagger ---
[INFO] No tests to run.
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building SingularityService 0.19.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- property-helper-maven-plugin:2.0:get (get-build-id) @ SingularityService ---
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (default) @ SingularityService ---
[INFO] 
[INFO] --- maven-dependency-versions-check-plugin:2.0.2:check (default) @ SingularityService ---
[INFO] Checking dependency versions
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (default) @ SingularityService ---
[INFO] Starting audit...
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/hooks/LoadBalancerClientImpl.java:114:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:12:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:14:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:16:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:18:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:20:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:22:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:24:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/mesos/OfferCache.java:26:3: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:175:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:224:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:249:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:289:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/scheduler/SingularityExpiringUserActionPoller.java:315:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/config/UIConfiguration.java:22:10: Redundant 'static' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorManager.java:64:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityCmdLineArgsMigration.java:57:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:84:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/zkmigrations/SingularityRequestTypeMigration.java:139:9: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/history/SingularityHistoryModule.java:126:5: Redundant 'public' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/data/CuratorAsyncManager.java:46:5: Redundant 'private' modifier. [RedundantModifier]
[WARN] /root/workspace/HubSpot/Singularity/319411833/SingularityService/src/main/java/com/hubspot/singularity/smtp/SmtpMailer.java:366:5: Redundant 'private' modifier. [RedundantModifier]
Audit done.
[INFO] 
[INFO] --- dependency-management-plugin:0.4:analyze (analyze) @ SingularityService ---
[INFO] No dependency management issues found
[INFO] 
[INFO] --- git-commit-id-plugin:2.2.0:revision (default) @ SingularityService ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.7.5.201505241946:prepare-agent (default) @ SingularityService ---
[INFO] argLine set to -javaagent:/root/./workspace/HubSpot/Singularity/319411833/.m2/org/jacoco/org.jacoco.agent/0.7.5.201505241946/org.jacoco.agent-0.7.5.201505241946-runtime.jar=destfile=/root/workspace/HubSpot/Singularity/319411833/SingularityService/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.7:resources (default-resources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 9 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:compile (default-compile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- swagger-maven-plugin:2.3.2:generate (build-embedded-documentation) @ SingularityService ---
[INFO] Reflections took 82 ms to scan 1 urls, producing 12 keys and 78 values 
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UsageResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskTrackerResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DisastersResource
[INFO] Detect Resource:com.hubspot.singularity.resources.SandboxResource
[INFO] Detect Resource:com.hubspot.singularity.resources.StateResource
[INFO] Detect Resource:com.hubspot.singularity.resources.UserResource
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
UNKNOWN TYPE: com.hubspot.singularity.SingularityPaginatedResponse
[INFO] Detect Resource:com.hubspot.singularity.resources.HistoryResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.PriorityResource
[INFO] Detect Resource:com.hubspot.singularity.resources.InactiveSlaveResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.S3LogResource
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.DeployResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.SlaveResource
removing duplicate
removing duplicate
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.RackResource
removing duplicate
[INFO] Detect Resource:com.hubspot.singularity.resources.WebhookResource
[INFO] Detect Resource:com.hubspot.singularity.resources.RequestGroupResource
UNKNOWN TYPE: java.lang.Iterable
removing duplicate
removing duplicate
removing duplicate
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
UNKNOWN TYPE: java.lang.Iterable
[INFO] Detect Resource:com.hubspot.singularity.resources.TaskResource
[INFO] Detect Resource:com.hubspot.singularity.resources.TestResource
[INFO] Writing doc to /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/index.html...
[INFO] Done!
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/service.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_requests.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_usage.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_track.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_disasters.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_sandbox.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_state.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_users.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_history.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_priority.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_inactive.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_logs.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_deploys.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_slaves.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_racks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_webhooks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_groups.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_tasks.json
[INFO] Creating file /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/classes/assets/api-docs/api_test.json
[INFO] 
[INFO] --- maven-resources-plugin:2.7:testResources (default-testResources) @ SingularityService ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.3:testCompile (default-testCompile) @ SingularityService ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-surefire-plugin:2.19:test (default-test) @ SingularityService ---
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.pom (4 KB at 9.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.19/surefire-providers-2.19.pom (3 KB at 119.1 KB/sec)
[INFO] Downloading: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar
[INFO] Downloaded: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.19/surefire-junit4-2.19.jar (75 KB at 1121.4 KB/sec)

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
Running com.hubspot.singularity.scheduler.SingularityHealthchecksTest
Running com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
Running com.hubspot.singularity.scheduler.SingularityMachineStatesTest
Running com.hubspot.singularity.data.StateManagerTest
Running com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
Running com.hubspot.singularity.data.ValidatorTest
Running com.hubspot.singularity.helpers.RFC5545ScheduleTest
23:23:04.271 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 431949360)
23:23:04.397 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:04.293 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 203697846)
23:23:04.414 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:04.508 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1335312345)
23:23:04.649 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:04.723 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1906790612)
23:23:04.851 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:04.901 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1496113856)
23:23:05.065 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:05.360 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1188243953)
23:23:05.472 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.202 sec - in com.hubspot.singularity.helpers.RFC5545ScheduleTest
Running com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
23:23:07.550 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 1851828702)
23:23:07.634 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:10.699 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:10.735 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @13611ms
23:23:10.888 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@65750ebb
23:23:10.984 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@218e565f{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@720e81c,MANAGED}
23:23:11.011 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@78dd82da
23:23:11.021 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@2215d8b5{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@65f774fb,MANAGED}
23:23:11.232 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@65f774fb added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:11.253 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@65f774fb added {[/tasks/*]=>tasks,POJO}
23:23:11.810 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:11.833 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14721ms
23:23:11.849 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:11.887 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14778ms
23:23:11.914 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:11.954 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @14849ms
23:23:11.964 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@39845efb
23:23:12.016 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@5bbd8230
23:23:12.035 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@70d9f9bd{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@ab6c149,MANAGED}
23:23:12.049 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6b435f4d
23:23:12.050 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7e18bf6{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@71b20cf,MANAGED}
23:23:12.076 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:12.070 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@23393014{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@4c293f94,MANAGED}
23:23:12.101 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@edf8180
23:23:12.104 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@b5320b4{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2fc8117d,MANAGED}
23:23:12.105 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@452e7f73
23:23:12.131 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @15014ms
23:23:12.178 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@76446317{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@53a6c4,MANAGED}
23:23:12.190 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@64b7a5f
23:23:12.197 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@71b20cf added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:12.203 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@71b20cf added {[/tasks/*]=>tasks,POJO}
23:23:12.208 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@74510fe4{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2f3469a8,MANAGED}
23:23:12.253 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2fc8117d added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:12.312 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2fc8117d added {[/tasks/*]=>tasks,POJO}
23:23:12.338 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@4c8ae525
23:23:12.359 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2f3469a8 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:12.384 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2f3469a8 added {[/tasks/*]=>tasks,POJO}
23:23:12.500 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@46103177{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@6c503309,MANAGED}
23:23:12.513 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@45932dce
23:23:12.514 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@3330d9ab{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@370d5132,MANAGED}
23:23:12.728 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@370d5132 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:12.732 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@370d5132 added {[/tasks/*]=>tasks,POJO}
23:23:13.337 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:13.333 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:13.367 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @16274ms
23:23:13.391 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @16288ms
23:23:13.523 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@5a9e252b
23:23:13.585 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@401fdc42{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@3ef10a9,MANAGED}
23:23:13.611 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@6d74ce79
23:23:13.612 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@b61fbc9{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@74e91d3c,MANAGED}
23:23:13.670 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@1083f7ac
23:23:13.755 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@74e91d3c added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:13.780 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@74e91d3c added {[/tasks/*]=>tasks,POJO}
23:23:13.806 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@371094cf{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@7e6d0baa,MANAGED}
23:23:13.818 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@dccbe73
23:23:13.819 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@13fcfae9{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@6983e2cc,MANAGED}
23:23:14.053 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@6983e2cc added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:14.058 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@6983e2cc added {[/tasks/*]=>tasks,POJO}
23:23:16.687 [Time-limited test] WARN com.squarespace.jersey2.guice.JerseyGuiceUtils - It appears jersey2-guice-spi is either not present or in conflict with some other Jar: ServiceLocatorGeneratorImpl(hk2-locator, 314609426)
23:23:16.788 [Time-limited test] INFO com.squarespace.jersey2.guice.JerseyGuiceUtils - Attempting to install (using relfection) a Guice-aware ServiceLocatorFactory...
23:23:21.734 [Time-limited test] DEBUG org.eclipse.jetty.util.log - Logging to Logger[org.eclipse.jetty.util.log] via org.eclipse.jetty.util.log.Slf4jLog
23:23:21.767 [Time-limited test] INFO org.eclipse.jetty.util.log - Logging initialized @24659ms
23:23:21.890 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@3728de6b
23:23:21.982 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@bcdab40{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@5ea0e3c7,MANAGED}
23:23:21.990 [Time-limited test] DEBUG org.eclipse.jetty.util.DecoratedObjectFactory - Adding Decorator: org.eclipse.jetty.util.DeprecationWarning@4d4fb10d
23:23:21.992 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - i.d.j.MutableServletContextHandler@7ac05481{/,null,null} added {org.eclipse.jetty.servlet.ServletHandler@2b4d2da8,MANAGED}
23:23:22.087 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2b4d2da8 added {tasks@6907b8e==io.dropwizard.servlets.tasks.TaskServlet,1,true,AUTO}
23:23:22.114 [Time-limited test] DEBUG org.eclipse.jetty.util.component.ContainerLifeCycle - org.eclipse.jetty.servlet.ServletHandler@2b4d2da8 added {[/tasks/*]=>tasks,POJO}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 32.379 sec <<< FAILURE! - in com.hubspot.singularity.data.StateManagerTest
itDoesntCountCleaningTasks(com.hubspot.singularity.data.StateManagerTest)  Time elapsed: 30.06 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.data.BlendedHistoryTest
23:23:34.069 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:34.557 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:36.301 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:37.128 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:37.404 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:37.751 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:37.843 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:37.806 [Curator-LeaderLatch-0] ERROR org.apache.curator.framework.recipes.AfterConnectionEstablished - An error occurred blocking until a connection is available
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.curator.framework.state.ConnectionStateManager.blockUntilConnected(ConnectionStateManager.java:215)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:212)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.blockUntilConnected(CuratorFrameworkImpl.java:218)
	at org.apache.curator.framework.recipes.AfterConnectionEstablished$1.run(AfterConnectionEstablished.java:55)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:38.085 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.897 sec - in com.hubspot.singularity.data.BlendedHistoryTest
Running com.hubspot.singularity.scheduler.SingularitySchedulerTest
23:23:38.659 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:39.530 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

23:23:39.662 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:39.867 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

23:23:39.939 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Lost a slave value: "slave1"

SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1513812219614-1-host1-rack1'}), timestamp=Optional.of(1.513812219E9)}), taskId=test-request-retry_test-1513812219614-1-host1-rack1, serverTimestamp=1513812219969, serverId='58b27237-1acd-4071-af13-09523f0c619c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218284-1-host1-rack1'}), timestamp=Optional.of(1.513812218E9)}), taskId=test-request-firstDeployId-1513812218284-1-host1-rack1, serverTimestamp=1513812219729, serverId='573e74b2-b380-4de0-b78b-f403e1c38405', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218475-1-host1-rack1'}), timestamp=Optional.of(1.513812218E9)}), taskId=test-request-firstDeployId-1513812218475-1-host1-rack1, serverTimestamp=1513812219963, serverId='adba17da-7dcc-4be7-99aa-536bf7c98f04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218272-1-host1-rack1'}), timestamp=Optional.of(1.513812218E9)}), taskId=test-request-firstDeployId-1513812218272-1-host1-rack1, serverTimestamp=1513812219729, serverId='a8571bf6-1535-424e-a3bf-3ec29917f767', slaveId=Optional.absent()}
23:23:40.693 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812218284-1-host1-rack1
23:23:40.781 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812218272-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218284-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812218284-1-host1-rack1, serverTimestamp=1513812220655, serverId='573e74b2-b380-4de0-b78b-f403e1c38405', slaveId=Optional.absent()}
23:23:40.804 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218272-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812218272-1-host1-rack1, serverTimestamp=1513812220765, serverId='a8571bf6-1535-424e-a3bf-3ec29917f767', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812220786-1-host1-rack1'}), timestamp=Optional.of(1.51381222E9)}), taskId=test-request-firstDeployId-1513812220786-1-host1-rack1, serverTimestamp=1513812220836, serverId='573e74b2-b380-4de0-b78b-f403e1c38405', slaveId=Optional.absent()}
23:23:40.963 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812220786-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812220786-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812220786-1-host1-rack1, serverTimestamp=1513812220913, serverId='573e74b2-b380-4de0-b78b-f403e1c38405', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812220976-1-host1-rack1'}), timestamp=Optional.of(1.51381222E9)}), taskId=test-request-firstDeployId-1513812220976-1-host1-rack1, serverTimestamp=1513812221047, serverId='adba17da-7dcc-4be7-99aa-536bf7c98f04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812221040-1-host1-rack1'}), timestamp=Optional.of(1.513812221E9)}), taskId=test-request-firstDeployId-1513812221040-1-host1-rack1, serverTimestamp=1513812221119, serverId='573e74b2-b380-4de0-b78b-f403e1c38405', slaveId=Optional.absent()}
23:23:41.302 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812218475-1-host1-rack1
23:23:41.377 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812218475-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812218475-1-host1-rack1, serverTimestamp=1513812221263, serverId='adba17da-7dcc-4be7-99aa-536bf7c98f04', slaveId=Optional.absent()}
23:23:41.835 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:42.211 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1513812219614-1-IMMEDIATE-1513812219614, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer79'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1513812219614-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:23:42.243 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1513812219614-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:42.249 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1513812219614-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812220898-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812220898-1-host1-DEFAULT, serverTimestamp=1513812222170, serverId='5a83cf24-b4ae-4192-9c70-65240ec7fb9b', slaveId=Optional.absent()}
23:23:42.311 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r1-d1-23-3-BOUNCE-1, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812221921-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812221921-2-host2-DEFAULT, serverTimestamp=1513812222323, serverId='5a83cf24-b4ae-4192-9c70-65240ec7fb9b', slaveId=Optional.absent()}
23:23:42.369 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityLeaderCache - savePendingTask SingularityPendingTask{pendingTaskId=r2-d3-231-1-UNPAUSED-23, cmdLineArgsList=Optional.of([cmd line args]), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}, but not active
23:23:42.385 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:42.493 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:42.541 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r2-de, already correct
23:23:42.549 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path r1-d1, already correct
23:23:42.550 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 0 requests in 00:00.057
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812222510-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812222510-1-host2-DEFAULT, serverTimestamp=1513812222612, serverId='5a83cf24-b4ae-4192-9c70-65240ec7fb9b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812220898-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812220898-1-host1-DEFAULT, serverTimestamp=1513812222700, serverId='5a83cf24-b4ae-4192-9c70-65240ec7fb9b', slaveId=Optional.absent()}
23:23:43.065 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812220976-1-IMMEDIATE-1513812220976, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer39'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812220976-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:23:43.066 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812220976-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:43.069 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812220976-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@5c9b83ee rejected from java.util.concurrent.ScheduledThreadPoolExecutor@525c660d[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:43.095 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:43.255 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:43.389 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1470)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1500)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:742)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:734)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.findProtectedNodeInForeground(CreateBuilderImpl.java:731)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$1100(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$10.callPerformBackgroundOperation(CreateBuilderImpl.java:633)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:43.672 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:43.672 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:44.099 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
[oneOffRequest-oneOffDeploy1513812224109, immediateRequest-immediateDeploy, newDeployRequest-newDeploy]
23:23:44.200 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:44.206 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path oneOffRequest-oneOffDeploy1513812224109, already correct
23:23:44.208 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Rewriting path immediateRequest-immediateDeploy to immediateRequest-immediateDeploy1513812224109
23:23:44.216 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Not rewriting path newDeployRequest-newDeploy, already correct
23:23:44.217 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Applied PendingRequestDataMigration to 1 requests in 00:00.017
[oneOffRequest-oneOffDeploy1513812224109, immediateRequest-immediateDeploy1513812224109, newDeployRequest-newDeploy]
23:23:44.549 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 4, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 38.468 sec <<< FAILURE! - in com.hubspot.singularity.data.zkmigrations.ZkMigrationTest
testMigrationRunner(com.hubspot.singularity.data.zkmigrations.ZkMigrationTest)  Time elapsed: 30.032 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.SingularityHistoryTest
23:23:44.643 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812224822-1-host1-rack1'}), timestamp=Optional.of(1.513812224E9)}), taskId=test-request-firstDeployId-1513812224822-1-host1-rack1, serverTimestamp=1513812224966, serverId='a8d799ba-edb0-4ef0-a92f-89fbd04c0fcf', slaveId=Optional.absent()}
23:23:45.404 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812225419-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812225419-1-host2-DEFAULT, serverTimestamp=1513812225749, serverId='a8d799ba-edb0-4ef0-a92f-89fbd04c0fcf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812225044-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812225044-1-host2-DEFAULT, serverTimestamp=1513812225683, serverId='01af93a4-9648-44a1-bfd7-a5c34ae55516', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812225565-1-host1-rack1'}), timestamp=Optional.of(1.513812225E9)}), taskId=test-request-firstDeployId-1513812225565-1-host1-rack1, serverTimestamp=1513812225773, serverId='d6688bd0-cc99-4b14-aea3-4440ef3f0da7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1513812225993-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1513812225993-1-host1-DEFAULT, serverTimestamp=1513812226097, serverId='01af93a4-9648-44a1-bfd7-a5c34ae55516', slaveId=Optional.absent()}
23:23:46.174 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812226296-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812226296-1-host1-DEFAULT, serverTimestamp=1513812226426, serverId='d6688bd0-cc99-4b14-aea3-4440ef3f0da7', slaveId=Optional.absent()}
23:23:46.464 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812225565-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812225565-1-host1-rack1, serverTimestamp=1513812226518, serverId='d6688bd0-cc99-4b14-aea3-4440ef3f0da7', slaveId=Optional.absent()}
23:23:46.829 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:46.840 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:47.520 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:47.900 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:48.163 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812227962-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812227962-1-host2-DEFAULT, serverTimestamp=1513812228279, serverId='6ca78647-bb0d-448c-951e-374406a2f723', slaveId=Optional.absent()}
23:23:48.631 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:49.136 [Time-limited test-EventThread] ERROR com.hubspot.singularity.SingularityLeaderLatch - Can't find our node. Resetting. Index: -1
23:23:49.621 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:49.791 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:50.066 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:50.442 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:50.691 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812224822-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812224822-1-host1-rack1, serverTimestamp=1513812230792, serverId='a8d799ba-edb0-4ef0-a92f-89fbd04c0fcf', slaveId=Optional.absent()}
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.908 sec - in com.hubspot.singularity.mesos.SingularityMesosOfferSchedulerTest
Running com.hubspot.singularity.scheduler.SingularityUsageTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812231286-1-host1-rack1'}), timestamp=Optional.of(1.513812231E9)}), taskId=test-request-firstDeployId-1513812231286-1-host1-rack1, serverTimestamp=1513812231345, serverId='9f985194-95bf-424c-ba9f-a813669dd028', slaveId=Optional.absent()}
23:23:51.527 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:52.213 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:52.425 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:52.788 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:53.182 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812233051-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812233051-2-host1-DEFAULT, serverTimestamp=1513812233229, serverId='83671f4f-14d3-46e8-9ebe-5d3b11e90d0d', slaveId=Optional.absent()}
23:23:53.501 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:53.929 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1268)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:274)
	at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:270)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:267)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:253)
	at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:41)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:114)
	... 1 common frames omitted
23:23:53.935 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812233664-1-host1-rack1'}), timestamp=Optional.of(1.513812233E9)}), taskId=test-request-firstDeployId-1513812233664-1-host1-rack1, serverTimestamp=1513812233882, serverId='c5a8cc60-7fae-4bd9-9587-f6497da97936', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234076-2-host1-rack1'}), timestamp=Optional.of(1.513812234E9)}), taskId=test-request-firstDeployId-1513812234076-2-host1-rack1, serverTimestamp=1513812234123, serverId='c5a8cc60-7fae-4bd9-9587-f6497da97936', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234159-3-host1-rack1'}), timestamp=Optional.of(1.513812234E9)}), taskId=test-request-firstDeployId-1513812234159-3-host1-rack1, serverTimestamp=1513812234199, serverId='c5a8cc60-7fae-4bd9-9587-f6497da97936', slaveId=Optional.absent()}
23:23:54.266 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:23:54.300 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812234076-2-host1-rack1
23:23:54.353 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234076-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812234076-2-host1-rack1, serverTimestamp=1513812234288, serverId='c5a8cc60-7fae-4bd9-9587-f6497da97936', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234528-1-host1-rack1'}), timestamp=Optional.of(1.513812234E9)}), taskId=test-request-firstDeployId-1513812234528-1-host1-rack1, serverTimestamp=1513812234621, serverId='a46e9d6d-23d1-4f38-a8a0-35791236c3a0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234695-2-host1-rack1'}), timestamp=Optional.of(1.513812234E9)}), taskId=test-request-firstDeployId-1513812234695-2-host1-rack1, serverTimestamp=1513812234762, serverId='a46e9d6d-23d1-4f38-a8a0-35791236c3a0', slaveId=Optional.absent()}
23:23:54.774 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234774-3-host1-rack1'}), timestamp=Optional.of(1.513812234E9)}), taskId=test-request-firstDeployId-1513812234774-3-host1-rack1, serverTimestamp=1513812234810, serverId='a46e9d6d-23d1-4f38-a8a0-35791236c3a0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234695-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812234695-2-host1-rack1, serverTimestamp=1513812235257, serverId='a46e9d6d-23d1-4f38-a8a0-35791236c3a0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812234528-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812234528-1-host1-rack1, serverTimestamp=1513812235310, serverId='a46e9d6d-23d1-4f38-a8a0-35791236c3a0', slaveId=Optional.absent()}
23:23:55.408 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:23:55.427 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
23:23:55.548 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:55.660 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812233051-2-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:55.661 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812233051-2-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3b515610 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@e5e9b11[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:55.765 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1513812235951, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1513812236156, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:56.229 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1513812236264, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1513812236453, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1513812236538, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1513812236632, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1513812236724, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:56.781 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
23:23:56.828 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1513812236765, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:56.878 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-2-firstDeployId-15000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-15000-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-15000-1-host1-rack1, serverTimestamp=1513812236851, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:56.910 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:56.926 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-2-firstDeployId-35000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-35000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-35000-3-host3-rack1, serverTimestamp=1513812236909, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:57.015 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-2-firstDeployId-25000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-25000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-25000-2-host2-rack1, serverTimestamp=1513812236994, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812236690-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812236690-1-host1-rack1, serverTimestamp=1513812237088, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812236892-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812236892-2-host2-rack1, serverTimestamp=1513812237139, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
23:23:57.393 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1513812237375, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
23:23:57.438 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1513812237421, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237322-3-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237322-3-host4-rack2, serverTimestamp=1513812237484, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
23:23:57.522 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-2-firstDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-2-firstDeployId-70000-7-host7-rack1'}), timestamp=Optional.absent()}), taskId=test-request-2-firstDeployId-70000-7-host7-rack1, serverTimestamp=1513812237481, serverId='6ec50b01-97cc-43b8-bf5a-0a2600fb03fd', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237425-1-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237425-1-host3-rack2, serverTimestamp=1513812237532, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812236690-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812236690-1-host1-rack1, serverTimestamp=1513812237597, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
23:23:57.842 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237769-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237769-1-host1-rack1, serverTimestamp=1513812237944, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237871-3-host2-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237871-3-host2-rack1, serverTimestamp=1513812237997, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
23:23:58.044 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237425-1-host3-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237425-1-host3-rack2, serverTimestamp=1513812238061, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
Max healthcheck time cannot be greater than 100, (was startup timeout: 50, interval: 5, attempts: 10)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812237322-3-host4-rack2'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812237322-3-host4-rack2, serverTimestamp=1513812238107, serverId='9df6c3ce-b98f-4fd5-9b5d-4733d033d710', slaveId=Optional.absent()}
23:23:58.276 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812232726-2-UPDATED_REQUEST-1513812232629, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer155'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812233051-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1513812233051-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:23:58.280 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.of(81), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812232726-2-UPDATED_REQUEST-1513812232629, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer155'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812233051-2-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1513812233051-2-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@6800a235 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@6c3f2bed[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238256-1-host1-rack1'}), timestamp=Optional.of(1.513812238E9)}), taskId=test-request-firstDeployId-1513812238256-1-host1-rack1, serverTimestamp=1513812238363, serverId='08fe6589-de76-492f-817f-25961ceefac4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238440-2-host1-rack1'}), timestamp=Optional.of(1.513812238E9)}), taskId=test-request-firstDeployId-1513812238440-2-host1-rack1, serverTimestamp=1513812238470, serverId='08fe6589-de76-492f-817f-25961ceefac4', slaveId=Optional.absent()}
23:23:58.500 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238490-3-host1-rack1'}), timestamp=Optional.of(1.513812238E9)}), taskId=test-request-firstDeployId-1513812238490-3-host1-rack1, serverTimestamp=1513812238519, serverId='08fe6589-de76-492f-817f-25961ceefac4', slaveId=Optional.absent()}
23:23:58.655 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238661-4-host1-rack1'}), timestamp=Optional.of(1.513812238E9)}), taskId=test-request-firstDeployId-1513812238661-4-host1-rack1, serverTimestamp=1513812238711, serverId='08fe6589-de76-492f-817f-25961ceefac4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238727-1-host1-rack1'}), timestamp=Optional.of(1.513812238E9)}), taskId=test-request-firstDeployId-1513812238727-1-host1-rack1, serverTimestamp=1513812238836, serverId='893ba5d7-da92-4dc1-90e1-6aae4bf26bdf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238490-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812238490-3-host1-rack1, serverTimestamp=1513812238862, serverId='08fe6589-de76-492f-817f-25961ceefac4', slaveId=Optional.absent()}
23:23:59.185 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:59.536 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:23:59.599 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 59.201 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityExpiringActionsTest
testExpiringSkipHealthchecks(com.hubspot.singularity.scheduler.SingularityExpiringActionsTest)  Time elapsed: 30.032 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.mesos.SingularityStartupTest
23:23:59.933 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812239670-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812239670-1-host2-DEFAULT, serverTimestamp=1513812239907, serverId='65d20045-8382-400d-a097-8987985a5f89', slaveId=Optional.absent()}
23:24:00.466 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:00.528 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812240562-1-host1-rack1'}), timestamp=Optional.of(1.51381224E9)}), taskId=test-request-firstDeployId-1513812240562-1-host1-rack1, serverTimestamp=1513812240637, serverId='db468a07-88e0-42f5-80bb-cf071a06f2f7', slaveId=Optional.absent()}
23:24:00.757 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812240562-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812240562-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812240562-1-host1-rack1, serverTimestamp=1513812240741, serverId='db468a07-88e0-42f5-80bb-cf071a06f2f7', slaveId=Optional.absent()}
23:24:00.834 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:00.836 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
23:24:00.919 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812238727-1-IMMEDIATE-1513812238727, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer810'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812238727-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812240941-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812240941-2-host1-DEFAULT, serverTimestamp=1513812240972, serverId='db468a07-88e0-42f5-80bb-cf071a06f2f7', slaveId=Optional.absent()}
23:24:01.008 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:60658] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763da2fd0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:01.068 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812238727-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812238727-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812238727-1-host1-rack1, serverTimestamp=1513812241056, serverId='893ba5d7-da92-4dc1-90e1-6aae4bf26bdf', slaveId=Optional.absent()}
23:24:01.214 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812241297-1-host1-rack1'}), timestamp=Optional.of(1.513812241E9)}), taskId=test-request-firstDeployId-1513812241297-1-host1-rack1, serverTimestamp=1513812241369, serverId='f2f3818b-30d4-408f-89e6-6016e360eb26', slaveId=Optional.absent()}
23:24:01.479 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:01.969 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1513812241833, serverId='1f2e906b-b3c9-4c9d-85b1-9e9847944a63', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1513812242025, serverId='1f2e906b-b3c9-4c9d-85b1-9e9847944a63', slaveId=Optional.absent()}
23:24:02.107 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1513812242109, serverId='1f2e906b-b3c9-4c9d-85b1-9e9847944a63', slaveId=Optional.absent()}
23:24:02.473 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:02.480 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:02.490 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:02.683 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:02.752 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812242897-1-host1-rack1'}), timestamp=Optional.of(1.513812242E9)}), taskId=test-request-firstDeployId-1513812242897-1-host1-rack1, serverTimestamp=1513812243008, serverId='12ce4ac1-fbcd-4191-b309-fdf8d5b7f676', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812242967-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812242967-1-host1-DEFAULT, serverTimestamp=1513812243116, serverId='376ddacf-3e8f-4541-91aa-1a12b0d0c097', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812243254-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812243254-1-host2-DEFAULT, serverTimestamp=1513812243300, serverId='12ce4ac1-fbcd-4191-b309-fdf8d5b7f676', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812242897-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812242897-1-host1-rack1, serverTimestamp=1513812243359, serverId='12ce4ac1-fbcd-4191-b309-fdf8d5b7f676', slaveId=Optional.absent()}
23:24:03.815 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:03.941 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:04.212 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812244141-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812244141-2-host2-DEFAULT, serverTimestamp=1513812244235, serverId='610d451e-2d2f-429e-a821-38e880a9fa03', slaveId=Optional.absent()}
Tests run: 12, Failures: 1, Errors: 1, Skipped: 0, Time elapsed: 64.433 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularitySlavePlacementTest
testReservedSlaveWithMatchinRequestAttribute(com.hubspot.singularity.scheduler.SingularitySlavePlacementTest)  Time elapsed: 30.061 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

testEvenRackPlacement(com.hubspot.singularity.scheduler.SingularitySlavePlacementTest)  Time elapsed: 8.131 sec  <<< FAILURE!
java.lang.AssertionError: expected:<4> but was:<7>
	at com.hubspot.singularity.scheduler.SingularitySlavePlacementTest.testEvenRackPlacement(SingularitySlavePlacementTest.java:275)

Running com.hubspot.singularity.data.SandboxManagerTest
23:24:04.507 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:04.763 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:04.785 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812244684-1-host1-rack1'}), timestamp=Optional.of(1.513812064E9)}), taskId=test-request-firstDeployId-1513812244684-1-host1-rack1, serverTimestamp=1513812244800, serverId='4ec57673-19f6-4de5-9cee-a622913893fd', slaveId=Optional.absent()}
23:24:04.939 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812244684-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812244684-1-host1-rack1'}), timestamp=Optional.of(1.513812124E9)}), taskId=test-request-firstDeployId-1513812244684-1-host1-rack1, serverTimestamp=1513812244930, serverId='4ec57673-19f6-4de5-9cee-a622913893fd', slaveId=Optional.absent()}
23:24:05.183 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812242967-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:05.183 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812242967-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@7a5e8413 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1f624254[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:300)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:05.389 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:05.828 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:05.829 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812245956-1-host1-rack1'}), timestamp=Optional.of(1.513812245E9)}), taskId=test-request-firstDeployId-1513812245956-1-host1-rack1, serverTimestamp=1513812246070, serverId='164d7cdd-b880-498f-b670-9dc6ac002241', slaveId=Optional.absent()}
23:24:06.272 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812245956-1-host1-rack1
23:24:06.277 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
23:24:06.283 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812245956-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812245956-1-host1-rack1, serverTimestamp=1513812246255, serverId='164d7cdd-b880-498f-b670-9dc6ac002241', slaveId=Optional.absent()}
23:24:06.295 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:06.699 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:06.721 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:06.906 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-new_task_healthcheck-1513812247030-1-host1-rack1'}), timestamp=Optional.of(1.513812247E9)}), taskId=test-request-new_task_healthcheck-1513812247030-1-host1-rack1, serverTimestamp=1513812247117, serverId='f4ffee71-0766-498c-9fd7-b57c34865694', slaveId=Optional.absent()}
23:24:07.474 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:07.959 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:08.032 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:08.187 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812242878-1-UPDATED_REQUEST-1513812242826, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer927'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812242967-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1513812242967-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:08.193 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.of(Resources{cpus=1.0, memoryMb=64.0, numPorts=3, diskMb=0.0}), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.of(1), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.of(0), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812242878-1-UPDATED_REQUEST-1513812242826, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer927'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812242967-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(ports), ranges=Optional.of(MesosRangesObject{range=Optional.of([MesosRangeObject{begin=Optional.of(80), end=Optional.of(82)}])}), allOtherFields={type=RANGES}}, MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=64.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=PORT0, value=80}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=PORT, value=80}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=PORT1, value=81}, {name=PORT2, value=82}, {name=TASK_ID, value=test-request-firstDeployId-1513812242967-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2b50ce0e rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2f6f4fbc[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812248168-1-host1-rack1'}), timestamp=Optional.of(1.513812248E9)}), taskId=test-request-firstDeployId-1513812248168-1-host1-rack1, serverTimestamp=1513812248285, serverId='993e1494-a9da-4cd2-8ecc-1034daca98b0', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812248172-1-host1-DEFAULT'}), timestamp=Optional.of(1.513812248E9)}), taskId=test-request-firstDeployId-1513812248172-1-host1-DEFAULT, serverTimestamp=1513812248304, serverId='535f77b9-394b-4e5b-b9f7-648ece383292', slaveId=Optional.absent()}
23:24:08.437 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:08.472 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:24:08.528 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812248168-1-host1-rack1
23:24:08.536 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812248168-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812248168-1-host1-rack1, serverTimestamp=1513812248513, serverId='993e1494-a9da-4cd2-8ecc-1034daca98b0', slaveId=Optional.absent()}
23:24:08.617 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:08.627 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:232)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:09.245 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='new_task_healthcheck', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.absent(), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-new_task_healthcheck-1513812247030-1-IMMEDIATE-1513812247030, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer30'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-new_task_healthcheck-1513812247030-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:09.247 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-new_task_healthcheck-1513812247030-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:09.248 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-new_task_healthcheck-1513812247030-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:09.320 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:09.521 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55492] WARN org.apache.zookeeper.server.NIOServerCnxnFactory - Ignoring unexpected runtime exception
java.nio.channels.CancelledKeyException: null
	at sun.nio.ch.SelectionKeyImpl.ensureValid(SelectionKeyImpl.java:73)
	at sun.nio.ch.SelectionKeyImpl.readyOps(SelectionKeyImpl.java:87)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:187)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 16, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 68.652 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityMachineStatesTest
testFrozenSlaveCanBeDecommissioned(com.hubspot.singularity.scheduler.SingularityMachineStatesTest)  Time elapsed: 30.229 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.scheduler.MesosUtilsTest
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.026 sec - in com.hubspot.singularity.scheduler.MesosUtilsTest
Running com.hubspot.singularity.scheduler.HistoryPersisterTest
23:24:09.721 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:09.940 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:09.981 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:10.130 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812250124-1-host1-rack1'}), timestamp=Optional.of(1.51381225E9)}), taskId=test-request-firstDeployId-1513812250124-1-host1-rack1, serverTimestamp=1513812250240, serverId='3b5a18b6-aade-4f60-8ff1-76f9644c4cac', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812250549-1-host1-rack1'}), timestamp=Optional.of(1.51381225E9)}), taskId=test-request-secondDeployId-1513812250549-1-host1-rack1, serverTimestamp=1513812250579, serverId='3b5a18b6-aade-4f60-8ff1-76f9644c4cac', slaveId=Optional.absent()}
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 10.693 sec - in com.hubspot.singularity.mesos.SingularityStartupTest
Running com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
23:24:10.824 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:10.851 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812250491-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812250491-2-host1-DEFAULT, serverTimestamp=1513812250796, serverId='8138b495-0c0b-45af-bbdc-0a9a1be56bcb', slaveId=Optional.absent()}
23:24:10.930 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:10.940 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$7.performBackgroundOperation(CreateBuilderImpl.java:522)
	at org.apache.curator.framework.imps.OperationAndData.callPerformBackgroundOperation(OperationAndData.java:65)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-hc_test-1513812251030-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-hc_test-1513812251030-1-host1-rack1, serverTimestamp=1513812251120, serverId='c03c952b-7ea1-4c77-b7a7-be33509d7600', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801450957-1-host1-rack1'}), timestamp=Optional.of(1.51381225E9)}), taskId=test-request-firstDeployId-1513801450957-1-host1-rack1, serverTimestamp=1513812251051, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.221 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801450957-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801450957-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801450957-1-host1-rack1, serverTimestamp=1513812251213, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451259-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451259-1-host1-rack1, serverTimestamp=1513812251300, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.311 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:11.329 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451259-1-host1-rack1
23:24:11.342 [Curator-Framework-0] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1470)
	at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1500)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:742)
	at org.apache.curator.framework.imps.CreateBuilderImpl$12.call(CreateBuilderImpl.java:734)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.findProtectedNodeInForeground(CreateBuilderImpl.java:731)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$1100(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$10.callPerformBackgroundOperation(CreateBuilderImpl.java:633)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:802)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:792)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:62)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:257)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451259-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451259-1-host1-rack1, serverTimestamp=1513812251316, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451361-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451361-1-host1-rack1, serverTimestamp=1513812251393, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.413 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451361-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451361-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451361-1-host1-rack1, serverTimestamp=1513812251404, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451472-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451472-1-host1-rack1, serverTimestamp=1513812251491, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.520 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451472-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451472-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451472-1-host1-rack1, serverTimestamp=1513812251514, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451541-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451541-1-host1-rack1, serverTimestamp=1513812251591, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.610 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451541-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451541-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451541-1-host1-rack1, serverTimestamp=1513812251603, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451658-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451658-1-host1-rack1, serverTimestamp=1513812251686, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.706 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451658-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451658-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451658-1-host1-rack1, serverTimestamp=1513812251699, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451748-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451748-1-host1-rack1, serverTimestamp=1513812251777, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.806 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451748-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451748-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451748-1-host1-rack1, serverTimestamp=1513812251798, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451837-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451837-1-host1-rack1, serverTimestamp=1513812251881, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:11.919 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451837-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451837-1-host1-rack1'}), timestamp=Optional.of(1.513805051E9)}), taskId=test-request-firstDeployId-1513801451837-1-host1-rack1, serverTimestamp=1513812251912, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
Tests run: 18, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 70.202 sec <<< FAILURE! - in com.hubspot.singularity.data.ValidatorTest
whenRunNowItForbidsTooLongRunIds(com.hubspot.singularity.data.ValidatorTest)  Time elapsed: 30.097 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

Running com.hubspot.singularity.JavaUtilsTest
23:24:11.970 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451962-1-host1-rack1'}), timestamp=Optional.of(1.513812251E9)}), taskId=test-request-firstDeployId-1513801451962-1-host1-rack1, serverTimestamp=1513812251989, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:12.030 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801451962-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801451962-1-host1-rack1'}), timestamp=Optional.of(1.513805052E9)}), taskId=test-request-firstDeployId-1513801451962-1-host1-rack1, serverTimestamp=1513812252021, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801452082-1-host1-rack1'}), timestamp=Optional.of(1.513812252E9)}), taskId=test-request-firstDeployId-1513801452082-1-host1-rack1, serverTimestamp=1513812252111, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:12.147 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801452082-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801452082-1-host1-rack1'}), timestamp=Optional.of(1.513805052E9)}), taskId=test-request-firstDeployId-1513801452082-1-host1-rack1, serverTimestamp=1513812252130, serverId='c00be857-6bac-4e7e-b3cd-22af28957f57', slaveId=Optional.absent()}
23:24:12.175 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812252062-1-host1-rack1'}), timestamp=Optional.of(1.513812252E9)}), taskId=test-request-firstDeployId-1513812252062-1-host1-rack1, serverTimestamp=1513812252139, serverId='c7b48d87-8954-4ca6-a8d6-495edfcf0a67', slaveId=Optional.absent()}
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.386 sec - in com.hubspot.singularity.JavaUtilsTest
Running com.hubspot.singularity.SingularityAuthorizationHelperTest
23:24:12.688 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.417 sec - in com.hubspot.singularity.scheduler.SingularityUsageTest
Running com.hubspot.singularity.data.InactiveSlaveManagerTest
23:24:12.969 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:13.167 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='hc_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-hc_test-1513812251030-1-IMMEDIATE-1513812251030, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer43'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-hc_test-1513812251030-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:13.168 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-hc_test-1513812251030-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:13.169 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-hc_test-1513812251030-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812254095-1-host1-rack1'}), timestamp=Optional.of(1.513812255E9)}), taskId=test-request-firstDeployId-1513812254095-1-host1-rack1, serverTimestamp=1513812253219, serverId='3cfe64f2-70e2-4add-be76-f3509dc0ef2d', slaveId=Optional.absent()}
Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.926 sec - in com.hubspot.singularity.SingularityAuthorizationHelperTest
Running com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812257095-2-host1-rack1'}), timestamp=Optional.of(1.513812258E9)}), taskId=test-request-firstDeployId-1513812257095-2-host1-rack1, serverTimestamp=1513812253317, serverId='3cfe64f2-70e2-4add-be76-f3509dc0ef2d', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812257095-3-host1-rack1'}), timestamp=Optional.of(1.513812258E9)}), taskId=test-request-firstDeployId-1513812257095-3-host1-rack1, serverTimestamp=1513812253382, serverId='3cfe64f2-70e2-4add-be76-f3509dc0ef2d', slaveId=Optional.absent()}
23:24:13.611 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:13.837 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-timeout_test-1513808653653-1-host1-rack1'}), timestamp=Optional.of(1.513808653E9)}), taskId=test-request-timeout_test-1513808653653-1-host1-rack1, serverTimestamp=1513812253904, serverId='7aa17a6e-2986-4605-8d9c-36457bb14673', slaveId=Optional.absent()}
23:24:14.072 [Time-limited test] WARN com.hubspot.singularity.data.history.SingularityRequestHistoryPersister - Failed to persist SingularityRequestHistory{createdAt=1513801453991, user=Optional.absent(), eventType=CREATED, request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, message=Optional.absent()} into History
java.lang.UnsupportedOperationException: NoopHistoryManager can not save
	at com.hubspot.singularity.data.history.NoopHistoryManager.saveRequestHistoryUpdate(NoopHistoryManager.java:26)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:141)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.moveToHistory(SingularityRequestHistoryPersister.java:25)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurgeAndShouldDelete(SingularityHistoryPersister.java:63)
	at com.hubspot.singularity.data.history.SingularityHistoryPersister.moveToHistoryOrCheckForPurge(SingularityHistoryPersister.java:52)
	at com.hubspot.singularity.data.history.SingularityRequestHistoryPersister.runActionOnPoll(SingularityRequestHistoryPersister.java:119)
	at com.hubspot.singularity.scheduler.HistoryPersisterTest.testPurgingDoesntApplyIfDatabasePresent(HistoryPersisterTest.java:211)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.93 sec - in com.hubspot.singularity.mesos.SingularityMesosTaskBuilderTest
Running com.hubspot.singularity.config.MergingSourceProviderTest
23:24:14.308 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:14.695 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:14.750 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1040)
	at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:1073)
	at org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:215)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:702)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:14.764 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812254772-1-host1-rack1'}), timestamp=Optional.of(1.513812254E9)}), taskId=test-request-firstDeployId-1513812254772-1-host1-rack1, serverTimestamp=1513812254829, serverId='2a4318d3-9160-4e2c-b492-036d59ad4d2f', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812254978-1-host1-rack1'}), timestamp=Optional.of(1.513812254E9)}), taskId=test-request-firstDeployId-1513812254978-1-host1-rack1, serverTimestamp=1513812255006, serverId='2a4318d3-9160-4e2c-b492-036d59ad4d2f', slaveId=Optional.absent()}
23:24:15.259 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812254095-1-IMMEDIATE-1513812254095, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer924'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812254095-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:15.264 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812254095-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.267 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812254095-1-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@c2452d7 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1326400c[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.274 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:15.302 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:15.321 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812257095-2-IMMEDIATE-1513812257095, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer643'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812257095-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:15.322 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812257095-2-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.323 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812257095-2-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@46237050 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1326400c[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.386 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.of(http://uri), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812257095-3-IMMEDIATE-1513812257095, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer733'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812257095-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:15.388 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812257095-3-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.389 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812257095-3-host1-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@653155bb rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1326400c[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1513812255568, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:15.662 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1513812255657, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:15.696 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42526] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763dde880000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1513812255712, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1513812255807, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1513812255846, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1513812255890, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:15.913 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:15.931 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='timeout_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(2), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.of(86400000), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-timeout_test-1513808653653-1-IMMEDIATE-1513808653653, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer190'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-timeout_test-1513808653653-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:15.932 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-timeout_test-1513808653653-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:15.933 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-timeout_test-1513808653653-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1513812255950, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:15.967 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1-1-host1-rack1'}), timestamp=Optional.of(20.0)}), taskId=test-request-firstDeployId-1-1-host1-rack1, serverTimestamp=1513812255960, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:15.986 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-2-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-2-2-host2-rack1'}), timestamp=Optional.of(21.0)}), taskId=test-request-firstDeployId-2-2-host2-rack1, serverTimestamp=1513812255980, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:16.019 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-6-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-6-6-host6-rack1'}), timestamp=Optional.of(22.0)}), taskId=test-request-secondDeployId-6-6-host6-rack1, serverTimestamp=1513812256012, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:16.039 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-4-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-4-4-host4-rack1'}), timestamp=Optional.of(23.0)}), taskId=test-request-secondDeployId-4-4-host4-rack1, serverTimestamp=1513812256033, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:16.057 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-3-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-3-3-host3-rack1'}), timestamp=Optional.of(24.0)}), taskId=test-request-firstDeployId-3-3-host3-rack1, serverTimestamp=1513812256050, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.444 sec - in com.hubspot.singularity.mesos.SingularityTaskShellCommandTest
Running com.hubspot.singularity.scheduler.SingularityDeploysTest
23:24:16.094 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-5-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-5-5-host5-rack1'}), timestamp=Optional.of(25.0)}), taskId=test-request-secondDeployId-5-5-host5-rack1, serverTimestamp=1513812256085, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:16.117 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-7-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-7-7-host7-rack1'}), timestamp=Optional.of(26.0)}), taskId=test-request-secondDeployId-7-7-host7-rack1, serverTimestamp=1513812256110, serverId='5cadb2b8-8d45-4f25-a15f-55a450bc06aa', slaveId=Optional.absent()}
23:24:16.195 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47942] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763dd95e0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:16.331 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1513812256447-1-host1-rack1'}), timestamp=Optional.of(1.513812256E9)}), taskId=test-request-retry_test-1513812256447-1-host1-rack1, serverTimestamp=1513812256521, serverId='b1cada28-9a20-452c-994c-04939786213e', slaveId=Optional.absent()}
23:24:16.763 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:16.892 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812256835-1-host1-rack1'}), timestamp=Optional.of(1.513812256E9)}), taskId=test-request-firstDeployId-1513812256835-1-host1-rack1, serverTimestamp=1513812256940, serverId='20b0e38c-8d89-4e1c-aaa1-7332486d01be', slaveId=Optional.absent()}
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.299 sec - in com.hubspot.singularity.data.InactiveSlaveManagerTest
Running com.hubspot.singularity.SingularityS3Test
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 sec - in com.hubspot.singularity.SingularityS3Test
23:24:17.205 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:703)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.841 sec - in com.hubspot.singularity.data.SandboxManagerTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812256835-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812256835-1-host1-rack1, serverTimestamp=1513812257322, serverId='20b0e38c-8d89-4e1c-aaa1-7332486d01be', slaveId=Optional.absent()}
23:24:17.390 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:17.499 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1513812257696, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:17.805 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1513812257813, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-test_new_request_data-1513812257765-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-test_new_request_data-1513812257765-1-host1-DEFAULT, serverTimestamp=1513812257834, serverId='8f1a9933-a21b-48fe-8687-75da8ab5e867', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1513812257861, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1513812257984, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1513812258049, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1513812258088, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(0.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1513812258146, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.164 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-10000-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-10000-1-host1-rack1'}), timestamp=Optional.of(80.0)}), taskId=test-request-firstDeployId-10000-1-host1-rack1, serverTimestamp=1513812258157, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.190 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave2 for task test-request-firstDeployId-20000-2-host2-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-20000-2-host2-rack1'}), timestamp=Optional.of(90.0)}), taskId=test-request-firstDeployId-20000-2-host2-rack1, serverTimestamp=1513812258180, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.227 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave6 for task test-request-secondDeployId-60000-6-host6-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave6'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave6'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-60000-6-host6-rack1'}), timestamp=Optional.of(100.0)}), taskId=test-request-secondDeployId-60000-6-host6-rack1, serverTimestamp=1513812258220, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.243 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave4 for task test-request-secondDeployId-40000-4-host4-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave4'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave4'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-40000-4-host4-rack1'}), timestamp=Optional.of(110.0)}), taskId=test-request-secondDeployId-40000-4-host4-rack1, serverTimestamp=1513812258237, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.384 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave3 for task test-request-firstDeployId-30000-3-host3-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-30000-3-host3-rack1'}), timestamp=Optional.of(120.0)}), taskId=test-request-firstDeployId-30000-3-host3-rack1, serverTimestamp=1513812258362, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.404 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave5 for task test-request-secondDeployId-50000-5-host5-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave5'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave5'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-50000-5-host5-rack1'}), timestamp=Optional.of(130.0)}), taskId=test-request-secondDeployId-50000-5-host5-rack1, serverTimestamp=1513812258398, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.427 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave7 for task test-request-secondDeployId-70000-7-host7-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave7'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave7'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-70000-7-host7-rack1'}), timestamp=Optional.of(140.0)}), taskId=test-request-secondDeployId-70000-7-host7-rack1, serverTimestamp=1513812258419, serverId='6d651577-6b4a-4bea-9ac2-af03c9f245bf', slaveId=Optional.absent()}
23:24:18.541 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(3), failureStatusCodes=Optional.of([404])}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1513812256447-1-IMMEDIATE-1513812256447, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer897'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1513812256447-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:18.543 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1513812256447-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:18.544 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1513812256447-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:18.604 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 34.083 sec - in com.hubspot.singularity.SingularityHistoryTest
23:24:18.959 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-retry_test-1513812259176-1-host1-rack1'}), timestamp=Optional.of(1.513812259E9)}), taskId=test-request-retry_test-1513812259176-1-host1-rack1, serverTimestamp=1513812259260, serverId='28f26c88-b307-4062-8244-cc845a737797', slaveId=Optional.absent()}
23:24:19.405 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801459475-1-host1-rack1'}), timestamp=Optional.of(1.513812259E9)}), taskId=test-request-firstDeployId-1513801459475-1-host1-rack1, serverTimestamp=1513812259532, serverId='4c45c1dc-0bb1-4e5f-8f99-fd8c1d418b51', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801459579-2-host1-rack1'}), timestamp=Optional.of(1.513812259E9)}), taskId=test-request-firstDeployId-1513801459579-2-host1-rack1, serverTimestamp=1513812259606, serverId='4c45c1dc-0bb1-4e5f-8f99-fd8c1d418b51', slaveId=Optional.absent()}
23:24:19.641 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801459475-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801459475-1-host1-rack1'}), timestamp=Optional.of(1.513805059E9)}), taskId=test-request-firstDeployId-1513801459475-1-host1-rack1, serverTimestamp=1513812259635, serverId='4c45c1dc-0bb1-4e5f-8f99-fd8c1d418b51', slaveId=Optional.absent()}
23:24:20.183 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:20.287 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812260376-1-host1-rack1'}), timestamp=Optional.of(1.51381226E9)}), taskId=test-request-firstDeployId-1513812260376-1-host1-rack1, serverTimestamp=1513812260473, serverId='9b96f0af-1dc3-4951-aefd-10cbb866921b', slaveId=Optional.absent()}
23:24:20.548 [SingularityStatePoller] ERROR com.hubspot.singularity.SingularityLeaderController - Caught exception while saving state
java.lang.RuntimeException: java.lang.InterruptedException
	at com.google.common.base.Throwables.propagate(Throwables.java:240)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:119)
	at com.hubspot.singularity.SingularityLeaderController$StatePoller.run(SingularityLeaderController.java:198)
Caused by: java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:502)
	at org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1342)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:781)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:696)
	at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:679)
	at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)
	at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:676)
	at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:453)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:443)
	at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)
	at com.hubspot.singularity.data.StateManager.save(StateManager.java:116)
	... 1 common frames omitted
23:24:20.561 [Time-limited test-EventThread] ERROR org.apache.curator.framework.imps.CuratorFrameworkImpl - Background exception was not retry-able or retry gave up
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:347)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.setNode(LeaderLatch.java:661)
	at org.apache.curator.framework.recipes.leader.LeaderLatch.access$300(LeaderLatch.java:63)
	at org.apache.curator.framework.recipes.leader.LeaderLatch$4.processResult(LeaderLatch.java:490)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.sendToBackgroundCallback(CuratorFrameworkImpl.java:728)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.processBackgroundOperation(CuratorFrameworkImpl.java:505)
	at org.apache.curator.framework.imps.CreateBuilderImpl.sendBackgroundResponse(CreateBuilderImpl.java:541)
	at org.apache.curator.framework.imps.CreateBuilderImpl.access$700(CreateBuilderImpl.java:44)
	at org.apache.curator.framework.imps.CreateBuilderImpl$6.processResult(CreateBuilderImpl.java:500)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:599)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812260421-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812260421-1-host1-DEFAULT, serverTimestamp=1513812260528, serverId='a62c5f17-a260-4bd9-ba1a-f89af02d754b', slaveId=Optional.absent()}
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 6.344 sec - in com.hubspot.singularity.config.MergingSourceProviderTest
23:24:20.614 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513801459579-2-IMMEDIATE-1513801459579, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer921'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513801459579-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:20.617 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513801459579-2-IMMEDIATE-1513801459579, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer921'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513801459579-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@66da8f85 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@1e51c593[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:20.674 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812260376-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812260376-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812260376-1-host1-rack1, serverTimestamp=1513812260662, serverId='9b96f0af-1dc3-4951-aefd-10cbb866921b', slaveId=Optional.absent()}
23:24:21.289 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='retry_test', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.of(1), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-retry_test-1513812259176-1-IMMEDIATE-1513812259176, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer226'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-retry_test-1513812259176-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:24:21.290 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-retry_test-1513812259176-1-host1-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:21.292 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-retry_test-1513812259176-1-host1-rack1, aborting
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.getChildren(CuratorFrameworkImpl.java:379)
	at com.hubspot.singularity.data.CuratorManager.getChildren(CuratorManager.java:131)
	at com.hubspot.singularity.data.TaskManager.getNumNonstartupHealthchecks(TaskManager.java:519)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:98)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:21.683 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-startup_timeout_test-1513808661710-1-host1-rack1'}), timestamp=Optional.of(1.513808661E9)}), taskId=test-request-startup_timeout_test-1513808661710-1-host1-rack1, serverTimestamp=1513812261884, serverId='ae849553-1b53-4fbb-be82-f697b759434b', slaveId=Optional.absent()}
23:24:21.918 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:21.938 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:22.015 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.506 sec - in com.hubspot.singularity.scheduler.HistoryPersisterTest
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262056-1-host1-rack1'}), timestamp=Optional.of(1.513812262E9)}), taskId=test-request-firstDeployId-1513812262056-1-host1-rack1, serverTimestamp=1513812262127, serverId='afbd61ca-b45e-430c-a1ef-e2a41707cad5', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262207-2-host1-rack1'}), timestamp=Optional.of(1.513812262E9)}), taskId=test-request-firstDeployId-1513812262207-2-host1-rack1, serverTimestamp=1513812262234, serverId='afbd61ca-b45e-430c-a1ef-e2a41707cad5', slaveId=Optional.absent()}
23:24:22.274 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812262169-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262169-1-host1-rack1'}), timestamp=Optional.of(1.513812262E9)}), taskId=test-request-firstDeployId-1513812262169-1-host1-rack1, serverTimestamp=1513812262256, serverId='3917c5c6-11a9-4e89-9a0a-b49a7abea503', slaveId=Optional.absent()}
23:24:22.319 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:24:22.333 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:24:22.375 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812262056-1-host1-rack1
23:24:22.386 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262323-1-host1-rack1'}), timestamp=Optional.of(1.513812262E9)}), taskId=test-request-firstDeployId-1513812262323-1-host1-rack1, serverTimestamp=1513812262386, serverId='3917c5c6-11a9-4e89-9a0a-b49a7abea503', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262056-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812262056-1-host1-rack1, serverTimestamp=1513812262343, serverId='afbd61ca-b45e-430c-a1ef-e2a41707cad5', slaveId=Optional.absent()}
23:24:22.419 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812262207-2-host1-rack1
23:24:22.428 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812262207-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812262207-2-host1-rack1, serverTimestamp=1513812262408, serverId='afbd61ca-b45e-430c-a1ef-e2a41707cad5', slaveId=Optional.absent()}
Tests run: 12, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 83.011 sec <<< FAILURE! - in com.hubspot.singularity.scheduler.SingularityHealthchecksTest
testMaxHealthcheckRetries(com.hubspot.singularity.scheduler.SingularityHealthchecksTest)  Time elapsed: 30.408 sec  <<< ERROR!
org.junit.runners.model.TestTimedOutException: test timed out after 30 seconds

23:24:23.628 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:23.712 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812263712-1-host1-rack1'}), timestamp=Optional.of(1.513812263E9)}), taskId=test-request-firstDeployId-1513812263712-1-host1-rack1, serverTimestamp=1513812263780, serverId='806a4fb0-90f3-4db4-8ead-0bf73bd5fea6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812263994-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812263994-1-host2-DEFAULT, serverTimestamp=1513812264047, serverId='806a4fb0-90f3-4db4-8ead-0bf73bd5fea6', slaveId=Optional.absent()}
23:24:25.360 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812265450-1-host1-rack1'}), timestamp=Optional.of(1.513812265E9)}), taskId=test-request-firstDeployId-1513812265450-1-host1-rack1, serverTimestamp=1513812265508, serverId='cb27f85c-9f92-4713-8e03-524fb7f5292c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812265546-2-host1-rack1'}), timestamp=Optional.of(1.513812265E9)}), taskId=test-request-firstDeployId-1513812265546-2-host1-rack1, serverTimestamp=1513812265574, serverId='cb27f85c-9f92-4713-8e03-524fb7f5292c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812265582-3-host1-rack1'}), timestamp=Optional.of(1.513812265E9)}), taskId=test-request-firstDeployId-1513812265582-3-host1-rack1, serverTimestamp=1513812265610, serverId='cb27f85c-9f92-4713-8e03-524fb7f5292c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812265708-5-host1-rack1'}), timestamp=Optional.of(1.513812265E9)}), taskId=test-request-firstDeployId-1513812265708-5-host1-rack1, serverTimestamp=1513812265742, serverId='cb27f85c-9f92-4713-8e03-524fb7f5292c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812265708-5-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812265708-5-host1-rack1, serverTimestamp=1513812265756, serverId='cb27f85c-9f92-4713-8e03-524fb7f5292c', slaveId=Optional.absent()}
23:24:26.338 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:26.443 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='timeout_test', timestamp=1513808666364, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1513808666364}), updatedRequest=Optional.absent()} is overdue (duration: 01:00:00.079), allowed: 00:01:00.000
23:24:26.477 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42271] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e08d40000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:27.691 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812267782-1-host1-rack1'}), timestamp=Optional.of(1.513812267E9)}), taskId=test-request-firstDeployId-1513812267782-1-host1-rack1, serverTimestamp=1513812267836, serverId='8a737b7a-e3f8-4fbf-a17c-b44e912cf6e6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812267885-2-host1-rack1'}), timestamp=Optional.of(1.513812267E9)}), taskId=test-request-firstDeployId-1513812267885-2-host1-rack1, serverTimestamp=1513812267918, serverId='8a737b7a-e3f8-4fbf-a17c-b44e912cf6e6', slaveId=Optional.absent()}
23:24:27.993 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:28.136 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='firstDeployId', timestamp=1513812267999, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=10, stepComplete=false, autoAdvanceDeploySteps=true, failedDeployTasks=[], timestamp=1513812267999}), updatedRequest=Optional.absent()} request was MISSING, removing deploy
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812268102-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812268102-1-host2-DEFAULT, serverTimestamp=1513812268165, serverId='8a737b7a-e3f8-4fbf-a17c-b44e912cf6e6', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812268130-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812268130-2-host2-DEFAULT, serverTimestamp=1513812268179, serverId='8a737b7a-e3f8-4fbf-a17c-b44e912cf6e6', slaveId=Optional.absent()}
23:24:29.331 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812269394-1-host1-rack1'}), timestamp=Optional.of(1.513812269E9)}), taskId=test-request-firstDeployId-1513812269394-1-host1-rack1, serverTimestamp=1513812269447, serverId='82ac6aaf-8a4c-4f89-87e4-4a66f3a67d4c', slaveId=Optional.absent()}
23:24:29.548 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812269394-1-host1-rack1
23:24:29.552 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is PAUSED
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812269394-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812269394-1-host1-rack1, serverTimestamp=1513812269529, serverId='82ac6aaf-8a4c-4f89-87e4-4a66f3a67d4c', slaveId=Optional.absent()}
23:24:30.450 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812270527-1-host1-rack1'}), timestamp=Optional.of(1.51381227E9)}), taskId=test-request-firstDeployId-1513812270527-1-host1-rack1, serverTimestamp=1513812270579, serverId='27f5145e-5f10-4f52-9725-bf6420fca22e', slaveId=Optional.absent()}
23:24:30.773 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812270768-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812270768-1-host1-DEFAULT, serverTimestamp=1513812270802, serverId='27f5145e-5f10-4f52-9725-bf6420fca22e', slaveId=Optional.absent()}
23:24:31.135 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:46683] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e1a170000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:32.293 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812272496-1-host1-rack1'}), timestamp=Optional.of(1.513812272E9)}), taskId=test-request-firstDeployId-1513812272496-1-host1-rack1, serverTimestamp=1513812272547, serverId='727a3b4d-55dd-4fda-8919-8fd9c6be7a3a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812272583-2-host1-rack1'}), timestamp=Optional.of(1.513812272E9)}), taskId=test-request-firstDeployId-1513812272583-2-host1-rack1, serverTimestamp=1513812272610, serverId='727a3b4d-55dd-4fda-8919-8fd9c6be7a3a', slaveId=Optional.absent()}
23:24:33.012 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:34.411 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:35.112 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:35.294 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:50729] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e2b330000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:35.720 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d3-1513812275917-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d3-1513812275917-1-host1-DEFAULT, serverTimestamp=1513812275961, serverId='621b7bf2-1888-4363-b884-160afc1dc41b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d4-1513812276056-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d4-1513812276056-1-host1-DEFAULT, serverTimestamp=1513812276083, serverId='621b7bf2-1888-4363-b884-160afc1dc41b', slaveId=Optional.absent()}
23:24:36.460 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276526-1-host1-rack1'}), timestamp=Optional.of(1.513812276E9)}), taskId=test-request-firstDeployId-1513812276526-1-host1-rack1, serverTimestamp=1513812276579, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276618-1-host1-rack1'}), timestamp=Optional.of(1.513812276E9)}), taskId=test-request-firstDeployId-1513812276618-1-host1-rack1, serverTimestamp=1513812276647, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
23:24:36.664 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812276526-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276526-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812276526-1-host1-rack1, serverTimestamp=1513812276658, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
23:24:36.681 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812276618-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276618-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812276618-1-host1-rack1, serverTimestamp=1513812276676, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276715-1-host1-rack1'}), timestamp=Optional.of(1.513812276E9)}), taskId=test-request-firstDeployId-1513812276715-1-host1-rack1, serverTimestamp=1513812276742, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
23:24:36.758 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812276715-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812276715-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812276715-1-host1-rack1, serverTimestamp=1513812276752, serverId='b11f9009-054f-4f7f-82be-6e1b89f73202', slaveId=Optional.absent()}
23:24:36.799 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:47917] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e306c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:37.285 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:37.451 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812277391-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812277391-1-host1-rack1'}), timestamp=Optional.of(1.513812277E9)}), taskId=test-request-firstDeployId-1513812277391-1-host1-rack1, serverTimestamp=1513812277439, serverId='3f1befe5-8106-475f-ab8a-65395d600069', slaveId=Optional.absent()}
23:24:37.516 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812277478-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812277478-1-host1-rack1'}), timestamp=Optional.of(1.513812277E9)}), taskId=test-request-firstDeployId-1513812277478-1-host1-rack1, serverTimestamp=1513812277511, serverId='3f1befe5-8106-475f-ab8a-65395d600069', slaveId=Optional.absent()}
23:24:37.560 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40583] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e33af0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:37.944 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:38.707 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812278798-1-host1-rack1'}), timestamp=Optional.of(1.513812278E9)}), taskId=test-request-firstDeployId-1513812278798-1-host1-rack1, serverTimestamp=1513812278847, serverId='e414165e-1b56-4cf4-9ece-486e374fcb1e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812278873-2-host1-rack1'}), timestamp=Optional.of(1.513812278E9)}), taskId=test-request-firstDeployId-1513812278873-2-host1-rack1, serverTimestamp=1513812278898, serverId='e414165e-1b56-4cf4-9ece-486e374fcb1e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812279011-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812279011-1-host2-DEFAULT, serverTimestamp=1513812279050, serverId='e414165e-1b56-4cf4-9ece-486e374fcb1e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812278798-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812278798-1-host1-rack1, serverTimestamp=1513812279099, serverId='e414165e-1b56-4cf4-9ece-486e374fcb1e', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812279152-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812279152-2-host2-DEFAULT, serverTimestamp=1513812279188, serverId='e414165e-1b56-4cf4-9ece-486e374fcb1e', slaveId=Optional.absent()}
23:24:39.231 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:40.653 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:41.422 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812281534-1-host1-rack1'}), timestamp=Optional.of(1.513812281E9)}), taskId=test-request-firstDeployId-1513812281534-1-host1-rack1, serverTimestamp=1513812281587, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812281615-2-host1-rack1'}), timestamp=Optional.of(1.513812281E9)}), taskId=test-request-firstDeployId-1513812281615-2-host1-rack1, serverTimestamp=1513812281662, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812281672-3-host1-rack1'}), timestamp=Optional.of(1.513812281E9)}), taskId=test-request-firstDeployId-1513812281672-3-host1-rack1, serverTimestamp=1513812281698, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812281819-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812281819-1-host2-DEFAULT, serverTimestamp=1513812281849, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812281534-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812281534-1-host1-rack1, serverTimestamp=1513812281868, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812281921-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812281921-2-host2-DEFAULT, serverTimestamp=1513812281971, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812281615-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812281615-2-host1-rack1, serverTimestamp=1513812282033, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
23:24:42.161 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812282082-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812282082-3-host2-DEFAULT, serverTimestamp=1513812282164, serverId='406c9b00-b345-432a-a34a-c1fb26873f76', slaveId=Optional.absent()}
23:24:43.437 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812283502-1-host1-rack1'}), timestamp=Optional.of(1.513812283E9)}), taskId=test-request-firstDeployId-1513812283502-1-host1-rack1, serverTimestamp=1513812283559, serverId='5f0b005a-37bd-4d51-9cfd-8bb433ef0f5e', slaveId=Optional.absent()}
23:24:43.623 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:24:43.652 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812283502-1-host1-rack1
23:24:43.661 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812283502-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812283502-1-host1-rack1, serverTimestamp=1513812283646, serverId='5f0b005a-37bd-4d51-9cfd-8bb433ef0f5e', slaveId=Optional.absent()}
23:24:43.736 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:38628] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e4bbc0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:44.412 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812284506-1-host1-rack1'}), timestamp=Optional.of(1.513812284E9)}), taskId=test-request-firstDeployId-1513812284506-1-host1-rack1, serverTimestamp=1513812284555, serverId='aced7878-584f-4c17-9fd1-0938ae8fd15c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812284581-2-host1-rack1'}), timestamp=Optional.of(1.513812284E9)}), taskId=test-request-firstDeployId-1513812284581-2-host1-rack1, serverTimestamp=1513812284606, serverId='aced7878-584f-4c17-9fd1-0938ae8fd15c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812284722-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812284722-1-host2-DEFAULT, serverTimestamp=1513812284754, serverId='aced7878-584f-4c17-9fd1-0938ae8fd15c', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812284506-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812284506-1-host1-rack1, serverTimestamp=1513812284908, serverId='aced7878-584f-4c17-9fd1-0938ae8fd15c', slaveId=Optional.absent()}
23:24:44.943 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812284957-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812284957-2-host2-DEFAULT, serverTimestamp=1513812284976, serverId='aced7878-584f-4c17-9fd1-0938ae8fd15c', slaveId=Optional.absent()}
23:24:45.110 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:35567] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e4f640000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812285030-1-host1-rack1'}), timestamp=Optional.of(1.513812285E9)}), taskId=test-request-firstDeployId-1513812285030-1-host1-rack1, serverTimestamp=1513812285091, serverId='844ab6e5-a518-42f3-8942-8fc7656ad616', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812285208-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812285208-1-host2-DEFAULT, serverTimestamp=1513812285236, serverId='844ab6e5-a518-42f3-8942-8fc7656ad616', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812285030-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812285030-1-host1-rack1, serverTimestamp=1513812285258, serverId='844ab6e5-a518-42f3-8942-8fc7656ad616', slaveId=Optional.absent()}
23:24:45.614 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812284581-2-IMMEDIATE-1513812284581, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer218'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812284581-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:45.617 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812284581-2-IMMEDIATE-1513812284581, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer218'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812284581-2-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@1ed4a0d2 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2a256ab1[Shutting down, pool size = 2, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:24:46.770 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:47.431 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:48.082 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812288258-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812288258-1-host2-DEFAULT, serverTimestamp=1513812288297, serverId='bed835e9-bcc3-4bfa-9367-ed286b522297', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812288258-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812288258-1-host2-DEFAULT, serverTimestamp=1513812288318, serverId='bed835e9-bcc3-4bfa-9367-ed286b522297', slaveId=Optional.absent()}
23:24:48.779 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:49.492 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812289588-1-host1-rack1'}), timestamp=Optional.of(1.513812289E9)}), taskId=test-request-secondDeployId-1513812289588-1-host1-rack1, serverTimestamp=1513812289626, serverId='b18ee556-fdc1-4474-9886-594a78ec99aa', slaveId=Optional.absent()}
23:24:50.116 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:50.828 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-deploy_test-1513812290917-1-host1-rack1'}), timestamp=Optional.of(1.51381229E9)}), taskId=test-request-deploy_test-1513812290917-1-host1-rack1, serverTimestamp=1513812290971, serverId='c129e2fd-ff95-45cf-8041-ed432b0ce31b', slaveId=Optional.absent()}
23:24:51.558 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:51.875 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41223] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e6b7c0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:52.152 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812292236-1-host1-rack1'}), timestamp=Optional.of(1.513812292E9)}), taskId=test-request-firstDeployId-1513812292236-1-host1-rack1, serverTimestamp=1513812292303, serverId='4c6cb205-32f5-439d-8c1f-9e047b36a2c2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812292326-2-host1-rack1'}), timestamp=Optional.of(1.513812292E9)}), taskId=test-request-firstDeployId-1513812292326-2-host1-rack1, serverTimestamp=1513812292354, serverId='4c6cb205-32f5-439d-8c1f-9e047b36a2c2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812292461-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812292461-1-host1-DEFAULT, serverTimestamp=1513812292492, serverId='4c6cb205-32f5-439d-8c1f-9e047b36a2c2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812292236-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812292236-1-host1-rack1, serverTimestamp=1513812292539, serverId='4c6cb205-32f5-439d-8c1f-9e047b36a2c2', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812292615-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812292615-2-host2-DEFAULT, serverTimestamp=1513812292641, serverId='4c6cb205-32f5-439d-8c1f-9e047b36a2c2', slaveId=Optional.absent()}
23:24:53.010 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:24:54.366 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812294563-2-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812294563-2-host1-DEFAULT, serverTimestamp=1513812294679, serverId='f3f55cc1-d3b4-42e2-89f7-57c0917c1e3a', slaveId=Optional.absent()}
[test-request-firstDeployId-1513812294689-2-TASK_DONE-1513812294689]
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812294645-5-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812294645-5-host1-DEFAULT, serverTimestamp=1513812294773, serverId='f3f55cc1-d3b4-42e2-89f7-57c0917c1e3a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812294586-4-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812294586-4-host1-DEFAULT, serverTimestamp=1513812294806, serverId='f3f55cc1-d3b4-42e2-89f7-57c0917c1e3a', slaveId=Optional.absent()}
23:24:54.891 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812294953-1-host1-rack1'}), timestamp=Optional.of(1.513812294E9)}), taskId=test-request-firstDeployId-1513812294953-1-host1-rack1, serverTimestamp=1513812294998, serverId='ae759657-2e0a-40b5-adbe-525ef0e91384', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812295049-1-host1-rack1'}), timestamp=Optional.of(1.513812295E9)}), taskId=test-request-secondDeployId-1513812295049-1-host1-rack1, serverTimestamp=1513812295079, serverId='ae759657-2e0a-40b5-adbe-525ef0e91384', slaveId=Optional.absent()}
23:24:55.121 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-secondDeployId-1513812295049-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812295049-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812295049-1-host1-rack1, serverTimestamp=1513812295115, serverId='ae759657-2e0a-40b5-adbe-525ef0e91384', slaveId=Optional.absent()}
23:24:55.141 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812294953-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812294953-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812294953-1-host1-rack1, serverTimestamp=1513812295137, serverId='ae759657-2e0a-40b5-adbe-525ef0e91384', slaveId=Optional.absent()}
23:24:55.188 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:55826] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e78590000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:56.042 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812296101-1-host1-rack1'}), timestamp=Optional.of(1.513812296E9)}), taskId=test-request-firstDeployId-1513812296101-1-host1-rack1, serverTimestamp=1513812296148, serverId='809774e3-5bea-413d-8f06-856c0191bf7a', slaveId=Optional.absent()}
23:24:56.213 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:53575] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e7cf80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:24:56.319 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812296409-1-host1-rack1'}), timestamp=Optional.of(1.513812296E9)}), taskId=test-request-firstDeployId-1513812296409-1-host1-rack1, serverTimestamp=1513812296478, serverId='6f875381-aa49-4ef7-a763-99e0697712bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812296501-2-host1-rack1'}), timestamp=Optional.of(1.513812296E9)}), taskId=test-request-firstDeployId-1513812296501-2-host1-rack1, serverTimestamp=1513812296526, serverId='6f875381-aa49-4ef7-a763-99e0697712bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812296632-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812296632-2-host2-DEFAULT, serverTimestamp=1513812296686, serverId='6f875381-aa49-4ef7-a763-99e0697712bf', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812296661-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812296661-1-host2-DEFAULT, serverTimestamp=1513812296697, serverId='6f875381-aa49-4ef7-a763-99e0697712bf', slaveId=Optional.absent()}
23:24:58.356 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298450-1-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298450-1-host1-rack1, serverTimestamp=1513812298494, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298522-2-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298522-2-host1-rack1, serverTimestamp=1513812298546, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298555-3-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298555-3-host1-rack1, serverTimestamp=1513812298582, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298591-4-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298591-4-host1-rack1, serverTimestamp=1513812298617, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.634 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298450-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298450-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298450-1-host1-rack1, serverTimestamp=1513812298628, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.664 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298522-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298522-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298522-2-host1-rack1, serverTimestamp=1513812298646, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.689 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298555-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298555-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298555-3-host1-rack1, serverTimestamp=1513812298683, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298724-1-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298724-1-host1-rack1, serverTimestamp=1513812298750, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298759-2-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298759-2-host1-rack1, serverTimestamp=1513812298782, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298791-3-host1-rack1'}), timestamp=Optional.of(1.513812298E9)}), taskId=test-request-firstDeployId-1513812298791-3-host1-rack1, serverTimestamp=1513812298813, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.828 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298724-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298724-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298724-1-host1-rack1, serverTimestamp=1513812298824, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.867 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298759-2-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298759-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298759-2-host1-rack1, serverTimestamp=1513812298861, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.890 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298791-3-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298791-3-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298791-3-host1-rack1, serverTimestamp=1513812298885, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.936 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812298591-4-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812298591-4-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812298591-4-host1-rack1, serverTimestamp=1513812298931, serverId='3d2bbccb-9e84-428e-9261-e402cace83eb', slaveId=Optional.absent()}
23:24:58.983 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299082-1-host1-rack1'}), timestamp=Optional.of(1.513812299E9)}), taskId=test-request-firstDeployId-1513812299082-1-host1-rack1, serverTimestamp=1513812299131, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299156-2-host1-rack1'}), timestamp=Optional.of(1.513812299E9)}), taskId=test-request-firstDeployId-1513812299156-2-host1-rack1, serverTimestamp=1513812299182, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299191-3-host1-rack1'}), timestamp=Optional.of(1.513812299E9)}), taskId=test-request-firstDeployId-1513812299191-3-host1-rack1, serverTimestamp=1513812299218, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299227-4-host1-rack1'}), timestamp=Optional.of(1.513812299E9)}), taskId=test-request-firstDeployId-1513812299227-4-host1-rack1, serverTimestamp=1513812299254, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812299366-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812299366-1-host2-DEFAULT, serverTimestamp=1513812299421, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812299392-2-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812299392-2-host2-DEFAULT, serverTimestamp=1513812299433, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299082-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812299082-1-host1-rack1, serverTimestamp=1513812299484, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812299156-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812299156-2-host1-rack1, serverTimestamp=1513812299512, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812299550-4-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812299550-4-host2-DEFAULT, serverTimestamp=1513812299606, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812299577-3-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812299577-3-host2-DEFAULT, serverTimestamp=1513812299618, serverId='d43706f4-e101-4473-a426-df363d4e4028', slaveId=Optional.absent()}
23:24:59.704 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:36024] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e885f0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:00.136 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:00.224 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB delete request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1513812300221, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-1513812300213-DELETE-1} (test-request-1513812300213-DELETE-1) got unexpected response FAILED
23:25:01.393 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812301489-1-host1-rack1'}), timestamp=Optional.of(1.513812301E9)}), taskId=test-request-firstDeployId-1513812301489-1-host1-rack1, serverTimestamp=1513812301540, serverId='c5bfef6d-dbc0-4f38-928c-9b58c64aae22', slaveId=Optional.absent()}
23:25:01.698 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:36404] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763e91e40000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:01.865 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:02.008 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityDeployChecker - Deploy SingularityPendingDeploy{deployMarker=SingularityDeployMarker{requestId='test-request', deployId='secondDeployId', timestamp=1513812301945, user=Optional.absent(), message=Optional.absent()}, lastLoadBalancerUpdate=Optional.absent(), currentDeployState=WAITING, deployProgress=Optional.of(SingularityIncrementalDeployProgress{targetActiveInstances=1, currentActiveInstances=0, deployInstanceCountPerStep=1, deployStepWaitTimeMs=0, stepComplete=false, autoAdvanceDeploySteps=false, failedDeployTasks=[], timestamp=1513812301945}), updatedRequest=Optional.absent()} request was PAUSED, removing deploy
23:25:03.219 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812303298-1-host1-rack1'}), timestamp=Optional.of(1.513812303E9)}), taskId=test-request-firstDeployId-1513812303298-1-host1-rack1, serverTimestamp=1513812303343, serverId='cf4af705-a169-4913-8754-dfec9aee6b0b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812303370-2-host1-rack1'}), timestamp=Optional.of(1.513812303E9)}), taskId=test-request-firstDeployId-1513812303370-2-host1-rack1, serverTimestamp=1513812303394, serverId='cf4af705-a169-4913-8754-dfec9aee6b0b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812303533-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812303533-1-host2-DEFAULT, serverTimestamp=1513812303561, serverId='cf4af705-a169-4913-8754-dfec9aee6b0b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812303298-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812303298-1-host1-rack1, serverTimestamp=1513812303606, serverId='cf4af705-a169-4913-8754-dfec9aee6b0b', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812303682-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812303682-1-host2-DEFAULT, serverTimestamp=1513812303716, serverId='cf4af705-a169-4913-8754-dfec9aee6b0b', slaveId=Optional.absent()}
23:25:03.833 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:05.309 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812305369-1-host1-rack1'}), timestamp=Optional.of(1.513812305E9)}), taskId=test-request-firstDeployId-1513812305369-1-host1-rack1, serverTimestamp=1513812305418, serverId='7b5dc62f-de42-4b5d-a905-2dc2f48f3d73', slaveId=Optional.absent()}
23:25:05.471 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812305369-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812305369-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812305369-1-host1-rack1, serverTimestamp=1513812305467, serverId='7b5dc62f-de42-4b5d-a905-2dc2f48f3d73', slaveId=Optional.absent()}
23:25:05.882 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812305960-1-host1-rack1'}), timestamp=Optional.of(1.513812305E9)}), taskId=test-request-firstDeployId-1513812305960-1-host1-rack1, serverTimestamp=1513812306006, serverId='e278d888-5e78-4b5b-bf5b-8410790fb8f3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812306030-2-host1-rack1'}), timestamp=Optional.of(1.513812306E9)}), taskId=test-request-firstDeployId-1513812306030-2-host1-rack1, serverTimestamp=1513812306058, serverId='e278d888-5e78-4b5b-bf5b-8410790fb8f3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812306174-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-secondDeployId-1513812306174-1-host2-DEFAULT, serverTimestamp=1513812306200, serverId='e278d888-5e78-4b5b-bf5b-8410790fb8f3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812305960-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812305960-1-host1-rack1, serverTimestamp=1513812306251, serverId='e278d888-5e78-4b5b-bf5b-8410790fb8f3', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812306369-1-host1-rack1'}), timestamp=Optional.of(1.513812306E9)}), taskId=test-request-firstDeployId-1513812306369-1-host1-rack1, serverTimestamp=1513812306394, serverId='e278d888-5e78-4b5b-bf5b-8410790fb8f3', slaveId=Optional.absent()}
23:25:06.667 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812306746-1-host1-rack1'}), timestamp=Optional.of(1.513812306E9)}), taskId=test-request-firstDeployId-1513812306746-1-host1-rack1, serverTimestamp=1513812306791, serverId='9ba51234-4466-407f-b11f-a89251fc73b2', slaveId=Optional.absent()}
23:25:06.829 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812306746-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812306746-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812306746-1-host1-rack1, serverTimestamp=1513812306824, serverId='9ba51234-4466-407f-b11f-a89251fc73b2', slaveId=Optional.absent()}
23:25:06.870 [Time-limited test] ERROR com.hubspot.singularity.scheduler.SingularityCleaner - LB removal request SingularityLoadBalancerUpdate{loadBalancerState=FAILED, message=Optional.absent(), timestamp=1513812306865, uri=Optional.absent(), method=CHECK_STATE, loadBalancerRequestId=test-request-firstDeployId-1513812306746-1-host1-rack1-REMOVE-1} (test-request-firstDeployId-1513812306746-1-host1-rack1-REMOVE-1) got unexpected response FAILED
Tests run: 25, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 51.338 sec - in com.hubspot.singularity.scheduler.SingularityDeploysTest
23:25:08.022 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:09.273 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:09.451 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42250] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763eb0be0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:10.579 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812310693-1-host1-rack1'}), timestamp=Optional.of(1.51381231E9)}), taskId=test-request-firstDeployId-1513812310693-1-host1-rack1, serverTimestamp=1513812310745, serverId='76ca594b-ebfc-4318-97f6-09418514f5d7', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812310693-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812310693-1-host1-rack1, serverTimestamp=1513812310838, serverId='76ca594b-ebfc-4318-97f6-09418514f5d7', slaveId=Optional.absent()}
23:25:10.883 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:35814] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763eb5d80000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:12.026 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812312198-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812312198-1-host1-DEFAULT, serverTimestamp=1513812312230, serverId='dba94673-7d72-484f-b020-9c80e32cc4e8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812312269-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812312269-1-host2-DEFAULT, serverTimestamp=1513812312285, serverId='dba94673-7d72-484f-b020-9c80e32cc4e8', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d1-1513812312325-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d1-1513812312325-1-host2-DEFAULT, serverTimestamp=1513812312347, serverId='dba94673-7d72-484f-b020-9c80e32cc4e8', slaveId=Optional.absent()}
23:25:13.546 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812313605-1-host1-rack1'}), timestamp=Optional.of(1.513812313E9)}), taskId=test-request-firstDeployId-1513812313605-1-host1-rack1, serverTimestamp=1513812313655, serverId='aa3ea40c-770a-4204-9a9f-dcf93d3470a8', slaveId=Optional.absent()}
23:25:13.688 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812313605-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812313605-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812313605-1-host1-rack1, serverTimestamp=1513812313683, serverId='aa3ea40c-770a-4204-9a9f-dcf93d3470a8', slaveId=Optional.absent()}
23:25:15.001 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:15.140 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:41161] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763ec71a0000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:16.266 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:17.782 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:17.923 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:40457] WARN org.apache.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x160763ed1d30000, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:745)
23:25:19.050 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812319173-1-host1-rack1'}), timestamp=Optional.of(1.513812319E9)}), taskId=test-request-firstDeployId-1513812319173-1-host1-rack1, serverTimestamp=1513812319226, serverId='f7861a36-7fc6-4fe1-8711-d6589e2e8bec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812319253-2-host2-rack1'}), timestamp=Optional.of(1.513812319E9)}), taskId=test-request-firstDeployId-1513812319253-2-host2-rack1, serverTimestamp=1513812319285, serverId='f7861a36-7fc6-4fe1-8711-d6589e2e8bec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave3'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave3'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812319380-2-host3-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1513812319380-2-host3-DEFAULT, serverTimestamp=1513812319399, serverId='f7861a36-7fc6-4fe1-8711-d6589e2e8bec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812319173-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812319173-1-host1-rack1, serverTimestamp=1513812319449, serverId='f7861a36-7fc6-4fe1-8711-d6589e2e8bec', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812319493-1-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1513812319493-1-host1-DEFAULT, serverTimestamp=1513812319509, serverId='f7861a36-7fc6-4fe1-8711-d6589e2e8bec', slaveId=Optional.absent()}
23:25:21.289 [healthcheck-pool-0] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812319253-2-IMMEDIATE-1513812319253, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host2', id=SingularityMesosIdObject{value='offer684'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812319253-2-host2-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave2'}, slaveId=SingularityMesosIdObject{value='slave2'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}
23:25:21.290 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812319253-2-host2-rack1, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:21.291 [healthcheck-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812319253-2-host2-rack1, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@2b954ba2 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2552b0a0[Shutting down, pool size = 3, active threads = 1, queued tasks = 2, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:21.404 [healthcheck-pool-2] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812319359-2-BOUNCE-1513812319301, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host3', id=SingularityMesosIdObject{value='offer502'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812319380-2-host3-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave3'}, slaveId=SingularityMesosIdObject{value='slave3'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=2}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host3}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1513812319380-2-host3-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
23:25:21.405 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812319380-2-host3-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:21.408 [healthcheck-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812319380-2-host3-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3611abb2 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2552b0a0[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:21.522 [healthcheck-pool-1] WARN com.hubspot.singularity.scheduler.SingularityHealthchecker - Couldn't find a port for health check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.of(2), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.of(SEPARATE_BY_REQUEST), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.of(HealthcheckOptions{uri='http://uri', portIndex=Optional.absent(), portNumber=Optional.absent(), protocol=Optional.absent(), startupTimeoutSeconds=Optional.absent(), startupDelaySeconds=Optional.absent(), startupIntervalSeconds=Optional.absent(), intervalSeconds=Optional.absent(), responseTimeoutSeconds=Optional.absent(), maxRetries=Optional.absent(), failureStatusCodes=Optional.absent()}), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812319460-1-TASK_DONE-1513812319457, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer841'}, allOtherFields={url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812319493-1-host1-DEFAULT'}, executor=Optional.absent(), labels=MesosLabels{labels=[]}, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[MesosResourceObject{name=Optional.of(cpus), ranges=Optional.absent(), allOtherFields={scalar={value=1.0}, type=SCALAR}}, MesosResourceObject{name=Optional.of(mem), ranges=Optional.absent(), allOtherFields={scalar={value=128.0}, type=SCALAR}}], name='test-request', allOtherFields={command={uris=[], environment={variables=[{name=TASK_DEPLOY_ID, value=firstDeployId}, {name=INSTANCE_NO, value=1}, {name=TASK_REQUEST_ID, value=test-request}, {name=AVAILABILITY_ZONE, value=DEFAULT}, {name=ESTIMATED_INSTANCE_COUNT, value=2}, {name=TASK_HOST, value=host1}, {name=TASK_RACK_ID, value=DEFAULT}, {name=TASK_ID, value=test-request-firstDeployId-1513812319493-1-host1-DEFAULT}]}, value=sleep 100, arguments=[]}}}, rackId=Optional.of(DEFAULT)}
23:25:21.523 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while saving health check result for test-request-firstDeployId-1513812319493-1-host1-DEFAULT, will re-enqueue
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.TaskManager.canSaveNewHealthcheck(TaskManager.java:330)
	at com.hubspot.singularity.data.TaskManager.saveHealthcheckResult(TaskManager.java:319)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:76)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:21.524 [healthcheck-pool-1] ERROR com.hubspot.singularity.scheduler.SingularityHealthchecker - Caught throwable while re-enqueuing health check for test-request-firstDeployId-1513812319493-1-host1-DEFAULT, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@578b269d rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2552b0a0[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheckWithDelay(SingularityHealthchecker.java:184)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.enqueueHealthcheck(SingularityHealthchecker.java:103)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.reEnqueueOrAbort(SingularityHealthchecker.java:203)
	at com.hubspot.singularity.scheduler.SingularityHealthcheckAsyncHandler.saveResult(SingularityHealthcheckAsyncHandler.java:101)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.saveFailure(SingularityHealthchecker.java:240)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.asyncHealthcheck(SingularityHealthchecker.java:278)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker.access$000(SingularityHealthchecker.java:45)
	at com.hubspot.singularity.scheduler.SingularityHealthchecker$1.run(SingularityHealthchecker.java:189)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:22.657 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:23.961 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812324017-1-host1-rack1'}), timestamp=Optional.of(1.513812324E9)}), taskId=test-request-firstDeployId-1513812324017-1-host1-rack1, serverTimestamp=1513812324062, serverId='0883fa46-325b-4905-b2e4-41f85b045cc9', slaveId=Optional.absent()}
23:25:26.306 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:26.313 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Unexpected taskId task 
com.hubspot.singularity.data.transcoders.SingularityTranscoderException: java.lang.reflect.InvocationTargetException
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:44)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.getTaskId(SingularityMesosStatusUpdateHandler.java:137)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.unsafeProcessStatusUpdate(SingularityMesosStatusUpdateHandler.java:179)
	at com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler.processStatusUpdate(SingularityMesosStatusUpdateHandler.java:262)
	at com.hubspot.singularity.mesos.SingularityMesosSchedulerImpl.statusUpdate(SingularityMesosSchedulerImpl.java:277)
	at com.hubspot.singularity.scheduler.SingularitySchedulerTest.testTaskOddities(SingularitySchedulerTest.java:1494)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.reflect.InvocationTargetException: null
	at sun.reflect.GeneratedMethodAccessor228.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.hubspot.singularity.data.transcoders.IdTranscoder.fromString(IdTranscoder.java:42)
	... 19 common frames omitted
Caused by: com.hubspot.singularity.InvalidSingularityTaskIdException: TaskId task was invalid (There must be at least 5 instances of - (there were 0))
	at com.hubspot.singularity.SingularityTaskId.valueOf(SingularityTaskId.java:114)
	... 23 common frames omitted
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_STARTING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812326369-1-host1-rack1'}), timestamp=Optional.of(1.513812326E9)}), taskId=test-request-firstDeployId-1513812326369-1-host1-rack1, serverTimestamp=1513812326414, serverId='4da1d4ab-334f-4934-beea-235db8640194', slaveId=Optional.absent()}
23:25:26.467 [Time-limited test] ERROR com.hubspot.singularity.mesos.SingularityMesosStatusUpdateHandler - Task test-request-firstDeployId-1513812326369-1-host1-rack1 is active but is missing task data
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812326369-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812326369-1-host1-rack1, serverTimestamp=1513812326466, serverId='4da1d4ab-334f-4934-beea-235db8640194', slaveId=Optional.absent()}
23:25:26.483 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812326369-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812326369-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812326369-1-host1-rack1, serverTimestamp=1513812326478, serverId='4da1d4ab-334f-4934-beea-235db8640194', slaveId=Optional.absent()}
[SingularityTaskHistoryUpdate[timestamp=1513812326466, taskState=TASK_RUNNING, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]], SingularityTaskHistoryUpdate[timestamp=1513812326478, taskState=TASK_FAILED, statusMessage=Optional.absent(), statusReason=Optional.absent(), previous=[]]]
23:25:27.654 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:29.352 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329429-1-host1-rack1'}), timestamp=Optional.of(1.513812329E9)}), taskId=test-request-firstDeployId-1513812329429-1-host1-rack1, serverTimestamp=1513812329474, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329499-2-host1-rack1'}), timestamp=Optional.of(1.513812329E9)}), taskId=test-request-firstDeployId-1513812329499-2-host1-rack1, serverTimestamp=1513812329522, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329530-3-host1-rack1'}), timestamp=Optional.of(1.513812329E9)}), taskId=test-request-firstDeployId-1513812329530-3-host1-rack1, serverTimestamp=1513812329554, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329785-3-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1513812329785-3-host1-DEFAULT, serverTimestamp=1513812329810, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329760-2-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1513812329760-2-host1-DEFAULT, serverTimestamp=1513812329825, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812329728-1-host1-DEFAULT'}), timestamp=Optional.of(0.0)}), taskId=test-request-firstDeployId-1513812329728-1-host1-DEFAULT, serverTimestamp=1513812329836, serverId='0c4f7060-01ca-4c13-aa37-ad969fa3d5bb', slaveId=Optional.absent()}
23:25:32.010 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:33.187 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:34.433 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801534494-1-host1-rack1'}), timestamp=Optional.of(1.513812334E9)}), taskId=test-request-firstDeployId-1513801534494-1-host1-rack1, serverTimestamp=1513812334535, serverId='d9a35fb2-8010-4846-b10a-b197a0167b04', slaveId=Optional.absent()}
23:25:34.586 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513801534494-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513801534494-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513801534494-1-host1-rack1, serverTimestamp=1513812334581, serverId='d9a35fb2-8010-4846-b10a-b197a0167b04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812333994-1-host1-rack1'}), timestamp=Optional.of(1.513812334E9)}), taskId=test-request-firstDeployId-1513812333994-1-host1-rack1, serverTimestamp=1513812334627, serverId='d9a35fb2-8010-4846-b10a-b197a0167b04', slaveId=Optional.absent()}
23:25:34.642 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812333994-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812333994-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812333994-1-host1-rack1, serverTimestamp=1513812334637, serverId='d9a35fb2-8010-4846-b10a-b197a0167b04', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812333992-1-host1-rack1'}), timestamp=Optional.of(1.513812334E9)}), taskId=test-request-firstDeployId-1513812333992-1-host1-rack1, serverTimestamp=1513812334704, serverId='d9a35fb2-8010-4846-b10a-b197a0167b04', slaveId=Optional.absent()}
23:25:36.874 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:38.369 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812338429-1-host1-rack1'}), timestamp=Optional.of(1.513812338E9)}), taskId=test-request-firstDeployId-1513812338429-1-host1-rack1, serverTimestamp=1513812338474, serverId='6aa1a135-3343-4254-a416-cb7d0ee33f11', slaveId=Optional.absent()}
23:25:38.529 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:25:38.553 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812338429-1-host1-rack1
23:25:38.560 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812338429-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812338429-1-host1-rack1, serverTimestamp=1513812338547, serverId='6aa1a135-3343-4254-a416-cb7d0ee33f11', slaveId=Optional.absent()}
23:25:39.784 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:41.038 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812341105-1-host1-rack1'}), timestamp=Optional.of(1.513812341E9)}), taskId=test-request-firstDeployId-1513812341105-1-host1-rack1, serverTimestamp=1513812341146, serverId='014f8dad-f749-452a-83f4-2e71f70f1c55', slaveId=Optional.absent()}
23:25:41.182 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812341105-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812341105-1-host1-rack1'}), timestamp=Optional.of(1.513794341E9)}), taskId=test-request-firstDeployId-1513812341105-1-host1-rack1, serverTimestamp=1513812341175, serverId='014f8dad-f749-452a-83f4-2e71f70f1c55', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812341196-1-host1-rack1'}), timestamp=Optional.of(1.513812341E9)}), taskId=test-request-firstDeployId-1513812341196-1-host1-rack1, serverTimestamp=1513812341228, serverId='014f8dad-f749-452a-83f4-2e71f70f1c55', slaveId=Optional.absent()}
23:25:41.242 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812341196-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812341196-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812341196-1-host1-rack1, serverTimestamp=1513812341237, serverId='014f8dad-f749-452a-83f4-2e71f70f1c55', slaveId=Optional.absent()}
23:25:42.414 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave2'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave2'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FINISHED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1513812342586-1-host2-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1513812342586-1-host2-DEFAULT, serverTimestamp=1513812342617, serverId='34b46ed3-6a24-4186-a479-e00e1047c2d4', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_LOST), taskId=Optional.of(SingularityMesosIdObject{value='test-request-d2-1513812342675-1-host1-DEFAULT'}), timestamp=Optional.absent()}), taskId=test-request-d2-1513812342675-1-host1-DEFAULT, serverTimestamp=1513812342698, serverId='34b46ed3-6a24-4186-a479-e00e1047c2d4', slaveId=Optional.absent()}
23:25:43.878 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.of(1.513812344E9)}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1513812344061, serverId='4eba6330-98d8-4544-ad8b-f2818ac029ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1'}), timestamp=Optional.of(1.513812344E9)}), taskId=mediumPriorityRequest-mediumPriorityDeploy-1-1-host1-rack1, serverTimestamp=1513812344124, serverId='4eba6330-98d8-4544-ad8b-f2818ac029ca', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='highPriorityRequest-highPriorityDeploy-10-1-host1-rack1'}), timestamp=Optional.of(1.513812344E9)}), taskId=highPriorityRequest-highPriorityDeploy-10-1-host1-rack1, serverTimestamp=1513812344160, serverId='4eba6330-98d8-4544-ad8b-f2818ac029ca', slaveId=Optional.absent()}
23:25:44.215 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=lowPriorityRequest-lowPriorityDeploy-2-1-host1-rack1, serverTimestamp=1513812344210, serverId='4eba6330-98d8-4544-ad8b-f2818ac029ca', slaveId=Optional.absent()}
23:25:46.482 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:47.865 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812347941-1-host1-rack1'}), timestamp=Optional.of(1.513812347E9)}), taskId=test-request-firstDeployId-1513812347941-1-host1-rack1, serverTimestamp=1513812347982, serverId='909aa415-c0f1-465c-9784-d0abf5426183', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812348008-2-host1-rack1'}), timestamp=Optional.of(1.513812348E9)}), taskId=test-request-firstDeployId-1513812348008-2-host1-rack1, serverTimestamp=1513812348034, serverId='909aa415-c0f1-465c-9784-d0abf5426183', slaveId=Optional.absent()}
23:25:48.064 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812347941-1-host1-rack1
23:25:48.067 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_FAILED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812347941-1-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812347941-1-host1-rack1, serverTimestamp=1513812348059, serverId='909aa415-c0f1-465c-9784-d0abf5426183', slaveId=Optional.absent()}
23:25:48.098 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularityMesosScheduler - Not using custom executor, will not send framework message to destroy task
23:25:48.117 [Time-limited test] WARN com.hubspot.singularity.mesos.SingularitySlaveAndRackManager - Couldn't find slave with id slave1 for task test-request-firstDeployId-1513812348008-2-host1-rack1
23:25:48.120 [Time-limited test] WARN com.hubspot.singularity.scheduler.SingularityScheduler - Not scheduling a new task, test-request is DELETING
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_KILLED), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812348008-2-host1-rack1'}), timestamp=Optional.absent()}), taskId=test-request-firstDeployId-1513812348008-2-host1-rack1, serverTimestamp=1513812348110, serverId='909aa415-c0f1-465c-9784-d0abf5426183', slaveId=Optional.absent()}
23:25:49.318 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:50.715 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:52.079 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-firstDeployId-1513812352137-1-host1-rack1'}), timestamp=Optional.of(1.513812352E9)}), taskId=test-request-firstDeployId-1513812352137-1-host1-rack1, serverTimestamp=1513812352184, serverId='76b17a0d-51d8-4b9b-ba56-a566f9e5356a', slaveId=Optional.absent()}
SingularityTaskStatusHolder{taskStatus=Optional.of(SingularityMesosTaskStatusObject{agentId=Optional.of(SingularityMesosIdObject{value='slave1'}), slaveId=Optional.of(SingularityMesosIdObject{value='slave1'}), healthy=Optional.absent(), message=Optional.absent(), reason=Optional.absent(), state=Optional.of(TASK_RUNNING), taskId=Optional.of(SingularityMesosIdObject{value='test-request-secondDeployId-1513812352230-1-host1-rack1'}), timestamp=Optional.of(1.513812352E9)}), taskId=test-request-secondDeployId-1513812352230-1-host1-rack1, serverTimestamp=1513812352263, serverId='76b17a0d-51d8-4b9b-ba56-a566f9e5356a', slaveId=Optional.absent()}
23:25:53.209 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812352137-1-IMMEDIATE-1513812352137, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer687'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812352137-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:53.214 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(true), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812352137-1-IMMEDIATE-1513812352137, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer687'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812352137-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@13820c0e rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3ab69845[Shutting down, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:54.345 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:55.045 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812233664-1-IMMEDIATE-1513812233664, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer378'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812233664-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:55.046 [check-new-task-pool-0] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812233664-1-IMMEDIATE-1513812233664, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer378'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812233664-1-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3a1f02f2 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@34d8fbc1[Shutting down, pool size = 3, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:55.214 [check-new-task-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable in task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812234159-3-IMMEDIATE-1513812234159, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer69'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812234159-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, re-enqueing
java.lang.IllegalStateException: instance must be started before calling this method
	at com.google.common.base.Preconditions.checkState(Preconditions.java:444)
	at org.apache.curator.framework.imps.CuratorFrameworkImpl.checkExists(CuratorFrameworkImpl.java:355)
	at com.hubspot.singularity.data.CuratorManager.checkExists(CuratorManager.java:109)
	at com.hubspot.singularity.data.CuratorManager.exists(CuratorManager.java:122)
	at com.hubspot.singularity.data.DisasterManager.isDisabled(DisasterManager.java:62)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.hasHealthcheck(SingularityNewTaskChecker.java:96)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.getTaskState(SingularityNewTaskChecker.java:313)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.checkTask(SingularityNewTaskChecker.java:254)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:209)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:55.215 [check-new-task-pool-2] ERROR com.hubspot.singularity.scheduler.SingularityNewTaskChecker - Uncaught throwable re-enqueuing task check for task SingularityTask{taskRequest=SingularityTaskRequest{request=SingularityRequest{id='test-request', requestType=WORKER, owners=Optional.absent(), numRetriesOnFailure=Optional.absent(), schedule=Optional.absent(), quartzSchedule=Optional.absent(), scheduleType=Optional.absent(), scheduleTimeZone=Optional.absent(), killOldNonLongRunningTasksAfterMillis=Optional.absent(), taskExecutionTimeLimitMillis=Optional.absent(), scheduledExpectedRuntimeMillis=Optional.absent(), waitAtLeastMillisAfterTaskFinishesForReschedule=Optional.absent(), instances=Optional.absent(), skipHealthchecks=Optional.absent(), rackSensitive=Optional.absent(), rackAffinity=Optional.absent(), slavePlacement=Optional.absent(), requiredSlaveAttributes=Optional.absent(), allowedSlaveAttributes=Optional.absent(), loadBalanced=Optional.of(false), group=Optional.absent(), requiredRole=Optional.absent(), readWriteGroups=Optional.absent(), readOnlyGroups=Optional.absent(), bounceAfterScale=Optional.absent(), emailConfigurationOverrides=Optional.absent(), hideEvenNumberAcrossRacksHint=Optional.absent(), taskLogErrorRegex=Optional.absent(), taskLogErrorRegexCaseSensitive=Optional.absent(), taskPriorityLevel=Optional.absent(), maxTasksPerOffer=Optional.absent(), allowBounceToSameHost=Optional.absent(), dataCenter=Optional.absent()}, deploy=SingularityDeploy{requestId='test-request', id='firstDeployId', version=Optional.absent(), timestamp=Optional.absent(), metadata=Optional.absent(), containerInfo=Optional.absent(), customExecutorCmd=Optional.absent(), customExecutorId=Optional.absent(), customExecutorSource=Optional.absent(), customExecutorResources=Optional.absent(), resources=Optional.absent(), command=Optional.of(sleep 100), arguments=Optional.absent(), env=Optional.absent(), runImmediatelyOptional.absent(), uris=Optional.absent(), executorData=Optional.absent(), labels=Optional.absent(), mesosLabels=Optional.absent(), taskLabels=Optional.absent(), mesosTaskLabels=Optional.absent(), taskEnv=Optional.absent(), healthcheckUri=Optional.absent(), healthcheckIntervalSeconds=Optional.absent(), healthcheckTimeoutSeconds=Optional.absent(), healthcheckPortIndex=Optional.absent(), healthcheckProtocol=Optional.absent(), healthcheckMaxRetries=Optional.absent(), healthcheckMaxTotalTimeoutSeconds=Optional.absent(), healthcheck=Optional.absent(), skipHealthchecksOnDeploy=Optional.absent(), deployHealthTimeoutSeconds=Optional.absent(), considerHealthyAfterRunningForSeconds=Optional.absent(), serviceBasePath=Optional.absent(), loadBalancerGroups=Optional.absent(), loadBalancerPortIndex=Optional.absent(), loadBalancerOptions=Optional.absent(), loadBalancerDomains=Optional.absent(), loadBalancerAdditionalRoutes=Optional.absent(), loadBalancerTemplate=Optional.absent(), loadBalancerServiceIdOverride=Optional.absent(), loadBalancerUpstreamGroup=Optional.absent(), deployInstanceCountPerStep=Optional.absent(), deployStepWaitTimeMs=Optional.absent(), autoAdvanceDeploySteps=Optional.absent(), maxTaskRetries=Optional.absent(), shell=Optional.absent(), user=Optional.absent()}, pendingTask=SingularityPendingTask{pendingTaskId=test-request-firstDeployId-1513812234159-3-IMMEDIATE-1513812234159, cmdLineArgsList=Optional.absent(), user=Optional.absent(), runId=Optional.absent(), skipHealthchecks=Optional.absent(), message=Optional.absent(), resources=Optional.absent(), runAsUserOverride=Optional.absent(), envOverrides={}, extraArtifacts[], actionId=Optional.absent()}}, offer=[MesosOfferObject{agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, frameworkId=SingularityMesosIdObject{value='framework1'}, hostname='host1', id=SingularityMesosIdObject{value='offer69'}, allOtherFields={resources=[{name=cpus, type=SCALAR, scalar={value=125.0}}, {name=mem, type=SCALAR, scalar={value=1024.0}}, {name=ports, type=RANGES, ranges={range=[]}}], attributes=[{name=rackid, type=TEXT, text={value=DEFAULT}}], executorIds=[], url={scheme=scheme, address={port=8080}, query=[]}}}], mesosTask=MesosTaskObject{taskId=SingularityMesosIdObject{value='test-request-firstDeployId-1513812234159-3-host1-rack1'}, executor=Optional.of(MesosExecutorInfo{executorId=Optional.of(SingularityMesosIdObject{value='executorID'}), allOtherFields={resources=[]}}), labels=null, agentId=SingularityMesosIdObject{value='slave1'}, slaveId=SingularityMesosIdObject{value='slave1'}, resources=[], name='name', allOtherFields={}}, rackId=Optional.of(rack1)}, aborting
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@60f17aee rejected from java.util.concurrent.ScheduledThreadPoolExecutor@34d8fbc1[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 1]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2047)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:823)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.enqueueCheckWithDelay(SingularityNewTaskChecker.java:242)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheck(SingularityNewTaskChecker.java:236)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.reEnqueueCheckOrAbort(SingularityNewTaskChecker.java:227)
	at com.hubspot.singularity.scheduler.SingularityNewTaskChecker.lambda$getTaskCheck$0(SingularityNewTaskChecker.java:220)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
23:25:55.738 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
23:25:58.092 [Time-limited test] WARN com.hubspot.singularity.data.zkmigrations.PendingRequestDataMigration - Starting migration to re-write pending request paths
Tests run: 75, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 139.994 sec - in com.hubspot.singularity.scheduler.SingularitySchedulerTest

Results :

Failed tests: 
  SingularitySlavePlacementTest.testEvenRackPlacement:275 expected:<4> but was:<7>
Tests in error: 
  StateManagerTest>SingularityCuratorTestBase.curatorSetup:37 Â» TestTimedOut tes...
  ValidatorTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut test t...
  ZkMigrationTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut test...
  SingularityExpiringActionsTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityHealthchecksTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularityMachineStatesTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut
  SingularitySlavePlacementTest>SingularityCuratorTestBase.curatorSetup:36 Â» TestTimedOut

Tests run: 256, Failures: 1, Errors: 7, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Singularity ........................................ SUCCESS [  3.368 s]
[INFO] SingularityBase .................................... SUCCESS [  5.629 s]
[INFO] SingularityUI ...................................... SUCCESS [02:56 min]
[INFO] SingularityMesosClient ............................. SUCCESS [  2.812 s]
[INFO] SingularitySwagger ................................. SUCCESS [  1.489 s]
[INFO] SingularityService ................................. FAILURE [03:28 min]
[INFO] SingularityRunnerBase .............................. SKIPPED
[INFO] SingularityS3Base .................................. SKIPPED
[INFO] SingularityClient .................................. SKIPPED
[INFO] SingularityExecutor ................................ SKIPPED
[INFO] SingularityExecutorCleanup ......................... SKIPPED
[INFO] SingularityS3Uploader .............................. SKIPPED
[INFO] SingularityS3Downloader ............................ SKIPPED
[INFO] EmbedSingularityExample ............................ SKIPPED
[INFO] SingularityServiceIntegrationTests ................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 06:40 min
[INFO] Finished at: 2017-12-21T00:25:58+01:00
[INFO] Final Memory: 165M/2009M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.19:test (default-test) on project SingularityService: There are test failures.
[ERROR] 
[ERROR] Please refer to /root/workspace/HubSpot/Singularity/319411833/SingularityService/target/surefire-reports for the individual test results.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :SingularityService
