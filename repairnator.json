{
  "totalNumberSkippingTests": 0,
  "bugType": "only_fail",
  "totalNumberErroringTests": 12,
  "repo": "apache/storm",
  "failingModule": "/root/workspace/apache/storm/232796019/external/storm-hdfs",
  "hostname": "repairnator",
  "totalNumberFailingTests": 2,
  "error-types": [
    "java.lang.AssertionError",
    "java.lang.NoClassDefFoundError",
    "org.apache.hadoop.ipc.RemoteException"
  ],
  "totalNumberRunningTests": 358,
  "failing-test-cases": [
    {
      "className": "org.apache.storm.hdfs.blobstore.BlobStoreTest",
      "failingMethods": [],
      "erroringMethods": [
        "org.apache.storm.hdfs.blobstore.BlobStoreTest#testHdfsReplication",
        "org.apache.storm.hdfs.blobstore.BlobStoreTest#testHdfsWithAuth",
        "org.apache.storm.hdfs.blobstore.BlobStoreTest#testMultipleHdfs",
        "org.apache.storm.hdfs.blobstore.BlobStoreTest#testBasicHdfs"
      ],
      "failures": [
        {
          "failureName": "java.lang.NoClassDefFoundError",
          "failureDetail": "org/apache/storm/thrift/TBase",
          "isError": true
        },
        {
          "failureName": "java.lang.NoClassDefFoundError",
          "failureDetail": "org/apache/storm/thrift/TBase",
          "isError": true
        },
        {
          "failureName": "java.lang.NoClassDefFoundError",
          "failureDetail": "org/apache/storm/thrift/TBase",
          "isError": true
        },
        {
          "failureName": "java.lang.NoClassDefFoundError",
          "failureDetail": "org/apache/storm/thrift/TBase",
          "isError": true
        }
      ],
      "nbFailures": 0,
      "nbErrors": 4
    },
    {
      "className": "org.apache.storm.hdfs.spout.TestFileLock",
      "failingMethods": [],
      "erroringMethods": [
        "org.apache.storm.hdfs.spout.TestFileLock#testStaleLockDetection_MultipleLocks",
        "org.apache.storm.hdfs.spout.TestFileLock#testLockRecovery",
        "org.apache.storm.hdfs.spout.TestFileLock#testHeartbeat"
      ],
      "failures": [
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/locskdir/file3 could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/locskdir/file1 could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/locskdir/file1 could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        }
      ],
      "nbFailures": 0,
      "nbErrors": 3
    },
    {
      "className": "org.apache.storm.hdfs.spout.TestHdfsSpout",
      "failingMethods": [
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testSimpleSequenceFile",
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testResumeAbandoned_Seq_NoAck"
      ],
      "erroringMethods": [
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testReadFailures",
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testLocking",
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testResumeAbandoned_Text_NoAck",
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testMultipleFileConsumption_Ack",
        "org.apache.storm.hdfs.spout.TestHdfsSpout#testSimpleText_noACK"
      ],
      "failures": [
        {
          "failureName": "java.lang.AssertionError",
          "failureDetail": "expected:\u003c10\u003e but was:\u003c0\u003e",
          "isError": false
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/junit3571870345478481437/hdfsspout/source/file1.txt could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/junit5653002873441364721/hdfsspout/source/file1.txt could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "java.lang.AssertionError",
          "failureDetail": "expected:\u003c2\u003e but was:\u003c0\u003e",
          "isError": false
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/junit3774061222145494423/hdfsspout/source/file1.txt could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/junit2168872029454153848/hdfsspout/source/file1.txt could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        },
        {
          "failureName": "org.apache.hadoop.ipc.RemoteException",
          "failureDetail": "File /tmp/junit9179995449552715618/hdfsspout/source/file1.txt could only be replicated to 0 nodes instead of minReplication (\u003d1).  There are 1 datanode(s) running and no node(s) are excluded in this operation.\n at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1562)\n at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3245)\n at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:663)\n at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)\n at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)\n at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)\n at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)\n at java.security.AccessController.doPrivileged(Native Method)\n at javax.security.auth.Subject.doAs(Subject.java:422)\n at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)\n at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)\n",
          "isError": true
        }
      ],
      "nbFailures": 2,
      "nbErrors": 5
    }
  ]
}