{
  "@type": "job",
  "@href": "/v3/job/331539202",
  "@representation": "standard",
  "@permissions": {
    "read": true,
    "delete_log": false,
    "debug": false,
    "cancel": false,
    "restart": false
  },
  "id": 331539202,
  "allow_failure": false,
  "number": "3443.1",
  "state": "passed",
  "started_at": "2018-01-21T20:03:15Z",
  "finished_at": "2018-01-21T20:39:19Z",
  "build": {
    "@type": "build",
    "@href": "/v3/build/331539201",
    "@representation": "minimal",
    "id": 331539201,
    "number": "3443",
    "state": "failed",
    "duration": 24527,
    "event_type": "push",
    "previous_state": "errored",
    "pull_request_title": null,
    "pull_request_number": null,
    "started_at": "2018-01-21T20:03:15Z",
    "finished_at": "2018-01-21T21:38:19Z",
    "private": false
  },
  "queue": "builds.gce",
  "repository": {
    "@type": "repository",
    "@href": "/v3/repo/2486180",
    "@representation": "minimal",
    "id": 2486180,
    "name": "flink",
    "slug": "zentol/flink"
  },
  "commit": {
    "@type": "commit",
    "@representation": "minimal",
    "id": 98496877,
    "sha": "e0f5ead7df74671d72ae46dd9e3a4de2dd326db3",
    "ref": "refs/heads/review5886",
    "message": "Various refactorings\n\nChangelog:\n\nGeneral:\n- rebase branch to current master\n- incremented version to 1.5-SNAPSHOT\n- fixed kafka-connector dependency declaration\n\t- set to provided\n\t- scala version set to scala.binary.version\n\t- flink version set to project.version\n- applied checkstyle\n\t- disabled method/parameter name rules for API classes\n- assigned flink-python-streaming to 'libraries' travis profile\n- copy streaming-python jar to /opt\n- change the name of the final jar to flink-streaming-python (previously flink-python)\n- replace maven-jar-plugin with maven-shade-plugin\n\nAPI:\n- PDS#map()/flat_map() now return PythonSingleOutputStreamOperator\n- renamed PDS#print() to PDS#output()\n\t- print is a keyword in python and thus not usable in native python APIs\n- added PythonSingleOutputStreamOperator#name()\n- removed env#execute methods that accepted local execution argument as they are redundant due to environment factory methods\n- narrow visibility of *DataStream constructors\n\nMoved/Renamed:\n- made SerializerMap top-level class and renamed it to AdapterMap\n- Moved UtilityFunctions#adapt to AdapterMap class\n- renamed UtilityFunctions to InterpreterUtils\n- moved PythonobjectInputStream2 to SerializationUtils\n- renamed PythonObjectInputStream2 to SerialVersionOverridingPythonObjectInputStream\n\nJython:\n- renamed InterpreterUtils#smartFunctionDeserialization to deserializeFunction\n- added generic return type to #deserializeFunction\n- #deserializeFunction uses static initialization flag to detect whether it has to load jython instead of waiting for exception to happen\n- removed file cleanup in #initAndExecPythonScript as it is the binders' responsibility\n\nConnectors:\n- replaced usage of deprecated serialiation schema interfaces\n- P(S/D)Schema#(de)serialize now fails with RuntimeException if schema deserialization fails\n\nFunctions:\n- Introduced AbstractPythonUDF class for sharing RichRunction#open()/close() implementations\n- PythonOutputSelector now throws FlinkRuntimeException when failing during initialization\n- added generic return type to Serializationutils#deserializeObject\n- added new serializers for PyBoolean/-Float/-Integer/-Long/-String\n- PyObjectSerializer not properly fails when an exceptioin occurs\n- improved error printing\n\n- PythonCollector now typed to Object and properly converts non-PyObjects\n- jython functions that use a collector now have Object has output type\n\t- otherwise you would get ClassCastException if jython returns something that isn't a PyObject\n\nPythonStreamBinder\n- adjusted to follow PythonPlanBinder structure\n- client-like main() exception handling\n- replaced Random usage with UUID.randomUIID()\n- now loads GlobalConfiguration\n- local/distributed tmp dir now configurable\n\t- introduced PythonOptions\n- no longer generate plan.py but instead import it directly via the PythonInterpreter\n\nEnvironment:\n- Reworked static environment factory methods from PythonStreamExecutionEnvironment into a PythonEnvironmentFactory\n- program main() method now accepts a PythonEnvironmentFactory\n- directories are now passed properly to the environment instead of using static fields\n- removed PythonEnvironmentConfig\n. #registerJythonSerializers now static\n\nExamples:\n- move examples to flink-streaming-python\n- change examples location in dist to examples/python/streaming\n- replace ParameterTool usage with argparse\n- pass arguments via run instead of constructor\n- remove 'if __name__ == '__main__':' block\n- remove exception wrapping around source/sink creation\n- add WordCount example\n\nTests:\n- removed 'if __name__ == '__main__':' blocks from tests since the condition is never fulfilled\n- removed python TestBase class\n- removed print statements from tests\n- standardized test job names\n- cleaned up PythonStreamBinderTest / made it more consistent with PythonPlanBinderTest\n- run_all_tests improvements\n\t- stop after first failure\n\t- print stacktrace on failure\n\t- no longer relies on dirname() to get cwd but uses the module file location instead\n- added log4j properties file\n- added end-to-end test",
    "compare_url": "https://github.com/zentol/flink/compare/c39575ab4d3a...e0f5ead7df74",
    "committed_at": "2018-01-21T19:26:07Z"
  },
  "owner": {
    "@type": "user",
    "@href": "/v3/user/77507",
    "@representation": "minimal",
    "id": 77507,
    "login": "zentol"
  },
  "stage": null,
  "created_at": "2018-01-21T19:26:26.827Z",
  "updated_at": "2018-06-03T23:25:06.467Z",
  "private": false
}